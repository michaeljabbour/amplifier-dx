AMPLIFIER DOCUMENTATION
========================

Amplifier is the ultra-thin kernel for modular AI agents from Microsoft.
This context contains the complete documentation for building AI agent systems.


============================================================
SECTION: HOME
============================================================

Open Source Â· Microsoft Â· MIT License
 
# Amplifier

The ultra-thin kernel for modular AI agents

 Build AI agent systems with Linux-kernel philosophy: a tiny, stable center (~2,600 lines)
 that provides mechanisms, while policies live as swappable modules at the edges.

 Get started
 Official Docs
 GitHub

 Use it
 
Run AI agents with pre-built providers and tools. Configure via profiles.

 Extend it
 
Write custom tools in 2 minutes. Duck typing, no inheritance.

 Embed it
 
Drop the kernel into your app. Full programmatic control.

## Developer quickstart

Make your first agent request in minutes.

 bash
 Copy

`# Install
uv tool install git+https://github.com/microsoft/amplifier@main

# Update and initialize
amplifier update
amplifier init

# Run
amplifier run "List all Python files in this directory"`
```

## Start building

 â–¶
 
 Use existing modules
 Configure profiles and run agents

 +
 
 Write a custom tool
 Extend agent capabilities

 { }
 
 Embed in your app
 Programmatic session control

 â—ˆ
 
 Hooks & events
 Observe and control execution

============================================================
SECTION: QUICKSTART
============================================================

# Quickstart

Choose your path. Each guide gets you productive in minutes.

 ðŸ“š Getting Started Guide
 
For the complete getting started experience including provider setup, see the official installation guide.

 Use a profile
 Write a tool
 Embed in app

Run AI agents using pre-built modules and profiles.

### 1. Install

 bash
 Copy

`uv tool install git+https://github.com/microsoft/amplifier@main`
```

### 2. Update and Initialize

 bash
 Copy

`amplifier update
amplifier init`
```

### 3. Run

 bash
 Copy

`# Interactive
amplifier

# Single command
amplifier run "Explain this codebase"

# With profile
amplifier run --profile dev "Review for security issues"`
```

### 4. Customize your profile

 yaml
 Copy

`# ~/.amplifier/profiles/my-profile.yaml
name: my-profile
session:
 orchestrator: loop-streaming
 context: context-persistent
providers:
 - module: provider-anthropic
 config:
 model: claude-sonnet-4-20250514
tools:
 - module: tool-filesystem
 - module: tool-bash`
```

### Troubleshooting

 bash
 Copy

`# Reset profile to defaults
amplifier profile reset

# Clear module cache (fixes stale module issues)
rm -rf ~/.amplifier/module-cache

# Reinstall from scratch
uv tool install git+https://github.com/microsoft/amplifier@main
amplifier update`
```

Write a custom tool in under 2 minutes using duck typing.

### 1. Implement the Tool protocol

 python
 Copy

`from amplifier_core.models import ToolResult

class WeatherTool:
 @property
 def name(self) -> str:
 return "weather"

 @property
 def description(self) -> str:
 return "Get current weather for a city"

 @property
 def input_schema(self) -> dict:
 """JSON Schema for input validation (RECOMMENDED)."""
 return {
 "type": "object",
 "properties": {
 "city": {"type": "string", "description": "City name"}
 },
 "required": ["city"]
 }

 async def execute(self, input: dict) -> ToolResult:
 # input["city"] is GUARANTEED to exist if we get here
 city = input["city"]
 return ToolResult(output=f"Weather in {city}: 72Â°F, Sunny")`
```

 Why input_schema matters
 
The Kernel validates inputs against `input_schema` before calling `execute()`. Without it, truncated LLM output may pass through. With it, missing required arguments are caught early with clear errors.

### 2. Add mount function

 python
 Copy

`async def mount(coordinator, config):
 await coordinator.mount("tools", WeatherTool(), name="weather")
 return lambda: None # cleanup`
```

### 3. Register entry point

 toml
 Copy

`# pyproject.toml
[project.entry-points."amplifier.modules"]
weather-tool = "my_package.weather:mount"`
```

### 4. Install and use

 bash
 Copy

`pip install -e .
amplifier run "What's the weather in Seattle?"`
```

 Tool Protocol

 | `name` | property â†’ str
 
 | `description` | property â†’ str
 
 | `execute(input)` | async â†’ ToolResult

Embed Amplifier in your application with full programmatic control.

### 1. Define mount plan

 python
 Copy

`from amplifier_core import AmplifierSession

async def run_agent(prompt: str) -> str:
 config = {
 "session": {
 "orchestrator": "loop-basic",
 "context": "context-simple"
 },
 "providers": [{"module": "provider-anthropic"}],
 "tools": [{"module": "tool-filesystem"}, {"module": "tool-bash"}],
 "hooks": [{"module": "hooks-logging"}]
 }

 async with AmplifierSession(config) as session:
 return await session.execute(prompt)`
```

### 2. Add custom hooks

 python
 Copy

`from amplifier_core.models import HookResult

async def audit_hook(event: str, data: dict) -> HookResult:
 if event == "tool:pre":
 print(f"Executing: {data['tool_name']}")
 return HookResult(action="continue")

config["hooks"].append({"handler": audit_hook, "events": ["tool:*"]})`
```

### 3. Session persistence with ID

 python
 Copy

`# Create session with explicit ID for persistence
session = AmplifierSession(config, session_id="user-123-session")
await session.initialize()

# Load conversation history
context = session.coordinator.get("context")
for msg in historical_messages:
 await context.add_message(msg)

# Continue conversation
response = await session.execute(prompt)`
```

### 4. Fork sessions for parallel work

 python
 Copy

`async with AmplifierSession(config) as parent:
 child1 = await parent.fork()
 child2 = await parent.fork()

 results = await asyncio.gather(
 child1.execute("Analyze backend"),
 child2.execute("Review frontend")
 )`
```

 Reference Implementation
 
See amplifierd for a complete HTTP/SSE API built on amplifier-core.

============================================================
SECTION: ARCHITECTURE
============================================================

# Architecture

Design philosophy: kernel, not framework. Mechanism over policy.

 ðŸ“š Complete Architecture Documentation
 
For in-depth architectural guides, see the official architecture documentation.

## The Four Tenets

### 1. Mechanism, Not Policy

The kernel provides capabilities and stable contracts. Behavioral decisions live outside the kernel. If teams could want different behavior, it belongs in modules.

### 2. Small, Stable, Boring

~2,600 lines of intentionally minimal code. Fewer changes = fewer breaking changes. Prioritizes auditability and predictability over clever implementations.

### 3. Don't Break Modules

Kernel interfaces follow sacred backward compatibility. Additive evolution only, with clear deprecation paths and extended sunset periods.

### 4. Extensibility via Composition

New capabilities come from combining modules, not accumulating kernel configuration flags. Avoids "configuration explosion" by pushing policy to the edges.

## The Linux Kernel Analogy

Amplifier mirrors Linux kernel concepts:

 | 
 
 | Linux Concept | Amplifier Analog | Purpose

 | Ring 0 kernel | `amplifier-core` | Mechanisms only, never policy
 
 | Syscalls | Session operations | Few, sharp APIs
 
 | Loadable drivers | Modules | Compete at edges
 
 | Signals/Netlink | Event bus / hooks | Observe and control
 
 | /proc & dmesg | JSONL logs | Single canonical stream
 
 | Capabilities | Approval system | Deny-by-default
 
 | Scheduler | Orchestrator modules | Swap execution strategies
 
 | VM/Memory | Context manager | Conversation memory

 System Stack
 Event Flow
 The Litmus Test

 DX Layer
 amplifier-app-cli
 
 CLI, scaffolding, dev mode, inspector
 
 â†“

 Helpers
 amplifier-helpers
 
 @tool decorator, testing utilities
 
 â†“

 Kernel
 amplifier-core
 
 Session, Coordinator, Protocols, Events

 ðŸ“¥
 
 Prompt Submitted
 User sends a prompt to the session
 
 session:start
 
 â†“
 
 ðŸ¤–
 
 Provider Request
 LLM generates response with tool calls
 
 provider:request
 
 â†“
 
 ðŸ”§
 
 Tool Execution
 Tools run with hook observation
 
 tool:pre â†’ tool:post
 
 â†“
 
 âœ…
 
 Response Complete
 Final answer returned to user
 
 session:end

 "Could two teams want different behavior?"

 No
 Universal requirement

 Yes
 Team preference

### It belongs in the Kernel

Mechanisms that everyone needs (e.g., Session management, Event emission).

### It belongs in a Module

Policies that vary by team (e.g., "Allow sudo?", "Which LLM to use?").

## Core concepts

### Coordinator

Infrastructure context injected into all modules.

- `session_id` â€” Unique identifier
 
- `config` â€” Session configuration
 
- `mount()` â€” Register module
 
- `emit()` â€” Fire events

### Mount Plan

Configuration specifying which modules to load.

`{
 "session": {"orchestrator": "loop-basic"},
 "providers": [{"module": "provider-anthropic"}],
 "tools": [{"module": "tool-filesystem"}]
}`
```

### Session Lifecycle

- Load modules from mount plan
 
- Call `mount()` on each
 
- Execute prompts via orchestrator
 
- Cleanup on session end

### Event System

30+ hookable events covering the agent lifecycle.

 session:*
 provider:*
 tool:*
 context:*

## Module Distribution Architecture

Understanding how modules are distributed and resolved is critical for building applications with amplifier-core.

 Key Insight
 
Only providers are distributed via Python entry points. Orchestrators and contexts use local implementations or the module cache.

### Two-Tier Module System

 | 
 
 | Distribution Method | Module Types | Location | Resolution

 | Entry Points
 | Providers (`provider-*`)
 | Python package metadata
 | `importlib.metadata`

 | Module Cache
 | Orchestrators, Contexts, Tools, Hooks
 | `~/.amplifier/module-cache/`
 | `amplifier_module_resolution`

 | Local Implementations
 | Any module type
 | Application code
 | Custom `ModuleLoader`

### Entry Points (`amplifier.modules`)

Provider modules bundled with the amplifier package are registered via Python entry points:

`# List available entry point modules
amplifier module list

# Output shows only providers:
# provider-anthropic, provider-openai, provider-google, provider-xai...`
```

### Module Cache

Git-based modules (orchestrators, tools, hooks) are cloned to the module cache:

`# Cache location
~/.amplifier/module-cache/

# Structure (hashed directories)
module-cache/
 â”œâ”€â”€ abc123.../ # loop-streaming
 â”œâ”€â”€ def456.../ # context-persistent
 â””â”€â”€ ghi789.../ # tool-filesystem`
```

Accessing cached modules requires the `amplifier_module_resolution` package, which handles path resolution and version management.

### Module Loading Priority

When loading a module, the system checks sources in this order:

- Local implementations â€” Custom loader's local module map
 
- Entry points â€” Python package metadata (`amplifier.modules`)
 
- Module cache â€” If `amplifier_module_resolution` is available

## External App Integration Guide

Building applications with amplifier-core follows the kernel design principle: your app provides policy, amplifier provides mechanism.

 Reference Implementation
 
The `amp` CLI (`amplifier-app-cli`) demonstrates the canonical integration pattern.

### Architecture Overview

The following diagram shows how external applications integrate with amplifier-core:

- 

- 

- 

- 

 Amplifier External App Architecture

 Your App UI
 web - desktop - service

- 
 session.execute("prompt")

 AmplifierSession
 amplifier-core kernel - config (mount plan)
 
 creates

 Coordinator
 session_id - mount_points - get() - emit()
 infrastructure for module access and events

 ModuleLoader
 entry points - filesystem - source resolver
 loader.load(id) - mount_fn(coordinator)

 uses
 Mount Plan defines all modules

 loads all modules at init time

 Orchestrator
 loop-*
 
- 
 DRIVES EXECUTION
 - plan - act - refine loop
 - calls providers
 - executes tools
 - returns to user

 Context
 context-*
 conversation
 memory / history
 add - get - compact

 Providers
 provider-*
 Anthropic - OpenAI
 Gemini - Local
 complete() - list_models()

 Tools
 tool-*
 filesystem - bash
 web - task - custom
 execute(input)

 Hooks
 hooks-*
 logging - approval
 redaction - tracking
 observe - modify

- 
 
- 
 
- 

- 
 
- 
 
- 
 
- 

 Orchestrator drives execution via coordinator.get()

 returns result

 Policy Layer
 (You own these)
 
 ModuleLoader
 
 ApprovalSystem
 
 DisplaySystem
 
 SourceResolver

 Execution Flow
 1. App calls session.execute(prompt)
 2. Session calls orchestrator.execute()
 3. Orchestrator takes control:
 - builds messages from context
 - calls provider.complete()
 - executes tools - emits hooks

 Legend
 
 Core / Session
 
 Loader
 
 Orchestrator (driver)
 
- 
 Load path (init)
 
- 
 Execution (orchestrator drives)
 
- 
 Return to app

 Orchestrator Owns the Transaction
 - Loaded as a module (like others)
 - But once execute() is called...
 - It decides: loops, exits, displays
 - Other modules serve the orchestrator

### Required Components

External applications must provide three policy components:

### 1. ModuleLoader

Custom loader to resolve modules from your preferred sources.

`from amplifier_core import ModuleLoader

class LocalLoader(ModuleLoader):
 # Always use local for orchestrators/contexts
 ALWAYS_LOCAL = ("loop-", "context-")

 async def load(self, module_id, config=None, profile_source=None):
 if any(module_id.startswith(p) for p in self.ALWAYS_LOCAL):
 return self.local_modules[module_id]
 # Fall back to entry points for providers
 return await super().load(module_id, config, profile_source)`
```

### 2. ApprovalSystem

UI/UX for user consent on tool execution.

`from amplifier_core import ApprovalCallback

class MyApprovalSystem:
 async def request(self, tool_name: str, input: dict) -> bool:
 # Show UI dialog, return True to approve
 return await show_approval_dialog(tool_name, input)`
```

### 3. DisplaySystem

Rendering for messages, tool calls, and streaming.

`class MyDisplaySystem:
 async def show_message(self, role: str, content: list):
 # Render message to your UI
 pass

 async def show_tool_call(self, name: str, input: dict, result: str):
 # Render tool execution
 pass`
```

### Creating an AmplifierSession

`from amplifier_core import AmplifierSession, SessionConfig

# Create session with your policy components
config = SessionConfig(
 orchestrator="loop-streaming",
 providers=[{"module": "provider-anthropic", "model": "claude-sonnet-4-20250514"}],
 tools=[{"module": "tool-filesystem"}, {"module": "tool-bash"}],
 context="context-simple",
)

session = AmplifierSession(
 config,
 loader=LocalLoader(), # Your custom module loader
 approval_system=MyApprovalSystem(), # Your approval UI
 display_system=MyDisplaySystem(), # Your message renderer
)

# Run a prompt
result = await session.run("What files are in this directory?")`
```

### Production Configuration

When deploying agents for code generation or complex tasks, configure providers defensively:

 Critical: Token Limits
 
The default `max_tokens` (4096) is insufficient for code generation. When the model hits this limit mid-stream, it truncates output producing incomplete JSON tool calls.

 | 
 
 | Setting | Default | Recommended | Why

 | `max_tokens`
 | 4096
 | 8192+
 | Prevents truncated tool calls during code generation

 | `temperature`
 | 1.0
 | 0.5-0.7
 | More consistent tool use and JSON structure

 | `timeout`
 | 60s
 | 120s
 | Long operations need time to complete

 python
 Copy

`# Production configuration for coding agents
config = {
 "session": {
 "orchestrator": "loop-streaming",
 "context": "context-persistent"
 },
 "providers": [{
 "module": "provider-anthropic",
 "config": {
 "model": "claude-sonnet-4-20250514",
 "max_tokens": 8192, # CRITICAL for code generation
 "temperature": 0.7, # More consistent tool calls
 }
 }],
 "tools": [
 {"module": "tool-filesystem"},
 {"module": "tool-bash"}
 ]
}`
```

### Hook Events for Streaming UI

Subscribe to hook events for real-time UI updates:

 | 
 
 | Event | Description | Payload

 | `content_block:start` | Text block begins | `{index, type}`
 
 | `content_block:delta` | Streaming text chunk | `{index, delta}`
 
 | `content_block:end` | Text block complete | `{index}`
 
 | `thinking:delta` | Extended thinking chunk | `{delta}`
 
 | `thinking:final` | Thinking complete | `{content}`
 
 | `tool:pre` | Before tool execution | `{tool, input, call_id}`
 
 | `tool:post` | After tool execution | `{tool, input, result, call_id}`
 
 | `provider:request` | LLM API call starts | `{messages}`
 
 | `provider:response` | LLM API call ends | `{response}`

### Desktop vs Core Mode Pattern

Applications can offer dual modes for provider loading:

### Desktop Mode (Default)

All modules use local implementations bundled with your app.

- Faster startup (no entry point resolution)
 
- Consistent behavior across environments
 
- Self-contained distribution

### Core Mode

Providers load from amplifier-core entry points.

- Use latest provider implementations
 
- Benefit from upstream bug fixes
 
- Only affects providers (orchestrators/contexts stay local)

 Important
 
In Core mode, orchestrators (`loop-*`) and contexts (`context-*`) should always use local implementations. Only providers benefit from entry point loading.

## Troubleshooting Common Errors

Common issues when integrating with amplifier-core and their solutions:

### `Missing required arguments: ['content']`

Cause: Token limit hit mid-generation, truncating JSON output.

Fix: Increase `max_tokens` in provider config to 8192+.

`"providers": [{
 "module": "provider-anthropic",
 "config": {"max_tokens": 8192}
}]`
```

### `tool_use.name: String should have at least 1 character`

Cause: LLM generated empty tool name (hallucination).

Fix: Add sanitization layer in your provider integration:

`# Sanitize empty tool names before API call
if not tool_call.get("name") or not tool_call["name"].strip():
 tool_call["name"] = "unknown_tool"
 logger.warning(f"Fixed empty tool name")`
```

### `ToolCallBlock has invalid name`

Cause: Same as above - LLM returned malformed tool call.

Fix: Validate tool calls before execution and add a sanitization hook.

### `'tuple' object has no attribute 'get'`

Cause: Patch/modification applied to incompatible module type (cached vs local).

Fix: Check module implementation matches expected interface. Clear module cache:

`rm -rf ~/.amplifier/module-cache`
```

### Reset Commands

 bash
 Copy

`# Reset profile to defaults
amplifier profile reset

# Clear module cache (fixes stale module issues)
rm -rf ~/.amplifier/module-cache

# Reinstall from scratch
uv tool install git+https://github.com/microsoft/amplifier@main
amplifier update`
```

### LLM Edge Case Handling

LLMs can generate invalid tool calls. Your integration should sanitize these defensively:

 python
 Copy

`def sanitize_tool_calls(tool_calls: list) -> list:
 """Clean up malformed LLM tool calls before execution."""
 sanitized = []
 for tc in tool_calls:
 # Fix empty names
 name = tc.get("name", "").strip()
 if not name:
 name = "unknown_tool"
 logger.warning(f"Fixed empty tool name for id={tc.get('id')}")

 # Ensure arguments is a dict
 args = tc.get("arguments") or tc.get("input") or {}
 if isinstance(args, str):
 try:
 args = json.loads(args)
 except json.JSONDecodeError:
 args = {"raw": args}

 sanitized.append({
 "id": tc.get("id"),
 "name": name,
 "arguments": args
 })
 return sanitized`
```

============================================================
SECTION: API REFERENCE
============================================================

# API Reference

Complete documentation for module developers.

 ðŸ“š Complete API Reference
 
For the full API documentation including all contracts and interfaces, see the official Developer Guide.

 Contracts
 Hooks API
 Events
 Profiles
 Sessions
 Agents

All modules use Python Protocols (structural typing). No inheritance required.

#### Provider LLM Backend

 `name: str`
 `get_info() â†’ ProviderInfo`
 `list_models() â†’ list[ModelInfo]`
 `complete(ChatRequest) â†’ ChatResponse`
 `parse_tool_calls(ChatResponse) â†’ list`

#### Tool Agent Capability

 `name: str`
 `description: str`
 `input_schema: dict` (recommended)
 `execute(input: dict) â†’ ToolResult`

#### Orchestrator Execution Loop

 `execute(prompt, context, providers, tools, hooks) â†’ str`

#### ContextManager Memory

 `add_message(message)`
 `get_messages() â†’ list`
 `should_compact() â†’ bool`
 `compact()`
 `clear()`

#### Hook Observability

 `async handler(event: str, data: dict) â†’ HookResult`

Hooks observe events and optionally modify behavior via HookResult.

 python
 Copy

`async def my_hook(event: str, data: dict) -> HookResult:
 if event == "tool:pre" and "rm -rf" in str(data.get("tool_input")):
 return HookResult(action="deny", reason="Blocked")
 return HookResult(action="continue")`
```

### HookResult Actions

 `continue`
 Proceed normally (default)

 `deny`
 Block with reason

 `modify`
 Alter event data

 `inject_context`
 Add message to context

 `ask_user`
 Pause for approval

30+ hookable events covering the entire agent lifecycle. Events are logged as JSONL for debugging and observability.

### Session Lifecycle

 | 
 | Event | When | Data

 | `session:start` | Session initialized | session_id, mount_plan
 
 | `session:end` | Session cleanup | session_id, duration
 
 | `session:fork` | Sub-session created | parent_id, child_id
 
 | `session:resume` | Session resumed | session_id

### Prompt Lifecycle

 | 
 | Event | When | Data

 | `prompt:submit` | User prompt received | prompt, session_id
 
 | `prompt:complete` | Response generated | response, duration

### Provider Events

 | 
 | Event | When | Data

 | `provider:request` | Before LLM call | messages, model
 
 | `provider:response` | After LLM response | response, usage
 
 | `provider:error` | LLM call failed | error, model

### Tool Events

 | 
 | Event | When | Data

 | `tool:pre` | Before tool execution | tool_name, input
 
 | `tool:post` | After tool execution | tool_name, result
 
 | `tool:error` | Tool execution failed | tool_name, error

### Context Events

 | 
 | Event | When | Data

 | `context:pre_compact` | Before compaction | message_count, tokens
 
 | `context:post_compact` | After compaction | message_count, tokens
 
 | `context:include` | Context injected | source, content

### Approval & Streaming Events

 | 
 | Event | When | Data

 | `approval:required` | Approval requested | operation, prompt
 
 | `approval:granted` | User approved | operation
 
 | `approval:denied` | User denied | operation, reason
 
 | `content_block:start` | Streaming starts | block_type
 
 | `content_block:delta` | Content chunk | delta
 
 | `content_block:end` | Streaming ends | block_type

### Event Log Format (JSONL)

 json
 Copy

`{
 "ts": "2024-01-15T10:30:00.123Z",
 "session_id": "abc123",
 "event": "tool:pre",
 "component": "orchestrator",
 "module": "tool-bash",
 "data": {"tool_name": "bash", "input": {"command": "ls"}}
}`
```

### Finding Logs

 bash
 Copy

`# Session logs location
ls ~/.amplifier/projects/<project>/sessions/<session-id>/events.jsonl

# Search for tool errors
grep '"event":"tool:error"' events.jsonl

# Pretty print with jq
cat events.jsonl | jq 'select(.event == "provider:request")'`
```

Profiles are pre-configured capability sets defining which modules are accessible during a session.

### Built-in Profiles

 | 
 
 | Profile | Purpose | Best For

 | `foundation` | Minimal LLM access only | Basic chat interactions
 
 | `base` | Filesystem and bash capabilities | Light development tasks
 
 | `dev` | Complete development tools | Daily development work
 
 | `test` | Testing-focused configuration | Running tests, debugging
 
 | `full` | All available features enabled | Exploring system capabilities

### Profile Commands

 bash
 Copy

`amplifier profile list # View all profiles
amplifier profile use dev # Set as default
amplifier profile show dev # Display configuration
amplifier profile current # Check active profile
amplifier run --profile dev "..." # Single command usage`
```

### Custom Profile Structure

Profiles use markdown with YAML frontmatter. Store in `.amplifier/profiles/` (project) or `~/.amplifier/profiles/` (user).

 yaml
 Copy

`---
name: my-profile
extends: base
description: Custom development profile
session:
 orchestrator: loop-streaming
 context: context-persistent
providers:
 - module: provider-anthropic
 config:
 default_model: claude-opus-4-1
tools:
 - module: tool-filesystem
 - module: tool-bash
 config:
 timeout: 60
hooks:
 - module: hooks-logging
agents:
 code-reviewer:
 description: Expert code reviewer
 tools:
 - tool-filesystem
---

# System Instructions

You are an expert assistant...`
```

### Profile Inheritance

Profiles inherit in a linear chain. Each level accumulates capabilities:

 `foundation` â†’ `base` â†’ `dev` â†’ `custom`

Sessions track conversations, preserving history, tool results, and metadata for resumption.

### Session Commands

 bash
 Copy

`# Starting & Listing
amplifier run "prompt" # Create new session
amplifier session list # Display all sessions
amplifier session show [id] # View session details

# Resuming
amplifier continue "follow-up" # Resume most recent
amplifier session resume [id] # Resume specific session
amplifier run --resume [id] "prompt"

# Management
amplifier session delete [id] # Remove a session
amplifier session cleanup --days 7 # Delete old sessions`
```

### Storage Structure

Sessions persist at `~/.amplifier/projects/<project-slug>/sessions/<session-id>/`

 | 
 
 | File | Contents

 | `transcript.jsonl` | Conversation history
 
 | `events.jsonl` | Complete event log
 
 | `metadata.json` | Session metadata

### Session Lifecycle

 Creation â†’
 Active â†’
 Ended â†’
 Resumption

### Context Preservation

 Preserved: Conversation history, session ID, project context

 Reloaded: Current profile and provider configurations

 Not preserved: Tool execution state, in-memory context beyond token limits

Agents are specialized configurations functioning as sub-sessions for focused tasks.

### Built-in Agents

 | 
 
 | Agent | Purpose

 | `explorer` | Breadth-first codebase exploration
 
 | `bug-hunter` | Systematic debugging and issue identification
 
 | `zen-architect` | System design emphasizing simplicity
 
 | `researcher` | Research and information synthesis
 
 | `modular-builder` | Code implementation and creation

### Using Agents

 bash
 Copy

`# Interactive mode - use @ prefix
amplifier> @explorer What is the architecture of this project?
amplifier> @bug-hunter Find issues in the authentication module

# List and show agents
amplifier agents list
amplifier agents show explorer`
```

### How Agents Work

- Create sub-session inheriting base settings
 
- Apply agent-specific tools and instructions
 
- Execute the request
 
- Return results to main session

### Custom Agents

Define in profile's `agents` section or create standalone files in `.amplifier/agents/`

 yaml
 Copy

`agents:
 my-agent:
 description: Custom agent for specific task
 tools:
 - tool-filesystem
 - tool-bash
 system: |
 You are an expert at...`
```

### Agent Search Path

Agents load from: current profile â†’ `.amplifier/agents/` (project) â†’ `~/.amplifier/agents/` (user) â†’ installed collections â†’ bundled agents

============================================================
SECTION: CLI COMMANDS
============================================================

# CLI Reference

Complete reference for all Amplifier command-line commands.

 ðŸ“š Full CLI Documentation
 
For comprehensive CLI usage including profiles, agents, and sessions, see the official User Guide.

### Global Options

 | 
 | Option | Description

 | `--version` | Show version and exit
 
 | `--help` | Show help and exit
 
 | `--install-completion` | Install shell completion
 
 | `--show-completion` | Show shell completion script

### Running

 `amplifier`Interactive chat mode
 `amplifier run "prompt"`Single command execution
 `amplifier run --profile name`Run with specific profile
 `amplifier run -m model`Override model
 `amplifier run --max-tokens N`Max response tokens
 `amplifier run --output-format json`Output format (text/json/json-trace)
 `amplifier run --no-tools`Disable tool use
 `amplifier run --resume [id]`Resume session by ID
 `amplifier continue`Resume last session
 `amplifier continue "follow-up"`Resume with new prompt

### Sessions

 `amplifier session list`Display all sessions
 `amplifier session list --all`Show all sessions
 `amplifier session show [id]`View session details
 `amplifier session resume [id]`Resume specific session
 `amplifier session delete [id]`Remove a session
 `amplifier session cleanup --days 7`Delete old sessions

### Profiles

 `amplifier profile list`View all profiles
 `amplifier profile use dev`Set as default
 `amplifier profile show name`Display configuration
 `amplifier profile show --resolved`Show full resolved profile
 `amplifier profile current`Check active profile
 `amplifier profile default [name]`Show/set default profile
 `amplifier profile reset`Reset to defaults

### Providers

 `amplifier provider list`List available providers
 `amplifier provider use anthropic`Set default provider
 `amplifier provider current`Show current provider
 `amplifier provider reset`Reset to default provider

### Modules

 `amplifier module list`Display installed modules
 `amplifier module list --type tool`Filter by type
 `amplifier module show [name]`View module details
 `amplifier module add tool-web`Add a module
 `amplifier module add --source [url]`Add from source
 `amplifier module remove [name]`Remove a module
 `amplifier module check-updates`Check for updates
 `amplifier module refresh`Refresh cache

### Tools

 `amplifier tool list`List available tools
 `amplifier tool info [name]`Show tool details
 `amplifier tool invoke [name]`Test tool directly

### Agents

 `amplifier agents list`List available agents
 `amplifier agents show [name]`View agent details

### Collections

 `amplifier collection list`List installed collections
 `amplifier collection add [url]`Add from Git
 `amplifier collection show [name]`Show collection details
 `amplifier collection remove [name]`Remove collection
 `amplifier collection refresh`Refresh cache

### Sources (Dev)

 `amplifier source list`List source overrides
 `amplifier source add [name] [path]`Add local override
 `amplifier source remove [name]`Remove override
 `amplifier source show [name]`Show source details

### System

 `amplifier update`Update Amplifier
 `amplifier update --cli`Update CLI only
 `amplifier update --modules`Update modules only
 `amplifier init`Initialize configuration
 `amplifier --help`General help

### Interactive Commands

While in interactive mode, use these slash commands:

 `/help`Display available commands
 `/tools`List accessible tools
 `/agents`List available agents
 `/status`Show session information
 `/think`Enable planning mode
 `/clear`Clear conversation history
 `/quit`, `/exit`Exit the application

### Using Agents & Mentions

 bash
 Copy

`# Use agents with @ prefix
amplifier> @explorer Analyze this codebase
amplifier> @bug-hunter Find issues in main.py

# Reference files with @mentions
amplifier> Review @src/main.py for issues
amplifier> @project:context/standards.md Apply these standards
amplifier> @collection:foundation/context/philosophy.md`
```

### Output Formats

Use `--output-format` for automation:

 | 
 | Format | Description

 | `text` | Human-readable markdown (default)
 
 | `json` | Structured JSON for scripting
 
 | `json-trace` | Complete execution trace with tool calls

### Environment Variables

 | 
 | Variable | Description

 | `ANTHROPIC_API_KEY` | Anthropic API key
 
 | `OPENAI_API_KEY` | OpenAI API key
 
 | `AZURE_OPENAI_API_KEY` | Azure OpenAI API key
 
 | `AZURE_OPENAI_ENDPOINT` | Azure OpenAI endpoint
 
 | `AMPLIFIER_PROFILE` | Default profile
 
 | `AMPLIFIER_PROVIDER` | Default provider
 
 | `AMPLIFIER_DEBUG` | Enable debug logging

### Configuration Files

 | 
 | File | Scope | Purpose

 | `~/.amplifier/settings.yaml` | User | Global user settings
 
 | `.amplifier/settings.yaml` | Project | Project settings (committed)
 
 | `.amplifier/settings.local.yaml` | Local | Machine-local (gitignored)

 Tips

- Pipe input: `cat file.py | amplifier run "Explain"`
 
- JSON output for scripting: `amplifier run -o json "What is 2+2?"`
 
- Verbose output: `-v` or `--verbose`
 
- Use agents with @ prefix: `@explorer What is the architecture?`

============================================================
SECTION: ECOSYSTEM
============================================================

# Ecosystem

Available modules, libraries, and collections for extending Amplifier.

 ðŸ“š Complete Ecosystem Reference
 
For detailed information on all available modules including Providers, Tools, Orchestrators, Contexts, and Hooks, see the official Ecosystem documentation.

## Runtime Modules

Swappable components that implement Amplifier's core contracts.

### ðŸ¤– Providers 7

Connect to AI model providers

- `provider-anthropic` - Claude models
 
- `provider-openai` - GPT models
 
- `provider-gemini` - Gemini (1M context)
 
- `provider-azure` - Azure OpenAI
 
- `provider-ollama` - Local models
 
- `provider-vllm` - vLLM server
 
- `provider-mock` - Testing

### ðŸ”§ Tools 6

Extend agent capabilities

- `tool-filesystem` - Read/write files
 
- `tool-bash` - Shell commands
 
- `tool-web` - Web browsing
 
- `tool-search` - Code search
 
- `tool-task` - Task delegation
 
- `tool-todo` - Todo management

### ðŸ”„ Orchestrators 3

Control execution loops

- `loop-basic` - Simple request/response
 
- `loop-streaming` - Streaming responses
 
- `loop-event` - Event-driven execution

### ðŸ’¾ Contexts 2

Manage conversation state

- `context-simple` - In-memory storage
 
- `context-persistent` - Disk persistence

### âš¡ Hooks 9

Observe and control behavior

- `hooks-logging` - Event logging
 
- `hooks-approval` - User approval gates
 
- `hooks-redaction` - Sensitive data filtering
 
- `hooks-backup` - Session backup
 
- `hooks-streaming-ui` - Streaming display
 
- `hooks-scheduler` - Rate limiting
 
- + 3 more...

## Libraries

Consumed by applications (not runtime modules).

 | 
 
 | Library | Purpose | Repository

 | `amplifier-profiles` | Profile and agent loading with inheritance | GitHub
 
 | `amplifier-collections` | Collection discovery and management | GitHub
 
 | `amplifier-config` | Three-scope configuration management | GitHub
 
 | `amplifier-module-resolution` | Module source resolution | GitHub

## Collections

Shareable bundles of profiles, agents, and modules.

 Toolkit
 Essential development tools

 Design Intelligence
 Architecture and design agents

 Recipes
 Common patterns and workflows

 Issues
 Issue tracking integration

 Convergent Dev
 Ideation â†’ sprints â†’ TDD workflow

### Community Collections

 bash
 Copy

`# Install convergent-dev collection
amplifier collection add git+https://github.com/momuno/amplifier-collection-convergent-dev@main

# Activate the profile
amplifier profile use convergent-dev:convergent-dev`
```

 Module Architecture

- Runtime modules only depend on `amplifier-core`
 
- Libraries are consumed by applications, never by modules
 
- Use `amplifier module list` to see installed modules
 
- Use `amplifier module show [name]` for details

============================================================
SECTION: SHOWCASE
============================================================

# Showcase

Applications and modules built with Amplifier by the community.

âš ï¸ Security Notice: Community applications and modules execute arbitrary code with full system access. Only use from sources you trust. Review code before installation.

## Community Applications

 | 
 
 | Application | Description | Author

 | `app-transcribe`
 | Transform YouTube videos and audio files into searchable transcripts with AI-powered insights
 | @robotdad

 | `app-blog-creator`
 | AI-powered blog creation with style-aware generation and rich markdown editor
 | @robotdad

 | `app-voice`
 | Desktop voice assistant with native speech-to-speech via OpenAI Realtime API
 | @robotdad

 | `app-tool-generator`
 | AI-powered tool generator for creating custom Amplifier tools
 | @samueljklee

 | `app-benchmarks`
 | Benchmarking and evaluation suite for Amplifier
 | @DavidKoleczek

 | `app-log-viewer`
 | Web-based debugging interface with real-time LLM interaction visualization
 | @microsoft

 | `amplifier-lakehouse`
 | Data integration daemon and web application for Amplifier
 | @microsoft

 | `amplifier-playground`
 | Interactive environment for building, configuring, and testing Amplifier sessions
 | @microsoft

## Community Modules

### Providers

 | 
 
 | Module | Description | Author

 | `provider-bedrock`
 | AWS Bedrock integration with cross-region inference support for Claude models
 | @brycecutt-msft

 | `provider-openai-realtime`
 | OpenAI Realtime API for native speech-to-speech with ultra-low latency
 | @robotdad

### Tools

 | 
 
 | Module | Description | Author

 | `tool-mcp`
 | Model Context Protocol integration for MCP servers
 | @robotdad

 | `tool-skills`
 | Load domain knowledge with progressive disclosure
 | @robotdad

 | `tool-youtube-dl`
 | Download audio/video from YouTube with metadata extraction
 | @robotdad

 | `tool-whisper`
 | Speech-to-text transcription using OpenAI Whisper
 | @robotdad

 | `module-image-generation`
 | Multi-provider AI image generation (DALL-E, Imagen, GPT-Image-1)
 | @robotdad

 | `module-style-extraction`
 | Extract and apply writing styles from text samples
 | @robotdad

 | `module-markdown-utils`
 | Markdown parsing, injection, and metadata utilities
 | @robotdad

### Collections

 | 
 
 | Collection | Description | Author

 | `collection-ddd`
 | Document-Driven Development with 5 specialized workflow agents
 | @robotdad

 | `collection-spec-kit`
 | Specification-Driven Development with 8 agents and constitutional governance
 | @robotdad

 | `collection-convergent-dev`
 | Ideation â†’ sprints â†’ TDD workflow
 | @momuno

## Official Collections

 | 
 
 | Collection | Description | Repository

 | `toolkit`
 | Building sophisticated CLI tools using metacognitive recipes
 | GitHub

 | `design-intelligence`
 | Comprehensive design intelligence with specialized agents
 | GitHub

 | `recipes`
 | Multi-step AI agent orchestration for repeatable workflows
 | GitHub

 | `issues`
 | Issue management workflows
 | GitHub

## Submit Your Project

Built something with Amplifier? Share it with the community!

- Build your project - Follow Amplifier conventions
 
- Publish to GitHub - Make code publicly reviewable
 
- Test thoroughly - Ensure compatibility with current Amplifier versions
 
- Submit a PR - Add to the MODULES.md catalog

============================================================
SECTION: CODE EXAMPLES
============================================================

# Examples

Copy-paste patterns for common Amplifier use cases.

 âš¡ Hooks
 ðŸ”§ Tools
 âš™ï¸ Configuration
 ðŸ“– Recipes

### Approval Gate

 Copy

Require user approval before executing sensitive operations like shell commands.

`async def approval_gate(event, data) -> HookResult:
 """Pause for user approval on bash commands."""
 if event == "tool:pre" and data["tool_name"] == "bash":
 return HookResult(
 action="ask_user",
 approval_prompt=f"Allow bash: {data['tool_input']}?",
 approval_options=["Allow", "Deny"]
 )
 return HookResult(action="continue")`
```

 Usage
 
hooks:
 - handler: approval_gate
 events: ["tool:pre"]
```

### Security Guard

 Copy

Block dangerous shell commands before they execute. Returns deny action with reason.

`from amplifier_core.models import HookResult

async def security_hook(event: str, data: dict) -> HookResult:
 """Block dangerous bash commands."""
 if event == "tool:pre" and data.get("tool_name") == "bash":
 cmd = str(data.get("tool_input", {}))
 dangerous = ["rm -rf", "mkfs", "dd if=", "> /dev/"]

 for pattern in dangerous:
 if pattern in cmd:
 return HookResult(
 action="deny",
 reason=f"Blocked dangerous pattern: {pattern}"
 )

 return HookResult(action="continue")`
```

 Output
 
Action: deny
Reason: Blocked dangerous pattern: rm -rf
```

### Token Tracker

 Copy

Monitor and log token usage across all provider calls for cost tracking.

`async def track_tokens(event, data) -> HookResult:
 """Log token usage from provider responses."""
 if event == "provider:response":
 usage = data.get("usage", {})
 tokens = usage.get("total_tokens", 0)
 cost = tokens * 0.00001 # Example pricing
 print(f"Used {tokens} tokens (~\${cost:.4f})")
 return HookResult(action="continue")`
```

 Output
 
Used 1523 tokens (~$0.0152)
```

### PII Redaction

 Copy

Automatically detect and redact sensitive information from streamed responses.

`import re
from amplifier_core.models import HookResult

PATTERNS = {
 "email": r'[\w.-]+@[\w.-]+\.[a-z]{2,}',
 "ssn": r'\d{3}-\d{2}-\d{4}',
 "phone": r'\d{3}[-.\s]?\d{3}[-.\s]?\d{4}'
}

async def redact_pii(event, data) -> HookResult:
 """Redact PII from streaming content."""
 if event == "content_block:delta":
 content = data.get("delta", "")
 for name, pattern in PATTERNS.items():
 content = re.sub(pattern, f"[{name.upper()}_REDACTED]", content)
 return HookResult(action="modify", data={"delta": content})
 return HookResult(action="continue")`
```

 Output
 
Input: "Contact john@email.com or 555-123-4567"
Output: "Contact [EMAIL_REDACTED] or [PHONE_REDACTED]"
```

### Custom Tool

 Copy

Implement a tool using the Protocol pattern - duck typing, no inheritance required.

`from amplifier_core.models import ToolResult

class WeatherTool:
 """A simple weather lookup tool."""

 @property
 def name(self) -> str:
 return "weather"

 @property
 def description(self) -> str:
 return "Get current weather for a city"

 async def execute(self, input: dict) -> ToolResult:
 city = input.get("city", "Unknown")
 # Your API call here
 return ToolResult(
 output=f"Weather in {city}: 72Â°F, Sunny"
 )

# Mount function for module discovery
async def mount(coordinator, config):
 await coordinator.mount("tools", WeatherTool(), name="weather")
 return lambda: None # cleanup function`
```

 pyproject.toml
 
[project.entry-points."amplifier.modules"]
weather-tool = "my_package.weather:mount"
```

### ToolResult: Success

 Copy

Return successful execution results. The LLM sees this output and can act on it.

`from amplifier_core.models import ToolResult

# Simple success
result = ToolResult(output="File created: /tmp/example.txt")

# Structured success with details
result = ToolResult(
 output="""Created: /tmp/report.csv
Rows: 1,523
Size: 45.2 KB
Columns: id, name, email, created_at"""
)`
```

 Output
 
Created: /tmp/report.csv
Rows: 1,523
Size: 45.2 KB
```

### ToolResult: Error

 Copy

Communicate failures so the LLM can try a different approach or ask for help.

`from amplifier_core.models import ToolResult

# Error with clear message
result = ToolResult(
 output="",
 error="Permission denied: /etc/passwd is read-only"
)

# Error with partial output
result = ToolResult(
 output="Processed 50 of 100 files",
 error="Disk full - operation incomplete"
)`
```

 Output
 
Error: Permission denied: /etc/passwd is read-only
```

### Session Configuration

 Copy

The mount plan structure that configures an Amplifier session with all components.

`from amplifier_core import AmplifierSession

config = {
 "session": {
 "orchestrator": "loop-basic",
 "context": "context-simple"
 },
 "providers": [
 {"module": "provider-anthropic"}
 ],
 "tools": [
 {"module": "tool-filesystem"},
 {"module": "tool-bash"}
 ],
 "hooks": [
 {"module": "hooks-logging"},
 {"handler": "my_security_hook"}
 ]
}

async with AmplifierSession(config) as session:
 response = await session.execute("Your prompt here")`
```

 CLI Usage
 
amplifier run --profile my_config "Hello!"
```

### Multi-Provider Fallback

 Copy

Configure provider priority for automatic failover between LLM backends.

`# profile.yaml - Provider failover chain
providers:
 - module: provider-anthropic
 priority: 1 # Primary - Claude
 config:
 model: claude-sonnet-4-20250514

 - module: provider-openai
 priority: 2 # First fallback - GPT-4
 config:
 model: gpt-4o

 - module: provider-ollama
 priority: 3 # Local fallback
 config:
 model: llama3.1`
```

 Behavior
 
1. Try Anthropic (primary)
2. On error â†’ Try OpenAI
3. On error â†’ Try Ollama (local)
```

### Chat Agent with Memory

 Copy

Build a conversational agent that maintains context across multiple turns.

`from amplifier_core import AmplifierSession

async def chat_loop():
 config = {
 "session": {
 "orchestrator": "loop-basic",
 "context": "context-simple"
 },
 "providers": [{"module": "provider-anthropic"}],
 "tools": [{"module": "tool-bash"}, {"module": "tool-filesystem"}]
 }

 async with AmplifierSession(config) as session:
 print("Chat started. Type 'quit' to exit.")
 while True:
 user_input = input("You: ")
 if user_input.lower() == 'quit':
 break

 # Context is automatically maintained
 response = await session.execute(user_input)
 print(f"Agent: {response}")`
```

 Output
 
You: What files are in the current directory?
Agent: I'll check that for you...
[Lists files]
You: Create a summary of the largest one
Agent: Looking at the largest file...
```

### Real-time Cost Tracking

 Copy

Monitor API costs in real-time with budget alerts and automatic cutoffs.

`from amplifier_core.models import HookResult

class CostTracker:
 PRICING = {
 "claude-sonnet-4-20250514": {"input": 0.003, "output": 0.015},
 "gpt-4o": {"input": 0.005, "output": 0.015},
 }

 def __init__(self, budget: float = 10.0):
 self.budget = budget
 self.spent = 0.0

 def track(self, model: str, input_tokens: int, output_tokens: int):
 rates = self.PRICING.get(model, {"input": 0.01, "output": 0.03})
 cost = (input_tokens * rates["input"] +
 output_tokens * rates["output"]) / 1000
 self.spent += cost
 return cost

tracker = CostTracker(budget=5.0)

async def cost_hook(event, data) -> HookResult:
 if event == "provider:response":
 usage = data.get("usage", {})
 cost = tracker.track(
 data.get("model", "unknown"),
 usage.get("input_tokens", 0),
 usage.get("output_tokens", 0)
 )
 print(f"Cost: \${cost:.4f} | Total: \${tracker.spent:.2f}")

 if tracker.spent >= tracker.budget:
 return HookResult(action="deny", reason="Budget exhausted")

 return HookResult(action="continue")`
```

 Output
 
Cost: $0.0234 | Total: $4.89/$5.00
Cost: $0.0156 | Total: $5.05/$5.00
Action: deny - Budget exhausted
```

### Complete Audit Trail

 Copy

Log every agent action to file for compliance and debugging.

`import json
from datetime import datetime
from pathlib import Path
from amplifier_core.models import HookResult

class AuditLogger:
 def __init__(self, log_dir: str = "./logs"):
 self.log_dir = Path(log_dir)
 self.log_dir.mkdir(exist_ok=True)
 self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
 self.log_file = self.log_dir / f"session_{self.session_id}.jsonl"

 def log(self, event: str, data: dict):
 entry = {
 "timestamp": datetime.now().isoformat(),
 "event": event,
 "data": {k: str(v)[:500] for k, v in data.items()}
 }
 with open(self.log_file, "a") as f:
 f.write(json.dumps(entry) + "\n")

audit = AuditLogger()

async def audit_hook(event, data) -> HookResult:
 if not event.startswith("content_block:"):
 audit.log(event, data)
 return HookResult(action="continue")`
```

 Output
 
# Creates: logs/session_20250115_143052.jsonl
{"timestamp": "2025-01-15T14:30:52", "event": "tool:pre", ...}
```

### Collection Migration Pattern

 Copy

Use Amplifier to analyze existing tools/agents and migrate them to a collection structure.

`# Point Amplifier at your project and the official docs
amplifier run "Analyze my project structure in ./my-tools
and compare it to the collection format in
github.com/microsoft/amplifier/docs/MODULES.md

Help me understand:
1. Which of my tools map to Amplifier modules?
2. How should my agents be structured?
3. What goes in profiles vs context?
4. Create a migration plan to collection format."`
```

 Result
 
my-collection/
â”œâ”€â”€ agents/ # Agent definitions
â”‚ â”œâ”€â”€ my-agent.md
â”‚ â””â”€â”€ helper-agent.md
â”œâ”€â”€ context/ # Workflow docs
â”‚ â””â”€â”€ commands/
â”œâ”€â”€ profiles/ # Configuration
â”‚ â””â”€â”€ my-profile.md
â””â”€â”€ collection.toml # Manifest
```

============================================================
SECTION: CONTRIBUTE
============================================================

# Contributors Guide

Help us build a world-class developer experience for Amplifier.

 ðŸ“š Community & Contributing
 
Join the community and see the roadmap at the official Amplifier documentation site.

 Overview
 Priority Tasks
 Specifications
 Roadmap

North Star: Amplifier makes advanced AI agent systems feel like scripting. Developers should go from an idea to a working extension in under 2 minutes.

### Understanding the Ecosystem

Contributing to Amplifier typically means creating your own repositories rather than submitting PRs to a monolithic codebase:

- Core kernel (`amplifier-core`) - Small, stable, boring. High bar for changes.
 
- CLI application (`amplifier-app-cli`) - Reference CLI, not user-focused.
 
- Reference implementations - Canonical examples for each module type.
 
- Community ecosystem - Your own modules, tools, apps, and collections.

 Reference Implementations

- provider-anthropic - Claude integration
 
- tool-filesystem - File operations
 
- tool-bash - Shell commands
 
- amplifierd - HTTP/SSE API server

### The Gap

The kernel is already built. It's stable, minimal, and powerful. What's missing is the developer experience layerâ€”the tooling that makes the kernel approachable.

### What Belongs Where

 | 
 
 | Feature | Layer | Status

 | Protocol contracts | Kernel (core) | âœ“ Done
 
 | AmplifierSession | Kernel (core) | âœ“ Done
 
 | Event system (30+ events) | Kernel (core) | âœ“ Done
 
 | Testing utilities (TestCoordinator, etc.) | Kernel (core) | âœ“ Done
 
 | Protocol validation utility | Kernel (core) | Needed
 
 | @tool / @hook decorators | Helpers | Needed
 
 | Test harness utilities | Helpers | Needed
 
 | `amplifier dev` (hot reload) | CLI | Needed
 
 | `amplifier inspect --events` | CLI | Needed
 
 | `amplifier scaffold` | CLI | Needed
 
 | `amplifier check` (validation) | CLI | Needed
 
 | `amplifier plan show` | CLI | Needed

### Developer Personas

 Consumer
 
Uses existing modules. Cares about profiles, CLI, and configuration.

 Extender
 
Adds custom tools/hooks. Needs minimal boilerplate and fast feedback.

 Architect
 
Embeds Amplifier in products. Needs integration patterns and observability.

### ðŸ”´ High Priority

 Testing Utilities âœ“
 amplifier-core

Built-in utilities for unit testing modules (AVAILABLE):

 python
 Copy

`from amplifier_core.testing import (
 TestCoordinator, MockTool, MockContextManager,
 EventRecorder, create_test_coordinator
)

# Usage in tests
async def test_my_tool():
 coord = create_test_coordinator()
 await mount(coord, {})

 tool = coord.mounted["tools"]["my_tool"]
 result = await tool.execute({"input": "test"})
 assert result.error is None`
```

 @tool Decorator
 amplifier-helpers

2-minute time-to-first-tool. Reduces boilerplate dramatically.

 python
 Copy

`# amplifier_helpers/decorators.py
def tool(name: str, description: str):
 def decorator(func):
 class GeneratedTool:
 @property
 def name(self): return name
 @property
 def description(self): return description
 async def execute(self, input: dict):
 return await func(**input)
 return GeneratedTool()
 return decorator

# Usage
from amplifier_helpers import tool

@tool(name="greet", description="Says hello")
async def greet(name: str) -> str:
 return f"Hello, {name}!"`
```

### ðŸŸ¡ Medium Priority

 Event Inspector
 amplifier-app-cli

Real-time visualization of the event stream.

 bash
 Copy

`$ amplifier inspect --events

# Output:
# 14:32:01.234 session:start {session_id: "abc123"}
# 14:32:01.567 prompt:submit {content: "Hello"}
# 14:32:02.123 provider:request {provider: "anthropic", messages: 1}
# 14:32:03.456 provider:response {tokens: 42}`
```

 Scaffold Templates
 amplifier-app-cli

Generate module templates with correct structure.

 bash
 Copy

`$ amplifier scaffold tool my_tool
# Creates:
# my_tool/
# __init__.py
# my_tool.py # Tool class + mount()
# pyproject.toml # Entry point configured
# tests/
# test_my_tool.py

$ amplifier scaffold hook --pattern approval
# Generates approval gate hook template`
```

### @hook Decorator Specification

 python
 Copy

`# amplifier_helpers/decorators.py
from functools import wraps
from amplifier_core.models import HookResult

def hook(events: list[str], priority: int = 100):
 """
 Decorator to create a hook handler.

 Args:
 events: List of event patterns (supports globs like "tool:*")
 priority: Lower runs first (default 100)
 """
 def decorator(func):
 @wraps(func)
 async def wrapper(event: str, data: dict) -> HookResult:
 result = await func(event, data)
 if result is None:
 return HookResult(action="continue")
 return result

 wrapper._hook_events = events
 wrapper._hook_priority = priority
 return wrapper
 return decorator

# Usage
@hook(events=["tool:pre", "tool:post"], priority=10)
async def my_hook(event: str, data: dict):
 print(f"{event}: {data}")
 # Returning None = continue`
```

### Directory Structure

 text

`amplifier-ecosystem/
â”œâ”€â”€ amplifier-core/ # Kernel (this repo)
â”‚ â”œâ”€â”€ amplifier_core/
â”‚ â”‚ â”œâ”€â”€ session.py # AmplifierSession
â”‚ â”‚ â”œâ”€â”€ coordinator.py # Coordinator
â”‚ â”‚ â”œâ”€â”€ hooks.py # HookRegistry
â”‚ â”‚ â”œâ”€â”€ protocols.py # Protocol definitions
â”‚ â”‚ â”œâ”€â”€ models.py # ToolResult, HookResult, etc.
â”‚ â”‚ â”œâ”€â”€ testing.py # TestCoordinator, MockTool, etc.
â”‚ â”‚ â””â”€â”€ validation.py # check_protocol() (NEW)
â”‚ â””â”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ amplifier-helpers/ # Convenience utilities (NEW)
â”‚ â”œâ”€â”€ amplifier_helpers/
â”‚ â”‚ â”œâ”€â”€ decorators.py # @tool, @hook
â”‚ â”‚ â””â”€â”€ testing.py # ToolTestHarness
â”‚ â””â”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ amplifier-app-cli/ # CLI application
â”‚ â”œâ”€â”€ amplifier_cli/
â”‚ â”‚ â”œâ”€â”€ commands/
â”‚ â”‚ â”‚ â”œâ”€â”€ run.py
â”‚ â”‚ â”‚ â”œâ”€â”€ dev.py # Hot reload (NEW)
â”‚ â”‚ â”‚ â”œâ”€â”€ inspect.py # Event inspector (NEW)
â”‚ â”‚ â”‚ â”œâ”€â”€ scaffold.py # Templates (NEW)
â”‚ â”‚ â”‚ â”œâ”€â”€ check.py # Validation (NEW)
â”‚ â”‚ â”‚ â””â”€â”€ plan.py # Visualizer (NEW)
â”‚ â”‚ â””â”€â”€ main.py
â”‚ â””â”€â”€ pyproject.toml
â”‚
â””â”€â”€ amplifier-profiles/ # Profile management
 â””â”€â”€ ...`
```

 External Specifications

 These specifications are automatically synced from
 amplifier-next-specs.
 They define enterprise productivity extensions for the Amplifier framework.

 Filter:
 All
 Design
 Tools
 Hooks
 Recipes
 Collections
 Integrations

 Enterprise Productivity Extensions Index
 overview

Status: Draft specifications for review

Purpose: Comprehensive specs for tools, hooks, scenario tools, collections, and integrations targeting enterprise product teams working in large codebases.

---

### Overview

This specification set defines extensions to the Amplifier framework optimized for:

- Product building - Feature development, planning, release management
 
- Team collaboration - Code review, knowledge sharing, onboarding
 
- Large codebase management - Navigation, understanding, tech debt
 
- Enterprise context - Compliance, security, audit trails
 
---

### Architectural Note

Why no custom orchestrators?

After analysis, we determined that multi-step workflows and multi-agent collaboration belong at the tool layer, not the orchestrator layer. This follows Amplifier's "mechanism vs policy" philosophy:

- Orchestrators (kernel-adjacent): Simple execution mechanisms (loop-basic, loop-streaming)
 
- Tools (app layer): Workflow policies (recipes, collaborative, swarm)
 
The existing `amplifier-collection-recipes` already provides declarative multi-step workflows. New coordination patterns (`tool-collaborative`, `tool-swarm`) are specified as tools that spawn sub-agents.

---

### Specification Index

#### Tools (Atomic Capabilities)

 | 
 
 | Spec | Purpose | Priority

 | tool-codebase-search | Semantic search across code, docs, tickets | P0
 
 | tool-dependency-graph | Trace imports, call chains, impact analysis | P1
 
 | tool-architecture-map | Generate/update architecture diagrams | P2
 
 | tool-tech-debt-scanner | Identify anti-patterns, dead code, outdated deps | P1
 
 | tool-pr-context | Fetch PR, comments, linked issues, related PRs | P0
 
 | tool-slack-search | Search team discussions, decisions | P1
 
 | tool-jira-ops | Create, update, link tickets | P0
 
 | tool-git-advanced | Branch ops, history analysis, contextual blame | P1
 
 | tool-test-runner | Run specific tests, analyze failures | P1
 
 | tool-migration-helper | Schema changes, migrations, rollback plans | P2
 
 | tool-feature-flag | Check/toggle flags, analyze flag debt | P2
 
 | tool-metrics-query | Query Prometheus/DataDog/etc. | P1

#### Tools (Coordination Patterns)

These tools enable sophisticated multi-agent patterns while keeping orchestrators simple:

 | 
 
 | Spec | Purpose | Priority

 | tool-collaborative | Multi-agent collaboration (parallel specialists) | P1
 
 | tool-swarm | Parallel exploration with convergence | P2

Note: For sequential multi-step workflows, use the existing `amplifier-collection-recipes`.

#### Hooks (Guardrails & Intelligence)

 | 
 
 | Spec | Purpose | Priority

 | hooks-style-enforcer | Auto-lint, inject feedback on violations | P1
 
 | hooks-security-scan | SAST scan, block critical vulnerabilities | P0
 
 | hooks-secret-detector | Prevent committing secrets/keys | P0
 
 | hooks-breaking-change | Detect API breaking changes | P1
 
 | hooks-ticket-linker | Auto-load JIRA context for current branch | P0
 
 | hooks-reviewer-suggester | Suggest reviewers based on code ownership | P2
 
 | hooks-standup-logger | Summarize work for async standups | P2
 
 | hooks-knowledge-capture | Extract learnings to team knowledge base | P1
 
 | hooks-audit-trail | Immutable log for compliance | P0
 
 | hooks-pii-guardian | Redact PII before sending to LLM | P0
 
 | hooks-license-checker | Flag incompatible licenses | P2
 
 | hooks-approval-workflow | Require human approval for sensitive changes | P1
 
 | hooks-token-budget | Enforce per-session/user token limits | P1
 
 | hooks-model-router | Route tasks to appropriate models | P1
 
 | hooks-usage-analytics | Track usage patterns for optimization | P1

#### Recipes (Declarative Multi-Step Workflows)

Recipes are declarative YAML specifications that define multi-step AI agent workflows. They leverage `amplifier-collection-recipes` for:

- Sequential/conditional execution with `foreach` and `parallel: true`
 
- Recipe composition (sub-recipes for reusable audits)
 
- Context isolation and checkpointing
 
- Agent mode switching (ANALYZE, ARCHITECT, REVIEW)
 
#### Main Recipes

 | 
 
 | Recipe | Purpose | Priority

 | pr-reviewer | Comprehensive PR review with parallel analysis | P0
 
 | incident-responder | Incident analysis with multi-hypothesis diagnosis | P0
 
 | feature-planner | Transform PRD to implementation plan | P1
 
 | codebase-onboarder | New developer onboarding guide generation | P1
 
 | tech-debt-prioritizer | Tech debt triage with JIRA integration | P1

#### Reusable Sub-Recipes (audits/)

Composable audit recipes that can be used standalone or within larger workflows:

 | 
 
 | Recipe | Purpose | Used By

 | security-audit | Security vulnerability analysis | pr-reviewer
 
 | quality-audit | Code quality and maintainability | pr-reviewer
 
 | breaking-change-audit | API/schema compatibility analysis | pr-reviewer
 
 | architecture-audit | Architectural impact assessment | pr-reviewer (thorough mode)

Migration Note: The previous scenario-tools (Python implementations) have been converted to declarative YAML recipes. This follows Amplifier's "mechanism vs policy" philosophy - complex workflows are now declarative specifications that the recipe engine executes.

#### Extended Recipes (Showcasing Advanced Features)

Additional recipes demonstrating advanced Amplifier@next capabilities:

 | 
 
 | Recipe | Purpose | Key Features | Priority

 | release-manager | Coordinate release process (changelog, notes, tagging) | `foreach` over commits, parallel notifications | P1
 
 | migration-orchestrator | Complex migrations with validation at each step | Checkpointing, rollback support, validation gates | P1
 
 | dependency-upgrader | Automated dep updates with compatibility checks | `foreach` + `parallel`, test integration, rollback | P1
 
 | root-cause-analyzer | Deep dive into production issues | Multi-hypothesis diagnosis, evidence weighting | P1
 
 | test-suite-analyzer | Coverage gaps, flaky tests, test prioritization | Parallel analysis, metrics aggregation | P1
 
 | api-evolution-tracker | Track API changes, suggest versioning, generate migrations | Temporal analysis, doc generation | P2
 
 | documentation-auditor | Find outdated docs, doc-code consistency | Multi-source correlation, quality scoring | P2
 
 | knowledge-harvester | Extract knowledge from Slack/PRs/meetings | Multi-source ingestion, entity extraction | P2
 
 | compliance-checker | SOC2/GDPR/HIPAA compliance scanning | Policy-based rules, parallel audits | P2
 
 | performance-profiler | Profile app, identify bottlenecks, track over time | Metrics integration, trend analysis | P2

Feature Showcase:

 | 
 
 | Feature | Demonstrated By

 | `foreach` + `parallel` | dependency-upgrader, release-manager
 
 | Checkpointing/Resumability | migration-orchestrator
 
 | Multi-hypothesis Reasoning | root-cause-analyzer, incident-responder
 
 | Recipe Composition | pr-reviewer (uses audit sub-recipes)
 
 | Conditional Steps | all recipes with `condition:`
 
 | Mode Switching | feature-planner (ANALYZE â†’ ARCHITECT â†’ REVIEW)
 
 | Multi-source Ingestion | knowledge-harvester, root-cause-analyzer
 
 | Evidence Collection | compliance-checker, root-cause-analyzer

#### Collections (Packaged Expertise)

 | 
 
 | Spec | Purpose | Priority

 | collection-enterprise-dev | Core enterprise development | P0
 
 | collection-platform-team | Platform/infrastructure teams | P1
 
 | collection-product-team | Product management integration | P2

#### Integrations (Enterprise Ecosystem)

#### Core Infrastructure

 | 
 
 | Spec | Purpose | Priority

 | integration-api-server | HTTP REST/GraphQL API server (enables all other integrations) | P0
 
 | integration-github-actions | CI/CD integration | P0
 
 | integration-git-hooks | Pre-commit, commit-msg, pre-push automation | P1

#### Developer Tools

 | 
 
 | Spec | Purpose | Priority

 | integration-tauri-desktop | Amplifier Desktop - Native Tauri app with streaming UI | P0
 
 | integration-vscode | VS Code IDE integration | P1
 
 | integration-browser-extension | GitHub/GitLab PR review, code explanation in browser | P1
 
 | integration-electron-app | Standalone desktop app with offline support | P2
 
 | integration-obsidian-plugin | Knowledge management, code-to-docs | P2

#### Team Communication

 | 
 
 | Spec | Purpose | Priority

 | integration-slack | Slack bot integration | P1
 
 | integration-teams-bot | Microsoft Teams bot with Azure DevOps | P2

#### Dashboards & Monitoring

 | 
 
 | Spec | Purpose | Priority

 | integration-web-dashboard | Web-based management UI | P1
 
 | integration-observability | Grafana/DataDog dashboards | P2
 
 | integration-mobile-companion | iOS/Android mobile app | P2

---

### Priority Legend

- P0: Foundation - Build first, enables other work
 
- P1: High value - Significant productivity gain
 
- P2: Enhancement - Nice to have, can defer
 
---

### Specification Template

Each spec follows this structure:

 markdown
 Copy

`# [Component Name]

## Overview
Brief description and value proposition

## Contract
Interface definition (inputs, outputs, events)

## Architecture
Internal design, dependencies, data flow

## Configuration
Available options and defaults

## Examples
Usage examples and common patterns

## Security Considerations
Permissions, data handling, risks

## Testing Strategy
How to verify correctness

## Open Questions
Decisions needing input`
```

---

### Review Process

- Review specs in priority order (P0 â†’ P1 â†’ P2)
 
- Mark decisions in "Open Questions" sections
 
- Iterate until spec is approved
 
- Implementation follows approved spec

 Cold Start Analysis
 analysis

### Problem Statement

Amplifier@next is a runtime platform for AI-powered workflows, but users don't know how to start using it to see value. Unlike visual builders (Zapier) or IDE extensions (Copilot), there's no obvious entry point.

---

### Market Research Findings

#### 1. Developer Platform Onboarding Patterns

Key Insight: Speed to first value is critical.

 | 
 
 | Platform | Approach | Key Metric

 | Railway | "Deploy in 4 clicks" | Minimal friction
 
 | Vercel | "In mere seconds, your code is live" | Frictionless onboarding
 
 | Render | Templates + simple defaults | Transparent pricing

Pattern: Offer templates/pre-configured starting points alongside blank canvas.

---

#### 2. AI Coding Assistant Onboarding

Key Insight: Make the tool feel like a teaching partner, not just a feature.

 | 
 
 | Tool | First Value Experience | Differentiator

 | GitHub Copilot | Real-time suggestions | "Senior engineer whispering syntax"
 
 | Cursor | Codebase-aware suggestions | "Explain my code" feature

Pattern: Junior developers using Cursor fix bugs 30-50% faster with inline explanations. The "explain my code" feature shortens learning curves dramatically.

---

#### 3. Workflow Automation Onboarding

Key Insight: Guide beginners, but don't block experts.

 | 
 
 | Platform | Approach | Target Audience

 | Zapier | Linear guided flow + templates | Non-technical users
 
 | n8n | Freedom to experiment immediately | Developers

Zapier's Secret: Doesn't just say "here's a builder, figure it out." Instead offers:

- Build from scratch
 
- Pre-made templates
 
- 3-minute tutorial
 
- Suggested workflows based on role
 
---

#### 4. Interactive Demo & Sandbox Patterns

Key Insight: 43% of B2B buyers want seller-free experience (Gartner).

 | 
 
 | Tool | Type | Best For

 | Instruqt | Browser-based sandbox | Software companies selling to developers
 
 | CodeSandbox | Live code environment | Documentation & learning
 
 | Sandpack | Embeddable code playground | In-context demonstrations

Pattern: Playgrounds allow learners to tinker, experiment, and commit lessons to memory. Active participation > passive demos.

---

#### 5. AI Agent Platform Experiences

Key Insight: 2024 was the year "narrowly scoped, highly controllable agents" started working in production.

 | 
 
 | Framework | Strength | Demo Suitability

 | LangChain | Modular pipelines | Production-ready
 
 | CrewAI | Multi-agent collaboration | "Best suited for demos and prototypes"
 
 | AutoGPT | Full autonomy | "Exciting experiment" but unreliable

Pattern: Vertical, focused use cases work better than general-purpose agents.

---

#### 6. Time to Value Research

Critical Stats:

- 70% of users abandon if onboarding takes >20 minutes (Visa)
 
- 90% of customers believe onboarding experiences are lacking
 
- 3-step tours have 72% completion vs 16% for 7-step (Chameleon.io)
 
---

#### 7. Developer "Aha Moments"

Key Insight: The aha moment is when developers first experience core value viscerally.

 | 
 
 | Company | Aha Moment

 | Twilio | "When developers sent their first text or made a phone ring with code"
 
 | Docker | "When developers realized they could containerize an entire application"
 
 | Stripe/Plaid | Well-designed APIs + comprehensive documentation

Pattern: Transform casual users into passionate advocates through tangible, visceral experiences.

---

### Amplifier@next Value Proposition Analysis

#### What Amplifier@next Does

- Multi-step AI workflows (recipes)
 
- Specialized agents (zen-architect, security-guardian, bug-hunter, etc.)
 
- Enterprise focus (PR review, incident response, tech debt, compliance)
 
#### Why Cold Start is Hard

- Runtime platform - No visual builder interface
 
- Requires codebase - Can't demo without real code
 
- Multi-step value - Benefits compound over workflow, not single action
 
- Enterprise context - Full value requires team/org setup
 
#### What the Aha Moment Should Be

"I pointed amplifier at my PR/incident/codebase, and in 60 seconds it gave me a comprehensive analysis I would have spent hours creating manually."

---

### Proposed Showcase Experiences

#### Option 1: "Recipe Playground" (Web-Based)

Concept: Interactive web sandbox where users run recipes against sample repos.

Experience Flow:

- Land on playground.amplifier.dev
 
- Choose a scenario: "PR Review" | "Incident Response" | "Tech Debt Scan"
 
- See pre-loaded sample repo with realistic code
 
- Click "Run Recipe" - watch agents work in real-time
 
- Get comprehensive output (security findings, review comments, etc.)
 
- Option to "Try on your repo" â†’ CLI installation
 
Why It Works:

- No setup required (like Zapier templates)
 
- Tangible output in Implementation:

- Web app with embedded terminal/output viewer
 
- Pre-baked scenarios with sample repos
 
- Real recipe execution (not simulated)
 
- Output comparison: "Manual effort: ~2 hours. Amplifier: 45 seconds."
 
Effort: Medium-High (requires web infrastructure)

---

#### Option 2: "Demo Mode" CLI Experience

Concept: Built-in demo command that runs against sample repos.

Experience Flow:

 bash
 Copy

`# Install
pip install amplifier-cli

# Run demo (no config needed)
amplifier demo pr-review

# Output: Downloads sample PR, runs full review, shows results
# "Want to try on your own repo? Run: amplifier init"`
```

Demo Scenarios:

 bash
 Copy

`amplifier demo pr-review # Full PR review with security/quality/breaking changes
amplifier demo incident # Incident response with log analysis, RCA
amplifier demo tech-debt # Tech debt scan with JIRA ticket creation
amplifier demo onboard # Codebase onboarding guide generation`
```

Why It Works:

- Zero config (like Railway's 4-click deploy)
 
- Developers stay in terminal (familiar environment)
 
- Real execution, not simulated
 
- Natural progression to "try on your code"
 
Implementation:

- Bundle sample repos or fetch from GitHub
 
- Pre-configured recipe contexts
 
- Output formatter showing agent steps + results
 
- Call-to-action for real usage
 
Effort: Low-Medium (CLI extension)

---

#### Option 3: "One-Click GitHub App"

Concept: GitHub App that installs in 1 click and immediately provides value.

Experience Flow:

- Visit amplifier.dev/github-app
 
- Click "Install on Repository"
 
- Select a repo
 
- Immediately:
 
 - Opens latest PR with AI review comments

 - Creates "Amplifier Analysis" issue with codebase health report

 - Shows tech debt summary in README badge

Triggered Workflows:

- On PR Open: Automatic security + quality review
 
- On Issue "incident": Automatic incident analysis
 
- Weekly: Tech debt report
 
Why It Works:

- One click to value (like Vercel's GitHub integration)
 
- Works where developers already are
 
- Demonstrates continuous value, not one-time
 
- Social proof via visible activity
 
Implementation:

- GitHub App with webhooks
 
- Recipe execution on PR/issue events
 
- Comment generation matching GitHub's format
 
- Dashboard for configuration
 
Effort: High (requires GitHub App infrastructure)

---

#### Option 4: "Vertical Showcases" (Persona-Based)

Concept: Tailored demo experiences for specific roles/use cases.

Personas & Experiences:

 | 
 
 | Persona | Showcase | Key Recipe

 | Platform Engineer | "Incident War Room" | incident-responder, root-cause-analyzer
 
 | Engineering Manager | "Tech Debt Dashboard" | tech-debt-prioritizer, compliance-checker
 
 | New Team Member | "Codebase Explorer" | codebase-onboarder
 
 | Security Engineer | "Security Audit" | security-audit, compliance-checker
 
 | Release Manager | "Release Coordinator" | release-manager, api-evolution-tracker

Experience (Platform Engineer Example):

- "Simulate" an incident alert
 
- Watch amplifier gather logs, metrics, recent deploys
 
- See hypothesis generation and testing
 
- Get actionable RCA with timeline
 
- "This normally takes your team 2 hours. Amplifier: 3 minutes."
 
Why It Works:

- Speaks to specific pain points (like Zapier's role-based onboarding)
 
- Demonstrates depth, not just breadth
 
- Creates multiple entry points to platform
 
- Content marketing opportunity (blog posts, videos per persona)
 
Implementation:

- Landing pages per persona
 
- Curated demo scenarios
 
- ROI calculators
 
- Case study format
 
Effort: Medium (content + web)

---

#### Option 5: "Recipe Gallery" with Live Execution

Concept: Browse, preview, and run recipes like an app store.

Experience Flow:

- Browse recipes by category (Code Review, Incident, Planning, etc.)
 
- Each recipe shows:
 
 - Description

 - Required inputs

 - Sample output preview

 - "Run Demo" button

- Click "Run Demo" â†’ executes against sample repo
 
- See step-by-step agent execution
 
- Download recipe to run locally
 
Why It Works:

- Discovery mechanism (like Zapier's app directory)
 
- Shows breadth of capabilities
 
- Each recipe is a mini-demo
 
- Community contribution model (submit recipes)
 
Implementation:

- Web gallery with recipe metadata
 
- Demo execution backend
 
- Output preview/streaming
 
- Recipe export/import
 
Effort: Medium-High

---

### Recommendation: Phased Approach

#### Phase 1: Demo Mode CLI (Weeks 1-2)

Why First:

- Lowest effort, highest developer authenticity
 
- Works with existing CLI infrastructure
 
- Proves value proposition before building web UI

 bash
 Copy

`amplifier demo pr-review
amplifier demo incident
amplifier demo tech-debt`
```

#### Phase 2: Vertical Landing Pages (Weeks 3-4)

Why Second:

- Marketing and content leverage
 
- Multiple entry points
 
- SEO + content marketing synergy
 
#### Phase 3: Recipe Playground (Weeks 5-8)

Why Third:

- Building on validated messaging from Phase 1-2
 
- Requires more infrastructure
 
- Higher conversion potential
 
#### Phase 4: GitHub App (Months 2-3)

Why Last:

- Highest effort
 
- Requires ongoing maintenance
 
- Best ROI once user base exists
 
---

### Success Metrics

 | 
 
 | Metric | Target | Measurement

 | Time to First Value | | From first command to seeing output
 
 | Demo Completion Rate | >60% | Users who complete a demo scenario
 
 | CLI â†’ Real Usage | >20% | Users who run on own repos after demo
 
 | GitHub App Installs | N/A (Phase 4) | Weekly active installations

---

### Open Questions

- Sample Repos: Should we use famous open-source repos (kubernetes, react) or create synthetic ones?
 
 - Pro of famous: Recognition, realistic complexity

 - Pro of synthetic: Controlled, consistent, no licensing issues

- Real vs Simulated: Should demos execute real recipes or show pre-baked results?
 
 - Pro of real: Authenticity, shows actual capabilities

 - Pro of pre-baked: Fast, consistent, no API costs

- Self-Hosted Option: Enterprise users may want to run demos on their infrastructure. Support this?
 
- Pricing Preview: Should demo experience show pricing/limits to set expectations?
 
---

### Next Steps

- [ ] Decide on Phase 1 scope (which demo scenarios)
 
- [ ] Select/create sample repositories
 
- [ ] Design demo output format
 
- [ ] Implement `amplifier demo` command
 
- [ ] Create landing page content for vertical showcases

 Skills Agents Plugins
 design

Status: Design Complete

Scope: Desktop implementation (extensible to CLI)

---

### Overview

This document defines the architecture for Skills, Agents, and Plugins systems that extend amplifier capabilities while maintaining kernel stability.

#### Design Principles

- Kernel Stability - amplifier-core remains unchanged
 
- Modular Loading - Skills/Agents/Plugins loaded as modules
 
- User Control - All features togglable
 
- Claude Compatibility - Same formats as Claude Code
 
- Local First - All data stored locally
 
---

### Skills System

A skill is a reusable capability that extends AI functionality through natural language instructions. Skills are model-invoked (Claude decides when to use them).

#### Directory Structure

 text
 Copy

`~/.amplifier/skills/ # User-level (all projects)
 â””â”€â”€ my-skill/
 â”œâ”€â”€ SKILL.md # Required: Skill definition
 â”œâ”€â”€ scripts/ # Optional: Executable scripts
 â”œâ”€â”€ references/ # Optional: Documentation
 â””â”€â”€ assets/ # Optional: Templates, files

.amplifier/skills/ # Project-level (this project only)
 â””â”€â”€ project-skill/
 â””â”€â”€ SKILL.md`
```

#### SKILL.md Format

 markdown
 Copy

`---
name: skill-name
description: Brief description of what this skill does
allowed-tools: "Read, Write, Bash" # Optional: Tool restrictions
version: 1.0.0
---

# Skill Name

## Instructions
Provide clear, step-by-step guidance for Claude.

## Examples
Show concrete examples of using this skill.`
```

#### Implementation

Backend: `sidecar/skills_manager.py`

 python
 Copy

`class Skill:
 name: str
 description: str
 skill_md: str
 allowed_tools: list[str]
 scripts: list[str]
 references: list[str]
 location: 'user' | 'project'
 enabled: bool

class SkillsManager:
 async def load_skills(project_path: str | None) -> list[Skill]
 async def enable_skill(name: str) -> None
 async def disable_skill(name: str) -> None`
```

Frontend: Skills loaded and injected into system prompt when enabled.

---

### Agents System

An agent is a specialized AI persona with focused capabilities. Agents use user-invoked activation via `/agent` command.

#### Directory Structure

 text
 Copy

`~/.amplifier/agents/ # User-level
 â””â”€â”€ my-agent.md

.amplifier/agents/ # Project-level
 â””â”€â”€ project-agent.md`
```

#### Agent Format

 markdown
 Copy

`---
name: agent-name
description: What this agent specializes in
model: claude-opus-4-5-20251101 # Optional: Override model
tools: [read_file, write_file] # Optional: Tool allowlist
temperature: 0.7 # Optional: Override temp
---

# Agent Name

## Role
Define the agent's specialized role and expertise.

## Approach
Describe how the agent should approach problems.

## Constraints
List any limitations or boundaries.`
```

#### Activation

 text
 Copy

`/agent code-reviewer # Switch to code reviewer agent
/agent # Return to default assistant`
```

---

### Plugins System

Plugins extend functionality with external integrations (MCP servers, API connections, etc.).

#### Plugin Types

- MCP Plugins - Model Context Protocol servers
 
- API Plugins - External API integrations
 
- Tool Plugins - Custom tool implementations
 
#### Configuration

 yaml
 Copy

`# ~/.amplifier/settings.yaml
plugins:
 mcp:
 filesystem:
 command: "npx"
 args: ["-y", "@modelcontextprotocol/server-filesystem", "~"]
 github:
 command: "npx"
 args: ["-y", "@modelcontextprotocol/server-github"]
 env:
 GITHUB_TOKEN: ${GITHUB_TOKEN}`
```

---

### Integration with amplifier-core

#### Hook Points

 python
 Copy

`# Skills injected via system prompt hook
hooks.register("prompt:pre", inject_skills_prompt)

# Agent switching via command hook
hooks.register("command:pre", handle_agent_command)

# Plugin tools registered via mount
coordinator.mount("tools", mcp_tool, name=f"mcp_{server}_{tool}")`
```

#### Module Loading

Skills/Agents use the existing `LocalLoader` infrastructure:

 python
 Copy

`# Skills treated as loadable modules
loader.register("skill-*", SkillModule)
loader.register("agent-*", AgentModule)`
```

---

### Feature Matrix

 | 
 
 | Feature | Skills | Agents | Plugins

 | Activation | Model-invoked | User-invoked | Always active
 
 | Scope | User/Project | User/Project | Global
 
 | Tool Restrictions | Yes | Yes | No
 
 | Model Override | No | Yes | No
 
 | Custom Scripts | Yes | No | Yes
 
 | Reference Docs | Yes | No | No

---

### Implementation Status

#### Desktop

- [x] Skills manager basic implementation
 
- [x] Skills UI (enable/disable)
 
- [x] MCP plugins integration
 
- [ ] Agents system
 
- [ ] Agent switching UI
 
- [ ] Skills auto-discovery
 
#### CLI

- [ ] Skills support
 
- [ ] Agents support
 
- [ ] Plugin system
 
---

### References

- Claude Code skills format: https://docs.anthropic.com/claude/docs/skills
 
- MCP specification: https://modelcontextprotocol.io/

 Tool Architecture Map
 tools

Priority: P2 (Enhancement)

Status: Draft

Module: `amplifier-module-tool-architecture-map`

### Overview

Generate and maintain architecture diagrams from code analysis. Creates visual representations of system structure, data flows, and component relationships that stay synchronized with the actual codebase.

#### Value Proposition

 | 
 
 | Without | With

 | Architecture docs always outdated | Diagrams generated from live code
 
 | Manual diagram maintenance | Auto-update on codebase changes
 
 | Inconsistent diagram styles | Consistent, templated output
 
 | Hours in diagramming tools | Instant generation from code analysis

#### Use Cases

- System overview: Generate high-level architecture diagram
 
- Component deep-dive: Detailed view of specific service/module
 
- Data flow visualization: How data moves through the system
 
- Onboarding: Quick visual understanding for new developers
 
- Documentation sync: Keep architecture docs current
 
---

### Contract

#### Tool Definition

 python
 Copy

`TOOL_DEFINITION = {
 "name": "architecture_map",
 "description": """
 Generate architecture diagrams from code analysis.

 Diagram types:
 - system: High-level system/service architecture
 - component: Internal component structure
 - data_flow: Data movement through system
 - deployment: Infrastructure/deployment view
 - sequence: Interaction sequences

 Output formats: mermaid, plantuml, dot, svg, png
 """,
 "parameters": {
 "type": "object",
 "properties": {
 "diagram_type": {
 "type": "string",
 "enum": ["system", "component", "data_flow", "deployment", "sequence"],
 "description": "Type of diagram to generate"
 },
 "scope": {
 "type": "string",
 "description": "Path or pattern to analyze (e.g., 'src/services/', 'PaymentService')"
 },
 "depth": {
 "type": "integer",
 "default": 2,
 "description": "Level of detail (1=high-level, 3=detailed)"
 },
 "output_format": {
 "type": "string",
 "enum": ["mermaid", "plantuml", "dot", "svg", "png"],
 "default": "mermaid",
 "description": "Output format"
 },
 "include_external": {
 "type": "boolean",
 "default": true,
 "description": "Include external services/dependencies"
 },
 "group_by": {
 "type": "string",
 "enum": ["module", "layer", "domain", "none"],
 "default": "module",
 "description": "How to group components"
 }
 },
 "required": ["diagram_type"]
 }
}`
```

#### Output Schema

 python
 Copy

`@dataclass
class ArchitectureMapOutput:
 diagram_type: str
 scope: str

 # Diagram content
 diagram: str # In requested format
 format: str

 # Metadata
 components: list[Component]
 relationships: list[Relationship]
 external_services: list[ExternalService]

 # Analysis summary
 summary: ArchitectureSummary

@dataclass
class Component:
 id: str
 name: str
 type: str # service | module | class | database | queue
 description: str | None
 source_path: str | None
 layer: str | None # api | service | data | infrastructure
 metrics: ComponentMetrics | None

@dataclass
class Relationship:
 source_id: str
 target_id: str
 type: str # calls | uses | stores | publishes | subscribes
 description: str | None
 async_: bool
 protocol: str | None # http | grpc | amqp | sql

@dataclass
class ExternalService:
 name: str
 type: str # database | cache | queue | api | storage
 provider: str | None # aws | gcp | azure | self-hosted

@dataclass
class ArchitectureSummary:
 total_components: int
 total_relationships: int
 layers_detected: list[str]
 patterns_detected: list[str] # "microservices", "monolith", "event-driven"
 suggestions: list[str] # Architecture improvement suggestions`
```

---

### Architecture

#### Diagram Generation Pipeline

 python
 Copy

`class ArchitectureMapper:
 """Generate architecture diagrams from code analysis."""

 async def generate(self, input: ArchitectureMapInput) -> ArchitectureMapOutput:
 # 1. Analyze codebase structure
 components = await self._discover_components(input.scope, input.depth)

 # 2. Analyze relationships
 relationships = await self._analyze_relationships(components)

 # 3. Detect external services
 external = await self._detect_external_services(components)

 # 4. Apply grouping/layout
 layout = self._compute_layout(components, relationships, input.group_by)

 # 5. Generate diagram
 diagram = self._render_diagram(
 components, relationships, external, layout,
 input.diagram_type, input.output_format
 )

 # 6. Analyze architecture patterns
 summary = self._analyze_architecture(components, relationships)

 return ArchitectureMapOutput(
 diagram_type=input.diagram_type,
 scope=input.scope,
 diagram=diagram,
 format=input.output_format,
 components=components,
 relationships=relationships,
 external_services=external,
 summary=summary
 )

 async def _discover_components(self, scope: str, depth: int) -> list[Component]:
 """Discover components from code structure."""
 components = []

 # Depth 1: Services/top-level modules
 if depth >= 1:
 services = await self._find_services(scope)
 components.extend(services)

 # Depth 2: Major classes/modules within services
 if depth >= 2:
 for service in services:
 modules = await self._find_modules(service.source_path)
 components.extend(modules)

 # Depth 3: Individual classes and functions
 if depth >= 3:
 for module in components:
 classes = await self._find_classes(module.source_path)
 components.extend(classes)

 return components

 def _render_diagram(
 self,
 components: list[Component],
 relationships: list[Relationship],
 external: list[ExternalService],
 layout: Layout,
 diagram_type: str,
 format: str
 ) -> str:
 """Render diagram in requested format."""
 renderers = {
 "mermaid": MermaidRenderer(),
 "plantuml": PlantUMLRenderer(),
 "dot": GraphvizRenderer(),
 }

 renderer = renderers[format]
 return renderer.render(components, relationships, external, layout, diagram_type)`
```

#### Mermaid Renderer

 python
 Copy

`class MermaidRenderer:
 """Render diagrams in Mermaid format."""

 def render_system(
 self,
 components: list[Component],
 relationships: list[Relationship],
 external: list[ExternalService]
 ) -> str:
 lines = ["graph TB"]

 # Add subgraphs for groupings
 groups = self._group_components(components)
 for group_name, group_components in groups.items():
 lines.append(f" subgraph {group_name}")
 for comp in group_components:
 shape = self._get_shape(comp.type)
 lines.append(f" {comp.id}{shape}")
 lines.append(" end")

 # Add external services
 if external:
 lines.append(" subgraph External")
 for ext in external:
 lines.append(f" {ext.name}[({ext.name})]")
 lines.append(" end")

 # Add relationships
 for rel in relationships:
 arrow = self._get_arrow(rel.type, rel.async_)
 label = f"|{rel.type}|" if rel.type else ""
 lines.append(f" {rel.source_id} {arrow}{label} {rel.target_id}")

 return "\n".join(lines)

 def _get_shape(self, component_type: str) -> str:
 shapes = {
 "service": "[{}]", # Rectangle
 "database": "[({})]", # Cylinder
 "queue": "{{{}}}", # Hexagon
 "api": "([{}])", # Stadium
 "module": "({})", # Rounded
 }
 return shapes.get(component_type, "[{}]")`
```

---

### Examples

#### Example 1: System Architecture Diagram

 python
 Copy

`# Input
{
 "diagram_type": "system",
 "scope": "src/services/",
 "depth": 1,
 "output_format": "mermaid"
}

# Output
{
 "diagram_type": "system",
 "diagram": """graph TB
 subgraph Services
 api-gateway[API Gateway]
 user-service[User Service]
 payment-service[Payment Service]
 order-service[Order Service]
 end
 subgraph Data
 postgres[(PostgreSQL)]
 redis[(Redis)]
 end
 subgraph External
 stripe([Stripe API])
 sendgrid([SendGrid])
 end

 api-gateway -->|REST| user-service
 api-gateway -->|REST| order-service
 order-service -->|gRPC| payment-service
 payment-service -->|HTTPS| stripe
 user-service --> postgres
 payment-service --> postgres
 user-service --> redis
 order-service -->|email| sendgrid""",
 "format": "mermaid",
 "summary": {
 "total_components": 4,
 "layers_detected": ["api", "service", "data"],
 "patterns_detected": ["microservices", "api-gateway"],
 "suggestions": [
 "Consider adding circuit breakers for external service calls",
 "payment-service has high coupling with order-service"
 ]
 }
}`
```

#### Example 2: Component Diagram

 python
 Copy

`# Input
{
 "diagram_type": "component",
 "scope": "src/services/payment/",
 "depth": 2
}

# Output
{
 "diagram": """graph TB
 subgraph payment-service
 subgraph API Layer
 PaymentController
 WebhookController
 end
 subgraph Service Layer
 PaymentService
 RefundService
 WebhookProcessor
 end
 subgraph Data Layer
 PaymentRepository
 TransactionRepository
 end
 end

 PaymentController --> PaymentService
 WebhookController --> WebhookProcessor
 PaymentService --> PaymentRepository
 PaymentService --> RefundService
 RefundService --> TransactionRepository"""
}`
```

---

### Configuration

 yaml
 Copy

`tool-architecture-map:
 # Analysis settings
 analysis:
 # Patterns to identify services
 service_patterns:
 - "**/services/*/"
 - "**/apps/*/"
 - "**/microservices/*/"

 # Patterns to identify modules
 module_patterns:
 - "**/*_service.py"
 - "**/*_controller.py"
 - "**/*_repository.py"

 # Layer detection
 layers:
 api: ["controller", "handler", "endpoint", "router"]
 service: ["service", "usecase", "interactor"]
 data: ["repository", "dao", "model", "entity"]
 infrastructure: ["client", "adapter", "gateway"]

 # External service detection
 external_services:
 # Detect from import patterns
 patterns:
 stripe: ["stripe"]
 aws: ["boto3", "aws_sdk"]
 redis: ["redis", "aioredis"]
 postgres: ["psycopg", "asyncpg", "sqlalchemy"]

 # Output settings
 output:
 default_format: "mermaid"
 include_metrics: false # Include LOC, complexity, etc.`
```

---

### Security Considerations

- Read-only analysis of codebase
 
- May reveal system architecture in outputs
 
- No external network access required
 
---

### Dependencies

#### Required

- `tree-sitter` - Code parsing
 
#### Optional

- `graphviz` - For DOT/SVG/PNG output
 
- `plantuml` - For PlantUML rendering
 
---

### Open Questions

- Real-time updates: Should diagrams update as files change?
 
- Diagram storage: Where to persist generated diagrams?
 
- Interactive diagrams: Support for clickable/zoomable output?
 
- Custom styling: Allow custom themes/colors?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Tool Codebase Search
 tools

Priority: P0 (Foundation)

Status: Draft

Module: `amplifier-module-tool-codebase-search`

### Overview

Semantic and structural search across codebases, documentation, and linked systems. Goes beyond grep/ripgrep by understanding code structure, natural language queries, and cross-referencing multiple data sources.

#### Value Proposition

 | 
 
 | Without | With

 | `grep -r "auth timeout"` â†’ 500 results, mostly noise | "Where do we handle authentication timeouts?" â†’ 3 relevant files with context
 
 | Manual cross-referencing between code, docs, tickets | Single query spans code + docs + tickets + Slack
 
 | Lost tribal knowledge | "Why was this implemented this way?" â†’ Links to original PR, discussion, decision

#### Use Cases

- Code discovery: "Find all API endpoints that require admin permissions"
 
- Impact analysis: "What code paths touch the user's email address?"
 
- Historical context: "Why does this function have this weird edge case?"
 
- Onboarding: "How does the payment flow work?"
 
- Debugging: "Where is this error message defined and when is it thrown?"
 
---

### Contract

#### Tool Definition

 python
 Copy

`TOOL_DEFINITION = {
 "name": "codebase_search",
 "description": """
 Search across the codebase, documentation, and linked systems using natural language
 or structured queries. Returns relevant code snippets, files, and cross-references.

 Use for:
 - Finding code by description ("authentication handling")
 - Understanding code relationships ("what calls this function")
 - Historical context ("why was this changed")
 - Cross-system search (code + docs + tickets)
 """,
 "parameters": {
 "type": "object",
 "properties": {
 "query": {
 "type": "string",
 "description": "Natural language query or structured search"
 },
 "scope": {
 "type": "string",
 "enum": ["code", "docs", "tickets", "discussions", "all"],
 "default": "all",
 "description": "Limit search to specific sources"
 },
 "file_patterns": {
 "type": "array",
 "items": {"type": "string"},
 "description": "Glob patterns to filter files (e.g., ['*.py', 'src/**'])"
 },
 "search_type": {
 "type": "string",
 "enum": ["semantic", "structural", "literal", "hybrid"],
 "default": "hybrid",
 "description": "Search strategy"
 },
 "include_context": {
 "type": "boolean",
 "default": true,
 "description": "Include surrounding code context and cross-references"
 },
 "max_results": {
 "type": "integer",
 "default": 10,
 "description": "Maximum results to return"
 }
 },
 "required": ["query"]
 }
}`
```

#### Input Schema

 python
 Copy

`@dataclass
class CodebaseSearchInput:
 query: str # Natural language or structured query
 scope: Scope = Scope.ALL # code | docs | tickets | discussions | all
 file_patterns: list[str] | None # Glob patterns to filter
 search_type: SearchType = HYBRID # semantic | structural | literal | hybrid
 include_context: bool = True # Include surrounding context
 max_results: int = 10 # Max results`
```

#### Output Schema

 python
 Copy

`@dataclass
class SearchResult:
 source_type: str # "code" | "doc" | "ticket" | "discussion"
 location: str # File path or URL
 snippet: str # Matched content
 relevance_score: float # 0.0 - 1.0
 context: ResultContext | None # Surrounding context if requested
 cross_references: list[CrossRef] # Related items

@dataclass
class ResultContext:
 before: str # Lines before match
 after: str # Lines after match
 file_summary: str # What this file does
 related_symbols: list[str] # Functions/classes in same file

@dataclass
class CrossRef:
 ref_type: str # "calls" | "called_by" | "imports" | "ticket" | "pr" | "doc"
 target: str # Target location
 description: str # Human-readable description

@dataclass
class CodebaseSearchOutput:
 results: list[SearchResult]
 query_interpretation: str # How the query was understood
 search_stats: SearchStats # Performance metrics
 suggestions: list[str] # Related queries to try`
```

#### Events Emitted

 | 
 
 | Event | When | Data

 | `tool:codebase_search:start` | Search begins | query, scope, search_type
 
 | `tool:codebase_search:index_hit` | Index lookup | index_type, hit_count
 
 | `tool:codebase_search:complete` | Search done | result_count, duration_ms
 
 | `tool:codebase_search:error` | Search failed | error_type, message

---

### Architecture

#### Component Diagram

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ tool-codebase-search â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Query â”‚â”€â”€â”€â–¶â”‚ Search â”‚â”€â”€â”€â–¶â”‚ Result â”‚ â”‚
â”‚ â”‚ Analyzer â”‚ â”‚ Executor â”‚ â”‚ Ranker â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Code â”‚ â”‚ Doc â”‚ â”‚ External â”‚ â”‚
â”‚ â”‚ Index â”‚ â”‚ Index â”‚ â”‚ Connectors â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ TreeSitter â”‚ â”‚ Markdown â”‚ â”‚ JIRA/Slack â”‚ â”‚
â”‚ â”‚ + Embeddingsâ”‚ â”‚ + Embeddingsâ”‚ â”‚ APIs â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Internal Components

#### 1. Query Analyzer

Interprets natural language queries into structured search operations:

 python
 Copy

`class QueryAnalyzer:
 """
 Transforms natural language into search operations.

 Examples:
 - "authentication timeout" â†’ semantic search for concept
 - "function handle_auth" â†’ structural search for symbol
 - "JIRA-123" â†’ literal search + external lookup
 - "where do we validate emails" â†’ hybrid (semantic + structural)
 """

 def analyze(self, query: str) -> AnalyzedQuery:
 # Detect query intent
 intent = self._classify_intent(query) # discovery | impact | history | debug

 # Extract search terms
 terms = self._extract_terms(query)

 # Determine optimal search strategy
 strategy = self._select_strategy(intent, terms)

 return AnalyzedQuery(intent, terms, strategy)`
```

#### 2. Code Index

Maintains searchable index of codebase:

 python
 Copy

`class CodeIndex:
 """
 Multi-layer code index:
 - Symbol index (TreeSitter): functions, classes, variables
 - Semantic index (embeddings): conceptual similarity
 - Literal index (trigram): exact text matching
 - Graph index: call relationships, imports
 """

 def __init__(self, root_path: Path, config: IndexConfig):
 self.symbol_index = SymbolIndex(root_path) # TreeSitter-based
 self.semantic_index = SemanticIndex(root_path) # Embedding-based
 self.literal_index = LiteralIndex(root_path) # Trigram-based
 self.graph_index = GraphIndex(root_path) # Relationship-based

 async def search(self, query: AnalyzedQuery) -> list[CodeMatch]:
 # Execute appropriate indexes based on query strategy
 results = []

 if query.strategy.use_semantic:
 results.extend(await self.semantic_index.search(query.terms))

 if query.strategy.use_structural:
 results.extend(await self.symbol_index.search(query.terms))

 if query.strategy.use_literal:
 results.extend(await self.literal_index.search(query.terms))

 # Enrich with relationships
 for result in results:
 result.relationships = await self.graph_index.get_relationships(result.symbol)

 return results`
```

#### 3. External Connectors

Integrates with external systems:

 python
 Copy

`class ExternalConnectors:
 """
 Connectors for external data sources.
 Each connector implements SearchableSource interface.
 """

 def __init__(self, config: ConnectorsConfig):
 self.connectors = {}

 if config.jira:
 self.connectors['jira'] = JiraConnector(config.jira)
 if config.slack:
 self.connectors['slack'] = SlackConnector(config.slack)
 if config.confluence:
 self.connectors['confluence'] = ConfluenceConnector(config.confluence)
 if config.github:
 self.connectors['github'] = GitHubConnector(config.github)

 async def search(self, query: AnalyzedQuery, sources: list[str]) -> list[ExternalMatch]:
 tasks = [
 self.connectors[source].search(query)
 for source in sources
 if source in self.connectors
 ]
 results = await asyncio.gather(*tasks, return_exceptions=True)
 return flatten_valid(results)`
```

#### 4. Result Ranker

Combines and ranks results from all sources:

 python
 Copy

`class ResultRanker:
 """
 Ranks and deduplicates results across all sources.
 Uses multiple signals for relevance scoring.
 """

 def rank(self, results: list[SearchResult], query: AnalyzedQuery) -> list[SearchResult]:
 for result in results:
 result.relevance_score = self._compute_score(result, query)

 # Sort by relevance
 ranked = sorted(results, key=lambda r: r.relevance_score, reverse=True)

 # Deduplicate (same content from different indexes)
 deduped = self._deduplicate(ranked)

 # Add cross-references between results
 enriched = self._add_cross_references(deduped)

 return enriched

 def _compute_score(self, result: SearchResult, query: AnalyzedQuery) -> float:
 """
 Scoring factors:
 - Text similarity (semantic or literal match quality)
 - Recency (recently modified files ranked higher)
 - Centrality (highly connected code ranked higher)
 - Query-type match (structural query + function match = boost)
 """
 score = result.base_score
 score *= self._recency_factor(result)
 score *= self._centrality_factor(result)
 score *= self._query_type_factor(result, query)
 return score`
```

#### Data Flow

 text
 Copy

`User Query
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Query Analyzer â”‚ â”€â”€ Classify intent, extract terms, select strategy
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Search Executor â”‚ â”€â”€ Fan out to appropriate indexes/connectors
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â–¼ â–¼ â–¼ â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Code â”‚ â”‚ Doc â”‚ â”‚ JIRA â”‚ â”‚ Slack â”‚
â”‚ Index â”‚ â”‚ Index â”‚ â”‚Connectorâ”‚ â”‚Connectorâ”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
 â”‚ â”‚ â”‚ â”‚
 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Result Ranker â”‚ â”€â”€ Combine, rank, dedupe, enrich
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
 Final Results`
```

---

### Configuration

 yaml
 Copy

`# Module configuration
tool-codebase-search:
 # Indexing configuration
 index:
 root_paths:
 - "." # Current repo
 - "../shared-libs" # Shared libraries
 exclude_patterns:
 - "node_modules/**"
 - ".git/**"
 - "**/*.min.js"

 # Index types to build
 indexes:
 symbol: true # TreeSitter symbol index
 semantic: true # Embedding-based semantic index
 literal: true # Trigram literal index
 graph: true # Call graph index

 # Embedding configuration (for semantic search)
 embeddings:
 model: "text-embedding-3-small" # OpenAI embedding model
 chunk_size: 500 # Tokens per chunk
 chunk_overlap: 50 # Overlap between chunks

 # Incremental update settings
 update:
 watch: true # Watch for file changes
 debounce_ms: 1000 # Debounce rapid changes

 # External connectors
 connectors:
 jira:
 enabled: true
 base_url: "${JIRA_URL}"
 auth_token: "${JIRA_TOKEN}"
 project_keys: ["PROJ", "PLATFORM"]

 slack:
 enabled: true
 auth_token: "${SLACK_TOKEN}"
 channels: ["#engineering", "#incidents"]

 github:
 enabled: true
 auth_token: "${GITHUB_TOKEN}"
 include_prs: true
 include_issues: true
 include_discussions: true

 # Search behavior
 search:
 default_scope: "all"
 default_max_results: 10
 context_lines_before: 5
 context_lines_after: 5

 # Ranking weights
 ranking:
 recency_weight: 0.2
 centrality_weight: 0.3
 match_quality_weight: 0.5

 # Performance limits
 timeout_ms: 10000
 max_files_to_scan: 10000

 # Caching
 cache:
 enabled: true
 ttl_seconds: 300 # Cache results for 5 minutes
 max_entries: 1000`
```

---

### Examples

#### Example 1: Natural Language Code Discovery

 python
 Copy

`# Input
{
 "query": "Where do we validate user email addresses?",
 "scope": "code"
}

# Output
{
 "results": [
 {
 "source_type": "code",
 "location": "src/validators/email.py:42",
 "snippet": "def validate_email(email: str) -> ValidationResult:\n \"\"\"Validates email format and domain.\"\"\"\n ...",
 "relevance_score": 0.95,
 "context": {
 "file_summary": "Email validation utilities",
 "related_symbols": ["validate_email", "EmailValidator", "VALID_DOMAINS"]
 },
 "cross_references": [
 {"ref_type": "called_by", "target": "src/api/users.py:create_user", "description": "Called during user registration"},
 {"ref_type": "called_by", "target": "src/api/settings.py:update_email", "description": "Called when updating email"}
 ]
 },
 {
 "source_type": "code",
 "location": "src/models/user.py:78",
 "snippet": "@validator('email')\ndef email_must_be_valid(cls, v):\n ...",
 "relevance_score": 0.88,
 "context": {...},
 "cross_references": [...]
 }
 ],
 "query_interpretation": "Searching for email validation logic in code",
 "suggestions": ["Where do we send verification emails?", "Email validation rules"]
}`
```

#### Example 2: Historical Context Search

 python
 Copy

`# Input
{
 "query": "Why was retry logic added to payment processing?",
 "scope": "all",
 "search_type": "semantic"
}

# Output
{
 "results": [
 {
 "source_type": "ticket",
 "location": "JIRA-4523",
 "snippet": "Payment failures during peak hours due to gateway timeouts. Adding retry with exponential backoff.",
 "relevance_score": 0.92,
 "cross_references": [
 {"ref_type": "pr", "target": "PR #892", "description": "Implementation PR"},
 {"ref_type": "doc", "target": "docs/payments/reliability.md", "description": "Documentation"}
 ]
 },
 {
 "source_type": "discussion",
 "location": "slack://engineering/p1699234567",
 "snippet": "We're seeing 5% payment failures during sales events. Gateway is timing out under load...",
 "relevance_score": 0.85
 },
 {
 "source_type": "code",
 "location": "src/payments/gateway.py:156",
 "snippet": "# Added retry logic per JIRA-4523\n@retry(max_attempts=3, backoff=exponential)\nasync def process_payment(...):",
 "relevance_score": 0.78
 }
 ],
 "query_interpretation": "Searching for historical context about payment retry implementation"
}`
```

#### Example 3: Impact Analysis

 python
 Copy

`# Input
{
 "query": "What code uses the User.email field?",
 "search_type": "structural"
}

# Output
{
 "results": [
 {
 "source_type": "code",
 "location": "src/models/user.py:23",
 "snippet": "email: EmailStr = Field(...)",
 "relevance_score": 1.0,
 "cross_references": [
 {"ref_type": "read_by", "target": "src/api/users.py:45", "description": "User profile endpoint"},
 {"ref_type": "read_by", "target": "src/notifications/email.py:12", "description": "Email sender"},
 {"ref_type": "written_by", "target": "src/api/users.py:89", "description": "Update email endpoint"},
 {"ref_type": "validated_by", "target": "src/validators/email.py:42", "description": "Email validator"}
 ]
 }
 ],
 "query_interpretation": "Structural analysis of User.email field usage",
 "search_stats": {
 "files_analyzed": 234,
 "references_found": 47,
 "duration_ms": 156
 }
}`
```

---

### Security Considerations

#### Data Access

- Code access: Reads files within configured root paths only
 
- External systems: Uses configured credentials, respects API permissions
 
- Cached data: Cached in memory/disk per configuration, cleared on session end
 
#### Sensitive Data

- Query logging: Queries logged to session events (may contain sensitive terms)
 
- Results: May contain sensitive code snippets
 
- Credentials: External connector credentials stored securely, never logged
 
#### Permissions Model

 python
 Copy

`REQUIRED_CAPABILITIES = [
 "filesystem:read", # Read codebase files
 "network:external", # Connect to external APIs (if connectors enabled)
]

# Optional capabilities based on connectors
OPTIONAL_CAPABILITIES = {
 "jira": "network:jira",
 "slack": "network:slack",
 "github": "network:github",
}`
```

#### Risk Mitigations

 | 
 
 | Risk | Mitigation

 | Exposing sensitive code in results | Results filtered by session's file access permissions
 
 | Credential leakage | Credentials never included in results or logs
 
 | Excessive resource use | Configurable timeouts and file limits
 
 | Stale cache serving wrong data | Cache keyed by query + file hashes, invalidated on changes

---

### Testing Strategy

#### Unit Tests

 python
 Copy

`# Query analyzer tests
def test_query_analyzer_detects_semantic_intent():
 analyzer = QueryAnalyzer()
 result = analyzer.analyze("where do we handle authentication")
 assert result.intent == QueryIntent.DISCOVERY
 assert result.strategy.use_semantic == True

def test_query_analyzer_detects_structural_intent():
 analyzer = QueryAnalyzer()
 result = analyzer.analyze("function validate_email")
 assert result.intent == QueryIntent.SYMBOL_LOOKUP
 assert result.strategy.use_structural == True

# Result ranking tests
def test_ranker_prioritizes_recent_files():
 ...

def test_ranker_deduplicates_same_content():
 ...`
```

#### Integration Tests

 python
 Copy

`# Full search flow tests
async def test_semantic_search_finds_relevant_code():
 tool = CodebaseSearchTool(test_config)
 await tool.build_index(TEST_REPO_PATH)

 result = await tool.execute({
 "query": "email validation",
 "scope": "code"
 })

 assert len(result.results) > 0
 assert "validate" in result.results[0].snippet.lower()
 assert "email" in result.results[0].snippet.lower()

async def test_external_connector_integration():
 # Requires mock JIRA/Slack servers
 ...`
```

#### Performance Tests

 python
 Copy

`def test_search_performance_under_load():
 """Search should complete within timeout on large codebase."""
 # 100k file synthetic codebase
 result = tool.execute({"query": "authentication"})
 assert result.search_stats.duration_ms < 10000

def test_index_incremental_update_performance():
 """Index update should be fast for single file changes."""
 ...`
```

---

### Implementation Notes

#### Index Storage

- Symbol index: SQLite database with FTS5 for text search
 
- Semantic index: Vector database (could use Chroma, FAISS, or SQLite with vector extension)
 
- Graph index: SQLite with adjacency list tables
 
- All indexes stored in `.amplifier/indexes/` directory
 
#### Incremental Updates

- File watcher monitors for changes
 
- On change: re-index only affected files
 
- Graph updates propagate to dependent files
 
- Embedding regeneration batched for efficiency
 
#### Embedding Strategy

- Code chunked by logical units (functions, classes) when possible
 
- Fall back to token-based chunking for long files
 
- Metadata (file path, language, symbols) included in embedding context
 
---

### Dependencies

#### Required

- `tree-sitter` + language grammars - Code parsing
 
- `tiktoken` - Token counting for chunking
 
- `aiosqlite` - Async SQLite for indexes
 
#### Optional (based on configuration)

- `openai` - For embeddings (or alternative embedding provider)
 
- `chromadb` or `faiss` - For vector search (alternative to SQLite vectors)
 
- `jira` - JIRA connector
 
- `slack-sdk` - Slack connector
 
- `PyGithub` - GitHub connector
 
---

### Open Questions

- Embedding provider: Should we support multiple embedding providers or standardize on one?
 
 - Option A: OpenAI embeddings only (simpler, consistent quality)

 - Option B: Pluggable providers (flexibility, cost control)

- Index persistence: Where should indexes live?
 
 - Option A: Project-local (`.amplifier/indexes/`) - isolated but duplicated

 - Option B: User-level cache (`~/.amplifier/indexes/`) - shared but complex invalidation

- Real-time vs batch indexing: Should we support real-time indexing for very large codebases?
 
 - Option A: Always real-time (simpler UX, may be slow)

 - Option B: Background batch with staleness indicator

- Cross-repo search: Should a single search span multiple repositories?
 
 - Option A: Single repo per search (simpler)

 - Option B: Multi-repo with repo prefixes (more powerful)

- Result format: How much context to include by default?
 
 - Trade-off: More context = more useful but more tokens consumed

---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Tool Collaborative
 tools

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-tool-collaborative`

### Overview

A tool for coordinating multiple specialized agents on complex tasks. Enables parallel specialist analysis, hierarchical delegation, and synthesis of multiple perspectives - all invoked as a tool call from the main session.

#### Why a Tool, Not an Orchestrator?

Multi-agent collaboration is policy (when to collaborate, which agents, how to synthesize) not mechanism. The kernel orchestrator should stay simple (loop-basic/streaming). Sophisticated coordination patterns belong at the tool layer where:

- The agent decides when collaboration is valuable
 
- Collaboration can be mixed with normal conversation
 
- Patterns can evolve without touching the kernel
 
- It composes naturally with other tools
 
#### Value Proposition

 | 
 
 | Without | With

 | Single generalist perspective | Multiple specialist perspectives
 
 | Sequential analysis | Parallel execution
 
 | Manual coordination | Automated synthesis
 
 | Context overload | Focused context per specialist

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Main Session (loop-basic) â”‚
â”‚ â”‚
â”‚ Agent: "This needs multiple perspectives..." â”‚
â”‚ â”‚ â”‚
â”‚ â””â”€â–º tool-collaborative.execute(...) â”‚
â”‚ â”‚ â”‚
â”‚ â”œâ”€â–º spawn: security-specialist â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”œâ”€â–º spawn: performance-specialist â”€â”€â”€â”¼â”€â–º parallel â”‚
â”‚ â”œâ”€â–º spawn: maintainability-specialistâ”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â””â”€â–º coordinator synthesizes â”€â”€â–º return result â”‚
â”‚ â”‚
â”‚ Agent: "Here's the comprehensive analysis..." â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Tool Contract

 yaml
 Copy

`name: tool-collaborative
description: Coordinate multiple specialized agents on a task

parameters:
 task:
 type: string
 description: The task for agents to collaborate on
 required: true

 agents:
 type: array
 description: Agent configurations to involve
 required: true
 items:
 type: object
 properties:
 name:
 type: string
 description: Identifier for this agent
 role:
 type: string
 description: The specialist role (e.g., "security", "performance")
 config:
 type: object
 description: Agent config (providers, tools, system prompt)
 focus:
 type: string
 description: Specific focus area for this agent

 mode:
 type: string
 enum: [parallel, sequential, hierarchical]
 default: parallel
 description: How agents execute

 synthesis:
 type: string
 enum: [coordinator, vote, merge, best_of]
 default: coordinator
 description: How to combine agent outputs

 coordinator_config:
 type: object
 description: Config for synthesis coordinator (if synthesis=coordinator)

 context:
 type: object
 description: Shared context passed to all agents

returns:
 type: object
 properties:
 result:
 type: string
 description: Synthesized output
 contributions:
 type: array
 description: Individual agent contributions
 consensus:
 type: object
 description: Agreement/disagreement analysis
 metadata:
 type: object
 description: Execution stats (agents, timing, tokens)`
```

---

### Implementation

 python
 Copy

`# tool.py

from amplifier_core import AmplifierSession
import asyncio
from dataclasses import dataclass

@dataclass
class Contribution:
 agent: str
 role: str
 response: str
 confidence: float | None = None
 tokens_used: int = 0

class CollaborativeTool:
 """Tool for multi-agent collaboration."""

 name = "tool-collaborative"

 async def execute(
 self,
 task: str,
 agents: list[dict],
 mode: str = "parallel",
 synthesis: str = "coordinator",
 coordinator_config: dict | None = None,
 context: dict | None = None
 ) -> dict:
 """Execute collaborative task."""

 # Phase 1: Execute agents
 if mode == "parallel":
 contributions = await self._parallel_execution(task, agents, context)
 elif mode == "sequential":
 contributions = await self._sequential_execution(task, agents, context)
 else:
 contributions = await self._hierarchical_execution(task, agents, context)

 # Phase 2: Synthesize
 if synthesis == "coordinator":
 result = await self._coordinator_synthesis(
 task, contributions, coordinator_config
 )
 elif synthesis == "vote":
 result = await self._voting_synthesis(contributions)
 elif synthesis == "merge":
 result = await self._merge_synthesis(contributions)
 else: # best_of
 result = await self._best_of_synthesis(contributions)

 return {
 "result": result,
 "contributions": [c.__dict__ for c in contributions],
 "consensus": self._analyze_consensus(contributions),
 "metadata": {
 "agents_count": len(agents),
 "mode": mode,
 "synthesis": synthesis,
 "total_tokens": sum(c.tokens_used for c in contributions)
 }
 }

 async def _parallel_execution(
 self,
 task: str,
 agents: list[dict],
 context: dict | None
 ) -> list[Contribution]:
 """Execute all agents in parallel."""

 async def run_agent(agent_def: dict) -> Contribution:
 config = self._build_agent_config(agent_def)

 prompt = self._build_agent_prompt(
 task=task,
 role=agent_def.get("role", "specialist"),
 focus=agent_def.get("focus"),
 context=context
 )

 async with AmplifierSession(config=config) as session:
 response = await session.execute(prompt)

 return Contribution(
 agent=agent_def["name"],
 role=agent_def.get("role", "specialist"),
 response=response.text,
 tokens_used=response.usage.total_tokens
 )

 contributions = await asyncio.gather(*[
 run_agent(agent) for agent in agents
 ])

 return list(contributions)

 async def _sequential_execution(
 self,
 task: str,
 agents: list[dict],
 context: dict | None
 ) -> list[Contribution]:
 """Execute agents sequentially, each seeing previous results."""

 contributions = []
 accumulated_context = context or {}

 for agent_def in agents:
 config = self._build_agent_config(agent_def)

 # Include previous contributions in context
 prompt = self._build_agent_prompt(
 task=task,
 role=agent_def.get("role", "specialist"),
 focus=agent_def.get("focus"),
 context=accumulated_context,
 previous_contributions=contributions
 )

 async with AmplifierSession(config=config) as session:
 response = await session.execute(prompt)

 contribution = Contribution(
 agent=agent_def["name"],
 role=agent_def.get("role", "specialist"),
 response=response.text,
 tokens_used=response.usage.total_tokens
 )
 contributions.append(contribution)

 # Add to accumulated context
 accumulated_context[f"{agent_def['name']}_analysis"] = response.text

 return contributions

 async def _hierarchical_execution(
 self,
 task: str,
 agents: list[dict],
 context: dict | None
 ) -> list[Contribution]:
 """Coordinator delegates subtasks to specialists."""

 # First agent is coordinator
 coordinator = agents[0]
 specialists = agents[1:]

 # Coordinator decomposes task
 decomposition = await self._decompose_task(
 task, coordinator, specialists, context
 )

 # Specialists execute their subtasks in parallel
 specialist_tasks = []
 for assignment in decomposition["assignments"]:
 specialist = next(
 (s for s in specialists if s["name"] == assignment["agent"]),
 None
 )
 if specialist:
 specialist_tasks.append(
 self._run_specialist(assignment["subtask"], specialist, context)
 )

 specialist_contributions = await asyncio.gather(*specialist_tasks)

 # Coordinator contribution includes orchestration
 coordinator_contribution = Contribution(
 agent=coordinator["name"],
 role="coordinator",
 response=decomposition["plan"],
 tokens_used=decomposition["tokens_used"]
 )

 return [coordinator_contribution] + list(specialist_contributions)

 async def _coordinator_synthesis(
 self,
 task: str,
 contributions: list[Contribution],
 coordinator_config: dict | None
 ) -> str:
 """Use coordinator agent to synthesize contributions."""

 config = coordinator_config or self._default_coordinator_config()

 prompt = f"""
You are synthesizing contributions from multiple specialist agents.

## Original Task
{task}

## Specialist Contributions

{self._format_contributions(contributions)}

## Your Task
Synthesize these perspectives into a unified, coherent response:
1. Identify key agreements across specialists
2. Highlight important disagreements or tensions
3. Resolve conflicts with reasoned judgment
4. Provide actionable conclusions
5. Note any gaps or areas needing further analysis

Provide a comprehensive synthesis that leverages the strengths of each perspective.
"""

 async with AmplifierSession(config=config) as session:
 response = await session.execute(prompt)
 return response.text

 async def _voting_synthesis(
 self,
 contributions: list[Contribution]
 ) -> str:
 """Synthesize by identifying consensus and majority views."""

 # Extract key points from each contribution
 # Identify overlapping conclusions
 # Weight by confidence if available

 consensus_points = self._extract_consensus(contributions)
 disagreements = self._extract_disagreements(contributions)

 return f"""
## Consensus ({len(consensus_points)} points)
{self._format_points(consensus_points)}

## Divergent Views
{self._format_disagreements(disagreements)}

## Majority Conclusion
{self._determine_majority(contributions)}
"""

 async def _merge_synthesis(
 self,
 contributions: list[Contribution]
 ) -> str:
 """Simple merge of all contributions."""

 sections = []
 for c in contributions:
 sections.append(f"### {c.agent} ({c.role})\n\n{c.response}")

 return "\n\n---\n\n".join(sections)

 def _build_agent_prompt(
 self,
 task: str,
 role: str,
 focus: str | None,
 context: dict | None,
 previous_contributions: list[Contribution] | None = None
 ) -> str:
 """Build prompt for specialist agent."""

 prompt_parts = [f"## Task\n{task}"]

 if focus:
 prompt_parts.append(f"## Your Focus\n{focus}")

 if context:
 prompt_parts.append(f"## Context\n{self._format_context(context)}")

 if previous_contributions:
 prompt_parts.append(
 f"## Previous Analysis\n{self._format_contributions(previous_contributions)}"
 )

 prompt_parts.append(f"""
## Instructions
You are a {role} specialist. Analyze the task from your expert perspective.
Provide specific, actionable insights based on your expertise.
Be thorough but focused on your domain.
""")

 return "\n\n".join(prompt_parts)

 def _format_contributions(self, contributions: list[Contribution]) -> str:
 """Format contributions for synthesis prompt."""

 formatted = []
 for c in contributions:
 formatted.append(f"### {c.agent} ({c.role})\n{c.response}")
 return "\n\n".join(formatted)

 def _analyze_consensus(self, contributions: list[Contribution]) -> dict:
 """Analyze agreement/disagreement across contributions."""

 # Simple heuristic - could be enhanced with AI analysis
 return {
 "agents_count": len(contributions),
 "has_consensus": len(contributions) <= 1, # Placeholder
 "agreement_score": None, # Could compute similarity
 "key_agreements": [],
 "key_disagreements": []
 }

 def _default_coordinator_config(self) -> dict:
 """Default config for synthesis coordinator."""

 return {
 "session": {
 "orchestrator": "loop-basic",
 "context": "context-simple"
 },
 "providers": [{
 "module": "provider-anthropic",
 "source": "git+https://github.com/microsoft/amplifier-module-provider-anthropic@main",
 "config": {
 "model": "claude-sonnet-4-5",
 "temperature": 0.3 # Balanced for synthesis
 }
 }]
 }`
```

---

### Collaboration Modes

#### Parallel Mode

All agents execute simultaneously, then results synthesized.

 yaml
 Copy

`# Best for: Independent specialist perspectives
mode: parallel

agents:
 - name: security-reviewer
 role: security
 focus: "vulnerabilities, auth, injection"

 - name: performance-reviewer
 role: performance
 focus: "complexity, caching, queries"

 - name: maintainability-reviewer
 role: maintainability
 focus: "patterns, coupling, readability"

synthesis: coordinator`
```

#### Sequential Mode

Agents execute in order, each seeing previous contributions.

 yaml
 Copy

`# Best for: Building analysis, refinement chains
mode: sequential

agents:
 - name: analyzer
 role: analysis
 focus: "understand the problem"

 - name: designer
 role: design
 focus: "propose solution based on analysis"

 - name: critic
 role: critique
 focus: "evaluate design, find gaps"

 - name: refiner
 role: refinement
 focus: "improve design based on critique"

synthesis: merge # Keep the chain visible`
```

#### Hierarchical Mode

First agent coordinates, delegates to specialists.

 yaml
 Copy

`# Best for: Complex tasks needing decomposition
mode: hierarchical

agents:
 - name: coordinator
 role: coordinator
 focus: "decompose task, assign to specialists, synthesize"

 - name: backend-specialist
 role: backend
 focus: "API, database, services"

 - name: frontend-specialist
 role: frontend
 focus: "UI, state, components"

 - name: infra-specialist
 role: infrastructure
 focus: "deployment, scaling, monitoring"

synthesis: coordinator # Coordinator synthesizes at end`
```

---

### Synthesis Strategies

 | 
 
 | Strategy | Description | Best For

 | `coordinator` | Dedicated agent synthesizes | Complex integration, nuanced judgment
 
 | `vote` | Identify consensus/majority | Clear yes/no decisions
 
 | `merge` | Concatenate all contributions | Preserving all perspectives
 
 | `best_of` | Select highest quality/confidence | When one answer needed

---

### Usage Examples

#### PR Review with Multiple Perspectives

 python
 Copy

`result = await tool_collaborative.execute(
 task=f"Review PR #{pr_number}: {pr_description}\n\nDiff:\n{diff}",
 agents=[
 {
 "name": "security-reviewer",
 "role": "security",
 "config": {
 "providers": [{
 "module": "provider-anthropic",
 "config": {"temperature": 0.1}
 }]
 },
 "focus": "Security vulnerabilities, auth issues, injection risks"
 },
 {
 "name": "quality-reviewer",
 "role": "code-quality",
 "config": {
 "providers": [{
 "module": "provider-anthropic",
 "config": {"temperature": 0.2}
 }]
 },
 "focus": "Code patterns, maintainability, SOLID principles"
 },
 {
 "name": "test-reviewer",
 "role": "testing",
 "focus": "Test coverage, edge cases, test quality"
 }
 ],
 mode="parallel",
 synthesis="coordinator"
)`
```

#### Architecture Decision with Debate

 python
 Copy

`result = await tool_collaborative.execute(
 task="Should we use microservices or monolith for the new payment system?",
 agents=[
 {
 "name": "microservices-advocate",
 "role": "advocate",
 "focus": "Argue FOR microservices architecture"
 },
 {
 "name": "monolith-advocate",
 "role": "advocate",
 "focus": "Argue FOR monolith architecture"
 },
 {
 "name": "pragmatist",
 "role": "evaluator",
 "focus": "Evaluate both arguments, consider team context"
 }
 ],
 mode="sequential", # Each sees previous arguments
 synthesis="coordinator",
 coordinator_config={
 "providers": [{
 "module": "provider-anthropic",
 "config": {
 "model": "claude-opus-4", # Strong reasoning for decision
 "temperature": 0.3
 }
 }]
 },
 context={
 "team_size": 8,
 "timeline": "6 months",
 "scale_requirements": "10k requests/day initially"
 }
)`
```

---

### Events

 | 
 
 | Event | Description | Data

 | `tool:collaborative:start` | Collaboration started | task, agents, mode
 
 | `tool:collaborative:agent:start` | Agent execution started | agent, role
 
 | `tool:collaborative:agent:complete` | Agent finished | agent, tokens
 
 | `tool:collaborative:synthesis:start` | Synthesis started | strategy
 
 | `tool:collaborative:complete` | Collaboration complete | agents_count, total_tokens

---

### Configuration

 yaml
 Copy

`tools:
 - module: tool-collaborative
 source: git+https://github.com/microsoft/amplifier-module-tool-collaborative@main
 config:
 # Defaults
 default_mode: parallel
 default_synthesis: coordinator

 # Limits
 max_agents: 5
 max_parallel: 3
 agent_timeout: 300s

 # Coordinator defaults
 coordinator:
 model: claude-sonnet-4-5
 temperature: 0.3`
```

---

### Comparison with Recipes

 | 
 
 | Aspect | tool-collaborative | recipes

 | Pattern | Parallel specialists | Sequential steps
 
 | Agents | Multiple simultaneous | One per step
 
 | Context flow | Shared to all | Accumulated step-by-step
 
 | Best for | Multiple perspectives | Linear workflows
 
 | Synthesis | Built-in coordinator | Final step handles it

Both are tools that spawn sub-agents. Use recipes for workflows, collaborative for multi-perspective analysis.

---

### Dependencies

#### Required

- amplifier-core (AmplifierSession for sub-agents)
 
- asyncio (parallel execution)
 
#### Optional

- None
 
---

### Open Questions

- Confidence scoring: Should agents report confidence levels?
 
- Disagreement resolution: Automated resolution or surface to user?
 
- Cost optimization: Route simpler subtasks to cheaper models?
 
- Caching: Cache specialist results for similar tasks?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification (converted from orchestrator to tool)

 Tool Dependency Graph
 tools

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-tool-dependency-graph`

### Overview

Analyzes and visualizes code dependencies at multiple levels: imports, function calls, class inheritance, and module relationships. Essential for impact analysis, refactoring planning, and understanding complex codebases.

#### Value Proposition

 | 
 
 | Without | With

 | Manual tracing through files to find callers | `get_callers("PaymentGateway.process")` â†’ instant list
 
 | Risky refactoring without knowing impact | "What breaks if I change this?" â†’ complete dependency tree
 
 | Circular dependency surprises at runtime | Static analysis catches cycles before they cause problems
 
 | Architecture documentation always stale | Live dependency graphs always current

#### Use Cases

- Impact analysis: "What code is affected if I change this function?"
 
- Refactoring safety: "Can I safely rename/move this class?"
 
- Dead code detection: "What code has no callers?"
 
- Architecture visualization: "Show me the dependency structure of this module"
 
- Circular dependency detection: "Are there any circular imports?"
 
- Coupling analysis: "Which modules are most tightly coupled?"
 
---

### Contract

#### Tool Definition

 python
 Copy

`TOOL_DEFINITION = {
 "name": "dependency_graph",
 "description": """
 Analyze code dependencies: imports, calls, inheritance, and module relationships.

 Operations:
 - get_dependents: What depends on this symbol/file? (callers, importers)
 - get_dependencies: What does this symbol/file depend on? (callees, imports)
 - get_graph: Full dependency graph for a scope
 - find_cycles: Detect circular dependencies
 - find_dead_code: Find code with no dependents
 - coupling_analysis: Measure coupling between modules

 Use for impact analysis, refactoring, and architecture understanding.
 """,
 "parameters": {
 "type": "object",
 "properties": {
 "operation": {
 "type": "string",
 "enum": ["get_dependents", "get_dependencies", "get_graph", "find_cycles", "find_dead_code", "coupling_analysis"],
 "description": "Analysis operation to perform"
 },
 "target": {
 "type": "string",
 "description": "Symbol (function, class) or file path to analyze"
 },
 "scope": {
 "type": "string",
 "description": "Limit analysis to path pattern (e.g., 'src/', '**/*.py')"
 },
 "depth": {
 "type": "integer",
 "default": 3,
 "description": "Maximum depth for recursive analysis"
 },
 "include_external": {
 "type": "boolean",
 "default": false,
 "description": "Include external library dependencies"
 },
 "dependency_types": {
 "type": "array",
 "items": {
 "type": "string",
 "enum": ["import", "call", "inheritance", "type_reference", "all"]
 },
 "default": ["all"],
 "description": "Types of dependencies to include"
 },
 "output_format": {
 "type": "string",
 "enum": ["tree", "list", "graph", "mermaid"],
 "default": "tree",
 "description": "Output format for results"
 }
 },
 "required": ["operation"]
 }
}`
```

#### Input Schema

 python
 Copy

`@dataclass
class DependencyGraphInput:
 operation: Operation # get_dependents | get_dependencies | get_graph | find_cycles | find_dead_code | coupling_analysis
 target: str | None = None # Symbol or file path
 scope: str | None = None # Path pattern to limit analysis
 depth: int = 3 # Max recursion depth
 include_external: bool = False # Include third-party dependencies
 dependency_types: list[str] = field(default_factory=lambda: ["all"])
 output_format: str = "tree" # tree | list | graph | mermaid`
```

#### Output Schema

 python
 Copy

`@dataclass
class DependencyGraphOutput:
 operation: str
 target: str | None

 # For get_dependents/get_dependencies
 dependencies: list[Dependency] | None = None

 # For get_graph
 graph: DependencyGraph | None = None

 # For find_cycles
 cycles: list[Cycle] | None = None

 # For find_dead_code
 dead_code: list[DeadCode] | None = None

 # For coupling_analysis
 coupling: CouplingAnalysis | None = None

 # Formatted output
 formatted: str | None = None # Formatted per output_format

 # Stats
 stats: AnalysisStats

@dataclass
class Dependency:
 source: Symbol # Where the dependency originates
 target: Symbol # What it depends on
 type: str # import | call | inheritance | type_reference
 location: Location # File and line
 context: str | None # Code snippet showing the dependency

@dataclass
class Symbol:
 name: str # Function/class/module name
 qualified_name: str # Full path (module.Class.method)
 kind: str # function | class | module | variable
 file_path: str
 line_number: int

@dataclass
class Location:
 file_path: str
 line_number: int
 column: int | None = None

@dataclass
class DependencyGraph:
 nodes: list[GraphNode]
 edges: list[GraphEdge]
 root: str | None # Root node if tree structure

@dataclass
class GraphNode:
 id: str # Unique identifier
 symbol: Symbol
 metadata: dict # Additional info (size, complexity, etc.)

@dataclass
class GraphEdge:
 source_id: str
 target_id: str
 type: str
 weight: int = 1 # Number of dependencies of this type

@dataclass
class Cycle:
 path: list[str] # Symbols in the cycle
 type: str # import | call
 severity: str # error | warning (import cycles more severe)

@dataclass
class DeadCode:
 symbol: Symbol
 kind: str # function | class | module | variable
 reason: str # "No callers found", "Only test references", etc.
 confidence: float # 0-1 confidence this is truly dead

@dataclass
class CouplingAnalysis:
 module_pairs: list[ModuleCoupling]
 metrics: CouplingMetrics

@dataclass
class ModuleCoupling:
 module_a: str
 module_b: str
 coupling_score: float # 0-1, higher = more coupled
 dependency_count: int
 bidirectional: bool # Both depend on each other

@dataclass
class CouplingMetrics:
 average_coupling: float
 max_coupling: float
 highly_coupled_pairs: int # Pairs above threshold
 suggested_refactors: list[str] # Suggestions to reduce coupling

@dataclass
class AnalysisStats:
 files_analyzed: int
 symbols_found: int
 dependencies_found: int
 analysis_time_ms: int`
```

#### Events Emitted

 | 
 
 | Event | When | Data

 | `tool:dependency_graph:start` | Analysis begins | operation, target, scope
 
 | `tool:dependency_graph:parsing` | File parsing | file_path, symbols_found
 
 | `tool:dependency_graph:complete` | Analysis done | stats
 
 | `tool:dependency_graph:error` | Analysis failed | error_type, message

---

### Architecture

#### Component Diagram

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ tool-dependency-graph â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Symbol â”‚â”€â”€â”€â–¶â”‚ Graph â”‚â”€â”€â”€â–¶â”‚ Output â”‚ â”‚
â”‚ â”‚ Resolver â”‚ â”‚ Builder â”‚ â”‚ Formatter â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Python â”‚ â”‚ TypeScript â”‚ â”‚ Other â”‚ â”‚
â”‚ â”‚ Analyzer â”‚ â”‚ Analyzer â”‚ â”‚ Analyzers â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ TreeSitter Parsers â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Internal Components

#### 1. Language-Specific Analyzers

 python
 Copy

`class PythonAnalyzer:
 """
 Python-specific dependency analysis using TreeSitter and AST.
 """

 def __init__(self):
 self.parser = TreeSitterParser("python")

 async def analyze_file(self, file_path: Path) -> FileAnalysis:
 content = file_path.read_text()
 tree = self.parser.parse(content)

 analysis = FileAnalysis(file_path=str(file_path))

 # Extract symbols (functions, classes, variables)
 analysis.symbols = self._extract_symbols(tree, file_path)

 # Extract imports
 analysis.imports = self._extract_imports(tree)

 # Extract function calls
 analysis.calls = self._extract_calls(tree)

 # Extract inheritance
 analysis.inheritance = self._extract_inheritance(tree)

 # Extract type hints
 analysis.type_refs = self._extract_type_references(tree)

 return analysis

 def _extract_imports(self, tree: Tree) -> list[ImportDep]:
 """Extract all import statements."""
 imports = []

 # import x, import x.y
 for node in self._find_nodes(tree, "import_statement"):
 module = self._get_module_name(node)
 imports.append(ImportDep(
 module=module,
 names=None, # Imports whole module
 location=self._get_location(node)
 ))

 # from x import y, z
 for node in self._find_nodes(tree, "import_from_statement"):
 module = self._get_from_module(node)
 names = self._get_imported_names(node)
 imports.append(ImportDep(
 module=module,
 names=names,
 location=self._get_location(node)
 ))

 return imports

 def _extract_calls(self, tree: Tree) -> list[CallDep]:
 """Extract all function/method calls."""
 calls = []

 for node in self._find_nodes(tree, "call"):
 callee = self._resolve_callee(node)
 if callee:
 calls.append(CallDep(
 caller=self._get_enclosing_function(node),
 callee=callee,
 location=self._get_location(node)
 ))

 return calls`
```

#### 2. Graph Builder

 python
 Copy

`class GraphBuilder:
 """
 Builds dependency graph from file analyses.
 Handles cross-file resolution and graph algorithms.
 """

 def __init__(self, analyses: list[FileAnalysis]):
 self.analyses = {a.file_path: a for a in analyses}
 self.symbol_index = self._build_symbol_index()

 def get_dependents(self, target: str, depth: int, types: list[str]) -> list[Dependency]:
 """Find all symbols that depend on target."""
 target_symbol = self._resolve_symbol(target)
 if not target_symbol:
 raise ValueError(f"Symbol not found: {target}")

 dependents = []
 visited = set()

 self._find_dependents_recursive(
 target_symbol, depth, types, dependents, visited
 )

 return dependents

 def get_dependencies(self, target: str, depth: int, types: list[str]) -> list[Dependency]:
 """Find all symbols that target depends on."""
 target_symbol = self._resolve_symbol(target)
 if not target_symbol:
 raise ValueError(f"Symbol not found: {target}")

 dependencies = []
 visited = set()

 self._find_dependencies_recursive(
 target_symbol, depth, types, dependencies, visited
 )

 return dependencies

 def find_cycles(self, scope: str | None = None) -> list[Cycle]:
 """Detect circular dependencies."""
 # Build directed graph
 graph = self._build_adjacency_graph(scope)

 # Find strongly connected components (Tarjan's algorithm)
 sccs = self._find_sccs(graph)

 # SCCs with more than one node are cycles
 cycles = []
 for scc in sccs:
 if len(scc) > 1:
 cycles.append(Cycle(
 path=scc,
 type=self._determine_cycle_type(scc),
 severity="error" if self._is_import_cycle(scc) else "warning"
 ))

 return cycles

 def find_dead_code(self, scope: str | None = None) -> list[DeadCode]:
 """Find symbols with no dependents."""
 dead = []

 for symbol in self._get_symbols_in_scope(scope):
 # Skip entry points and special methods
 if self._is_entry_point(symbol):
 continue

 dependents = self.get_dependents(symbol.qualified_name, depth=1, types=["all"])

 # Filter out test-only references
 non_test_dependents = [d for d in dependents if not self._is_test_file(d.source.file_path)]

 if not non_test_dependents:
 confidence = 1.0
 reason = "No callers found"

 # Lower confidence if there are test references
 if dependents:
 confidence = 0.7
 reason = "Only test references"

 # Lower confidence for certain patterns (callbacks, plugins)
 if self._might_be_dynamic(symbol):
 confidence = 0.5
 reason += " (may be used dynamically)"

 dead.append(DeadCode(
 symbol=symbol,
 kind=symbol.kind,
 reason=reason,
 confidence=confidence
 ))

 return dead

 def coupling_analysis(self, scope: str | None = None) -> CouplingAnalysis:
 """Analyze module coupling."""
 modules = self._get_modules_in_scope(scope)
 pairs = []

 for i, mod_a in enumerate(modules):
 for mod_b in modules[i+1:]:
 # Count dependencies between modules
 a_to_b = self._count_dependencies(mod_a, mod_b)
 b_to_a = self._count_dependencies(mod_b, mod_a)

 if a_to_b > 0 or b_to_a > 0:
 total = a_to_b + b_to_a
 # Normalize by module sizes
 coupling_score = self._calculate_coupling_score(mod_a, mod_b, total)

 pairs.append(ModuleCoupling(
 module_a=mod_a,
 module_b=mod_b,
 coupling_score=coupling_score,
 dependency_count=total,
 bidirectional=a_to_b > 0 and b_to_a > 0
 ))

 # Sort by coupling score
 pairs.sort(key=lambda p: p.coupling_score, reverse=True)

 return CouplingAnalysis(
 module_pairs=pairs,
 metrics=self._calculate_metrics(pairs)
 )`
```

#### 3. Output Formatter

 python
 Copy

`class OutputFormatter:
 """Format analysis results for different output formats."""

 def format(self, result: Any, format: str) -> str:
 formatters = {
 "tree": self._format_tree,
 "list": self._format_list,
 "graph": self._format_graph_json,
 "mermaid": self._format_mermaid,
 }
 return formatters[format](result)

 def _format_tree(self, dependencies: list[Dependency]) -> str:
 """Format as indented tree."""
 lines = []

 def add_node(dep: Dependency, depth: int):
 indent = " " * depth
 prefix = "â”œâ”€â”€ " if depth > 0 else ""
 lines.append(f"{indent}{prefix}{dep.target.name} ({dep.type})")
 lines.append(f"{indent} â””â”€â”€ {dep.location.file_path}:{dep.location.line_number}")

 for dep in dependencies:
 add_node(dep, 0)

 return "\n".join(lines)

 def _format_mermaid(self, graph: DependencyGraph) -> str:
 """Format as Mermaid diagram."""
 lines = ["graph TD"]

 # Add nodes
 for node in graph.nodes:
 label = f"{node.symbol.name}"
 lines.append(f" {node.id}[{label}]")

 # Add edges
 for edge in graph.edges:
 arrow = "-->" if edge.type == "call" else "-.->|{edge.type}|"
 lines.append(f" {edge.source_id} {arrow} {edge.target_id}")

 return "\n".join(lines)`
```

---

### Configuration

 yaml
 Copy

`tool-dependency-graph:
 # Analysis settings
 analysis:
 # Languages to analyze (auto-detected if not specified)
 languages:
 - python
 - typescript
 - javascript

 # File patterns to include
 include_patterns:
 - "**/*.py"
 - "**/*.ts"
 - "**/*.tsx"
 - "**/*.js"
 - "**/*.jsx"

 # Patterns to exclude
 exclude_patterns:
 - "node_modules/**"
 - ".venv/**"
 - "**/__pycache__/**"
 - "**/dist/**"
 - "**/*.test.*"
 - "**/*.spec.*"

 # External dependencies
 include_external: false
 external_packages:
 # Packages to always exclude from analysis
 exclude:
 - "typing"
 - "typing_extensions"
 - "builtins"

 # Graph building
 graph:
 # Maximum depth for recursive analysis
 default_depth: 3
 max_depth: 10

 # Entry points (roots for dead code detection)
 entry_points:
 patterns:
 - "**/main.py"
 - "**/cli.py"
 - "**/__main__.py"
 - "**/index.ts"
 functions:
 - "main"
 - "cli"
 - "app"

 # Symbols to exclude from dead code detection
 exclude_from_dead_code:
 patterns:
 - "__*__" # Dunder methods
 - "test_*" # Test functions
 - "*_test"
 decorators:
 - "@app.route" # Flask routes
 - "@pytest.fixture" # Pytest fixtures
 - "@click.command" # CLI commands

 # Output
 output:
 default_format: "tree"

 # Mermaid diagram settings
 mermaid:
 direction: "TD" # TB, TD, LR, RL
 max_nodes: 50 # Limit for readability

 # Caching
 cache:
 enabled: true
 ttl_seconds: 300
 invalidate_on_file_change: true`
```

---

### Examples

#### Example 1: Impact Analysis

 python
 Copy

`# Input
{
 "operation": "get_dependents",
 "target": "PaymentGateway.process",
 "depth": 2,
 "output_format": "tree"
}

# Output
{
 "operation": "get_dependents",
 "target": "PaymentGateway.process",
 "dependencies": [
 {
 "source": {"name": "OrderService.checkout", "file_path": "src/orders/service.py"},
 "target": {"name": "PaymentGateway.process", "file_path": "src/payments/gateway.py"},
 "type": "call",
 "location": {"file_path": "src/orders/service.py", "line_number": 89}
 },
 {
 "source": {"name": "SubscriptionRenewer.renew", "file_path": "src/subscriptions/renewer.py"},
 "target": {"name": "PaymentGateway.process", "file_path": "src/payments/gateway.py"},
 "type": "call",
 "location": {"file_path": "src/subscriptions/renewer.py", "line_number": 45}
 }
 ],
 "formatted": "PaymentGateway.process\nâ”œâ”€â”€ OrderService.checkout (call)\nâ”‚ â””â”€â”€ src/orders/service.py:89\nâ”œâ”€â”€ SubscriptionRenewer.renew (call)\nâ”‚ â””â”€â”€ src/subscriptions/renewer.py:45",
 "stats": {
 "files_analyzed": 45,
 "symbols_found": 234,
 "dependencies_found": 2,
 "analysis_time_ms": 156
 }
}`
```

#### Example 2: Circular Dependency Detection

 python
 Copy

`# Input
{
 "operation": "find_cycles",
 "scope": "src/",
 "dependency_types": ["import"]
}

# Output
{
 "operation": "find_cycles",
 "cycles": [
 {
 "path": ["src/models/user.py", "src/services/auth.py", "src/models/session.py", "src/models/user.py"],
 "type": "import",
 "severity": "error"
 }
 ],
 "formatted": "Circular import detected:\n src/models/user.py\n â†’ src/services/auth.py\n â†’ src/models/session.py\n â†’ src/models/user.py (cycle)",
 "stats": {...}
}`
```

#### Example 3: Coupling Analysis

 python
 Copy

`# Input
{
 "operation": "coupling_analysis",
 "scope": "src/"
}

# Output
{
 "operation": "coupling_analysis",
 "coupling": {
 "module_pairs": [
 {
 "module_a": "src/orders",
 "module_b": "src/payments",
 "coupling_score": 0.85,
 "dependency_count": 23,
 "bidirectional": true
 },
 {
 "module_a": "src/users",
 "module_b": "src/auth",
 "coupling_score": 0.72,
 "dependency_count": 18,
 "bidirectional": false
 }
 ],
 "metrics": {
 "average_coupling": 0.34,
 "max_coupling": 0.85,
 "highly_coupled_pairs": 2,
 "suggested_refactors": [
 "Consider extracting shared types between src/orders and src/payments",
 "src/payments depends heavily on src/orders internals - consider interface extraction"
 ]
 }
 }
}`
```

#### Example 4: Mermaid Architecture Diagram

 python
 Copy

`# Input
{
 "operation": "get_graph",
 "scope": "src/api/",
 "depth": 1,
 "output_format": "mermaid"
}

# Output
{
 "operation": "get_graph",
 "graph": {...},
 "formatted": "graph TD\n api_users[users.py]\n api_orders[orders.py]\n api_payments[payments.py]\n svc_user[UserService]\n svc_order[OrderService]\n api_users --> svc_user\n api_orders --> svc_order\n api_orders --> svc_user\n api_payments --> svc_order"
}`
```

---

### Security Considerations

#### Data Access

- Reads source files within configured scope
 
- Does not execute code, only static analysis
 
- No network access required
 
#### Risks

- Large codebases may consume significant memory
 
- Analysis results may reveal code structure
 
#### Permissions

 python
 Copy

`REQUIRED_CAPABILITIES = [
 "filesystem:read", # Read source files
]`
```

---

### Testing Strategy

#### Unit Tests

 python
 Copy

`def test_python_analyzer_extracts_imports():
 analyzer = PythonAnalyzer()
 code = "from foo.bar import baz, qux"
 analysis = analyzer.analyze_string(code)

 assert len(analysis.imports) == 1
 assert analysis.imports[0].module == "foo.bar"
 assert analysis.imports[0].names == ["baz", "qux"]

def test_cycle_detection_finds_cycles():
 builder = GraphBuilder([
 FileAnalysis("a.py", imports=[ImportDep("b")]),
 FileAnalysis("b.py", imports=[ImportDep("c")]),
 FileAnalysis("c.py", imports=[ImportDep("a")]),
 ])

 cycles = builder.find_cycles()
 assert len(cycles) == 1
 assert set(cycles[0].path) == {"a.py", "b.py", "c.py"}`
```

#### Integration Tests

 python
 Copy

`async def test_real_codebase_analysis():
 tool = DependencyGraphTool(config)
 result = await tool.execute({
 "operation": "get_dependents",
 "target": "test_function",
 "scope": "tests/fixtures/"
 })

 assert result.stats.files_analyzed > 0
 # Known fixture has specific dependencies
 assert len(result.dependencies) == 3`
```

---

### Dependencies

#### Required

- `tree-sitter` - Language parsing
 
- `tree-sitter-python` - Python grammar
 
- `tree-sitter-typescript` - TypeScript grammar
 
- `tree-sitter-javascript` - JavaScript grammar
 
#### Optional

- Additional language grammars as needed
 
---

### Open Questions

- Language support priority: Which languages beyond Python/TypeScript?
 
 - Go, Rust, Java are common enterprise languages

 - Each requires grammar and analyzer implementation

- Dynamic dependencies: How to handle dynamic imports/calls?
 
 - `importlib.import_module()`, `getattr()`, etc.

 - Could warn about detected dynamic patterns

- Cross-repository analysis: Should we support analyzing dependencies across repos?
 
 - Useful for microservices

 - Significantly increases complexity

- Incremental updates: How to efficiently update graph on file changes?
 
 - Full rebuild vs incremental

 - Trade-off: complexity vs performance

- Visual output: Should we generate SVG/PNG diagrams?
 
 - Mermaid can be rendered by many tools

 - Direct image generation adds dependencies

---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Tool Feature Flag
 tools

Priority: P2 (Enhancement)

Status: Draft

Module: `amplifier-module-tool-feature-flag`

### Overview

Manage feature flags across the codebase. Check flag status, toggle flags, analyze flag usage and debt, and manage flag lifecycle from creation to cleanup.

#### Value Proposition

 | 
 
 | Without | With

 | Check multiple dashboards for flag status | "Is dark-mode enabled for 10% of users?" â†’ instant answer
 
 | Old flags accumulate forever | Automated flag debt detection and cleanup reminders
 
 | Flag changes require dashboard access | Toggle flags from your workflow
 
 | Unknown flag coverage | See exactly which code paths are flagged

#### Use Cases

- Flag status: Check if a flag is enabled and for whom
 
- Flag management: Create, toggle, archive flags
 
- Debt detection: Find stale flags ready for cleanup
 
- Code analysis: Find all code paths controlled by a flag
 
- Impact assessment: What happens if we toggle this flag?
 
---

### Contract

#### Tool Definition

 python
 Copy

`TOOL_DEFINITION = {
 "name": "feature_flag",
 "description": """
 Manage feature flags and analyze flag usage.

 Operations:
 - status: Check flag status and targeting
 - toggle: Enable/disable flag or change targeting
 - list: List all flags with status
 - analyze: Find flag usage in code
 - debt: Identify stale flags for cleanup
 - create: Create new flag
 - archive: Archive/delete flag

 Supports: LaunchDarkly, Split, Unleash, ConfigCat, custom systems.
 """,
 "parameters": {
 "type": "object",
 "properties": {
 "operation": {
 "type": "string",
 "enum": ["status", "toggle", "list", "analyze", "debt", "create", "archive"],
 "description": "Operation to perform"
 },
 "flag_key": {
 "type": "string",
 "description": "Flag key/name"
 },
 "environment": {
 "type": "string",
 "default": "production",
 "description": "Environment (production, staging, development)"
 },
 "targeting": {
 "type": "object",
 "description": "Targeting rules for toggle operation"
 },
 "include_code_references": {
 "type": "boolean",
 "default": false,
 "description": "Include code locations using this flag"
 }
 },
 "required": ["operation"]
 }
}`
```

#### Output Schema

 python
 Copy

`@dataclass
class FeatureFlagOutput:
 operation: str

 # For status
 flag_status: FlagStatus | None = None

 # For list
 flags: list[FlagSummary] | None = None

 # For analyze
 code_references: list[CodeReference] | None = None

 # For debt
 stale_flags: list[StaleFlag] | None = None

@dataclass
class FlagStatus:
 key: str
 name: str
 description: str | None
 kind: str # boolean | multivariate | string | number

 # Status per environment
 environments: dict[str, EnvironmentStatus]

 # Metadata
 created_at: datetime
 updated_at: datetime
 created_by: str
 tags: list[str]

 # Usage stats
 evaluation_count_24h: int | None
 unique_users_24h: int | None

 # Code references (if requested)
 code_references: list[CodeReference] | None

@dataclass
class EnvironmentStatus:
 enabled: bool
 targeting: TargetingRules | None
 percentage_rollout: float | None # 0-100 for percentage rollouts
 default_value: Any

@dataclass
class TargetingRules:
 rules: list[TargetingRule]
 fallthrough: Any # Default when no rules match

@dataclass
class TargetingRule:
 description: str
 clauses: list[TargetClause] # AND conditions
 variation: Any # Value when rule matches

@dataclass
class TargetClause:
 attribute: str # user attribute to check
 operator: str # equals | contains | startsWith | in | etc.
 values: list[Any]

@dataclass
class CodeReference:
 file_path: str
 line_number: int
 code_snippet: str
 context: str # function/class containing the reference
 type: str # check | variation | default

@dataclass
class FlagSummary:
 key: str
 name: str
 enabled_environments: list[str]
 age_days: int
 evaluation_count_7d: int
 stale_score: float # 0-1, higher = more stale

@dataclass
class StaleFlag:
 key: str
 name: str
 age_days: int
 last_modified: datetime
 reasons: list[str] # Why it's considered stale
 code_references: list[CodeReference]
 recommendation: str # "remove", "review", "keep"`
```

---

### Architecture

#### Platform Adapters

 python
 Copy

`class LaunchDarklyAdapter:
 """Adapter for LaunchDarkly."""

 async def get_flag(self, key: str) -> FlagStatus:
 flag = await self.client.get_flag(self.project_key, key)

 environments = {}
 for env_key, env_config in flag.environments.items():
 environments[env_key] = EnvironmentStatus(
 enabled=env_config.on,
 targeting=self._parse_targeting(env_config.rules),
 percentage_rollout=self._extract_percentage(env_config.fallthrough),
 default_value=env_config.off_variation
 )

 return FlagStatus(
 key=flag.key,
 name=flag.name,
 description=flag.description,
 kind=flag.kind,
 environments=environments,
 created_at=flag.creation_date,
 updated_at=flag.last_modified,
 tags=flag.tags
 )

 async def toggle(self, key: str, environment: str, enabled: bool) -> None:
 patch = [{"op": "replace", "path": f"/environments/{environment}/on", "value": enabled}]
 await self.client.patch_flag(self.project_key, key, patch)

class CodeAnalyzer:
 """Find flag usage in code."""

 async def find_references(self, flag_key: str) -> list[CodeReference]:
 references = []

 # Search patterns for common flag SDKs
 patterns = [
 f'variation\\(["\\']{flag_key}["\\'', # variation("flag")
 f'is_enabled\\(["\\']{flag_key}["\\'', # is_enabled("flag")
 f'get_flag\\(["\\']{flag_key}["\\'', # get_flag("flag")
 f'flag\\(["\\']{flag_key}["\\'', # flag("flag")
 f'["\\']{flag_key}["\\'\\s*\\]', # flags["flag"]
 ]

 for pattern in patterns:
 matches = await self._grep(pattern)
 for match in matches:
 references.append(CodeReference(
 file_path=match.file_path,
 line_number=match.line_number,
 code_snippet=match.line,
 context=await self._get_context(match),
 type=self._classify_reference(match.line)
 ))

 return references

class FlagDebtAnalyzer:
 """Identify stale flags for cleanup."""

 async def analyze(self) -> list[StaleFlag]:
 flags = await self.adapter.list_flags()
 stale = []

 for flag in flags:
 reasons = []
 stale_score = 0.0

 # Age-based staleness
 if flag.age_days > 180:
 reasons.append(f"Flag is {flag.age_days} days old")
 stale_score += 0.3

 # No recent evaluations
 if flag.evaluation_count_7d == 0:
 reasons.append("No evaluations in last 7 days")
 stale_score += 0.3

 # Fully rolled out (100% on)
 if self._is_fully_rolled_out(flag):
 reasons.append("Flag is 100% enabled everywhere")
 stale_score += 0.2

 # Fully rolled back (100% off)
 if self._is_fully_rolled_back(flag):
 reasons.append("Flag is disabled everywhere")
 stale_score += 0.2

 # No code references
 refs = await self.code_analyzer.find_references(flag.key)
 if not refs:
 reasons.append("No code references found")
 stale_score += 0.2

 if stale_score > 0.4:
 stale.append(StaleFlag(
 key=flag.key,
 name=flag.name,
 age_days=flag.age_days,
 last_modified=flag.updated_at,
 reasons=reasons,
 code_references=refs,
 recommendation=self._recommend_action(stale_score, refs)
 ))

 return sorted(stale, key=lambda f: -f.age_days)`
```

---

### Examples

#### Example 1: Check Flag Status

 python
 Copy

`# Input
{
 "operation": "status",
 "flag_key": "new-checkout-flow",
 "include_code_references": true
}

# Output
{
 "flag_status": {
 "key": "new-checkout-flow",
 "name": "New Checkout Flow",
 "description": "Redesigned checkout experience with fewer steps",
 "kind": "boolean",
 "environments": {
 "production": {
 "enabled": true,
 "percentage_rollout": 25.0,
 "targeting": {
 "rules": [
 {
 "description": "Beta users",
 "clauses": [{"attribute": "beta", "operator": "equals", "values": [true]}],
 "variation": true
 }
 ],
 "fallthrough": "percentage"
 }
 },
 "staging": {
 "enabled": true,
 "percentage_rollout": 100.0
 }
 },
 "evaluation_count_24h": 45230,
 "unique_users_24h": 12500,
 "code_references": [
 {
 "file_path": "src/checkout/flow.py",
 "line_number": 42,
 "code_snippet": "if flag_client.variation('new-checkout-flow', user):",
 "context": "CheckoutController.process"
 }
 ]
 }
}`
```

#### Example 2: Find Stale Flags

 python
 Copy

`# Input
{
 "operation": "debt"
}

# Output
{
 "stale_flags": [
 {
 "key": "holiday-banner-2023",
 "name": "Holiday Banner 2023",
 "age_days": 412,
 "last_modified": "2023-01-15T10:00:00Z",
 "reasons": [
 "Flag is 412 days old",
 "No evaluations in last 7 days",
 "Flag is disabled everywhere"
 ],
 "code_references": [
 {
 "file_path": "src/components/Banner.tsx",
 "line_number": 15,
 "code_snippet": "const showHoliday = useFlag('holiday-banner-2023')"
 }
 ],
 "recommendation": "remove"
 },
 {
 "key": "payment-v2",
 "name": "Payment V2",
 "age_days": 245,
 "reasons": [
 "Flag is 245 days old",
 "Flag is 100% enabled everywhere"
 ],
 "recommendation": "remove (clean up code references first)"
 }
 ]
}`
```

---

### Configuration

 yaml
 Copy

`tool-feature-flag:
 # Platform configuration
 platform: launchdarkly # launchdarkly | split | unleash | configcat

 launchdarkly:
 api_key: "${LD_API_KEY}"
 project_key: "default"

 # Code analysis
 code_analysis:
 include_patterns:
 - "**/*.py"
 - "**/*.ts"
 - "**/*.tsx"
 - "**/*.js"
 exclude_patterns:
 - "**/node_modules/**"
 - "**/*.test.*"

 # Staleness thresholds
 staleness:
 age_warning_days: 90
 age_error_days: 180
 no_evaluation_days: 7`
```

---

### Security Considerations

- Requires API access to feature flag platform
 
- Can toggle flags (affects production behavior)
 
- Should require approval for production toggles
 
---

### Dependencies

#### Required

- Platform-specific SDK (launchdarkly-api, etc.)
 
#### Optional

- None
 
---

### Open Questions

- Toggle approval: Require approval for production toggles?
 
- Audit logging: Log all flag operations?
 
- Automated cleanup: Auto-archive stale flags?
 
- Cross-environment sync: Help sync targeting across environments?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Tool Git Advanced
 tools

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-tool-git-advanced`

### Overview

Advanced git operations beyond basic add/commit/push. Provides contextual blame, history analysis, branch management, and intelligent merge conflict assistance. Designed for complex codebase navigation and workflow automation.

#### Value Proposition

 | 
 
 | Without | With

 | `git blame` shows who, not why | Contextual blame links to PR, ticket, and discussion
 
 | Manual branch cleanup | Intelligent stale branch detection and cleanup
 
 | Merge conflicts are painful | AI-assisted conflict resolution with context
 
 | History is hard to navigate | Semantic search through commit history

#### Use Cases

- Contextual blame: "Who changed this and why?" with full context
 
- History search: "When did we change the auth timeout?"
 
- Branch management: Clean up stale branches, find related branches
 
- Conflict resolution: Understand both sides of a conflict with context
 
- Bisect assistance: Help find which commit introduced a bug
 
- Cherry-pick planning: Identify commits to backport
 
---

### Contract

#### Tool Definition

 python
 Copy

`TOOL_DEFINITION = {
 "name": "git_advanced",
 "description": """
 Advanced git operations with contextual information.

 Operations:
 - blame: Contextual blame with PR/ticket links
 - history: Search commit history semantically
 - branches: List, analyze, and manage branches
 - conflicts: Analyze merge conflicts with context
 - bisect: Assisted bisection to find bug introduction
 - cherry_pick_plan: Plan cherry-picks for backporting
 - diff_analysis: Analyze changes between refs

 Use for understanding code history and managing complex git workflows.
 """,
 "parameters": {
 "type": "object",
 "properties": {
 "operation": {
 "type": "string",
 "enum": ["blame", "history", "branches", "conflicts", "bisect", "cherry_pick_plan", "diff_analysis"],
 "description": "Git operation to perform"
 },
 "file_path": {
 "type": "string",
 "description": "File path for blame/history operations"
 },
 "line_range": {
 "type": "string",
 "description": "Line range for blame (e.g., '10-20', '42')"
 },
 "query": {
 "type": "string",
 "description": "Search query for history operation"
 },
 "ref": {
 "type": "string",
 "description": "Git ref (branch, tag, commit) for operations"
 },
 "base_ref": {
 "type": "string",
 "description": "Base ref for diff/comparison operations"
 },
 "include_context": {
 "type": "boolean",
 "default": true,
 "description": "Include PR/ticket context in results"
 },
 "max_results": {
 "type": "integer",
 "default": 20,
 "description": "Maximum results for search operations"
 }
 },
 "required": ["operation"]
 }
}`
```

#### Output Schema

 python
 Copy

`@dataclass
class GitAdvancedOutput:
 operation: str

 # For blame
 blame_results: list[BlameEntry] | None = None

 # For history
 commits: list[EnrichedCommit] | None = None

 # For branches
 branches: BranchAnalysis | None = None

 # For conflicts
 conflicts: list[ConflictAnalysis] | None = None

 # For diff_analysis
 diff: DiffAnalysis | None = None

@dataclass
class BlameEntry:
 line_start: int
 line_end: int
 content: str # The actual code lines

 # Git info
 commit_sha: str
 author: str
 author_date: datetime
 commit_message: str

 # Context (if include_context=True)
 pr_number: int | None
 pr_title: str | None
 ticket_key: str | None
 ticket_title: str | None
 discussion_summary: str | None # AI-summarized context

@dataclass
class EnrichedCommit:
 sha: str
 short_sha: str
 author: str
 author_email: str
 date: datetime
 message: str
 body: str | None

 # Stats
 files_changed: int
 insertions: int
 deletions: int

 # Context
 pr_number: int | None
 ticket_keys: list[str]
 tags: list[str] # Tags pointing to this commit

 # Relevance (for search)
 relevance_score: float | None

@dataclass
class BranchAnalysis:
 current: str
 local_branches: list[BranchInfo]
 remote_branches: list[BranchInfo]
 stale_branches: list[BranchInfo] # No commits in X days
 merged_branches: list[BranchInfo] # Already merged to main

@dataclass
class BranchInfo:
 name: str
 last_commit_date: datetime
 last_commit_sha: str
 last_commit_message: str
 ahead_of_main: int
 behind_main: int
 author: str # Most recent committer
 pr_status: str | None # open | merged | closed | none

@dataclass
class ConflictAnalysis:
 file_path: str
 conflict_type: str # content | rename | delete
 ours_summary: str # What our side changed
 theirs_summary: str # What their side changed
 suggested_resolution: str | None # AI suggestion if clear
 context: ConflictContext

@dataclass
class ConflictContext:
 ours_commits: list[str] # Commits on our side
 theirs_commits: list[str] # Commits on their side
 common_ancestor: str
 ours_pr: int | None
 theirs_pr: int | None`
```

---

### Architecture

#### Component Diagram

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ tool-git-advanced â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Operation â”‚â”€â”€â”€â–¶â”‚ Git â”‚â”€â”€â”€â–¶â”‚ Context â”‚ â”‚
â”‚ â”‚ Dispatcher â”‚ â”‚ Engine â”‚ â”‚ Enricher â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ GitPython â”‚ â”‚ GitHub â”‚ â”‚
â”‚ â”‚ / libgit2 â”‚ â”‚ Client â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Internal Components

#### 1. Blame with Context

 python
 Copy

`class ContextualBlame:
 """Blame with PR and ticket context."""

 async def blame(
 self,
 file_path: str,
 line_range: tuple[int, int] | None = None,
 include_context: bool = True
 ) -> list[BlameEntry]:
 # Get raw blame
 raw_blame = await self.git.blame(file_path, line_range)

 # Group consecutive lines with same commit
 entries = self._group_blame_entries(raw_blame)

 if include_context:
 # Enrich with PR/ticket context
 for entry in entries:
 entry.pr_number, entry.pr_title = await self._find_pr_for_commit(entry.commit_sha)
 entry.ticket_key, entry.ticket_title = await self._find_ticket_for_commit(entry.commit_sha)

 # Generate discussion summary if we have context
 if entry.pr_number or entry.ticket_key:
 entry.discussion_summary = await self._summarize_context(entry)

 return entries

 async def _find_pr_for_commit(self, sha: str) -> tuple[int | None, str | None]:
 """Find PR that introduced this commit."""
 # Check if commit message references PR
 commit = await self.git.get_commit(sha)
 pr_match = re.search(r'#(\d+)', commit.message)
 if pr_match:
 pr_num = int(pr_match.group(1))
 pr = await self.github.get_pr(pr_num)
 return pr_num, pr.title

 # Search GitHub for PR containing this commit
 prs = await self.github.search_prs_for_commit(sha)
 if prs:
 return prs[0].number, prs[0].title

 return None, None`
```

#### 2. History Search

 python
 Copy

`class HistorySearch:
 """Semantic search through commit history."""

 async def search(
 self,
 query: str,
 file_path: str | None = None,
 max_results: int = 20
 ) -> list[EnrichedCommit]:
 # Get commit log
 commits = await self.git.log(
 path=file_path,
 max_count=1000 # Search through recent history
 )

 # Score commits by relevance
 scored = []
 for commit in commits:
 score = self._score_commit(commit, query)
 if score > 0.3: # Minimum relevance threshold
 scored.append((commit, score))

 # Sort by relevance
 scored.sort(key=lambda x: x[1], reverse=True)

 # Enrich top results
 results = []
 for commit, score in scored[:max_results]:
 enriched = await self._enrich_commit(commit)
 enriched.relevance_score = score
 results.append(enriched)

 return results

 def _score_commit(self, commit: Commit, query: str) -> float:
 """Score commit relevance to query."""
 query_lower = query.lower()
 score = 0.0

 # Message match
 if query_lower in commit.message.lower():
 score += 0.5
 elif any(word in commit.message.lower() for word in query_lower.split()):
 score += 0.3

 # File path match (if commit touches relevant files)
 for file in commit.files:
 if query_lower in file.lower():
 score += 0.2
 break

 # Ticket reference match
 ticket_match = re.search(r'([A-Z]+-\d+)', commit.message)
 if ticket_match and query_lower in ticket_match.group(1).lower():
 score += 0.4

 return min(score, 1.0)`
```

#### 3. Conflict Analysis

 python
 Copy

`class ConflictAnalyzer:
 """Analyze and assist with merge conflicts."""

 async def analyze_conflicts(self) -> list[ConflictAnalysis]:
 # Get list of conflicted files
 conflicted = await self.git.get_conflicted_files()

 analyses = []
 for file_path in conflicted:
 analysis = await self._analyze_file_conflict(file_path)
 analyses.append(analysis)

 return analyses

 async def _analyze_file_conflict(self, file_path: str) -> ConflictAnalysis:
 # Get conflict markers and content
 content = await self.git.get_file_with_conflicts(file_path)
 ours, theirs, base = self._parse_conflict_regions(content)

 # Get commits involved
 ours_commits = await self.git.log(f"MERGE_HEAD..HEAD", path=file_path)
 theirs_commits = await self.git.log(f"HEAD..MERGE_HEAD", path=file_path)

 # Summarize changes
 ours_summary = self._summarize_changes(base, ours)
 theirs_summary = self._summarize_changes(base, theirs)

 # Try to suggest resolution
 suggestion = await self._suggest_resolution(ours, theirs, base, ours_summary, theirs_summary)

 return ConflictAnalysis(
 file_path=file_path,
 conflict_type=self._detect_conflict_type(content),
 ours_summary=ours_summary,
 theirs_summary=theirs_summary,
 suggested_resolution=suggestion,
 context=ConflictContext(
 ours_commits=[c.sha for c in ours_commits],
 theirs_commits=[c.sha for c in theirs_commits],
 common_ancestor=await self.git.merge_base("HEAD", "MERGE_HEAD"),
 ours_pr=await self._find_pr_for_branch("HEAD"),
 theirs_pr=await self._find_pr_for_branch("MERGE_HEAD")
 )
 )

 async def _suggest_resolution(
 self,
 ours: str,
 theirs: str,
 base: str,
 ours_summary: str,
 theirs_summary: str
 ) -> str | None:
 """Suggest resolution if changes don't truly conflict."""

 # Case 1: One side is superset of other
 if theirs in ours:
 return f"Keep ours - already includes their changes"
 if ours in theirs:
 return f"Keep theirs - already includes our changes"

 # Case 2: Changes to different parts (textual conflict but logical merge possible)
 if self._changes_are_independent(ours, theirs, base):
 return f"Both changes are independent - combine both"

 # Case 3: Need manual resolution
 return None`
```

---

### Configuration

 yaml
 Copy

`tool-git-advanced:
 # Git settings
 git:
 repo_path: "." # Repository root

 # Context enrichment
 context:
 enabled: true
 github_token: "${GITHUB_TOKEN}" # For PR lookups
 jira_token: "${JIRA_TOKEN}" # For ticket lookups

 # Ticket patterns to recognize in commit messages
 ticket_patterns:
 - "[A-Z]{2,10}-\\d+" # JIRA-style

 # History search
 history:
 max_commits_to_search: 1000
 relevance_threshold: 0.3

 # Branch management
 branches:
 stale_days: 30 # Days without commits = stale
 protected_branches:
 - main
 - master
 - develop
 - release/*

 # Conflict resolution
 conflicts:
 enable_suggestions: true
 ai_assisted: true # Use AI for complex conflicts`
```

---

### Examples

#### Example 1: Contextual Blame

 python
 Copy

`# Input
{
 "operation": "blame",
 "file_path": "src/payments/gateway.py",
 "line_range": "42-50",
 "include_context": true
}

# Output
{
 "operation": "blame",
 "blame_results": [
 {
 "line_start": 42,
 "line_end": 48,
 "content": "@retry(max_attempts=3)\nasync def process_payment(...):\n ...",
 "commit_sha": "abc123",
 "author": "alice",
 "author_date": "2024-01-15T10:30:00Z",
 "commit_message": "Add retry logic to payment gateway\n\nCloses JIRA-4523",
 "pr_number": 892,
 "pr_title": "Add retry logic to payment gateway",
 "ticket_key": "JIRA-4523",
 "ticket_title": "Payment failures during peak hours",
 "discussion_summary": "Added retry with exponential backoff after 5% payment failures during Black Friday. Team decided on 3 retries max to avoid customer confusion."
 }
 ]
}`
```

#### Example 2: History Search

 python
 Copy

`# Input
{
 "operation": "history",
 "query": "authentication timeout",
 "max_results": 5
}

# Output
{
 "operation": "history",
 "commits": [
 {
 "sha": "def456",
 "short_sha": "def456",
 "author": "bob",
 "date": "2024-01-10T14:20:00Z",
 "message": "Increase auth session timeout to 30 minutes\n\nPer JIRA-4400",
 "files_changed": 2,
 "insertions": 5,
 "deletions": 2,
 "pr_number": 845,
 "ticket_keys": ["JIRA-4400"],
 "relevance_score": 0.92
 },
 {
 "sha": "ghi789",
 "author": "carol",
 "date": "2023-12-15T09:00:00Z",
 "message": "Fix authentication timeout race condition",
 "relevance_score": 0.78
 }
 ]
}`
```

#### Example 3: Conflict Analysis

 python
 Copy

`# Input
{
 "operation": "conflicts"
}

# Output
{
 "operation": "conflicts",
 "conflicts": [
 {
 "file_path": "src/config/settings.py",
 "conflict_type": "content",
 "ours_summary": "Added PAYMENT_TIMEOUT setting",
 "theirs_summary": "Added AUTH_TIMEOUT setting",
 "suggested_resolution": "Both changes are independent - combine both",
 "context": {
 "ours_commits": ["abc123"],
 "theirs_commits": ["def456"],
 "common_ancestor": "base00",
 "ours_pr": 900,
 "theirs_pr": 901
 }
 }
 ]
}`
```

---

### Security Considerations

- Reads git history (may contain sensitive commit messages)
 
- Connects to GitHub API (uses provided token)
 
- Does not modify repository (read-only operations)
 
- Credentials never logged or returned
 
---

### Dependencies

#### Required

- `gitpython` - Git operations
 
- `httpx` - HTTP client for GitHub API
 
#### Optional

- `libgit2` / `pygit2` - Alternative git backend (faster for large repos)
 
---

### Open Questions

- Git provider support: GitHub-specific or support GitLab/Bitbucket?
 
- Large repo performance: How to handle repos with millions of commits?
 
- Conflict resolution: How much AI assistance for complex conflicts?
 
- Branch operations: Should we support branch deletion/creation?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Tool Jira Ops
 tools

Priority: P0 (Foundation)

Status: Draft

Module: `amplifier-module-tool-jira-ops`

### Overview

Comprehensive JIRA operations including creating, updating, querying, and linking issues. Enables workflow automation and tight integration between code work and ticket management.

#### Value Proposition

 | 
 
 | Without | With

 | Switch to browser, find project, create ticket, copy ID back | `create_issue("Bug in auth", type="bug")` returns PROJ-456
 
 | Manual status updates forgotten during coding flow | Automatic status transitions as work progresses
 
 | Lost context between code and tickets | Bidirectional linking between commits/PRs and tickets
 
 | Searching JIRA's clunky UI | JQL queries from your workflow

#### Use Cases

- Issue creation: Create tickets from code context (bugs found, tasks identified)
 
- Status management: Transition tickets as work progresses
 
- Query & search: Find relevant tickets by JQL, assignee, sprint, etc.
 
- Linking: Link issues to PRs, commits, other issues
 
- Bulk operations: Update multiple tickets (sprint planning, grooming)
 
- Time tracking: Log work against tickets
 
---

### Contract

#### Tool Definition

 python
 Copy

`TOOL_DEFINITION = {
 "name": "jira_ops",
 "description": """
 JIRA operations: create, update, query, and link issues.

 Operations:
 - create: Create new issue (bug, story, task, etc.)
 - update: Update issue fields (status, assignee, description, etc.)
 - transition: Move issue through workflow (To Do â†’ In Progress â†’ Done)
 - query: Search issues using JQL
 - get: Get single issue details
 - link: Link issues together or to external resources
 - comment: Add comment to issue
 - log_work: Log time against issue

 Use for ticket management without leaving your workflow.
 """,
 "parameters": {
 "type": "object",
 "properties": {
 "operation": {
 "type": "string",
 "enum": ["create", "update", "transition", "query", "get", "link", "comment", "log_work"],
 "description": "Operation to perform"
 },
 "issue_key": {
 "type": "string",
 "description": "Issue key (e.g., PROJ-123). Required for update/transition/get/link/comment/log_work."
 },
 "project": {
 "type": "string",
 "description": "Project key for create operation"
 },
 "issue_type": {
 "type": "string",
 "enum": ["bug", "story", "task", "epic", "subtask"],
 "description": "Issue type for create operation"
 },
 "summary": {
 "type": "string",
 "description": "Issue summary/title"
 },
 "description": {
 "type": "string",
 "description": "Issue description (supports JIRA markdown)"
 },
 "fields": {
 "type": "object",
 "description": "Additional fields to set (assignee, priority, labels, custom fields, etc.)"
 },
 "transition": {
 "type": "string",
 "description": "Transition name for transition operation (e.g., 'Start Progress', 'Done')"
 },
 "jql": {
 "type": "string",
 "description": "JQL query for query operation"
 },
 "link_type": {
 "type": "string",
 "description": "Link type (blocks, is blocked by, relates to, etc.)"
 },
 "link_target": {
 "type": "string",
 "description": "Target issue key or URL for linking"
 },
 "comment": {
 "type": "string",
 "description": "Comment text for comment operation"
 },
 "time_spent": {
 "type": "string",
 "description": "Time spent for log_work (e.g., '2h', '30m', '1d')"
 },
 "max_results": {
 "type": "integer",
 "default": 20,
 "description": "Maximum results for query operation"
 }
 },
 "required": ["operation"]
 }
}`
```

#### Input Schema

 python
 Copy

`@dataclass
class JiraOpsInput:
 operation: Operation # create | update | transition | query | get | link | comment | log_work

 # Issue identification
 issue_key: str | None = None # Required for most ops except create/query
 project: str | None = None # Required for create

 # Issue content
 issue_type: IssueType | None = None
 summary: str | None = None
 description: str | None = None
 fields: dict | None = None # Additional/custom fields

 # Operation-specific
 transition: str | None = None # For transition op
 jql: str | None = None # For query op
 link_type: str | None = None # For link op
 link_target: str | None = None # For link op
 comment: str | None = None # For comment op
 time_spent: str | None = None # For log_work op

 # Query options
 max_results: int = 20`
```

#### Output Schema

 python
 Copy

`@dataclass
class JiraOpsOutput:
 success: bool
 operation: str

 # For create/update/get operations
 issue: JiraIssue | None = None

 # For query operation
 issues: list[JiraIssue] | None = None
 total_count: int | None = None

 # For transition operation
 available_transitions: list[Transition] | None = None

 # Operation metadata
 message: str | None = None

@dataclass
class JiraIssue:
 key: str # PROJ-123
 id: str # Internal ID
 self_url: str # API URL

 # Core fields
 summary: str
 description: str | None
 issue_type: str
 status: str
 priority: str | None

 # People
 assignee: str | None
 reporter: str

 # Dates
 created: datetime
 updated: datetime
 resolved: datetime | None
 due_date: date | None

 # Organization
 project: str
 labels: list[str]
 components: list[str]
 sprint: str | None
 epic: str | None # Epic key if linked

 # Links
 links: list[IssueLink]
 subtasks: list[str] # Subtask keys
 parent: str | None # Parent key if subtask

 # Custom fields (project-specific)
 custom_fields: dict[str, Any]

 # Computed
 url: str # Browser URL

@dataclass
class IssueLink:
 type: str # "blocks", "is blocked by", etc.
 direction: str # "inward" | "outward"
 target_key: str
 target_summary: str
 target_status: str

@dataclass
class Transition:
 id: str
 name: str # "Start Progress", "Done", etc.
 to_status: str # Target status name`
```

#### Events Emitted

 | 
 
 | Event | When | Data

 | `tool:jira:start` | Operation begins | operation, issue_key, project
 
 | `tool:jira:api_call` | JIRA API call | endpoint, method, duration_ms
 
 | `tool:jira:created` | Issue created | issue_key, project, issue_type
 
 | `tool:jira:updated` | Issue updated | issue_key, fields_changed
 
 | `tool:jira:transitioned` | Status changed | issue_key, from_status, to_status
 
 | `tool:jira:complete` | Operation done | operation, success
 
 | `tool:jira:error` | Operation failed | error_type, message

---

### Architecture

#### Component Diagram

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ tool-jira-ops â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Operation â”‚â”€â”€â”€â–¶â”‚ JIRA â”‚â”€â”€â”€â–¶â”‚ Result â”‚ â”‚
â”‚ â”‚ Dispatcher â”‚ â”‚ Client â”‚ â”‚ Mapper â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Field â”‚ â”‚
â”‚ â”‚ Resolver â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Internal Components

#### 1. Operation Dispatcher

 python
 Copy

`class OperationDispatcher:
 """Routes operations to appropriate handlers."""

 async def dispatch(self, input: JiraOpsInput) -> JiraOpsOutput:
 handlers = {
 "create": self._handle_create,
 "update": self._handle_update,
 "transition": self._handle_transition,
 "query": self._handle_query,
 "get": self._handle_get,
 "link": self._handle_link,
 "comment": self._handle_comment,
 "log_work": self._handle_log_work,
 }

 handler = handlers.get(input.operation)
 if not handler:
 raise ValueError(f"Unknown operation: {input.operation}")

 return await handler(input)

 async def _handle_create(self, input: JiraOpsInput) -> JiraOpsOutput:
 # Validate required fields
 if not input.project:
 raise ValueError("project required for create")
 if not input.summary:
 raise ValueError("summary required for create")

 # Resolve field IDs (custom fields, etc.)
 fields = await self.field_resolver.resolve(input.project, {
 "project": {"key": input.project},
 "issuetype": {"name": input.issue_type or "Task"},
 "summary": input.summary,
 "description": input.description,
 **(input.fields or {})
 })

 # Create issue
 result = await self.client.create_issue(fields)

 return JiraOpsOutput(
 success=True,
 operation="create",
 issue=self.result_mapper.map_issue(result),
 message=f"Created {result['key']}"
 )

 async def _handle_transition(self, input: JiraOpsInput) -> JiraOpsOutput:
 if not input.issue_key:
 raise ValueError("issue_key required for transition")

 # Get available transitions
 transitions = await self.client.get_transitions(input.issue_key)

 if not input.transition:
 # Just return available transitions
 return JiraOpsOutput(
 success=True,
 operation="transition",
 available_transitions=[
 Transition(id=t["id"], name=t["name"], to_status=t["to"]["name"])
 for t in transitions
 ]
 )

 # Find matching transition
 transition_id = None
 for t in transitions:
 if t["name"].lower() == input.transition.lower():
 transition_id = t["id"]
 break

 if not transition_id:
 available = [t["name"] for t in transitions]
 raise ValueError(f"Transition '{input.transition}' not available. Available: {available}")

 # Execute transition
 await self.client.transition_issue(input.issue_key, transition_id)

 # Get updated issue
 issue = await self.client.get_issue(input.issue_key)

 return JiraOpsOutput(
 success=True,
 operation="transition",
 issue=self.result_mapper.map_issue(issue),
 message=f"Transitioned {input.issue_key} to {input.transition}"
 )`
```

#### 2. Field Resolver

 python
 Copy

`class FieldResolver:
 """
 Resolves human-friendly field names to JIRA field IDs.
 Handles custom fields and project-specific configurations.
 """

 def __init__(self, client: JiraClient):
 self.client = client
 self._field_cache: dict[str, dict] = {}

 async def resolve(self, project: str, fields: dict) -> dict:
 """Convert user-provided fields to JIRA API format."""

 # Get field definitions for project
 if project not in self._field_cache:
 self._field_cache[project] = await self._load_fields(project)

 field_defs = self._field_cache[project]
 resolved = {}

 for key, value in fields.items():
 # Standard field
 if key in STANDARD_FIELDS:
 resolved[key] = self._resolve_standard(key, value)

 # Custom field by name
 elif key in field_defs:
 field_id = field_defs[key]["id"]
 resolved[field_id] = self._resolve_custom(field_defs[key], value)

 # Custom field by ID
 elif key.startswith("customfield_"):
 resolved[key] = value

 else:
 raise ValueError(f"Unknown field: {key}")

 return resolved

 def _resolve_standard(self, key: str, value: Any) -> Any:
 """Handle standard field formatting."""

 # Assignee/reporter: accept username string
 if key in ("assignee", "reporter"):
 if isinstance(value, str):
 return {"name": value}
 return value

 # Priority: accept name string
 if key == "priority":
 if isinstance(value, str):
 return {"name": value}
 return value

 # Labels: ensure list
 if key == "labels":
 if isinstance(value, str):
 return [value]
 return value

 return value`
```

#### 3. JIRA Client

 python
 Copy

`class JiraClient:
 """
 Low-level JIRA REST API client.
 Handles authentication, rate limiting, and error handling.
 """

 def __init__(self, config: JiraConfig):
 self.base_url = config.base_url.rstrip("/")
 self.auth = (config.username, config.api_token) if config.username else None
 self.headers = {
 "Content-Type": "application/json",
 "Accept": "application/json"
 }
 if config.api_token and not config.username:
 self.headers["Authorization"] = f"Bearer {config.api_token}"

 async def create_issue(self, fields: dict) -> dict:
 return await self._request("POST", "/rest/api/2/issue", json={"fields": fields})

 async def update_issue(self, key: str, fields: dict) -> None:
 await self._request("PUT", f"/rest/api/2/issue/{key}", json={"fields": fields})

 async def get_issue(self, key: str, expand: list[str] | None = None) -> dict:
 params = {}
 if expand:
 params["expand"] = ",".join(expand)
 return await self._request("GET", f"/rest/api/2/issue/{key}", params=params)

 async def search(self, jql: str, max_results: int = 50, fields: list[str] | None = None) -> dict:
 body = {
 "jql": jql,
 "maxResults": max_results,
 "fields": fields or ["*all"]
 }
 return await self._request("POST", "/rest/api/2/search", json=body)

 async def get_transitions(self, key: str) -> list[dict]:
 result = await self._request("GET", f"/rest/api/2/issue/{key}/transitions")
 return result["transitions"]

 async def transition_issue(self, key: str, transition_id: str, fields: dict | None = None) -> None:
 body = {"transition": {"id": transition_id}}
 if fields:
 body["fields"] = fields
 await self._request("POST", f"/rest/api/2/issue/{key}/transitions", json=body)

 async def add_comment(self, key: str, body: str) -> dict:
 return await self._request("POST", f"/rest/api/2/issue/{key}/comment", json={"body": body})

 async def add_worklog(self, key: str, time_spent: str, comment: str | None = None) -> dict:
 body = {"timeSpent": time_spent}
 if comment:
 body["comment"] = comment
 return await self._request("POST", f"/rest/api/2/issue/{key}/worklog", json=body)

 async def create_link(self, link_type: str, inward_key: str, outward_key: str) -> None:
 body = {
 "type": {"name": link_type},
 "inwardIssue": {"key": inward_key},
 "outwardIssue": {"key": outward_key}
 }
 await self._request("POST", "/rest/api/2/issueLink", json=body)

 async def _request(self, method: str, path: str, **kwargs) -> Any:
 url = f"{self.base_url}{path}"
 async with httpx.AsyncClient() as client:
 response = await client.request(
 method, url,
 auth=self.auth,
 headers=self.headers,
 **kwargs
 )

 if response.status_code >= 400:
 error_body = response.json() if response.content else {}
 raise JiraAPIError(
 status_code=response.status_code,
 messages=error_body.get("errorMessages", []),
 errors=error_body.get("errors", {})
 )

 if response.content:
 return response.json()
 return None`
```

---

### Configuration

 yaml
 Copy

`tool-jira-ops:
 # Connection
 base_url: "${JIRA_URL}" # https://company.atlassian.net

 # Authentication (choose one)
 # Option 1: API token (Atlassian Cloud)
 username: "${JIRA_USERNAME}" # email for cloud
 api_token: "${JIRA_API_TOKEN}"

 # Option 2: Personal Access Token (Server/Data Center)
 # api_token: "${JIRA_PAT}" # PAT without username

 # Option 3: OAuth (advanced)
 # oauth:
 # consumer_key: "..."
 # access_token: "..."
 # ...

 # Default project
 default_project: "PROJ" # Used when project not specified

 # Field mappings (project-specific custom field names)
 field_aliases:
 story_points: "customfield_10001"
 sprint: "customfield_10002"
 team: "customfield_10003"

 # Workflow shortcuts
 workflow_aliases:
 start: "Start Progress"
 done: "Done"
 review: "Ready for Review"
 block: "Blocked"

 # Query defaults
 query:
 default_fields:
 - summary
 - status
 - assignee
 - priority
 - created
 - updated
 max_results: 50

 # Behavior
 behavior:
 # Auto-assign to current user on transition to "In Progress"
 auto_assign_on_start: true

 # Add comment with PR link when linking
 comment_on_link: true

 # Validate transitions before attempting
 validate_transitions: true`
```

---

### Examples

#### Example 1: Create Bug from Code Context

 python
 Copy

`# Input
{
 "operation": "create",
 "project": "PROJ",
 "issue_type": "bug",
 "summary": "NullPointerException in PaymentGateway.process()",
 "description": "Found while reviewing PR #456.\n\n{code:java}\n// Line 142 in PaymentGateway.java\nuser.getEmail().toLowerCase() // user can be null\n{code}\n\nReproduction: Call process() with null user.",
 "fields": {
 "priority": "High",
 "labels": ["backend", "payments"],
 "components": ["payment-service"]
 }
}

# Output
{
 "success": true,
 "operation": "create",
 "issue": {
 "key": "PROJ-789",
 "summary": "NullPointerException in PaymentGateway.process()",
 "status": "To Do",
 "priority": "High",
 "url": "https://company.atlassian.net/browse/PROJ-789"
 },
 "message": "Created PROJ-789"
}`
```

#### Example 2: Transition with Auto-Assign

 python
 Copy

`# Input
{
 "operation": "transition",
 "issue_key": "PROJ-789",
 "transition": "Start Progress"
}

# Output
{
 "success": true,
 "operation": "transition",
 "issue": {
 "key": "PROJ-789",
 "status": "In Progress",
 "assignee": "current-user" // Auto-assigned
 },
 "message": "Transitioned PROJ-789 to Start Progress"
}`
```

#### Example 3: Query My Sprint Work

 python
 Copy

`# Input
{
 "operation": "query",
 "jql": "assignee = currentUser() AND sprint in openSprints() ORDER BY priority DESC",
 "max_results": 10
}

# Output
{
 "success": true,
 "operation": "query",
 "issues": [
 {
 "key": "PROJ-456",
 "summary": "Implement retry logic",
 "status": "In Progress",
 "priority": "High"
 },
 {
 "key": "PROJ-457",
 "summary": "Add unit tests for auth",
 "status": "To Do",
 "priority": "Medium"
 }
 ],
 "total_count": 2
}`
```

#### Example 4: Link PR to Issue

 python
 Copy

`# Input
{
 "operation": "link",
 "issue_key": "PROJ-456",
 "link_type": "is implemented by",
 "link_target": "https://github.com/company/repo/pull/123"
}

# Output
{
 "success": true,
 "operation": "link",
 "message": "Linked PROJ-456 to PR #123"
}`
```

#### Example 5: Get Available Transitions

 python
 Copy

`# Input
{
 "operation": "transition",
 "issue_key": "PROJ-456"
 // No transition specified - returns available options
}

# Output
{
 "success": true,
 "operation": "transition",
 "available_transitions": [
 {"id": "21", "name": "Done", "to_status": "Done"},
 {"id": "31", "name": "Blocked", "to_status": "Blocked"},
 {"id": "41", "name": "Ready for Review", "to_status": "In Review"}
 ]
}`
```

---

### Security Considerations

#### Authentication

- API tokens stored securely (environment variables or secret manager)
 
- Tokens never logged or returned in output
 
- Support for multiple auth methods (basic, PAT, OAuth)
 
#### Permissions

- Tool respects JIRA project permissions
 
- Operations fail gracefully if user lacks permission
 
- No privilege escalation possible
 
#### Audit

- All operations logged with user context
 
- JIRA maintains its own audit log
 
#### Risk Mitigations

 | 
 
 | Risk | Mitigation

 | Credential exposure | Tokens from env vars, never in config files
 
 | Unauthorized modifications | API enforces JIRA permissions
 
 | Data leakage | Issue content may contain sensitive data - same as viewing in JIRA
 
 | Rate limiting | Built-in rate limit handling, exponential backoff

---

### Testing Strategy

#### Unit Tests

 python
 Copy

`def test_field_resolver_handles_standard_fields():
 resolver = FieldResolver(mock_client)
 result = await resolver.resolve("PROJ", {
 "assignee": "alice",
 "priority": "High"
 })
 assert result["assignee"] == {"name": "alice"}
 assert result["priority"] == {"name": "High"}

def test_operation_dispatcher_validates_required_fields():
 dispatcher = OperationDispatcher(...)
 with pytest.raises(ValueError, match="project required"):
 await dispatcher.dispatch(JiraOpsInput(operation="create", summary="Test"))`
```

#### Integration Tests

 python
 Copy

`async def test_create_and_transition_flow(mock_jira_server):
 tool = JiraOpsTool(config)

 # Create
 create_result = await tool.execute({
 "operation": "create",
 "project": "TEST",
 "summary": "Integration test issue"
 })
 assert create_result.success
 issue_key = create_result.issue.key

 # Transition
 transition_result = await tool.execute({
 "operation": "transition",
 "issue_key": issue_key,
 "transition": "Start Progress"
 })
 assert transition_result.success
 assert transition_result.issue.status == "In Progress"`
```

---

### Dependencies

#### Required

- `httpx` - Async HTTP client
 
- `jira` (optional) - Can use official JIRA library or direct REST
 
#### Optional

- None
 
---

### Open Questions

- Bulk operations: Should we support bulk create/update?
 
 - Useful for sprint planning automation

 - API supports it but adds complexity

- Webhook integration: Should this tool support receiving JIRA webhooks?
 
 - Would enable reactive workflows

 - Significantly increases scope

- Custom workflow support: How to handle project-specific workflows?
 
 - Currently: Discover transitions dynamically

 - Could: Pre-configure workflow mappings

- Attachment support: Should we support uploading attachments?
 
 - Useful for screenshots, logs

 - Requires file handling

- Board/Sprint operations: Should we include board-level operations?
 
 - Sprint management, backlog ordering

 - Different API (Agile API vs Issue API)

---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Tool Metrics Query
 tools

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-tool-metrics-query`

### Overview

Query observability platforms (Prometheus, DataDog, Grafana, CloudWatch) to get metrics, logs, and traces. Enables data-driven analysis during debugging, incident response, and performance optimization.

#### Value Proposition

 | 
 
 | Without | With

 | Switch to Grafana, build query, interpret graphs | "What's the p99 latency for payment API?" â†’ instant answer
 
 | Manually correlate metrics across dashboards | Single query spans metrics, logs, traces
 
 | Learn each platform's query language | Natural language queries translated automatically

#### Use Cases

- Performance analysis: "What's the latency trend for /api/orders?"
 
- Incident investigation: "Show error rates for the last hour"
 
- Capacity planning: "What's the CPU utilization trend this week?"
 
- Debugging: "Correlate this error with metrics and traces"
 
- Alerting context: "What triggered the PagerDuty alert?"
 
---

### Contract

#### Tool Definition

 python
 Copy

`TOOL_DEFINITION = {
 "name": "metrics_query",
 "description": """
 Query observability platforms for metrics, logs, and traces.

 Supports:
 - Prometheus/VictoriaMetrics (PromQL)
 - DataDog (metrics, logs, APM)
 - Grafana (as unified query layer)
 - CloudWatch (AWS metrics and logs)

 Operations:
 - query: Execute a metrics query
 - logs: Search logs
 - traces: Find distributed traces
 - alerts: Get active alerts

 Use for performance analysis, debugging, and incident investigation.
 """,
 "parameters": {
 "type": "object",
 "properties": {
 "operation": {
 "type": "string",
 "enum": ["query", "logs", "traces", "alerts"],
 "description": "Type of observability query"
 },
 "query": {
 "type": "string",
 "description": "Query in natural language or native syntax (PromQL, etc.)"
 },
 "service": {
 "type": "string",
 "description": "Service/application to query"
 },
 "time_range": {
 "type": "object",
 "properties": {
 "start": {"type": "string"},
 "end": {"type": "string"},
 "relative": {"type": "string"}
 },
 "description": "Time range (e.g., {relative: '1h'} or {start: '...', end: '...'})"
 },
 "platform": {
 "type": "string",
 "enum": ["auto", "prometheus", "datadog", "grafana", "cloudwatch"],
 "default": "auto",
 "description": "Observability platform"
 },
 "aggregation": {
 "type": "string",
 "enum": ["avg", "sum", "min", "max", "p50", "p90", "p95", "p99"],
 "description": "Aggregation for metrics"
 }
 },
 "required": ["operation", "query"]
 }
}`
```

#### Output Schema

 python
 Copy

`@dataclass
class MetricsQueryOutput:
 operation: str
 platform: str
 native_query: str # Translated query in native syntax

 # For query operation
 metrics: MetricsResult | None = None

 # For logs operation
 logs: LogsResult | None = None

 # For traces operation
 traces: TracesResult | None = None

 # For alerts operation
 alerts: list[Alert] | None = None

@dataclass
class MetricsResult:
 series: list[TimeSeries]
 summary: MetricsSummary

@dataclass
class TimeSeries:
 labels: dict[str, str] # {service: "api", endpoint: "/orders"}
 values: list[DataPoint]

@dataclass
class DataPoint:
 timestamp: datetime
 value: float

@dataclass
class MetricsSummary:
 min: float
 max: float
 avg: float
 current: float
 trend: str # increasing | decreasing | stable
 anomalies: list[Anomaly]

@dataclass
class LogsResult:
 entries: list[LogEntry]
 total_count: int
 patterns: list[LogPattern] # Detected patterns/clusters

@dataclass
class LogEntry:
 timestamp: datetime
 level: str
 message: str
 service: str
 trace_id: str | None
 attributes: dict

@dataclass
class TracesResult:
 traces: list[Trace]
 service_map: ServiceMap | None

@dataclass
class Trace:
 trace_id: str
 root_span: Span
 duration_ms: float
 service_count: int
 error: bool

@dataclass
class Span:
 span_id: str
 service: str
 operation: str
 duration_ms: float
 status: str
 children: list[Span]

@dataclass
class Alert:
 id: str
 name: str
 status: str # firing | resolved
 severity: str
 message: str
 triggered_at: datetime
 labels: dict`
```

---

### Architecture

#### Query Translation

 python
 Copy

`class QueryTranslator:
 """Translate natural language to native query syntax."""

 async def translate(
 self,
 query: str,
 platform: str,
 context: QueryContext
 ) -> str:
 """
 Examples:
 - "p99 latency for payment-service"
 â†’ histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{service="payment-service"}[5m]))

 - "error rate for /api/orders"
 â†’ sum(rate(http_requests_total{endpoint="/api/orders",status=~"5.."}[5m]))
 / sum(rate(http_requests_total{endpoint="/api/orders"}[5m]))

 - "CPU usage trending"
 â†’ avg(rate(container_cpu_usage_seconds_total{...}[5m])) by (pod)
 """

 # Detect if already native query
 if self._is_native_query(query, platform):
 return query

 # Use platform-specific translation
 return await self._translate_natural_language(query, platform, context)`
```

#### Platform Adapters

 python
 Copy

`class PrometheusAdapter:
 """Adapter for Prometheus/VictoriaMetrics."""

 async def query(self, promql: str, time_range: TimeRange) -> MetricsResult:
 # Query range for time series
 result = await self.client.query_range(
 query=promql,
 start=time_range.start,
 end=time_range.end,
 step=self._calculate_step(time_range)
 )

 series = self._parse_matrix(result)
 summary = self._compute_summary(series)

 return MetricsResult(series=series, summary=summary)

class DataDogAdapter:
 """Adapter for DataDog."""

 async def query_metrics(self, query: str, time_range: TimeRange) -> MetricsResult:
 result = await self.client.query_timeseries(
 query=query,
 start=int(time_range.start.timestamp()),
 end=int(time_range.end.timestamp())
 )
 return self._parse_result(result)

 async def search_logs(self, query: str, time_range: TimeRange) -> LogsResult:
 result = await self.client.logs_list(
 filter_query=query,
 filter_from=time_range.start.isoformat(),
 filter_to=time_range.end.isoformat()
 )
 return self._parse_logs(result)`
```

---

### Configuration

 yaml
 Copy

`tool-metrics-query:
 # Platform configurations
 platforms:
 prometheus:
 enabled: true
 url: "${PROMETHEUS_URL}"
 auth:
 type: basic # basic | bearer | none
 username: "${PROMETHEUS_USER}"
 password: "${PROMETHEUS_PASS}"

 datadog:
 enabled: true
 api_key: "${DD_API_KEY}"
 app_key: "${DD_APP_KEY}"
 site: "datadoghq.com" # or datadoghq.eu, etc.

 grafana:
 enabled: true
 url: "${GRAFANA_URL}"
 api_key: "${GRAFANA_API_KEY}"

 cloudwatch:
 enabled: true
 region: "us-east-1"
 # Uses AWS credentials from environment

 # Query settings
 query:
 default_time_range: "1h"
 max_data_points: 1000
 timeout_seconds: 30

 # Service discovery
 services:
 # Map friendly names to label selectors
 payment-service:
 prometheus: {service: "payment-api"}
 datadog: {service: "payment-api"}
 auth-service:
 prometheus: {service: "auth-api"}

 # Translation hints
 translation:
 # Common metric name mappings
 latency: "http_request_duration_seconds"
 errors: "http_requests_total{status=~'5..'}"
 requests: "http_requests_total"`
```

---

### Examples

#### Example 1: Latency Query

 python
 Copy

`# Input
{
 "operation": "query",
 "query": "p99 latency for payment-service",
 "time_range": {"relative": "1h"}
}

# Output
{
 "operation": "query",
 "platform": "prometheus",
 "native_query": "histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket{service=\"payment-api\"}[5m])) by (le))",
 "metrics": {
 "series": [
 {
 "labels": {"service": "payment-api"},
 "values": [
 {"timestamp": "2024-01-15T10:00:00Z", "value": 0.245},
 {"timestamp": "2024-01-15T10:05:00Z", "value": 0.251},
 ...
 ]
 }
 ],
 "summary": {
 "min": 0.198,
 "max": 0.312,
 "avg": 0.247,
 "current": 0.251,
 "trend": "stable",
 "anomalies": []
 }
 }
}`
```

#### Example 2: Log Search with Correlation

 python
 Copy

`# Input
{
 "operation": "logs",
 "query": "error payment timeout",
 "service": "payment-service",
 "time_range": {"relative": "30m"}
}

# Output
{
 "operation": "logs",
 "platform": "datadog",
 "logs": {
 "entries": [
 {
 "timestamp": "2024-01-15T10:42:15Z",
 "level": "error",
 "message": "Payment gateway timeout after 30s",
 "service": "payment-api",
 "trace_id": "abc123",
 "attributes": {
 "user_id": "u_456",
 "payment_id": "pay_789",
 "gateway": "stripe"
 }
 }
 ],
 "total_count": 23,
 "patterns": [
 {
 "pattern": "Payment gateway timeout after *",
 "count": 20,
 "first_seen": "2024-01-15T10:30:00Z"
 }
 ]
 }
}`
```

#### Example 3: Active Alerts

 python
 Copy

`# Input
{
 "operation": "alerts",
 "service": "payment-service"
}

# Output
{
 "operation": "alerts",
 "alerts": [
 {
 "id": "alert_123",
 "name": "PaymentServiceHighLatency",
 "status": "firing",
 "severity": "warning",
 "message": "p99 latency > 500ms for 5 minutes",
 "triggered_at": "2024-01-15T10:35:00Z",
 "labels": {"service": "payment-api", "endpoint": "/process"}
 }
 ]
}`
```

---

### Security Considerations

- Accesses sensitive operational data
 
- API keys stored securely
 
- Query results may reveal infrastructure details
 
#### Permissions

 python
 Copy

`REQUIRED_CAPABILITIES = [
 "network:prometheus", # If Prometheus enabled
 "network:datadog", # If DataDog enabled
 "network:grafana", # If Grafana enabled
 "network:aws", # If CloudWatch enabled
]`
```

---

### Dependencies

#### Required

- `httpx` - HTTP client
 
#### Optional (per platform)

- `prometheus-api-client` - Prometheus
 
- `datadog-api-client` - DataDog
 
- `boto3` - CloudWatch
 
---

### Open Questions

- Query validation: Should we validate queries before execution?
 
- Result caching: Cache recent query results?
 
- Alerting integration: Support creating/modifying alerts?
 
- Dashboard linking: Link to relevant dashboards in results?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Tool Migration Helper
 tools

Priority: P2 (Enhancement)

Status: Draft

Module: `amplifier-module-tool-migration-helper`

### Overview

Assists with database schema migrations, data migrations, and API version migrations. Generates migration scripts, validates safety, plans rollback strategies, and monitors migration execution.

#### Value Proposition

 | 
 
 | Without | With

 | Manually write migration scripts | Auto-generate from schema diff
 
 | Hope rollback works | Validated rollback scripts before deployment
 
 | Migration issues discovered in prod | Pre-flight safety checks
 
 | Complex data migrations are scary | Step-by-step execution with checkpoints

#### Use Cases

- Schema migration: Generate migration from model changes
 
- Safety validation: Check migration for data loss risks
 
- Rollback planning: Generate and test rollback scripts
 
- Data migration: Transform data during schema changes
 
- Migration monitoring: Track progress of long-running migrations
 
---

### Contract

#### Tool Definition

 python
 Copy

`TOOL_DEFINITION = {
 "name": "migration_helper",
 "description": """
 Database and API migration assistance.

 Operations:
 - generate: Generate migration from schema changes
 - validate: Check migration safety
 - plan_rollback: Generate rollback strategy
 - execute: Run migration with monitoring
 - status: Check migration status

 Supports: PostgreSQL, MySQL, SQLite, MongoDB, and framework ORMs.
 """,
 "parameters": {
 "type": "object",
 "properties": {
 "operation": {
 "type": "string",
 "enum": ["generate", "validate", "plan_rollback", "execute", "status"],
 "description": "Operation to perform"
 },
 "migration_type": {
 "type": "string",
 "enum": ["schema", "data", "api"],
 "default": "schema",
 "description": "Type of migration"
 },
 "source": {
 "type": "string",
 "description": "Source schema/version (for generate)"
 },
 "target": {
 "type": "string",
 "description": "Target schema/version (for generate)"
 },
 "migration_file": {
 "type": "string",
 "description": "Migration file path (for validate/execute)"
 },
 "dry_run": {
 "type": "boolean",
 "default": true,
 "description": "Simulate without applying changes"
 }
 },
 "required": ["operation"]
 }
}`
```

#### Output Schema

 python
 Copy

`@dataclass
class MigrationHelperOutput:
 operation: str

 # For generate
 migration: GeneratedMigration | None = None

 # For validate
 validation: MigrationValidation | None = None

 # For plan_rollback
 rollback: RollbackPlan | None = None

 # For execute
 execution: ExecutionResult | None = None

 # For status
 status: MigrationStatus | None = None

@dataclass
class GeneratedMigration:
 name: str
 up_script: str # Forward migration SQL
 down_script: str # Rollback SQL
 changes: list[SchemaChange]
 estimated_duration: str
 data_at_risk: bool

@dataclass
class SchemaChange:
 type: str # add_column | drop_column | rename | alter_type | add_index | etc.
 table: str
 column: str | None
 details: dict
 reversible: bool
 data_loss_risk: str # none | low | high

@dataclass
class MigrationValidation:
 safe: bool
 warnings: list[ValidationWarning]
 errors: list[ValidationError]
 recommendations: list[str]

@dataclass
class ValidationWarning:
 type: str
 message: str
 location: str
 suggestion: str

@dataclass
class ValidationError:
 type: str
 message: str
 location: str
 blocking: bool

@dataclass
class RollbackPlan:
 script: str
 steps: list[RollbackStep]
 data_recovery: DataRecoveryPlan | None
 estimated_duration: str
 tested: bool

@dataclass
class RollbackStep:
 order: int
 description: str
 sql: str
 verification: str # Query to verify step succeeded

@dataclass
class ExecutionResult:
 success: bool
 duration_seconds: float
 rows_affected: int
 steps_completed: list[str]
 errors: list[str]
 rollback_triggered: bool`
```

---

### Architecture

#### Migration Generator

 python
 Copy

`class MigrationGenerator:
 """Generate migrations from schema differences."""

 async def generate(
 self,
 source: str,
 target: str,
 migration_type: str
 ) -> GeneratedMigration:
 # Parse schemas
 source_schema = await self._parse_schema(source)
 target_schema = await self._parse_schema(target)

 # Compute differences
 changes = self._diff_schemas(source_schema, target_schema)

 # Generate SQL
 up_script = self._generate_up_script(changes)
 down_script = self._generate_down_script(changes)

 # Analyze risks
 data_at_risk = any(c.data_loss_risk != "none" for c in changes)

 return GeneratedMigration(
 name=self._generate_name(changes),
 up_script=up_script,
 down_script=down_script,
 changes=changes,
 estimated_duration=self._estimate_duration(changes),
 data_at_risk=data_at_risk
 )

 def _diff_schemas(
 self,
 source: Schema,
 target: Schema
 ) -> list[SchemaChange]:
 changes = []

 # Compare tables
 for table in target.tables:
 if table.name not in source.table_names:
 changes.append(SchemaChange(
 type="create_table",
 table=table.name,
 details={"columns": table.columns},
 reversible=True,
 data_loss_risk="none"
 ))
 else:
 # Compare columns
 source_table = source.get_table(table.name)
 changes.extend(self._diff_columns(source_table, table))

 # Detect dropped tables
 for table_name in source.table_names:
 if table_name not in target.table_names:
 changes.append(SchemaChange(
 type="drop_table",
 table=table_name,
 details={},
 reversible=False,
 data_loss_risk="high"
 ))

 return changes`
```

#### Safety Validator

 python
 Copy

`class MigrationValidator:
 """Validate migration safety."""

 def validate(self, migration: GeneratedMigration) -> MigrationValidation:
 warnings = []
 errors = []

 for change in migration.changes:
 # Check for data loss
 if change.data_loss_risk == "high":
 errors.append(ValidationError(
 type="data_loss",
 message=f"Dropping {change.table}.{change.column} will cause data loss",
 location=f"{change.table}.{change.column}",
 blocking=True
 ))

 # Check for irreversible changes
 if not change.reversible:
 warnings.append(ValidationWarning(
 type="irreversible",
 message=f"Change to {change.table} cannot be automatically rolled back",
 location=change.table,
 suggestion="Create manual rollback script and backup data first"
 ))

 # Check for locking issues
 if change.type in ["add_index", "alter_type"] and self._is_large_table(change.table):
 warnings.append(ValidationWarning(
 type="lock_risk",
 message=f"This operation may lock {change.table} for extended time",
 location=change.table,
 suggestion="Consider using CONCURRENTLY option or off-peak deployment"
 ))

 recommendations = self._generate_recommendations(migration, warnings, errors)

 return MigrationValidation(
 safe=len(errors) == 0,
 warnings=warnings,
 errors=errors,
 recommendations=recommendations
 )`
```

---

### Examples

#### Example 1: Generate Migration

 python
 Copy

`# Input
{
 "operation": "generate",
 "source": "HEAD~1", # Previous commit's schema
 "target": "HEAD" # Current schema
}

# Output
{
 "migration": {
 "name": "20240115_add_payment_retry_columns",
 "up_script": """
-- Add retry tracking columns to payments table
ALTER TABLE payments ADD COLUMN retry_count INTEGER DEFAULT 0;
ALTER TABLE payments ADD COLUMN last_retry_at TIMESTAMP;
ALTER TABLE payments ADD COLUMN retry_reason TEXT;

-- Add index for retry queries
CREATE INDEX idx_payments_retry ON payments (retry_count, last_retry_at);
""",
 "down_script": """
-- Remove retry tracking
DROP INDEX IF EXISTS idx_payments_retry;
ALTER TABLE payments DROP COLUMN retry_reason;
ALTER TABLE payments DROP COLUMN last_retry_at;
ALTER TABLE payments DROP COLUMN retry_count;
""",
 "changes": [
 {
 "type": "add_column",
 "table": "payments",
 "column": "retry_count",
 "reversible": true,
 "data_loss_risk": "none"
 },
 {
 "type": "add_index",
 "table": "payments",
 "details": {"columns": ["retry_count", "last_retry_at"]},
 "reversible": true,
 "data_loss_risk": "none"
 }
 ],
 "estimated_duration": "< 1 minute",
 "data_at_risk": false
 }
}`
```

#### Example 2: Validate Migration

 python
 Copy

`# Input
{
 "operation": "validate",
 "migration_file": "migrations/20240115_remove_legacy_auth.sql"
}

# Output
{
 "validation": {
 "safe": false,
 "errors": [
 {
 "type": "data_loss",
 "message": "Dropping column users.legacy_token will delete 45,000 rows of data",
 "location": "users.legacy_token",
 "blocking": true
 }
 ],
 "warnings": [
 {
 "type": "irreversible",
 "message": "DROP COLUMN cannot be automatically rolled back",
 "suggestion": "Backup users.legacy_token before migration"
 },
 {
 "type": "foreign_key",
 "message": "sessions.user_token references users.legacy_token",
 "suggestion": "Drop foreign key constraint first"
 }
 ],
 "recommendations": [
 "1. Create backup: SELECT id, legacy_token INTO users_legacy_backup FROM users",
 "2. Update sessions to use new auth: UPDATE sessions SET auth_type = 'new'",
 "3. Drop foreign key: ALTER TABLE sessions DROP CONSTRAINT fk_user_token",
 "4. Then proceed with migration"
 ]
 }
}`
```

---

### Configuration

 yaml
 Copy

`tool-migration-helper:
 # Database connections
 databases:
 primary:
 type: postgresql
 connection_string: "${DATABASE_URL}"

 # ORM integration
 orm:
 framework: sqlalchemy # sqlalchemy | django | alembic
 models_path: "src/models/"

 # Safety thresholds
 safety:
 large_table_rows: 100000 # Tables larger than this get warnings
 max_lock_seconds: 60 # Warn if operation might lock longer
 require_backup_for_drops: true

 # Migration settings
 migration:
 directory: "migrations/"
 naming: "timestamp_description" # timestamp_description | sequential`
```

---

### Security Considerations

- Executes SQL against databases
 
- Requires database credentials
 
- Dry-run mode recommended before production
 
---

### Dependencies

#### Required

- `sqlparse` - SQL parsing
 
- Database drivers (psycopg2, mysql-connector, etc.)
 
#### Optional

- `alembic` - SQLAlchemy migrations
 
- `django` - Django migrations
 
---

### Open Questions

- Multi-database migrations: Support coordinated migrations across databases?
 
- Zero-downtime patterns: Generate online schema change scripts?
 
- Data transformation: Support complex data migrations with Python?
 
- Approval workflow: Require approval for risky migrations?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Tool Pr Context
 tools

Priority: P0 (Foundation)

Status: Draft

Module: `amplifier-module-tool-pr-context`

### Overview

Fetches comprehensive context about pull requests including the PR itself, all comments, linked issues, CI status, related PRs, and relevant code context. Provides everything needed to understand, review, or continue work on a PR.

#### Value Proposition

 | 
 
 | Without | With

 | Open GitHub, read PR, click through to issues, check CI, find related PRs | Single call returns complete PR context
 
 | Context switching between browser and terminal | Full context in your workflow
 
 | Missing context from linked issues and prior discussions | Complete picture with cross-references
 
 | Manual correlation of PR with tickets | Automatic JIRA/GitHub issue linkage

#### Use Cases

- PR review: Get full context before reviewing code
 
- Continue work: Understand where a PR left off, what feedback exists
 
- Impact analysis: See what other PRs touch related code
 
- Status check: Quick summary of PR state, blockers, approvals
 
- Historical lookup: "What was in PR #123 and why?"
 
---

### Contract

#### Tool Definition

 python
 Copy

`TOOL_DEFINITION = {
 "name": "pr_context",
 "description": """
 Fetches comprehensive context about a pull request including:
 - PR details (title, description, author, status, branch info)
 - All comments and review threads
 - Linked issues (JIRA, GitHub Issues)
 - CI/CD status and logs
 - Related PRs (same files, same branch, dependencies)
 - Code diff with surrounding context

 Use when you need to understand, review, or work on a PR.
 """,
 "parameters": {
 "type": "object",
 "properties": {
 "pr_identifier": {
 "type": "string",
 "description": "PR number, URL, or branch name"
 },
 "repo": {
 "type": "string",
 "description": "Repository (owner/repo). Defaults to current repo."
 },
 "include": {
 "type": "array",
 "items": {
 "type": "string",
 "enum": ["comments", "reviews", "ci", "linked_issues", "related_prs", "diff", "files"]
 },
 "default": ["comments", "reviews", "ci", "linked_issues", "diff"],
 "description": "What context to include"
 },
 "diff_context_lines": {
 "type": "integer",
 "default": 5,
 "description": "Lines of context around diff hunks"
 }
 },
 "required": ["pr_identifier"]
 }
}`
```

#### Input Schema

 python
 Copy

`@dataclass
class PRContextInput:
 pr_identifier: str # PR number, URL, or branch name
 repo: str | None = None # owner/repo, defaults to current
 include: list[str] = field(default_factory=lambda: [
 "comments", "reviews", "ci", "linked_issues", "diff"
 ])
 diff_context_lines: int = 5`
```

#### Output Schema

 python
 Copy

`@dataclass
class PRContext:
 # Core PR info
 pr: PRDetails

 # Included based on 'include' parameter
 comments: list[Comment] | None
 reviews: list[Review] | None
 ci_status: CIStatus | None
 linked_issues: list[LinkedIssue] | None
 related_prs: list[RelatedPR] | None
 diff: Diff | None
 files: list[FileChange] | None

 # Computed summaries
 summary: PRSummary

@dataclass
class PRDetails:
 number: int
 title: str
 description: str
 author: str
 state: str # open | closed | merged
 draft: bool
 base_branch: str
 head_branch: str
 created_at: datetime
 updated_at: datetime
 merged_at: datetime | None
 url: str

 # Approval status
 approvals: int
 changes_requested: int
 pending_reviewers: list[str]

@dataclass
class Comment:
 id: str
 author: str
 body: str
 created_at: datetime
 updated_at: datetime | None
 reply_to: str | None # Parent comment ID if reply
 reactions: dict[str, int] # emoji -> count

 # For line comments
 file_path: str | None
 line_number: int | None
 diff_hunk: str | None

@dataclass
class Review:
 id: str
 author: str
 state: str # approved | changes_requested | commented
 body: str | None
 submitted_at: datetime
 comments: list[Comment] # Review-specific comments

@dataclass
class CIStatus:
 overall: str # success | failure | pending | neutral
 checks: list[CICheck]

@dataclass
class CICheck:
 name: str
 status: str # success | failure | pending | skipped
 conclusion: str | None
 url: str | None
 started_at: datetime | None
 completed_at: datetime | None
 summary: str | None # Brief failure reason if failed

@dataclass
class LinkedIssue:
 source: str # "github" | "jira"
 key: str # Issue number or JIRA key
 title: str
 status: str
 url: str
 relationship: str # "closes" | "references" | "related"

@dataclass
class RelatedPR:
 number: int
 title: str
 author: str
 state: str
 relationship: str # "same_files" | "same_branch" | "dependency" | "dependent"
 overlap_files: list[str] | None # Files touched by both PRs

@dataclass
class Diff:
 stats: DiffStats
 files: list[FileDiff]

@dataclass
class FileDiff:
 path: str
 status: str # added | modified | deleted | renamed
 additions: int
 deletions: int
 hunks: list[DiffHunk]

@dataclass
class PRSummary:
 """Computed summary for quick understanding."""
 one_liner: str # "Add retry logic to payment gateway"
 change_type: str # feature | bugfix | refactor | docs | test
 risk_level: str # low | medium | high
 blockers: list[str] # What's blocking merge
 ready_to_merge: bool
 key_changes: list[str] # Bullet points of main changes
 outstanding_threads: int # Unresolved comment threads`
```

#### Events Emitted

 | 
 
 | Event | When | Data

 | `tool:pr_context:start` | Fetch begins | pr_identifier, repo, include
 
 | `tool:pr_context:github_fetch` | GitHub API call | endpoint, duration_ms
 
 | `tool:pr_context:jira_fetch` | JIRA API call | issue_key, duration_ms
 
 | `tool:pr_context:complete` | Fetch done | pr_number, sections_fetched
 
 | `tool:pr_context:error` | Fetch failed | error_type, message

---

### Architecture

#### Component Diagram

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ tool-pr-context â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Identifier â”‚â”€â”€â”€â–¶â”‚ Context â”‚â”€â”€â”€â–¶â”‚ Summary â”‚ â”‚
â”‚ â”‚ Resolver â”‚ â”‚ Fetcher â”‚ â”‚ Generator â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ GitHub â”‚ â”‚ JIRA â”‚ â”‚ Local â”‚ â”‚
â”‚ â”‚ Client â”‚ â”‚ Client â”‚ â”‚ Git â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Internal Components

#### 1. Identifier Resolver

 python
 Copy

`class IdentifierResolver:
 """
 Resolves various PR identifier formats to canonical form.

 Supports:
 - PR number: "123" or "#123"
 - URL: "https://github.com/owner/repo/pull/123"
 - Branch: "feature/add-retry" (finds PR for branch)
 - Current: "current" or "." (PR for current branch)
 """

 async def resolve(self, identifier: str, repo: str | None) -> ResolvedPR:
 # Detect format
 if identifier in ("current", "."):
 branch = await self._get_current_branch()
 return await self._find_pr_for_branch(branch, repo)

 if identifier.startswith("http"):
 return self._parse_url(identifier)

 if identifier.replace("#", "").isdigit():
 pr_number = int(identifier.replace("#", ""))
 return ResolvedPR(number=pr_number, repo=repo or await self._detect_repo())

 # Assume branch name
 return await self._find_pr_for_branch(identifier, repo)`
```

#### 2. Context Fetcher

 python
 Copy

`class ContextFetcher:
 """
 Orchestrates fetching from multiple sources based on 'include' param.
 """

 async def fetch(self, pr: ResolvedPR, include: list[str]) -> PRContext:
 # Always fetch core PR details
 pr_details = await self.github.get_pr(pr.repo, pr.number)

 # Parallel fetch of included sections
 tasks = {}

 if "comments" in include:
 tasks["comments"] = self._fetch_comments(pr)
 if "reviews" in include:
 tasks["reviews"] = self._fetch_reviews(pr)
 if "ci" in include:
 tasks["ci"] = self._fetch_ci_status(pr)
 if "linked_issues" in include:
 tasks["linked_issues"] = self._fetch_linked_issues(pr, pr_details)
 if "related_prs" in include:
 tasks["related_prs"] = self._fetch_related_prs(pr)
 if "diff" in include:
 tasks["diff"] = self._fetch_diff(pr)
 if "files" in include:
 tasks["files"] = self._fetch_files(pr)

 results = await asyncio.gather(*tasks.values(), return_exceptions=True)

 return PRContext(
 pr=pr_details,
 **dict(zip(tasks.keys(), results))
 )

 async def _fetch_linked_issues(self, pr: ResolvedPR, details: PRDetails) -> list[LinkedIssue]:
 """Extract and fetch linked issues from PR description and commits."""
 # Parse PR description for issue references
 github_refs = self._parse_github_refs(details.description)
 jira_refs = self._parse_jira_refs(details.description)

 # Also check commit messages
 commits = await self.github.get_pr_commits(pr.repo, pr.number)
 for commit in commits:
 github_refs.extend(self._parse_github_refs(commit.message))
 jira_refs.extend(self._parse_jira_refs(commit.message))

 # Fetch issue details
 issues = []

 for ref in set(github_refs):
 issue = await self.github.get_issue(pr.repo, ref.number)
 issues.append(LinkedIssue(
 source="github",
 key=f"#{ref.number}",
 title=issue.title,
 status=issue.state,
 url=issue.url,
 relationship=ref.relationship
 ))

 for ref in set(jira_refs):
 if self.jira:
 issue = await self.jira.get_issue(ref.key)
 issues.append(LinkedIssue(
 source="jira",
 key=ref.key,
 title=issue.summary,
 status=issue.status,
 url=issue.url,
 relationship=ref.relationship
 ))

 return issues`
```

#### 3. Summary Generator

 python
 Copy

`class SummaryGenerator:
 """
 Generates human-readable summaries from raw PR context.
 """

 def generate(self, context: PRContext) -> PRSummary:
 return PRSummary(
 one_liner=self._generate_one_liner(context),
 change_type=self._classify_change_type(context),
 risk_level=self._assess_risk(context),
 blockers=self._identify_blockers(context),
 ready_to_merge=self._check_merge_readiness(context),
 key_changes=self._extract_key_changes(context),
 outstanding_threads=self._count_unresolved_threads(context)
 )

 def _identify_blockers(self, context: PRContext) -> list[str]:
 blockers = []

 # CI failures
 if context.ci_status and context.ci_status.overall == "failure":
 failed = [c.name for c in context.ci_status.checks if c.status == "failure"]
 blockers.append(f"CI failing: {', '.join(failed)}")

 # Changes requested
 if context.pr.changes_requested > 0:
 blockers.append(f"{context.pr.changes_requested} reviewer(s) requested changes")

 # Unresolved threads
 unresolved = self._count_unresolved_threads(context)
 if unresolved > 0:
 blockers.append(f"{unresolved} unresolved comment thread(s)")

 # Missing approvals
 if context.pr.approvals < 1:
 blockers.append("No approvals yet")

 # Draft status
 if context.pr.draft:
 blockers.append("PR is still in draft")

 return blockers

 def _assess_risk(self, context: PRContext) -> str:
 """Assess risk level based on changes."""
 risk_score = 0

 if context.diff:
 # Large changes
 if context.diff.stats.total_changes > 500:
 risk_score += 2
 elif context.diff.stats.total_changes > 200:
 risk_score += 1

 # Many files
 if len(context.diff.files) > 20:
 risk_score += 1

 # Critical file patterns
 critical_patterns = ["migration", "auth", "payment", "security", "config"]
 for file in context.diff.files:
 if any(p in file.path.lower() for p in critical_patterns):
 risk_score += 1
 break

 if risk_score >= 3:
 return "high"
 elif risk_score >= 1:
 return "medium"
 return "low"`
```

---

### Configuration

 yaml
 Copy

`tool-pr-context:
 # GitHub configuration
 github:
 auth_token: "${GITHUB_TOKEN}"
 api_url: "https://api.github.com" # or GitHub Enterprise URL

 # Rate limiting
 rate_limit_buffer: 100 # Keep this many requests in reserve

 # Caching
 cache_ttl_seconds: 60 # Cache PR data briefly

 # JIRA configuration (optional)
 jira:
 enabled: true
 base_url: "${JIRA_URL}"
 auth_token: "${JIRA_TOKEN}"

 # Issue key patterns to recognize
 key_patterns:
 - "[A-Z]{2,10}-\\d+" # Standard JIRA key format

 # Default behavior
 defaults:
 include:
 - comments
 - reviews
 - ci
 - linked_issues
 - diff
 diff_context_lines: 5

 # Related PR detection
 related_prs:
 # How to find related PRs
 strategies:
 - same_files # PRs touching same files
 - same_branch_prefix # feature/X-* branches
 - linked_issues # PRs linked to same issues

 # Limits
 max_related: 5
 lookback_days: 30 # Only PRs from last 30 days

 # Summary generation
 summary:
 # Risk assessment thresholds
 high_risk_lines: 500
 medium_risk_lines: 200
 critical_paths:
 - "migrations/"
 - "auth/"
 - "security/"
 - "payments/"`
```

---

### Examples

#### Example 1: Current Branch PR Context

 python
 Copy

`# Input
{
 "pr_identifier": "current"
}

# Output
{
 "pr": {
 "number": 456,
 "title": "Add retry logic to payment gateway",
 "description": "Implements exponential backoff retry for payment API calls.\n\nCloses JIRA-4523\nRelated to #451",
 "author": "alice",
 "state": "open",
 "draft": false,
 "base_branch": "main",
 "head_branch": "feature/payment-retry",
 "approvals": 1,
 "changes_requested": 0,
 "pending_reviewers": ["bob", "carol"]
 },
 "comments": [
 {
 "id": "c1",
 "author": "bob",
 "body": "Should we add a circuit breaker too?",
 "created_at": "2024-01-15T10:30:00Z",
 "file_path": "src/payments/gateway.py",
 "line_number": 42
 }
 ],
 "reviews": [
 {
 "id": "r1",
 "author": "carol",
 "state": "approved",
 "body": "LGTM! Nice use of tenacity.",
 "submitted_at": "2024-01-15T11:00:00Z"
 }
 ],
 "ci_status": {
 "overall": "success",
 "checks": [
 {"name": "tests", "status": "success"},
 {"name": "lint", "status": "success"},
 {"name": "security-scan", "status": "success"}
 ]
 },
 "linked_issues": [
 {
 "source": "jira",
 "key": "JIRA-4523",
 "title": "Payment failures during peak hours",
 "status": "In Progress",
 "relationship": "closes"
 },
 {
 "source": "github",
 "key": "#451",
 "title": "Improve payment reliability",
 "status": "open",
 "relationship": "related"
 }
 ],
 "summary": {
 "one_liner": "Adds retry logic with exponential backoff to payment gateway",
 "change_type": "feature",
 "risk_level": "medium",
 "blockers": ["1 unresolved comment thread(s)"],
 "ready_to_merge": false,
 "key_changes": [
 "New retry decorator in payments/retry.py",
 "Applied to PaymentGateway.process_payment()",
 "Config for max retries and backoff"
 ],
 "outstanding_threads": 1
 }
}`
```

#### Example 2: PR Status Quick Check

 python
 Copy

`# Input
{
 "pr_identifier": "789",
 "include": ["ci", "reviews"]
}

# Output (minimal, fast)
{
 "pr": {
 "number": 789,
 "title": "Update dependencies",
 "state": "open",
 "approvals": 0,
 "changes_requested": 1,
 "pending_reviewers": ["security-team"]
 },
 "reviews": [
 {
 "author": "security-bot",
 "state": "changes_requested",
 "body": "Found 2 vulnerabilities in updated packages"
 }
 ],
 "ci_status": {
 "overall": "failure",
 "checks": [
 {"name": "security-scan", "status": "failure", "summary": "CVE-2024-1234 in lodash"}
 ]
 },
 "summary": {
 "blockers": [
 "CI failing: security-scan",
 "1 reviewer(s) requested changes"
 ],
 "ready_to_merge": false
 }
}`
```

---

### Security Considerations

#### Data Access

- GitHub API: Uses provided token, respects repository permissions
 
- JIRA API: Uses provided token, respects project permissions
 
- Local git: Reads from current repository only
 
#### Sensitive Data

- PR descriptions: May contain sensitive information
 
- Comments: May contain sensitive discussions
 
- Diff content: May contain sensitive code
 
#### Permissions Model

 python
 Copy

`REQUIRED_CAPABILITIES = [
 "network:github", # GitHub API access
]

OPTIONAL_CAPABILITIES = [
 "network:jira", # JIRA API access (if configured)
 "filesystem:read", # Local git operations
]`
```

#### Risk Mitigations

 | 
 
 | Risk | Mitigation

 | Token exposure | Tokens never logged or returned in output
 
 | Unauthorized repo access | API calls fail if token lacks permissions
 
 | Rate limiting | Built-in rate limit awareness, graceful degradation

---

### Testing Strategy

#### Unit Tests

 python
 Copy

`def test_identifier_resolver_handles_pr_number():
 resolver = IdentifierResolver()
 result = await resolver.resolve("123", "owner/repo")
 assert result.number == 123
 assert result.repo == "owner/repo"

def test_identifier_resolver_handles_url():
 resolver = IdentifierResolver()
 result = await resolver.resolve(
 "https://github.com/owner/repo/pull/456",
 None
 )
 assert result.number == 456
 assert result.repo == "owner/repo"

def test_summary_identifies_blockers():
 context = PRContext(
 pr=PRDetails(approvals=0, changes_requested=1, ...),
 ci_status=CIStatus(overall="failure", ...),
 ...
 )
 summary = SummaryGenerator().generate(context)
 assert len(summary.blockers) >= 2
 assert not summary.ready_to_merge`
```

#### Integration Tests

 python
 Copy

`async def test_fetches_real_pr_context(mock_github):
 """Test against mock GitHub API."""
 mock_github.setup_pr(number=123, title="Test PR", ...)

 tool = PRContextTool(config)
 result = await tool.execute({"pr_identifier": "123"})

 assert result.pr.number == 123
 assert result.pr.title == "Test PR"

async def test_handles_linked_jira_issues(mock_github, mock_jira):
 """Test JIRA integration."""
 mock_github.setup_pr(description="Fixes PROJ-123")
 mock_jira.setup_issue(key="PROJ-123", summary="Bug")

 result = await tool.execute({"pr_identifier": "1", "include": ["linked_issues"]})

 assert len(result.linked_issues) == 1
 assert result.linked_issues[0].key == "PROJ-123"`
```

---

### Dependencies

#### Required

- `httpx` - Async HTTP client for API calls
 
- `PyGithub` or direct API - GitHub operations
 
#### Optional

- `jira` - JIRA API client (if JIRA enabled)
 
- `gitpython` - Local git operations
 
---

### Open Questions

- Diff size limits: Should we truncate large diffs?
 
 - Option A: Always return full diff (complete but potentially huge)

 - Option B: Truncate with indication (smaller but lossy)

 - Option C: Return stats only for large diffs, full for small

- Comment threading: How to represent nested comment threads?
 
 - Option A: Flat list with reply_to references

 - Option B: Nested structure

 - Option C: Both (flat + thread groupings)

- CI log access: Should we fetch full CI logs or just status?
 
 - Full logs useful for debugging but can be very large

 - Could offer as separate follow-up query

- Webhook vs polling: For real-time updates, should we support webhooks?
 
 - Currently: Point-in-time fetch

 - Future: Could add streaming updates

---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Tool Slack Search
 tools

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-tool-slack-search`

### Overview

Search team Slack conversations to find decisions, context, and tribal knowledge. Surfaces relevant discussions that explain why code was written a certain way or captures historical context not found in documentation.

#### Value Proposition

 | 
 
 | Without | With

 | "Why did we do it this way?" â†’ Ask around, hope someone remembers | Search Slack, find the original discussion
 
 | Context lost when people leave | Institutional knowledge preserved and searchable
 
 | Decisions made in DMs never documented | Surface relevant conversations (with permissions)
 
 | Hours searching Slack's clunky UI | Semantic search finds relevant threads instantly

#### Use Cases

- Decision archaeology: "Why did we choose Redis over Memcached?"
 
- Context recovery: "What was discussed about the auth refactor?"
 
- Incident history: "What happened during the outage on Jan 15?"
 
- Expert finding: "Who knows about the payment gateway?"
 
- Meeting follow-up: "What did we decide in the sprint planning?"
 
---

### Contract

#### Tool Definition

 python
 Copy

`TOOL_DEFINITION = {
 "name": "slack_search",
 "description": """
 Search Slack conversations for context and decisions.

 Search across:
 - Public channels you have access to
 - Private channels you're a member of
 - Direct messages (your own only)
 - Threads and replies

 Use for finding decisions, context, and institutional knowledge.
 """,
 "parameters": {
 "type": "object",
 "properties": {
 "query": {
 "type": "string",
 "description": "Search query (natural language or keywords)"
 },
 "channels": {
 "type": "array",
 "items": {"type": "string"},
 "description": "Limit search to specific channels"
 },
 "from_user": {
 "type": "string",
 "description": "Filter by sender"
 },
 "date_range": {
 "type": "object",
 "properties": {
 "after": {"type": "string", "format": "date"},
 "before": {"type": "string", "format": "date"}
 },
 "description": "Filter by date range"
 },
 "has": {
 "type": "array",
 "items": {"type": "string", "enum": ["link", "file", "reaction", "thread"]},
 "description": "Filter by content type"
 },
 "include_threads": {
 "type": "boolean",
 "default": true,
 "description": "Include thread replies in search"
 },
 "max_results": {
 "type": "integer",
 "default": 20,
 "description": "Maximum results to return"
 }
 },
 "required": ["query"]
 }
}`
```

#### Output Schema

 python
 Copy

`@dataclass
class SlackSearchOutput:
 results: list[SlackMessage]
 total_count: int
 query_interpretation: str
 channels_searched: list[str]

@dataclass
class SlackMessage:
 # Message identity
 id: str # Slack message ID
 permalink: str # Direct link to message

 # Content
 text: str # Message text (markdown)
 user: SlackUser
 channel: SlackChannel
 timestamp: datetime

 # Thread context
 thread_ts: str | None # Thread parent timestamp
 is_thread_parent: bool
 reply_count: int
 thread_participants: list[str] # Users in thread

 # Rich content
 attachments: list[Attachment]
 files: list[SlackFile]
 reactions: list[Reaction]
 links: list[str]

 # Context
 thread_messages: list[SlackMessage] | None # If is_thread_parent
 relevance_score: float

@dataclass
class SlackUser:
 id: str
 name: str
 display_name: str
 avatar_url: str | None

@dataclass
class SlackChannel:
 id: str
 name: str
 is_private: bool

@dataclass
class Attachment:
 title: str | None
 text: str | None
 type: str # message, file, etc.

@dataclass
class Reaction:
 name: str # emoji name
 count: int
 users: list[str] # User IDs who reacted`
```

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ tool-slack-search â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Query â”‚â”€â”€â”€â–¶â”‚ Slack â”‚â”€â”€â”€â–¶â”‚ Result â”‚ â”‚
â”‚ â”‚ Builder â”‚ â”‚ API â”‚ â”‚ Enricher â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Query Builder

 python
 Copy

`class SlackQueryBuilder:
 """Build Slack search queries from natural language."""

 def build(self, input: SlackSearchInput) -> str:
 """Convert input to Slack search query syntax."""
 parts = [input.query]

 if input.channels:
 channel_part = " ".join(f"in:{c}" for c in input.channels)
 parts.append(channel_part)

 if input.from_user:
 parts.append(f"from:{input.from_user}")

 if input.date_range:
 if input.date_range.after:
 parts.append(f"after:{input.date_range.after}")
 if input.date_range.before:
 parts.append(f"before:{input.date_range.before}")

 if input.has:
 for h in input.has:
 parts.append(f"has:{h}")

 return " ".join(parts)`
```

#### Result Enricher

 python
 Copy

`class ResultEnricher:
 """Enrich search results with thread context."""

 async def enrich(
 self,
 messages: list[dict],
 include_threads: bool
 ) -> list[SlackMessage]:
 enriched = []

 for msg in messages:
 slack_msg = self._parse_message(msg)

 # Fetch thread if parent and include_threads
 if include_threads and slack_msg.is_thread_parent and slack_msg.reply_count > 0:
 slack_msg.thread_messages = await self._fetch_thread(
 slack_msg.channel.id,
 slack_msg.thread_ts
 )

 enriched.append(slack_msg)

 return enriched

 async def _fetch_thread(
 self,
 channel_id: str,
 thread_ts: str
 ) -> list[SlackMessage]:
 """Fetch all replies in a thread."""
 replies = await self.slack.conversations_replies(
 channel=channel_id,
 ts=thread_ts
 )
 return [self._parse_message(r) for r in replies["messages"][1:]] # Skip parent`
```

---

### Configuration

 yaml
 Copy

`tool-slack-search:
 # Authentication
 auth:
 # User token with search:read scope
 user_token: "${SLACK_USER_TOKEN}"

 # Or bot token (more limited)
 # bot_token: "${SLACK_BOT_TOKEN}"

 # Search settings
 search:
 # Default channels to search (if none specified)
 default_channels:
 - general
 - engineering
 - incidents

 # Channels to never search
 excluded_channels:
 - random
 - social

 # Include archived channels
 include_archived: false

 # Results
 results:
 max_results: 50
 include_threads: true
 max_thread_messages: 20

 # Rate limiting
 rate_limit:
 requests_per_minute: 20`
```

---

### Examples

#### Example 1: Decision Search

 python
 Copy

`# Input
{
 "query": "Redis vs Memcached decision",
 "channels": ["engineering", "architecture"],
 "has": ["thread"],
 "max_results": 5
}

# Output
{
 "results": [
 {
 "id": "msg123",
 "permalink": "https://workspace.slack.com/archives/C123/p1234567890",
 "text": "We need to decide on caching. Options are Redis and Memcached. Let's discuss pros/cons.",
 "user": {"name": "alice", "display_name": "Alice Chen"},
 "channel": {"name": "architecture", "is_private": false},
 "timestamp": "2023-11-15T10:30:00Z",
 "is_thread_parent": true,
 "reply_count": 12,
 "thread_messages": [
 {
 "text": "Redis gives us persistence and pub/sub which we'll need for the notification system",
 "user": {"name": "bob"}
 },
 {
 "text": "Agreed. Let's go with Redis. I'll document this in the ADR.",
 "user": {"name": "alice"}
 }
 ],
 "relevance_score": 0.95
 }
 ],
 "total_count": 3,
 "query_interpretation": "Searching for 'Redis vs Memcached decision' in #architecture, #engineering"
}`
```

#### Example 2: Incident Context

 python
 Copy

`# Input
{
 "query": "outage payment gateway",
 "channels": ["incidents"],
 "date_range": {"after": "2024-01-01", "before": "2024-01-31"}
}

# Output
{
 "results": [
 {
 "text": ":rotating_light: INCIDENT: Payment gateway timeout errors spiking",
 "channel": {"name": "incidents"},
 "timestamp": "2024-01-15T03:45:00Z",
 "reply_count": 45,
 "thread_messages": [
 {"text": "Root cause: Database connection pool exhaustion"},
 {"text": "Fix deployed. Monitoring."},
 {"text": "Resolved. Postmortem scheduled for tomorrow."}
 ],
 "reactions": [
 {"name": "eyes", "count": 8},
 {"name": "white_check_mark", "count": 5}
 ]
 }
 ]
}`
```

---

### Security Considerations

#### Data Access

- Only searches channels user has access to
 
- User token required (more access than bot token)
 
- DMs only searchable by the user themselves
 
#### Sensitive Data

- Messages may contain sensitive information
 
- Results should be treated with same confidentiality as Slack itself
 
#### Permissions

 python
 Copy

`REQUIRED_CAPABILITIES = [
 "network:slack", # Slack API access
]

# Required Slack scopes
SLACK_SCOPES = [
 "search:read", # Search messages
 "channels:read", # List channels
 "groups:read", # Private channels
 "im:read", # Direct messages
 "users:read", # User info
]`
```

---

### Dependencies

#### Required

- `slack-sdk` - Official Slack Python SDK
 
#### Optional

- None
 
---

### Open Questions

- Bot vs User token: User tokens have more access but require OAuth flow
 
- Caching: Should we cache search results? For how long?
 
- Summarization: Should we AI-summarize long threads?
 
- Privacy: How to handle searches that might surface sensitive DMs?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Tool Swarm
 tools

Priority: P2 (Medium Value)

Status: Draft

Module: `amplifier-module-tool-swarm`

### Overview

A tool for parallel exploration with convergence - spawn multiple variations of the same agent with different parameters, let them explore independently, then converge on the best result. Useful for creative tasks, optimization, and exploring solution spaces.

#### Why a Tool, Not an Orchestrator?

Like `tool-collaborative`, swarm exploration is policy (when to explore, how many variations, how to converge) not mechanism. The agent decides when parallel exploration adds value.

#### Value Proposition

 | 
 
 | Without | With

 | Single attempt | Multiple parallel explorations
 
 | Local optima | Broader solution space coverage
 
 | One temperature setting | Temperature sweep
 
 | Manual iteration | Automated best-of-n

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Main Session â”‚
â”‚ â”‚
â”‚ Agent: "Let me explore multiple approaches..." â”‚
â”‚ â”‚ â”‚
â”‚ â””â”€â–º tool-swarm.execute(...) â”‚
â”‚ â”‚ â”‚
â”‚ â”œâ”€â–º variation 1 (temp=0.3) â”€â”€â” â”‚
â”‚ â”œâ”€â–º variation 2 (temp=0.5) â”€â”€â”¼â”€â–º parallel â”‚
â”‚ â”œâ”€â–º variation 3 (temp=0.7) â”€â”€â”¤ â”‚
â”‚ â”œâ”€â–º variation 4 (temp=0.9) â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â””â”€â–º converge (vote/best/synthesis) â”€â”€â–º return â”‚
â”‚ â”‚
â”‚ Agent: "After exploring 4 variations, the best approach..." â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Tool Contract

 yaml
 Copy

`name: tool-swarm
description: Parallel exploration with multiple agent variations

parameters:
 task:
 type: string
 description: The task to explore
 required: true

 variations:
 type: integer
 default: 3
 description: Number of parallel variations to spawn

 vary_by:
 type: string
 enum: [temperature, prompt, model, custom]
 default: temperature
 description: What to vary across agents

 temperature_range:
 type: array
 default: [0.3, 0.5, 0.7, 0.9]
 description: Temperatures to use (if vary_by=temperature)

 prompt_variations:
 type: array
 description: Different prompts to try (if vary_by=prompt)

 convergence:
 type: string
 enum: [best_of, vote, synthesis, all]
 default: best_of
 description: How to select/combine results

 evaluation_criteria:
 type: string
 description: Criteria for judging "best" result

 base_config:
 type: object
 description: Base agent configuration (variations modify this)

returns:
 type: object
 properties:
 result:
 type: string
 description: Converged result
 all_results:
 type: array
 description: All variation results
 selection:
 type: object
 description: Why this result was selected
 metadata:
 type: object
 description: Execution stats`
```

---

### Implementation

 python
 Copy

`# tool.py

from amplifier_core import AmplifierSession
import asyncio
from dataclasses import dataclass

@dataclass
class ExplorationResult:
 variation_id: int
 parameters: dict
 response: str
 score: float | None = None
 tokens_used: int = 0

class SwarmTool:
 """Tool for parallel exploration with convergence."""

 name = "tool-swarm"

 async def execute(
 self,
 task: str,
 variations: int = 3,
 vary_by: str = "temperature",
 temperature_range: list[float] | None = None,
 prompt_variations: list[str] | None = None,
 convergence: str = "best_of",
 evaluation_criteria: str | None = None,
 base_config: dict | None = None
 ) -> dict:
 """Execute parallel exploration."""

 # Generate variation configs
 variation_configs = self._generate_variations(
 base_config=base_config or self._default_config(),
 vary_by=vary_by,
 count=variations,
 temperature_range=temperature_range or [0.3, 0.5, 0.7, 0.9],
 prompt_variations=prompt_variations
 )

 # Execute all variations in parallel
 results = await self._parallel_explore(task, variation_configs)

 # Converge on result
 if convergence == "best_of":
 final = await self._best_of_convergence(
 results, evaluation_criteria or "quality and correctness"
 )
 elif convergence == "vote":
 final = await self._voting_convergence(results)
 elif convergence == "synthesis":
 final = await self._synthesis_convergence(task, results)
 else: # all
 final = self._all_results(results)

 return {
 "result": final["result"],
 "all_results": [r.__dict__ for r in results],
 "selection": final.get("selection", {}),
 "metadata": {
 "variations_count": len(results),
 "vary_by": vary_by,
 "convergence": convergence,
 "total_tokens": sum(r.tokens_used for r in results)
 }
 }

 def _generate_variations(
 self,
 base_config: dict,
 vary_by: str,
 count: int,
 temperature_range: list[float],
 prompt_variations: list[str] | None
 ) -> list[dict]:
 """Generate variation configurations."""

 variations = []

 if vary_by == "temperature":
 # Use specified temperatures or generate range
 temps = temperature_range[:count]
 for i, temp in enumerate(temps):
 config = self._deep_copy(base_config)
 config["providers"][0]["config"]["temperature"] = temp
 config["_variation"] = {"id": i, "temperature": temp}
 variations.append(config)

 elif vary_by == "prompt":
 # Use different prompt framings
 for i, prompt_mod in enumerate(prompt_variations[:count]):
 config = self._deep_copy(base_config)
 config["_variation"] = {"id": i, "prompt_modifier": prompt_mod}
 config["_prompt_modifier"] = prompt_mod
 variations.append(config)

 elif vary_by == "model":
 # Use different models
 models = ["claude-sonnet-4-5", "claude-opus-4"]
 for i, model in enumerate(models[:count]):
 config = self._deep_copy(base_config)
 config["providers"][0]["config"]["model"] = model
 config["_variation"] = {"id": i, "model": model}
 variations.append(config)

 return variations

 async def _parallel_explore(
 self,
 task: str,
 variation_configs: list[dict]
 ) -> list[ExplorationResult]:
 """Execute all variations in parallel."""

 async def run_variation(config: dict) -> ExplorationResult:
 variation_info = config.pop("_variation", {"id": 0})
 prompt_modifier = config.pop("_prompt_modifier", None)

 # Modify prompt if needed
 actual_task = task
 if prompt_modifier:
 actual_task = f"{prompt_modifier}\n\n{task}"

 async with AmplifierSession(config=config) as session:
 response = await session.execute(actual_task)

 return ExplorationResult(
 variation_id=variation_info["id"],
 parameters=variation_info,
 response=response.text,
 tokens_used=response.usage.total_tokens
 )

 results = await asyncio.gather(*[
 run_variation(config) for config in variation_configs
 ])

 return list(results)

 async def _best_of_convergence(
 self,
 results: list[ExplorationResult],
 criteria: str
 ) -> dict:
 """Select best result using evaluator."""

 # Use AI to evaluate and select best
 evaluation_prompt = f"""
Evaluate these {len(results)} responses and select the best one.

Evaluation Criteria: {criteria}

## Responses

{self._format_results_for_eval(results)}

## Your Task
1. Score each response 1-10 based on the criteria
2. Explain your reasoning for each score
3. Select the best response
4. Explain why it's the best

Respond with:
- scores: [list of scores]
- best_index: (0-indexed)
- reasoning: explanation
"""

 async with AmplifierSession(config=self._evaluator_config()) as session:
 eval_response = await session.execute(evaluation_prompt)

 # Parse evaluation (simplified - would use structured output)
 best_idx = self._parse_best_index(eval_response.text, len(results))
 best_result = results[best_idx]

 # Update scores
 scores = self._parse_scores(eval_response.text, len(results))
 for i, result in enumerate(results):
 result.score = scores[i] if i < len(scores) else None

 return {
 "result": best_result.response,
 "selection": {
 "method": "best_of",
 "selected_variation": best_result.variation_id,
 "parameters": best_result.parameters,
 "score": best_result.score,
 "reasoning": eval_response.text
 }
 }

 async def _voting_convergence(
 self,
 results: list[ExplorationResult]
 ) -> dict:
 """Identify consensus across variations."""

 # Extract key points from each result
 # Find overlapping conclusions
 # Return majority view

 voting_prompt = f"""
Analyze these {len(results)} responses for consensus.

{self._format_results_for_eval(results)}

Identify:
1. Points all/most responses agree on
2. Points with disagreement
3. The majority conclusion

Synthesize a response that represents the consensus view.
"""

 async with AmplifierSession(config=self._evaluator_config()) as session:
 consensus = await session.execute(voting_prompt)

 return {
 "result": consensus.text,
 "selection": {
 "method": "vote",
 "variations_analyzed": len(results)
 }
 }

 async def _synthesis_convergence(
 self,
 task: str,
 results: list[ExplorationResult]
 ) -> dict:
 """Synthesize best elements from all variations."""

 synthesis_prompt = f"""
Original task: {task}

You have {len(results)} different approaches to this task:

{self._format_results_for_eval(results)}

Create an improved response that:
1. Takes the best elements from each approach
2. Addresses weaknesses found in individual responses
3. Synthesizes into a coherent, superior result

Provide the synthesized response.
"""

 async with AmplifierSession(config=self._evaluator_config()) as session:
 synthesis = await session.execute(synthesis_prompt)

 return {
 "result": synthesis.text,
 "selection": {
 "method": "synthesis",
 "variations_synthesized": len(results)
 }
 }

 def _format_results_for_eval(self, results: list[ExplorationResult]) -> str:
 """Format results for evaluation prompt."""

 formatted = []
 for r in results:
 formatted.append(
 f"### Variation {r.variation_id} ({r.parameters})\n{r.response}"
 )
 return "\n\n---\n\n".join(formatted)

 def _evaluator_config(self) -> dict:
 """Config for evaluation/synthesis agent."""

 return {
 "session": {
 "orchestrator": "loop-basic",
 "context": "context-simple"
 },
 "providers": [{
 "module": "provider-anthropic",
 "source": "git+https://github.com/microsoft/amplifier-module-provider-anthropic@main",
 "config": {
 "model": "claude-sonnet-4-5",
 "temperature": 0.2 # Low temp for evaluation
 }
 }]
 }

 def _default_config(self) -> dict:
 """Default base config for variations."""

 return {
 "session": {
 "orchestrator": "loop-basic",
 "context": "context-simple"
 },
 "providers": [{
 "module": "provider-anthropic",
 "source": "git+https://github.com/microsoft/amplifier-module-provider-anthropic@main",
 "config": {
 "model": "claude-sonnet-4-5",
 "temperature": 0.5
 }
 }]
 }`
```

---

### Variation Strategies

#### Temperature Sweep

Explore creativity spectrum:

 python
 Copy

`result = await tool_swarm.execute(
 task="Write a tagline for our new AI product",
 vary_by="temperature",
 temperature_range=[0.2, 0.5, 0.8, 1.0],
 convergence="best_of",
 evaluation_criteria="creativity, memorability, brand fit"
)`
```

#### Prompt Variations

Explore different framings:

 python
 Copy

`result = await tool_swarm.execute(
 task="Explain quantum computing",
 vary_by="prompt",
 prompt_variations=[
 "Explain like I'm a 5-year-old:",
 "Explain for a software engineer:",
 "Explain for a physics PhD:",
 "Explain using only analogies:"
 ],
 convergence="all" # Keep all for different audiences
)`
```

#### Model Comparison

Compare model capabilities:

 python
 Copy

`result = await tool_swarm.execute(
 task="Solve this complex reasoning problem...",
 vary_by="model",
 convergence="best_of",
 evaluation_criteria="correctness and reasoning clarity"
)`
```

---

### Convergence Strategies

 | 
 
 | Strategy | Description | Best For

 | `best_of` | Evaluate and select best | Clear quality criteria
 
 | `vote` | Find consensus view | Factual tasks
 
 | `synthesis` | Combine best elements | Creative tasks
 
 | `all` | Return all results | Need multiple versions

---

### Usage Examples

#### Creative Exploration

 python
 Copy

`# Generate multiple creative options
result = await tool_swarm.execute(
 task="Design a logo concept for an eco-friendly tech startup",
 variations=5,
 vary_by="temperature",
 temperature_range=[0.5, 0.7, 0.9, 1.0, 1.2],
 convergence="all", # Present all options to user
)

# User picks their favorite from result["all_results"]`
```

#### Solution Optimization

 python
 Copy

`# Find best solution approach
result = await tool_swarm.execute(
 task=f"Optimize this function for performance:\n\n{code}",
 variations=4,
 vary_by="prompt",
 prompt_variations=[
 "Focus on algorithmic complexity:",
 "Focus on memory efficiency:",
 "Focus on parallelization:",
 "Focus on caching strategies:"
 ],
 convergence="synthesis", # Combine best optimizations
 evaluation_criteria="performance improvement, code clarity, correctness"
)`
```

---

### Events

 | 
 
 | Event | Description | Data

 | `tool:swarm:start` | Swarm started | task, variations, vary_by
 
 | `tool:swarm:variation:start` | Variation started | variation_id, parameters
 
 | `tool:swarm:variation:complete` | Variation finished | variation_id, tokens
 
 | `tool:swarm:convergence:start` | Convergence started | method
 
 | `tool:swarm:complete` | Swarm complete | selected, total_tokens

---

### Configuration

 yaml
 Copy

`tools:
 - module: tool-swarm
 source: git+https://github.com/microsoft/amplifier-module-tool-swarm@main
 config:
 # Defaults
 default_variations: 3
 default_convergence: best_of

 # Limits
 max_variations: 10
 max_parallel: 5
 variation_timeout: 120s

 # Default temperature range
 temperature_range: [0.3, 0.5, 0.7, 0.9]`
```

---

### Comparison with tool-collaborative

 | 
 
 | Aspect | tool-swarm | tool-collaborative

 | Agents | Same agent, different params | Different specialist agents
 
 | Goal | Explore solution space | Multiple perspectives
 
 | Variation | Parameters (temp, prompt) | Roles and expertise
 
 | Best for | Creative, optimization | Analysis, review

---

### Open Questions

- Adaptive stopping: Stop early if consensus emerges?
 
- Cost vs exploration: Auto-tune variation count by task complexity?
 
- Learning: Track which temperatures/prompts work best for task types?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification (converted from orchestrator to tool)

 Tool Tech Debt Scanner
 tools

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-tool-tech-debt-scanner`

### Overview

Identify and categorize technical debt across the codebase. Detects anti-patterns, outdated dependencies, dead code, code duplication, complexity hotspots, and TODO/FIXME comments. Provides prioritized recommendations for debt reduction.

#### Value Proposition

 | 
 
 | Without | With

 | Tech debt accumulates invisibly | Quantified, visible debt inventory
 
 | "We'll fix it later" â†’ never fixed | Prioritized backlog with impact estimates
 
 | Outdated deps discovered in incidents | Proactive vulnerability and freshness scanning
 
 | Gut feeling about code quality | Data-driven quality metrics

#### Use Cases

- Debt inventory: "What tech debt exists in our codebase?"
 
- Sprint planning: "What debt should we tackle this sprint?"
 
- Risk assessment: "What's our exposure from outdated dependencies?"
 
- Refactoring targets: "Where are the complexity hotspots?"
 
- Quality gates: "Does this PR increase tech debt?"
 
---

### Contract

#### Tool Definition

 python
 Copy

`TOOL_DEFINITION = {
 "name": "tech_debt_scanner",
 "description": """
 Scan codebase for technical debt and quality issues.

 Categories:
 - dependencies: Outdated, vulnerable, or deprecated deps
 - dead_code: Unused functions, classes, imports
 - complexity: High cyclomatic complexity, long functions
 - duplication: Duplicated code blocks
 - todos: TODO, FIXME, HACK comments
 - patterns: Anti-patterns, code smells
 - tests: Missing or inadequate test coverage

 Use for debt prioritization, sprint planning, and quality monitoring.
 """,
 "parameters": {
 "type": "object",
 "properties": {
 "scope": {
 "type": "string",
 "description": "Path pattern to scan (default: entire repo)"
 },
 "categories": {
 "type": "array",
 "items": {
 "type": "string",
 "enum": ["dependencies", "dead_code", "complexity", "duplication", "todos", "patterns", "tests", "all"]
 },
 "default": ["all"],
 "description": "Debt categories to scan"
 },
 "severity_threshold": {
 "type": "string",
 "enum": ["low", "medium", "high", "critical"],
 "default": "low",
 "description": "Minimum severity to report"
 },
 "include_metrics": {
 "type": "boolean",
 "default": true,
 "description": "Include code metrics in output"
 },
 "compare_to": {
 "type": "string",
 "description": "Git ref to compare against (for delta analysis)"
 }
 }
 }
}`
```

#### Output Schema

 python
 Copy

`@dataclass
class TechDebtScanOutput:
 scope: str
 scan_time: datetime
 categories_scanned: list[str]

 # Findings by category
 dependencies: DependencyDebt | None
 dead_code: DeadCodeDebt | None
 complexity: ComplexityDebt | None
 duplication: DuplicationDebt | None
 todos: TodoDebt | None
 patterns: PatternDebt | None
 tests: TestDebt | None

 # Summary
 summary: DebtSummary
 recommendations: list[Recommendation]

 # Delta (if compare_to specified)
 delta: DebtDelta | None

@dataclass
class DependencyDebt:
 outdated: list[OutdatedDep]
 vulnerable: list[VulnerableDep]
 deprecated: list[DeprecatedDep]
 unused: list[UnusedDep]

@dataclass
class OutdatedDep:
 name: str
 current_version: str
 latest_version: str
 age_days: int
 breaking_changes: bool
 update_effort: str # low | medium | high

@dataclass
class VulnerableDep:
 name: str
 version: str
 cve_ids: list[str]
 severity: str # low | medium | high | critical
 fixed_in: str | None
 description: str

@dataclass
class DeadCodeDebt:
 unused_functions: list[UnusedSymbol]
 unused_classes: list[UnusedSymbol]
 unused_imports: list[UnusedImport]
 unused_files: list[str]
 total_dead_lines: int

@dataclass
class UnusedSymbol:
 name: str
 file_path: str
 line_number: int
 lines_of_code: int
 confidence: float # 0-1, lower if might be used dynamically

@dataclass
class ComplexityDebt:
 hotspots: list[ComplexityHotspot]
 long_functions: list[LongFunction]
 deep_nesting: list[DeepNesting]
 average_complexity: float

@dataclass
class ComplexityHotspot:
 file_path: str
 function_name: str
 cyclomatic_complexity: int
 cognitive_complexity: int
 lines: int
 recommendation: str

@dataclass
class DuplicationDebt:
 duplicates: list[CodeDuplicate]
 total_duplicated_lines: int
 duplication_percentage: float

@dataclass
class CodeDuplicate:
 locations: list[DuplicateLocation]
 lines: int
 similarity: float # 0-1
 suggested_extraction: str | None

@dataclass
class TodoDebt:
 todos: list[TodoItem]
 by_age: dict[str, int] # "< 1 month": 5, "1-6 months": 10, ...
 by_author: dict[str, int]

@dataclass
class TodoItem:
 type: str # TODO | FIXME | HACK | XXX
 text: str
 file_path: str
 line_number: int
 author: str | None # From git blame
 age_days: int | None
 linked_issue: str | None # If references ticket

@dataclass
class PatternDebt:
 anti_patterns: list[AntiPattern]
 code_smells: list[CodeSmell]

@dataclass
class AntiPattern:
 name: str # "God Class", "Spaghetti Code", etc.
 file_path: str
 description: str
 severity: str
 fix_suggestion: str

@dataclass
class TestDebt:
 untested_functions: list[str]
 low_coverage_files: list[FileCoverage]
 missing_test_files: list[str]
 flaky_tests: list[str]

@dataclass
class DebtSummary:
 total_items: int
 by_severity: dict[str, int]
 by_category: dict[str, int]
 estimated_effort_hours: float
 debt_score: float # 0-100, lower is better
 trend: str # improving | stable | degrading

@dataclass
class Recommendation:
 priority: int # 1 = highest
 category: str
 title: str
 description: str
 effort: str
 impact: str
 affected_items: list[str]`
```

---

### Architecture

#### Component Diagram

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ tool-tech-debt-scanner â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Scanner Orchestrator â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â–¼ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Dep â”‚ â”‚ Dead â”‚ â”‚ Dup â”‚ â”‚ Pattern â”‚ ... â”‚
â”‚ â”‚ Scanner â”‚ â”‚ Code â”‚ â”‚ Finder â”‚ â”‚ Checker â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Prioritization Engine â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Scanner Components

 python
 Copy

`class DependencyScanner:
 """Scan for dependency-related tech debt."""

 async def scan(self, scope: str) -> DependencyDebt:
 # Find package manifests
 manifests = await self._find_manifests(scope)

 results = DependencyDebt(
 outdated=[], vulnerable=[], deprecated=[], unused=[]
 )

 for manifest in manifests:
 if manifest.type == "python":
 deps = await self._scan_python_deps(manifest)
 elif manifest.type == "npm":
 deps = await self._scan_npm_deps(manifest)
 # ... other package managers

 results.outdated.extend(deps.outdated)
 results.vulnerable.extend(deps.vulnerable)

 return results

 async def _scan_python_deps(self, manifest: Manifest) -> DependencyScanResult:
 # Check for outdated
 outdated = []
 for dep, version in manifest.dependencies.items():
 latest = await self._get_latest_version(dep, "pypi")
 if latest and version < latest:
 outdated.append(OutdatedDep(
 name=dep,
 current_version=str(version),
 latest_version=str(latest),
 age_days=self._calculate_age(version, latest),
 breaking_changes=self._has_breaking_changes(version, latest),
 update_effort=self._estimate_effort(dep, version, latest)
 ))

 # Check for vulnerabilities (via safety, pip-audit, etc.)
 vulnerable = await self._check_vulnerabilities(manifest)

 return DependencyScanResult(outdated=outdated, vulnerable=vulnerable)

class DeadCodeScanner:
 """Detect unused code."""

 async def scan(self, scope: str) -> DeadCodeDebt:
 # Build dependency graph
 graph = await self._build_dependency_graph(scope)

 # Find unreachable nodes
 entry_points = await self._find_entry_points(scope)
 reachable = self._compute_reachable(graph, entry_points)

 unused_functions = []
 unused_classes = []

 for symbol in graph.symbols:
 if symbol.id not in reachable:
 confidence = self._compute_confidence(symbol)

 item = UnusedSymbol(
 name=symbol.name,
 file_path=symbol.file_path,
 line_number=symbol.line_number,
 lines_of_code=symbol.lines,
 confidence=confidence
 )

 if symbol.kind == "function":
 unused_functions.append(item)
 elif symbol.kind == "class":
 unused_classes.append(item)

 # Find unused imports
 unused_imports = await self._find_unused_imports(scope)

 return DeadCodeDebt(
 unused_functions=unused_functions,
 unused_classes=unused_classes,
 unused_imports=unused_imports,
 unused_files=self._find_unused_files(reachable),
 total_dead_lines=sum(s.lines_of_code for s in unused_functions + unused_classes)
 )

class PrioritizationEngine:
 """Prioritize debt items for remediation."""

 def prioritize(self, debt: TechDebtScanOutput) -> list[Recommendation]:
 recommendations = []

 # Critical vulnerabilities first
 for vuln in debt.dependencies.vulnerable:
 if vuln.severity == "critical":
 recommendations.append(Recommendation(
 priority=1,
 category="dependencies",
 title=f"Critical vulnerability in {vuln.name}",
 description=f"{vuln.description}. CVE: {', '.join(vuln.cve_ids)}",
 effort="low" if vuln.fixed_in else "high",
 impact="critical",
 affected_items=[vuln.name]
 ))

 # High-impact complexity hotspots
 for hotspot in sorted(debt.complexity.hotspots,
 key=lambda h: h.cyclomatic_complexity,
 reverse=True)[:5]:
 recommendations.append(Recommendation(
 priority=2,
 category="complexity",
 title=f"Refactor {hotspot.function_name}",
 description=f"Cyclomatic complexity: {hotspot.cyclomatic_complexity}",
 effort="medium",
 impact="high",
 affected_items=[f"{hotspot.file_path}:{hotspot.function_name}"]
 ))

 # Large dead code blocks
 significant_dead = [d for d in debt.dead_code.unused_functions
 if d.lines_of_code > 50 and d.confidence > 0.8]
 if significant_dead:
 recommendations.append(Recommendation(
 priority=3,
 category="dead_code",
 title=f"Remove {len(significant_dead)} unused functions",
 description=f"~{sum(d.lines_of_code for d in significant_dead)} lines of dead code",
 effort="low",
 impact="medium",
 affected_items=[d.name for d in significant_dead]
 ))

 return sorted(recommendations, key=lambda r: r.priority)`
```

---

### Configuration

 yaml
 Copy

`tool-tech-debt-scanner:
 # Scanning settings
 scan:
 # File patterns
 include:
 - "**/*.py"
 - "**/*.ts"
 - "**/*.js"
 exclude:
 - "**/node_modules/**"
 - "**/.venv/**"
 - "**/dist/**"

 # Dependency scanning
 dependencies:
 # Vulnerability databases
 vuln_sources:
 - safety # Python
 - npm-audit # npm
 - snyk # Multi-language

 # Freshness thresholds
 outdated_thresholds:
 minor_days: 90 # Consider outdated after 90 days
 major_days: 180

 # Complexity thresholds
 complexity:
 cyclomatic_warn: 10
 cyclomatic_error: 20
 cognitive_warn: 15
 cognitive_error: 25
 function_length_warn: 50
 function_length_error: 100

 # Dead code detection
 dead_code:
 # Entry points to consider as roots
 entry_points:
 - "main"
 - "cli"
 - "**/test_*.py"
 - "**/*_test.py"

 # Patterns that might indicate dynamic usage
 dynamic_patterns:
 - "@app.route"
 - "@pytest.fixture"
 - "__getattr__"

 # Duplication detection
 duplication:
 min_lines: 6 # Minimum lines to consider duplicate
 min_tokens: 50 # Minimum tokens
 similarity_threshold: 0.9

 # TODO scanning
 todos:
 patterns:
 - "TODO"
 - "FIXME"
 - "HACK"
 - "XXX"
 - "TECHNICAL_DEBT"
 # Extract ticket references
 ticket_patterns:
 - "[A-Z]+-\\d+" # JIRA-style`
```

---

### Examples

#### Example 1: Full Scan

 python
 Copy

`# Input
{
 "scope": "src/",
 "categories": ["all"],
 "severity_threshold": "medium"
}

# Output
{
 "dependencies": {
 "outdated": [
 {
 "name": "requests",
 "current_version": "2.25.0",
 "latest_version": "2.31.0",
 "age_days": 450,
 "breaking_changes": false,
 "update_effort": "low"
 }
 ],
 "vulnerable": [
 {
 "name": "pyyaml",
 "version": "5.3",
 "cve_ids": ["CVE-2020-14343"],
 "severity": "critical",
 "fixed_in": "5.4",
 "description": "Arbitrary code execution via yaml.load()"
 }
 ]
 },
 "dead_code": {
 "unused_functions": [
 {
 "name": "legacy_auth_handler",
 "file_path": "src/auth/legacy.py",
 "line_number": 45,
 "lines_of_code": 78,
 "confidence": 0.95
 }
 ],
 "total_dead_lines": 234
 },
 "complexity": {
 "hotspots": [
 {
 "file_path": "src/payments/processor.py",
 "function_name": "process_payment",
 "cyclomatic_complexity": 32,
 "cognitive_complexity": 45,
 "lines": 156,
 "recommendation": "Split into smaller functions by payment type"
 }
 ]
 },
 "todos": {
 "todos": [
 {
 "type": "FIXME",
 "text": "This is a race condition waiting to happen",
 "file_path": "src/cache/manager.py",
 "line_number": 89,
 "author": "alice",
 "age_days": 342
 }
 ],
 "by_age": {"< 1 month": 3, "1-6 months": 12, "> 6 months": 8}
 },
 "summary": {
 "total_items": 47,
 "by_severity": {"critical": 1, "high": 5, "medium": 18, "low": 23},
 "by_category": {"dependencies": 8, "dead_code": 12, "complexity": 5, "todos": 22},
 "estimated_effort_hours": 40,
 "debt_score": 67,
 "trend": "stable"
 },
 "recommendations": [
 {
 "priority": 1,
 "category": "dependencies",
 "title": "Critical vulnerability in pyyaml",
 "description": "CVE-2020-14343: Arbitrary code execution",
 "effort": "low",
 "impact": "critical"
 },
 {
 "priority": 2,
 "category": "complexity",
 "title": "Refactor process_payment",
 "description": "Cyclomatic complexity: 32 (threshold: 20)",
 "effort": "medium",
 "impact": "high"
 }
 ]
}`
```

---

### Security Considerations

- Reads source code and dependencies
 
- Vulnerability data fetched from external sources
 
- Scan results may reveal security weaknesses
 
---

### Dependencies

#### Required

- `tree-sitter` - Code analysis
 
- `radon` - Python complexity (or language-specific tools)
 
#### Optional

- `safety` - Python vulnerability scanning
 
- `npm-audit` - npm vulnerability scanning
 
- `jscpd` - Cross-language duplication detection
 
---

### Open Questions

- Historical tracking: Should we store scan history for trend analysis?
 
- CI integration: Block PRs that increase debt beyond threshold?
 
- Custom rules: Allow project-specific anti-pattern definitions?
 
- Effort estimation: How to improve effort estimates?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Tool Test Runner
 tools

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-tool-test-runner`

### Overview

Intelligent test execution with failure analysis, coverage tracking, and test selection optimization. Runs specific tests, analyzes failures, and suggests fixes based on error context.

#### Value Proposition

 | 
 
 | Without | With

 | Run all tests hoping to catch the right one | Smart test selection based on changed files
 
 | Parse test output manually | Structured failure analysis with context
 
 | Hunt for relevant test files | "Run tests for PaymentGateway" finds them
 
 | Rerun flaky tests manually | Automatic flaky test detection and retry

#### Use Cases

- Targeted testing: Run tests for specific functions/classes
 
- Failure analysis: Understand why tests failed with context
 
- Change-based testing: Run tests affected by recent changes
 
- Coverage analysis: Track what's tested and what's not
 
- Flaky test management: Detect and handle flaky tests
 
- Performance tracking: Monitor test execution times
 
---

### Contract

#### Tool Definition

 python
 Copy

`TOOL_DEFINITION = {
 "name": "test_runner",
 "description": """
 Intelligent test execution and analysis.

 Operations:
 - run: Execute tests (all, specific, or affected by changes)
 - analyze: Analyze test failures with context
 - coverage: Get coverage information
 - list: List available tests
 - history: Test execution history and trends

 Supports pytest, jest, go test, and other common frameworks.
 """,
 "parameters": {
 "type": "object",
 "properties": {
 "operation": {
 "type": "string",
 "enum": ["run", "analyze", "coverage", "list", "history"],
 "description": "Operation to perform"
 },
 "target": {
 "type": "string",
 "description": "Test target: file path, test name, or symbol name"
 },
 "selection": {
 "type": "string",
 "enum": ["all", "failed", "affected", "target"],
 "default": "target",
 "description": "Test selection strategy"
 },
 "framework": {
 "type": "string",
 "enum": ["auto", "pytest", "jest", "go", "cargo"],
 "default": "auto",
 "description": "Test framework (auto-detected if not specified)"
 },
 "options": {
 "type": "object",
 "description": "Framework-specific options (verbose, parallel, etc.)"
 },
 "analyze_failures": {
 "type": "boolean",
 "default": true,
 "description": "Include failure analysis in results"
 }
 },
 "required": ["operation"]
 }
}`
```

#### Output Schema

 python
 Copy

`@dataclass
class TestRunnerOutput:
 operation: str

 # For run operation
 run_result: TestRunResult | None = None

 # For analyze operation
 failure_analysis: list[FailureAnalysis] | None = None

 # For coverage operation
 coverage: CoverageReport | None = None

 # For list operation
 tests: list[TestInfo] | None = None

 # For history operation
 history: TestHistory | None = None

@dataclass
class TestRunResult:
 success: bool
 total: int
 passed: int
 failed: int
 skipped: int
 duration_seconds: float

 # Detailed results
 test_results: list[TestResult]

 # Failure analysis (if analyze_failures=True)
 failure_analyses: list[FailureAnalysis] | None

 # Framework info
 framework: str
 command: str

@dataclass
class TestResult:
 name: str
 file_path: str
 status: str # passed | failed | skipped | error
 duration_seconds: float
 output: str | None # Captured output
 error: TestError | None # If failed

@dataclass
class TestError:
 type: str # AssertionError, TypeError, etc.
 message: str
 traceback: str
 location: Location # File and line where error occurred

@dataclass
class FailureAnalysis:
 test_name: str
 error: TestError

 # Analysis
 failure_type: str # assertion | exception | timeout | fixture
 root_cause: str # AI-analyzed root cause
 relevant_code: list[CodeSnippet] # Related code snippets
 suggested_fix: str | None # If determinable
 similar_failures: list[str] # Other tests with similar failures

@dataclass
class CoverageReport:
 total_lines: int
 covered_lines: int
 coverage_percent: float
 files: list[FileCoverage]
 uncovered_functions: list[str] # Functions with 0% coverage

@dataclass
class FileCoverage:
 path: str
 lines: int
 covered: int
 percent: float
 uncovered_lines: list[int] # Line numbers not covered

@dataclass
class TestInfo:
 name: str
 file_path: str
 line_number: int
 markers: list[str] # pytest markers, jest tags, etc.
 parameters: list[str] | None # Parameterized test variants`
```

---

### Architecture

#### Component Diagram

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ tool-test-runner â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Test â”‚â”€â”€â”€â–¶â”‚ Framework â”‚â”€â”€â”€â–¶â”‚ Result â”‚ â”‚
â”‚ â”‚ Selector â”‚ â”‚ Runner â”‚ â”‚ Analyzer â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ pytest â”‚ â”‚ jest â”‚ â”‚ go test â”‚ â”‚
â”‚ â”‚ adapter â”‚ â”‚ adapter â”‚ â”‚ adapter â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Internal Components

#### 1. Test Selector

 python
 Copy

`class TestSelector:
 """Select tests to run based on strategy."""

 async def select(
 self,
 strategy: str,
 target: str | None,
 framework: str
 ) -> list[str]:
 if strategy == "all":
 return [] # Empty = run all

 if strategy == "target":
 return await self._select_for_target(target, framework)

 if strategy == "affected":
 return await self._select_affected()

 if strategy == "failed":
 return await self._select_previously_failed()

 async def _select_for_target(self, target: str, framework: str) -> list[str]:
 """Find tests for a target symbol or file."""

 # If target is a test file, return it
 if self._is_test_file(target):
 return [target]

 # If target is a symbol (class/function), find related tests
 symbol_tests = await self._find_tests_for_symbol(target)
 if symbol_tests:
 return symbol_tests

 # If target is a source file, find tests that import it
 if Path(target).exists():
 return await self._find_tests_importing(target)

 # Search by name pattern
 return await self._find_tests_by_pattern(target)

 async def _select_affected(self) -> list[str]:
 """Select tests affected by recent changes."""
 # Get changed files
 changed = await self.git.get_changed_files()

 affected_tests = set()
 for file_path in changed:
 # Direct test file changes
 if self._is_test_file(file_path):
 affected_tests.add(file_path)
 else:
 # Find tests that depend on this file
 tests = await self._find_tests_importing(file_path)
 affected_tests.update(tests)

 return list(affected_tests)`
```

#### 2. Framework Adapters

 python
 Copy

`class PytestAdapter:
 """Adapter for pytest."""

 async def run(
 self,
 tests: list[str],
 options: dict
 ) -> TestRunResult:
 # Build command
 cmd = ["pytest", "--tb=short", "-v"]

 if options.get("parallel"):
 cmd.extend(["-n", "auto"])
 if options.get("coverage"):
 cmd.extend(["--cov", "--cov-report=json"])
 if options.get("markers"):
 cmd.extend(["-m", options["markers"]])

 cmd.extend(tests)

 # Run pytest
 result = await self._run_command(cmd)

 # Parse output
 return self._parse_result(result)

 def _parse_result(self, result: ProcessResult) -> TestRunResult:
 """Parse pytest output into structured result."""
 # Parse pytest's output format
 # Also look for pytest-json-report output if available
 ...

class JestAdapter:
 """Adapter for Jest."""

 async def run(self, tests: list[str], options: dict) -> TestRunResult:
 cmd = ["npx", "jest", "--json"]

 if tests:
 cmd.extend(["--testPathPattern", "|".join(tests)])
 if options.get("coverage"):
 cmd.append("--coverage")
 if options.get("watch") is False:
 cmd.append("--watchAll=false")

 result = await self._run_command(cmd)
 return self._parse_json_result(result)`
```

#### 3. Result Analyzer

 python
 Copy

`class ResultAnalyzer:
 """Analyze test failures."""

 async def analyze_failures(
 self,
 results: list[TestResult]
 ) -> list[FailureAnalysis]:
 failures = [r for r in results if r.status == "failed"]
 analyses = []

 for failure in failures:
 analysis = await self._analyze_failure(failure)
 analyses.append(analysis)

 return analyses

 async def _analyze_failure(self, failure: TestResult) -> FailureAnalysis:
 error = failure.error

 # Classify failure type
 failure_type = self._classify_failure(error)

 # Get relevant code context
 relevant_code = await self._get_relevant_code(error)

 # Analyze root cause
 root_cause = await self._analyze_root_cause(
 failure, error, relevant_code
 )

 # Generate fix suggestion if possible
 suggested_fix = await self._suggest_fix(
 failure_type, error, relevant_code
 )

 # Find similar failures
 similar = await self._find_similar_failures(error)

 return FailureAnalysis(
 test_name=failure.name,
 error=error,
 failure_type=failure_type,
 root_cause=root_cause,
 relevant_code=relevant_code,
 suggested_fix=suggested_fix,
 similar_failures=similar
 )

 def _classify_failure(self, error: TestError) -> str:
 """Classify the type of test failure."""
 if "AssertionError" in error.type:
 return "assertion"
 if "Timeout" in error.type or "timeout" in error.message.lower():
 return "timeout"
 if "fixture" in error.message.lower():
 return "fixture"
 return "exception"

 async def _suggest_fix(
 self,
 failure_type: str,
 error: TestError,
 relevant_code: list[CodeSnippet]
 ) -> str | None:
 """Suggest a fix based on failure analysis."""

 # Common assertion fixes
 if failure_type == "assertion":
 if "assertEqual" in error.message or "==" in error.message:
 # Extract expected vs actual
 return self._suggest_assertion_fix(error)

 # Fixture issues
 if failure_type == "fixture":
 if "not found" in error.message.lower():
 return f"Fixture not defined. Add @pytest.fixture or import from conftest.py"

 # Type errors often have clear fixes
 if "TypeError" in error.type:
 return self._suggest_type_error_fix(error)

 return None`
```

---

### Configuration

 yaml
 Copy

`tool-test-runner:
 # Framework detection
 frameworks:
 # Auto-detection patterns
 detect:
 pytest:
 - "pytest.ini"
 - "pyproject.toml:pytest"
 - "conftest.py"
 jest:
 - "jest.config.js"
 - "package.json:jest"
 go:
 - "go.mod"
 - "*_test.go"

 # Default options per framework
 defaults:
 pytest:
 verbose: true
 tb: "short"
 parallel: false
 jest:
 verbose: true
 coverage: false

 # Test selection
 selection:
 # Patterns for test files
 test_file_patterns:
 - "**/test_*.py"
 - "**/*_test.py"
 - "**/*.test.ts"
 - "**/*.spec.ts"
 - "**/*_test.go"

 # Exclude patterns
 exclude_patterns:
 - "**/node_modules/**"
 - "**/.venv/**"

 # Failure analysis
 analysis:
 enabled: true
 max_relevant_files: 5
 include_similar_failures: true

 # History tracking
 history:
 enabled: true
 retention_days: 30
 track_flaky: true`
```

---

### Examples

#### Example 1: Run Tests for Symbol

 python
 Copy

`# Input
{
 "operation": "run",
 "target": "PaymentGateway",
 "selection": "target",
 "analyze_failures": true
}

# Output
{
 "operation": "run",
 "run_result": {
 "success": false,
 "total": 8,
 "passed": 7,
 "failed": 1,
 "skipped": 0,
 "duration_seconds": 2.34,
 "test_results": [...],
 "failure_analyses": [
 {
 "test_name": "test_payment_gateway_timeout",
 "error": {
 "type": "AssertionError",
 "message": "Expected retry count 3, got 2",
 "location": {"file_path": "tests/test_payments.py", "line_number": 45}
 },
 "failure_type": "assertion",
 "root_cause": "PaymentGateway.process() only retries twice. The retry decorator has max_attempts=2 but test expects 3.",
 "relevant_code": [
 {
 "file": "src/payments/gateway.py",
 "line": 42,
 "code": "@retry(max_attempts=2) # Should be 3?"
 }
 ],
 "suggested_fix": "Update max_attempts to 3 in gateway.py:42 or update test expectation to 2"
 }
 ],
 "framework": "pytest",
 "command": "pytest tests/test_payments.py -k PaymentGateway -v"
 }
}`
```

#### Example 2: Run Affected Tests

 python
 Copy

`# Input
{
 "operation": "run",
 "selection": "affected"
}

# Output
{
 "operation": "run",
 "run_result": {
 "success": true,
 "total": 12,
 "passed": 12,
 "failed": 0,
 "duration_seconds": 4.56,
 "framework": "pytest",
 "command": "pytest tests/test_auth.py tests/test_users.py -v"
 }
}`
```

#### Example 3: Coverage Report

 python
 Copy

`# Input
{
 "operation": "coverage",
 "target": "src/payments/"
}

# Output
{
 "operation": "coverage",
 "coverage": {
 "total_lines": 450,
 "covered_lines": 387,
 "coverage_percent": 86.0,
 "files": [
 {
 "path": "src/payments/gateway.py",
 "lines": 120,
 "covered": 115,
 "percent": 95.8,
 "uncovered_lines": [45, 67, 89, 90, 91]
 }
 ],
 "uncovered_functions": [
 "PaymentGateway._handle_timeout",
 "PaymentGateway._legacy_fallback"
 ]
 }
}`
```

---

### Security Considerations

- Executes test commands (potential code execution)
 
- Reads test files and source code
 
- May expose test data in output
 
#### Permissions

 python
 Copy

`REQUIRED_CAPABILITIES = [
 "filesystem:read", # Read test files
 "process:execute", # Run test commands
]`
```

---

### Dependencies

#### Required

- `pytest` (for Python projects)
 
- `jest` (for JavaScript/TypeScript projects)
 
#### Optional

- `pytest-cov` - Coverage reporting
 
- `pytest-xdist` - Parallel execution
 
- `pytest-json-report` - Structured output
 
---

### Open Questions

- Framework support: Which frameworks beyond pytest/jest/go?
 
- Parallel execution: Default parallel or sequential?
 
- Coverage thresholds: Should we enforce minimum coverage?
 
- Test generation: Should this tool suggest missing tests?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Approval Workflow
 hooks

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-hooks-approval-workflow`

### Overview

Dynamic approval gates for sensitive operations beyond the kernel's built-in approval system. Enables sophisticated approval logic based on operation context, time of day, affected resources, and organizational policies.

#### Value Proposition

 | 
 
 | Without | With

 | Binary allow/deny decisions | Context-aware approval logic
 
 | Same rules for all operations | Different rules for dev/staging/prod
 
 | Manual approval tracking | Automated approval workflows
 
 | No escalation paths | Multi-level approval for high-risk operations

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-approval-workflow
 config:
 # Approval rules (evaluated in order)
 rules:
 # Production file protection
 - name: production_files
 match:
 tool: filesystem
 operation: write
 path_patterns:
 - "production/**"
 - "prod/**"
 - "**/config/production.*"
 action: require_approval
 approval:
 prompt: "Write to production file: {file_path}?"
 timeout: 300
 default: deny

 # Database migrations
 - name: database_migrations
 match:
 tool: migration_helper
 operation: execute
 action: require_approval
 approval:
 prompt: "Execute database migration: {migration_name}?"
 options: ["Run", "Dry-run first", "Cancel"]
 require_reason: true

 # Destructive operations
 - name: destructive_ops
 match:
 tool: "*"
 operation: delete
 action: require_approval
 approval:
 prompt: "Delete {resource_type}: {resource_id}?"
 default: deny

 # After-hours changes
 - name: after_hours
 match:
 time:
 outside: "09:00-18:00"
 timezone: "America/New_York"
 action: require_approval
 approval:
 prompt: "After-hours change. Proceed?"

 # High-cost operations
 - name: expensive_llm_calls
 match:
 event: provider:request
 conditions:
 estimated_tokens: "> 50000"
 action: require_approval
 approval:
 prompt: "Large LLM request (~{estimated_tokens} tokens, ~${estimated_cost}). Continue?"

 # Default behavior for non-matched operations
 default_action: continue

 # Approval caching
 caching:
 enabled: true
 ttl_seconds: 300 # Cache approvals for 5 minutes
 scope: session # session | operation`
```

#### HookResult Actions

 python
 Copy

`# Request approval from user
HookResult(
 action="ask_user",
 approval_prompt="Write to production/config.yaml?\n\nChanges:\n- Updated API endpoint\n- Changed timeout from 30s to 60s",
 approval_options=["Allow", "Deny", "Show diff"],
 approval_timeout=300.0,
 approval_default="deny"
)

# After approval received, continue or deny
HookResult(action="continue") # If approved
HookResult(action="deny", reason="User denied production file write") # If denied`
```

---

### Architecture

 python
 Copy

`class ApprovalWorkflowHook:
 """Dynamic approval gates based on configurable rules."""

 def __init__(self, config: ApprovalWorkflowConfig):
 self.config = config
 self.rules = [ApprovalRule(r) for r in config.rules]
 self.cache = ApprovalCache(config.caching) if config.caching.enabled else None
 self.pending_approvals: dict[str, PendingApproval] = {}

 async def __call__(self, event: str, data: dict) -> HookResult:
 # Check if any rule matches
 for rule in self.rules:
 if rule.matches(event, data):
 return await self._handle_rule(rule, event, data)

 return HookResult(action="continue")

 async def _handle_rule(
 self,
 rule: ApprovalRule,
 event: str,
 data: dict
 ) -> HookResult:
 # Check cache first
 cache_key = self._compute_cache_key(rule, data)
 if self.cache:
 cached = self.cache.get(cache_key)
 if cached:
 if cached.approved:
 return HookResult(action="continue")
 else:
 return HookResult(action="deny", reason=cached.reason)

 # Build approval prompt
 prompt = rule.format_prompt(data)
 options = rule.options or ["Allow", "Deny"]

 # Request approval
 return HookResult(
 action="ask_user",
 approval_prompt=prompt,
 approval_options=options,
 approval_timeout=rule.timeout,
 approval_default=rule.default
 )

 def _compute_cache_key(self, rule: ApprovalRule, data: dict) -> str:
 """Compute cache key based on rule scope."""
 if self.config.caching.scope == "session":
 return f"{rule.name}"
 else: # operation scope
 return f"{rule.name}:{hash(frozenset(data.items()))}"

class ApprovalRule:
 """Single approval rule with matching and formatting."""

 def __init__(self, config: dict):
 self.name = config["name"]
 self.match_config = config["match"]
 self.action = config["action"]
 self.approval_config = config.get("approval", {})

 # Compile matchers
 self.matchers = self._compile_matchers()

 def matches(self, event: str, data: dict) -> bool:
 """Check if rule matches current event/data."""
 for matcher in self.matchers:
 if not matcher.matches(event, data):
 return False
 return True

 def _compile_matchers(self) -> list[Matcher]:
 matchers = []

 if "tool" in self.match_config:
 matchers.append(ToolMatcher(self.match_config["tool"]))

 if "operation" in self.match_config:
 matchers.append(OperationMatcher(self.match_config["operation"]))

 if "path_patterns" in self.match_config:
 matchers.append(PathMatcher(self.match_config["path_patterns"]))

 if "event" in self.match_config:
 matchers.append(EventMatcher(self.match_config["event"]))

 if "time" in self.match_config:
 matchers.append(TimeMatcher(self.match_config["time"]))

 if "conditions" in self.match_config:
 matchers.append(ConditionMatcher(self.match_config["conditions"]))

 return matchers

 def format_prompt(self, data: dict) -> str:
 """Format approval prompt with data."""
 template = self.approval_config.get("prompt", "Approve this operation?")
 return template.format(**data)

class PathMatcher:
 """Match file paths against patterns."""

 def __init__(self, patterns: list[str]):
 self.patterns = [re.compile(fnmatch.translate(p)) for p in patterns]

 def matches(self, event: str, data: dict) -> bool:
 file_path = data.get("file_path", "")
 return any(p.match(file_path) for p in self.patterns)

class TimeMatcher:
 """Match based on time of day."""

 def __init__(self, config: dict):
 self.outside = config.get("outside") # "09:00-18:00"
 self.timezone = pytz.timezone(config.get("timezone", "UTC"))

 def matches(self, event: str, data: dict) -> bool:
 now = datetime.now(self.timezone)
 current_time = now.time()

 if self.outside:
 start, end = self._parse_time_range(self.outside)
 # Match if OUTSIDE the range
 return not (start <= current_time <= end)

 return True`
```

---

### Rule Matching

#### Match Criteria

 | 
 
 | Criterion | Description | Example

 | `tool` | Tool name (glob) | `"filesystem"`, `"*"`
 
 | `operation` | Operation type | `"write"`, `"delete"`, `"execute"`
 
 | `path_patterns` | File path patterns | `["production/**", "*.prod.*"]`
 
 | `event` | Event type | `"provider:request"`, `"tool:pre"`
 
 | `time.outside` | Time range | `"09:00-18:00"`
 
 | `time.timezone` | Timezone | `"America/New_York"`
 
 | `conditions` | Custom conditions | `{"estimated_tokens": "> 50000"}`

#### Condition Operators

- `"="` - Equals
 
- `"!="` - Not equals
 
- `">"` - Greater than
 
- `"="` - Greater or equal
 
- `"
 
 yaml
 Copy

`rules:
 - name: production_files
 match:
 tool: filesystem
 operation: write
 path_patterns:
 - "production/**"
 - "**/config/prod.*"
 action: require_approval
 approval:
 prompt: |
 âš ï¸ Production file change detected

 File: {file_path}

 Are you sure you want to modify this production file?
 options: ["Allow", "Deny"]
 default: deny`
```

#### Example 2: Multi-Option Approval

 yaml
 Copy

`rules:
 - name: database_migration
 match:
 tool: migration_helper
 action: require_approval
 approval:
 prompt: |
 Database migration: {migration_name}

 Changes:
 {changes_summary}

 What would you like to do?
 options:
 - "Run migration"
 - "Dry-run first"
 - "Show full SQL"
 - "Cancel"`
```

#### Example 3: Cost-Based Approval

 yaml
 Copy

`rules:
 - name: expensive_operations
 match:
 event: provider:request
 conditions:
 estimated_cost: "> 1.00"
 action: require_approval
 approval:
 prompt: |
 ðŸ’° Expensive LLM operation

 Estimated cost: ${estimated_cost}
 Estimated tokens: {estimated_tokens}

 Continue?
 default: deny`
```

#### Example 4: After-Hours Warning

 yaml
 Copy

`rules:
 - name: after_hours
 match:
 tool: "*"
 operation: write
 time:
 outside: "09:00-18:00"
 timezone: "America/Los_Angeles"
 action: require_approval
 approval:
 prompt: |
 ðŸŒ™ After-hours change

 It's currently outside business hours.
 This change may not receive timely review.

 Proceed anyway?`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `rules` | list | [] | Approval rules
 
 | `default_action` | string | "continue" | Action when no rule matches
 
 | `caching.enabled` | bool | false | Cache approvals
 
 | `caching.ttl_seconds` | int | 300 | Cache TTL
 
 | `caching.scope` | string | "session" | Cache scope

---

### Security Considerations

- Rules evaluated server-side, can't be bypassed
 
- Approval cache prevents prompt fatigue attacks
 
- Default-deny recommended for sensitive operations
 
- Audit log should capture all approval decisions
 
---

### Dependencies

#### Required

- `fnmatch` - Pattern matching (stdlib)
 
#### Optional

- `pytz` - Timezone handling
 
---

### Open Questions

- Escalation: Support multi-level approval (manager approval)?
 
- Delegation: Allow pre-approved operations for specific users?
 
- Time limits: Approval valid for specific time window?
 
- Notifications: Notify team on certain approvals?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Audit Trail
 hooks

Priority: P0 (Foundation)

Status: Draft

Module: `amplifier-module-hooks-audit-trail`

### Overview

Comprehensive audit logging for compliance and security. Creates immutable records of all agent operations, decisions, and changes. Designed for enterprise environments with regulatory requirements.

#### Value Proposition

 | 
 
 | Without | With

 | No record of AI actions | Complete audit trail
 
 | Compliance gaps | SOC2/HIPAA/GDPR ready
 
 | Incident investigation difficult | Full replay capability
 
 | "What did the AI do?" | Detailed operation log

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-audit-trail
 config:
 # Storage configuration
 storage:
 type: file # file | s3 | elasticsearch | splunk
 path: "${AUDIT_LOG_PATH}" # For file storage
 # s3:
 # bucket: "audit-logs"
 # prefix: "amplifier/"

 # What to log
 capture:
 session_lifecycle: true # start, end
 prompts: true # User inputs
 responses: true # Agent outputs
 tool_operations: true # All tool calls
 file_changes: true # File content changes
 approvals: true # User approvals
 errors: true # Errors and failures

 # Data handling
 retention:
 days: 365 # Keep logs for 1 year
 archive_after_days: 90 # Move to cold storage

 # Privacy
 privacy:
 redact_secrets: true # Redact detected secrets
 hash_user_ids: false # Hash user identifiers
 exclude_patterns: # Don't log matching content
 - "password"
 - "credit_card"

 # Integrity
 integrity:
 sign_entries: true # Cryptographically sign entries
 chain_hashes: true # Hash chain for tamper detection

 # Format
 format:
 type: jsonl # jsonl | json | parquet
 include_timestamp: true
 include_session_id: true
 include_user_id: true`
```

#### Audit Entry Schema

 python
 Copy

`@dataclass
class AuditEntry:
 # Identity
 entry_id: str # Unique entry ID
 timestamp: datetime # ISO 8601
 session_id: str
 user_id: str | None

 # Event classification
 event_type: str # session:start, tool:execute, etc.
 event_category: str # lifecycle | operation | data | error

 # Event details
 action: str # create, read, update, delete, execute
 resource_type: str # file, tool, prompt, response
 resource_id: str | None # File path, tool name, etc.

 # Operation details
 input: dict | None # Sanitized input
 output: dict | None # Sanitized output
 outcome: str # success | failure | denied

 # Context
 metadata: dict # Additional context
 previous_hash: str | None # For hash chain
 signature: str | None # For signed entries

@dataclass
class AuditQuery:
 """Query parameters for audit search."""
 session_id: str | None
 user_id: str | None
 event_type: str | None
 resource_type: str | None
 start_time: datetime | None
 end_time: datetime | None
 outcome: str | None`
```

---

### Architecture

 python
 Copy

`class AuditTrailHook:
 """Comprehensive audit logging hook."""

 # Events to capture
 CAPTURED_EVENTS = [
 "session:start",
 "session:end",
 "prompt:submit",
 "prompt:complete",
 "tool:pre",
 "tool:post",
 "tool:error",
 "approval:required",
 "approval:granted",
 "approval:denied",
 "policy:violation",
 "error:*",
 ]

 def __init__(self, config: AuditTrailConfig):
 self.config = config
 self.storage = self._create_storage(config.storage)
 self.sanitizer = AuditSanitizer(config.privacy)
 self.signer = AuditSigner(config.integrity) if config.integrity.sign_entries else None
 self.previous_hash: str | None = None

 async def __call__(self, event: str, data: dict) -> HookResult:
 # Check if we should capture this event
 if not self._should_capture(event):
 return HookResult(action="continue")

 # Create audit entry
 entry = self._create_entry(event, data)

 # Sanitize sensitive data
 entry = self.sanitizer.sanitize(entry)

 # Add integrity features
 if self.config.integrity.chain_hashes:
 entry.previous_hash = self.previous_hash
 self.previous_hash = self._compute_hash(entry)

 if self.signer:
 entry.signature = self.signer.sign(entry)

 # Store entry
 await self.storage.store(entry)

 # Always continue - audit is observational only
 return HookResult(action="continue")

 def _create_entry(self, event: str, data: dict) -> AuditEntry:
 """Create audit entry from event."""
 return AuditEntry(
 entry_id=str(uuid.uuid4()),
 timestamp=datetime.utcnow(),
 session_id=data.get("session_id", "unknown"),
 user_id=data.get("user_id"),
 event_type=event,
 event_category=self._categorize_event(event),
 action=self._extract_action(event, data),
 resource_type=self._extract_resource_type(event, data),
 resource_id=self._extract_resource_id(event, data),
 input=self._extract_input(event, data),
 output=self._extract_output(event, data),
 outcome=self._determine_outcome(event, data),
 metadata=self._extract_metadata(event, data),
 )

class AuditSanitizer:
 """Sanitize audit entries to remove sensitive data."""

 def __init__(self, config: PrivacyConfig):
 self.config = config
 self.secret_patterns = self._compile_patterns()

 def sanitize(self, entry: AuditEntry) -> AuditEntry:
 """Remove or redact sensitive information."""
 if self.config.redact_secrets:
 if entry.input:
 entry.input = self._redact_secrets(entry.input)
 if entry.output:
 entry.output = self._redact_secrets(entry.output)

 if self.config.hash_user_ids and entry.user_id:
 entry.user_id = hashlib.sha256(entry.user_id.encode()).hexdigest()[:16]

 return entry

 def _redact_secrets(self, data: dict) -> dict:
 """Recursively redact secrets from data."""
 if isinstance(data, dict):
 return {k: self._redact_secrets(v) for k, v in data.items()}
 if isinstance(data, str):
 for pattern in self.secret_patterns:
 data = pattern.sub("[REDACTED]", data)
 return data
 return data

class AuditSigner:
 """Sign audit entries for integrity verification."""

 def __init__(self, config: IntegrityConfig):
 self.private_key = self._load_private_key(config.key_path)

 def sign(self, entry: AuditEntry) -> str:
 """Create signature for audit entry."""
 payload = self._serialize_for_signing(entry)
 signature = self.private_key.sign(payload.encode())
 return base64.b64encode(signature).decode()

 def verify(self, entry: AuditEntry) -> bool:
 """Verify audit entry signature."""
 payload = self._serialize_for_signing(entry)
 signature = base64.b64decode(entry.signature)
 try:
 self.public_key.verify(signature, payload.encode())
 return True
 except Exception:
 return False`
```

---

### Storage Backends

#### File Storage

 python
 Copy

`class FileAuditStorage:
 """Store audit logs as local files."""

 async def store(self, entry: AuditEntry) -> None:
 # Rotate files by date
 file_path = self._get_file_path(entry.timestamp)

 async with aiofiles.open(file_path, "a") as f:
 await f.write(json.dumps(asdict(entry)) + "\n")

 def _get_file_path(self, timestamp: datetime) -> Path:
 date_str = timestamp.strftime("%Y-%m-%d")
 return self.base_path / f"audit-{date_str}.jsonl"`
```

#### S3 Storage

 python
 Copy

`class S3AuditStorage:
 """Store audit logs in S3."""

 async def store(self, entry: AuditEntry) -> None:
 # Buffer entries and flush periodically
 self.buffer.append(entry)

 if len(self.buffer) >= self.batch_size:
 await self._flush()

 async def _flush(self) -> None:
 # Write buffered entries to S3
 key = f"{self.prefix}{datetime.utcnow().isoformat()}.jsonl"
 body = "\n".join(json.dumps(asdict(e)) for e in self.buffer)
 await self.s3.put_object(Bucket=self.bucket, Key=key, Body=body)
 self.buffer.clear()`
```

---

### Examples

#### Example 1: Tool Execution Audit Entry

 json
 Copy

`{
 "entry_id": "audit-001-abc123",
 "timestamp": "2024-01-15T10:30:45.123Z",
 "session_id": "sess-456",
 "user_id": "alice",
 "event_type": "tool:post",
 "event_category": "operation",
 "action": "execute",
 "resource_type": "tool",
 "resource_id": "filesystem:write",
 "input": {
 "tool": "filesystem",
 "operation": "write",
 "file_path": "src/payments/gateway.py",
 "content_length": 1234
 },
 "output": {
 "success": true,
 "bytes_written": 1234
 },
 "outcome": "success",
 "metadata": {
 "duration_ms": 45,
 "provider": "anthropic",
 "model": "claude-3"
 },
 "previous_hash": "sha256:abc123...",
 "signature": "base64:xyz789..."
}`
```

#### Example 2: Approval Audit Entry

 json
 Copy

`{
 "entry_id": "audit-002-def456",
 "timestamp": "2024-01-15T10:31:00.000Z",
 "session_id": "sess-456",
 "user_id": "alice",
 "event_type": "approval:granted",
 "event_category": "lifecycle",
 "action": "approve",
 "resource_type": "operation",
 "resource_id": "delete:production/config.yaml",
 "input": {
 "prompt": "Delete production config file?",
 "options": ["Allow", "Deny"]
 },
 "output": {
 "decision": "Allow",
 "reason": "User approved"
 },
 "outcome": "success"
}`
```

#### Example 3: Session Summary

 python
 Copy

`# Query audit log for session summary
entries = await audit_storage.query(AuditQuery(session_id="sess-456"))

# Produces report:
"""
Session Audit Report: sess-456
User: alice
Duration: 15 minutes
Start: 2024-01-15T10:30:00Z
End: 2024-01-15T10:45:00Z

Operations:
- Files written: 5
- Files read: 12
- Tools executed: 23
- Approvals requested: 2
- Approvals granted: 2
- Errors: 0

File Changes:
1. src/payments/gateway.py (created)
2. src/payments/retry.py (created)
3. tests/test_gateway.py (modified)
4. pyproject.toml (modified)
5. README.md (modified)
"""`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `storage.type` | string | "file" | Storage backend
 
 | `storage.path` | string | "./audit" | Path for file storage
 
 | `capture.*` | bool | true | What events to capture
 
 | `retention.days` | int | 365 | Log retention period
 
 | `privacy.redact_secrets` | bool | true | Redact detected secrets
 
 | `privacy.hash_user_ids` | bool | false | Hash user identifiers
 
 | `integrity.sign_entries` | bool | false | Sign entries
 
 | `integrity.chain_hashes` | bool | false | Create hash chain

---

### Compliance Notes

- SOC 2: Immutable logs with integrity verification
 
- HIPAA: Redaction of PHI, access logging
 
- GDPR: User identification controls, retention limits
 
- PCI-DSS: Cardholder data redaction
 
---

### Security Considerations

- Audit logs themselves contain sensitive data
 
- Signing keys must be protected
 
- Storage must be access-controlled
 
- Log tampering detection via hash chains
 
---

### Dependencies

#### Required

- `aiofiles` - Async file operations
 
#### Optional

- `boto3` - S3 storage
 
- `cryptography` - Entry signing
 
- `elasticsearch` - ES storage
 
---

### Open Questions

- Real-time streaming: Stream audit logs to SIEM?
 
- Query interface: Provide search API within hook?
 
- Log rotation: Built-in rotation vs external tools?
 
- Alert integration: Trigger alerts on suspicious patterns?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Breaking Change
 hooks

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-hooks-breaking-change`

### Overview

Detects potential breaking changes in API contracts, database schemas, and public interfaces. Warns developers before they accidentally break downstream consumers.

#### Value Proposition

 | 
 
 | Without | With

 | Breaking changes discovered by consumers | Detected before merge
 
 | "We didn't know that was public API" | Clear visibility into contracts
 
 | Versioning afterthought | Version bump reminders

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-breaking-change
 config:
 # What to analyze
 analyze:
 api_endpoints: true # REST/GraphQL endpoints
 function_signatures: true # Public function changes
 database_schemas: true # Schema migrations
 config_files: true # Configuration formats
 proto_files: true # Protocol buffers

 # Detection rules
 rules:
 api:
 # Breaking: removing endpoint, changing required params
 - type: endpoint_removed
 severity: error
 - type: required_param_added
 severity: error
 - type: response_field_removed
 severity: error
 # Non-breaking: adding optional param, new endpoint
 - type: optional_param_added
 severity: info
 - type: endpoint_added
 severity: info

 functions:
 # Public functions (exported)
 - type: signature_changed
 scope: public
 severity: error
 - type: function_removed
 scope: public
 severity: error
 # Private functions (not exported)
 - type: signature_changed
 scope: private
 severity: info

 database:
 - type: column_removed
 severity: error
 - type: column_type_changed
 severity: error
 - type: not_null_added
 severity: warning

 # Action on detection
 on_breaking_change:
 action: inject_context # inject_context | deny | warn
 require_acknowledgment: true`
```

#### HookResult

 python
 Copy

`# Detected breaking change
HookResult(
 action="inject_context",
 context_injection="""
âš ï¸ **Breaking Change Detected**

File: src/api/users.py

**Changes:**
1. **BREAKING**: Removed endpoint `DELETE /api/users/{id}`
 - This endpoint may have consumers depending on it
 - Consider deprecation period before removal

2. **BREAKING**: Added required parameter `email` to `POST /api/users`
 - Existing clients will fail without this parameter
 - Consider making optional with default, or versioning API

**Recommendations:**
- Add `@deprecated` decorator with removal date
- Create v2 endpoint with new signature
- Update API changelog

Do you want to proceed with these breaking changes?
""",
 user_message="Breaking changes detected in users.py API",
 user_message_level="warning"
)`
```

---

### Architecture

 python
 Copy

`class BreakingChangeHook:
 """Detect breaking changes in code."""

 def __init__(self, config: BreakingChangeConfig):
 self.config = config
 self.analyzers = self._initialize_analyzers()

 async def __call__(self, event: str, data: dict) -> HookResult:
 if event != "tool:post" or not self._is_code_write(data):
 return HookResult(action="continue")

 file_path = data.get("file_path", "")
 new_content = data.get("content", "")

 # Get previous content from git
 old_content = await self._get_previous_content(file_path)
 if old_content is None:
 return HookResult(action="continue") # New file

 # Analyze for breaking changes
 changes = await self._analyze_changes(file_path, old_content, new_content)

 if not changes:
 return HookResult(action="continue")

 # Filter by severity
 breaking = [c for c in changes if c.severity in ("error", "warning")]

 if not breaking:
 return HookResult(action="continue")

 return self._generate_feedback(file_path, breaking)

 async def _analyze_changes(
 self,
 file_path: str,
 old_content: str,
 new_content: str
 ) -> list[ChangeDetection]:
 """Analyze changes using appropriate analyzer."""
 changes = []

 for analyzer in self.analyzers:
 if analyzer.can_analyze(file_path):
 analyzer_changes = await analyzer.analyze(
 file_path, old_content, new_content
 )
 changes.extend(analyzer_changes)

 return changes

class APIAnalyzer:
 """Analyze REST API changes."""

 async def analyze(
 self,
 file_path: str,
 old_content: str,
 new_content: str
 ) -> list[ChangeDetection]:
 changes = []

 # Extract endpoints from both versions
 old_endpoints = self._extract_endpoints(old_content)
 new_endpoints = self._extract_endpoints(new_content)

 # Check for removed endpoints
 for endpoint in old_endpoints:
 if endpoint not in new_endpoints:
 changes.append(ChangeDetection(
 type="endpoint_removed",
 severity="error",
 location=file_path,
 description=f"Endpoint removed: {endpoint.method} {endpoint.path}",
 old_value=str(endpoint),
 new_value=None
 ))

 # Check for signature changes
 for old_ep in old_endpoints:
 new_ep = self._find_endpoint(new_endpoints, old_ep.method, old_ep.path)
 if new_ep:
 param_changes = self._compare_parameters(old_ep, new_ep)
 changes.extend(param_changes)

 return changes

 def _extract_endpoints(self, content: str) -> list[Endpoint]:
 """Extract API endpoints from code."""
 endpoints = []

 # Flask/FastAPI style decorators
 patterns = [
 r'@app\.(?:get|post|put|delete|patch)\(["\']([^"\']+)["\']',
 r'@router\.(?:get|post|put|delete|patch)\(["\']([^"\']+)["\']',
 ]

 for pattern in patterns:
 for match in re.finditer(pattern, content):
 # Extract method and path
 # Parse function signature for parameters
 endpoints.append(self._parse_endpoint(match, content))

 return endpoints

class FunctionSignatureAnalyzer:
 """Analyze public function signature changes."""

 async def analyze(
 self,
 file_path: str,
 old_content: str,
 new_content: str
 ) -> list[ChangeDetection]:
 changes = []

 # Parse both versions
 old_functions = self._extract_functions(old_content)
 new_functions = self._extract_functions(new_content)

 # Check public functions only
 for name, old_func in old_functions.items():
 if not self._is_public(name, old_func):
 continue

 if name not in new_functions:
 changes.append(ChangeDetection(
 type="function_removed",
 severity="error",
 location=f"{file_path}:{old_func.line}",
 description=f"Public function removed: {name}",
 ))
 else:
 new_func = new_functions[name]
 sig_changes = self._compare_signatures(old_func, new_func)
 if sig_changes:
 changes.append(ChangeDetection(
 type="signature_changed",
 severity="error",
 location=f"{file_path}:{new_func.line}",
 description=f"Signature changed for {name}: {sig_changes}",
 ))

 return changes

 def _is_public(self, name: str, func: FunctionInfo) -> bool:
 """Determine if function is public."""
 # Python: doesn't start with _
 if name.startswith("_"):
 return False
 # Check for @public decorator or __all__ export
 return True`
```

---

### Change Detection Types

#### API Changes

 | 
 
 | Type | Severity | Description

 | `endpoint_removed` | error | Endpoint deleted
 
 | `required_param_added` | error | New required parameter
 
 | `response_field_removed` | error | Field removed from response
 
 | `return_type_changed` | error | Return type changed
 
 | `optional_param_added` | info | New optional parameter
 
 | `endpoint_added` | info | New endpoint

#### Function Signature Changes

 | 
 
 | Type | Severity | Description

 | `function_removed` | error | Public function removed
 
 | `param_removed` | error | Parameter removed
 
 | `param_type_changed` | error | Parameter type changed
 
 | `return_type_changed` | error | Return type changed
 
 | `param_added_required` | error | Required param added
 
 | `param_added_optional` | info | Optional param added

#### Database Schema Changes

 | 
 
 | Type | Severity | Description

 | `column_removed` | error | Column dropped
 
 | `column_type_changed` | error | Column type changed
 
 | `not_null_added` | warning | NOT NULL constraint added
 
 | `table_removed` | error | Table dropped
 
 | `column_added_nullable` | info | Nullable column added

---

### Examples

#### Example 1: API Endpoint Removed

 python
 Copy

`# Old code:
@app.delete("/api/users/{id}")
def delete_user(id: int):
 ...

# New code: (endpoint removed)

# Hook detects and warns:
"""
âš ï¸ **Breaking Change Detected**

**BREAKING**: Endpoint removed: DELETE /api/users/{id}
- Consumers using this endpoint will receive 404

**Recommendation:**
- Add deprecation notice before removal
- Provide migration path in documentation
"""`
```

#### Example 2: Function Signature Change

 python
 Copy

`# Old:
def process_payment(amount: float, currency: str) -> bool:
 ...

# New:
def process_payment(amount: float, currency: str, idempotency_key: str) -> PaymentResult:
 ...

# Hook detects:
"""
âš ï¸ **Breaking Change Detected**

1. **BREAKING**: New required parameter `idempotency_key`
 - Existing callers will fail with TypeError

2. **BREAKING**: Return type changed from `bool` to `PaymentResult`
 - Callers expecting boolean will break

**Recommendations:**
- Make `idempotency_key` optional with default
- Keep backward-compatible return for transition period
"""`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `analyze.*` | bool | true | What to analyze
 
 | `rules.` | list | (defaults) | Detection rules
 
 | `on_breaking_change.action` | string | "inject_context" | Action on detection
 
 | `on_breaking_change.require_acknowledgment` | bool | true | Require user ack

---

### Security Considerations

- Reads file content and git history
 
- No external network access
 
- Analysis is local and fast
 
---

### Dependencies

#### Required

- `tree-sitter` - Code parsing
 
- `gitpython` - Git history access
 
#### Optional

- Language-specific parsers
 
---

### Open Questions

- Semantic versioning: Auto-suggest version bump?
 
- Changelog: Auto-generate changelog entries?
 
- Consumer notification: Integrate with deprecation notices?
 
- Custom contracts: Support custom API contract formats?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Knowledge Capture
 hooks

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-hooks-knowledge-capture`

### Overview

Automatically captures learnings, decisions, and insights from AI sessions and stores them in a team knowledge base. Transforms ephemeral conversations into persistent organizational knowledge.

#### Value Proposition

 | 
 
 | Without | With

 | Knowledge lost after session ends | Insights captured automatically
 
 | "We figured this out before..." | Searchable knowledge base
 
 | Tribal knowledge in people's heads | Documented and shared
 
 | Repeated problem-solving | Learn from past sessions

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-knowledge-capture
 config:
 # What to capture
 capture:
 decisions: true # "Let's use X approach"
 learnings: true # "TIL...", "I learned..."
 solutions: true # Problem-solution pairs
 code_patterns: true # Reusable code patterns
 gotchas: true # "Watch out for...", "Don't forget..."

 # Knowledge base storage
 storage:
 type: markdown # markdown | notion | confluence | custom
 path: "docs/knowledge-base/"
 organize_by: topic # topic | date | project

 # Extraction settings
 extraction:
 min_significance: 0.7 # Confidence threshold
 require_confirmation: false # Ask before saving
 deduplicate: true # Skip if similar exists

 # Categories/tags
 categories:
 - architecture
 - debugging
 - performance
 - security
 - testing
 - deployment`
```

#### HookResult

 python
 Copy

`# Capture knowledge at session end
HookResult(
 action="inject_context",
 context_injection="", # No injection needed
 suppress_output=True,
 user_message="Captured 3 learnings to knowledge base"
)

# Or ask for confirmation
HookResult(
 action="ask_user",
 approval_prompt="""
Knowledge capture found these insights:

1. **Decision**: Use exponential backoff for payment retries (max 3 attempts)
2. **Gotcha**: Payment gateway returns 200 even on soft failures - check response body
3. **Pattern**: Retry decorator pattern for idempotent operations

Save to knowledge base?
""",
 approval_options=["Save all", "Save selected", "Skip"]
)`
```

---

### Architecture

 python
 Copy

`class KnowledgeCaptureHook:
 """Capture and store knowledge from sessions."""

 def __init__(self, config: KnowledgeCaptureConfig):
 self.config = config
 self.storage = self._create_storage(config.storage)
 self.extractor = KnowledgeExtractor(config.extraction)
 self.session_messages: list[dict] = []

 async def __call__(self, event: str, data: dict) -> HookResult:
 # Collect messages during session
 if event in ("prompt:submit", "prompt:complete"):
 self._collect_message(event, data)
 return HookResult(action="continue")

 # Extract knowledge at session end
 if event == "session:end":
 return await self._extract_and_save()

 return HookResult(action="continue")

 def _collect_message(self, event: str, data: dict) -> None:
 """Collect messages for later analysis."""
 if event == "prompt:submit":
 self.session_messages.append({
 "role": "user",
 "content": data.get("prompt", "")
 })
 elif event == "prompt:complete":
 self.session_messages.append({
 "role": "assistant",
 "content": data.get("response", "")
 })

 async def _extract_and_save(self) -> HookResult:
 """Extract knowledge and save to storage."""
 if not self.session_messages:
 return HookResult(action="continue")

 # Extract knowledge items
 items = await self.extractor.extract(self.session_messages)

 if not items:
 return HookResult(action="continue")

 # Deduplicate if configured
 if self.config.extraction.deduplicate:
 items = await self._deduplicate(items)

 if not items:
 return HookResult(action="continue")

 # Save or request confirmation
 if self.config.extraction.require_confirmation:
 return self._request_confirmation(items)
 else:
 await self._save_items(items)
 return HookResult(
 action="continue",
 user_message=f"Captured {len(items)} knowledge items"
 )

class KnowledgeExtractor:
 """Extract knowledge items from conversation."""

 # Patterns indicating knowledge
 DECISION_PATTERNS = [
 r"let's use",
 r"we('ll| will) go with",
 r"decided to",
 r"the approach (is|will be)",
 r"choosing .* because",
 ]

 LEARNING_PATTERNS = [
 r"(TIL|I learned|we learned)",
 r"turns out",
 r"discovered that",
 r"found out",
 r"realized",
 ]

 GOTCHA_PATTERNS = [
 r"watch out for",
 r"don't forget",
 r"gotcha",
 r"caveat",
 r"be careful",
 r"important to note",
 r"heads up",
 ]

 SOLUTION_PATTERNS = [
 r"(the |this )?(fix|solution) (is|was)",
 r"solved (it |this )by",
 r"fixed (it |this )by",
 r"the answer (is|was)",
 ]

 async def extract(self, messages: list[dict]) -> list[KnowledgeItem]:
 """Extract knowledge items from messages."""
 items = []

 # Concatenate conversation
 full_text = "\n".join(m["content"] for m in messages)

 # Pattern-based extraction
 items.extend(self._extract_by_patterns(messages))

 # LLM-based extraction for deeper insights
 items.extend(await self._extract_with_llm(messages))

 # Filter by significance
 items = [i for i in items if i.significance >= self.config.min_significance]

 return items

 def _extract_by_patterns(self, messages: list[dict]) -> list[KnowledgeItem]:
 """Extract using pattern matching."""
 items = []

 for message in messages:
 content = message["content"]

 # Check each category
 for pattern in self.DECISION_PATTERNS:
 matches = re.finditer(pattern, content, re.IGNORECASE)
 for match in matches:
 context = self._get_context(content, match)
 items.append(KnowledgeItem(
 type="decision",
 content=context,
 significance=0.8
 ))

 for pattern in self.GOTCHA_PATTERNS:
 matches = re.finditer(pattern, content, re.IGNORECASE)
 for match in matches:
 context = self._get_context(content, match)
 items.append(KnowledgeItem(
 type="gotcha",
 content=context,
 significance=0.85
 ))

 return items

 async def _extract_with_llm(self, messages: list[dict]) -> list[KnowledgeItem]:
 """Use LLM to extract deeper insights."""
 # Use a small, fast model for extraction
 prompt = f"""
Analyze this conversation and extract key knowledge items:

{self._format_conversation(messages)}

Extract:
1. Decisions made and their rationale
2. Learnings or discoveries
3. Solutions to problems encountered
4. Gotchas or caveats mentioned
5. Reusable patterns or approaches

Format as JSON array with: type, content, category, significance (0-1)
"""
 # Call LLM and parse response
 # ...`
```

---

### Knowledge Item Schema

 python
 Copy

`@dataclass
class KnowledgeItem:
 type: str # decision | learning | gotcha | solution | pattern
 content: str # The knowledge content
 category: str | None # architecture | debugging | etc.
 significance: float # 0-1 confidence score

 # Metadata
 source_session: str | None
 timestamp: datetime
 related_files: list[str]
 tags: list[str]

 # For solutions
 problem: str | None # What problem this solves
 solution: str | None # How it solves it`
```

---

### Storage Formats

#### Markdown (Default)

 markdown
 Copy

`# Knowledge Base

## Decisions

### Use exponential backoff for payment retries
**Date**: 2024-01-15
**Category**: Architecture
**Context**: Payment gateway integration

Decided to implement exponential backoff with max 3 retries for payment processing.
Rationale: Gateway has intermittent timeouts during peak load.

**Related files**: src/payments/gateway.py

---

## Gotchas

### Payment gateway returns 200 on soft failures
**Date**: 2024-01-15
**Category**: Debugging

Watch out: The payment gateway returns HTTP 200 even when payment fails.
Must check `response.body.success` field, not just HTTP status.

---`
```

#### Notion Integration

 python
 Copy

`class NotionStorage:
 """Store knowledge in Notion database."""

 async def save(self, item: KnowledgeItem) -> None:
 await self.notion.pages.create(
 parent={"database_id": self.database_id},
 properties={
 "Title": {"title": [{"text": {"content": item.content[:100]}}]},
 "Type": {"select": {"name": item.type}},
 "Category": {"select": {"name": item.category}},
 "Date": {"date": {"start": item.timestamp.isoformat()}},
 "Tags": {"multi_select": [{"name": t} for t in item.tags]},
 },
 children=self._format_content_blocks(item)
 )`
```

---

### Examples

#### Example 1: Decision Capture

 python
 Copy

`# From session conversation:
# User: "Should we use Redis or Memcached for caching?"
# Assistant: "Given your need for persistence and pub/sub, let's use Redis..."

# Extracted:
{
 "type": "decision",
 "content": "Use Redis over Memcached for caching",
 "category": "architecture",
 "problem": "Choosing caching solution",
 "solution": "Redis - provides persistence and pub/sub needed for notifications",
 "significance": 0.9
}`
```

#### Example 2: Gotcha Capture

 python
 Copy

`# From session:
# Assistant: "...watch out for timezone handling. The API returns UTC but
# the database stores local time, so you need to convert..."

# Extracted:
{
 "type": "gotcha",
 "content": "API returns UTC, database stores local time - convert at boundary",
 "category": "debugging",
 "tags": ["timezone", "api", "database"],
 "significance": 0.85
}`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `capture.*` | bool | true | What to capture
 
 | `storage.type` | string | "markdown" | Storage backend
 
 | `storage.path` | string | "docs/kb/" | Path for markdown
 
 | `extraction.min_significance` | float | 0.7 | Confidence threshold
 
 | `extraction.require_confirmation` | bool | false | Ask before saving
 
 | `extraction.deduplicate` | bool | true | Skip duplicates

---

### Security Considerations

- May capture sensitive information from sessions
 
- Storage should be access-controlled
 
- Consider PII filtering before storage
 
---

### Dependencies

#### Required

- `aiofiles` - File operations
 
#### Optional

- `notion-client` - Notion integration
 
- `atlassian-python-api` - Confluence integration
 
---

### Open Questions

- Confirmation flow: Always ask, never ask, or smart selection?
 
- Cross-session: Link related knowledge across sessions?
 
- Retrieval: Should this hook also inject relevant knowledge?
 
- Quality: How to ensure captured knowledge is accurate?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks License Checker
 hooks

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-hooks-license-checker`

### Overview

Scans dependencies for license compatibility issues in real-time. Flags problematic licenses (GPL in proprietary code, unknown licenses) before they're committed, preventing legal compliance issues.

#### Value Proposition

 | 
 
 | Without | With

 | License issues found late in legal review | Caught at addition time
 
 | Accidental GPL contamination | Blocked proactively
 
 | Unknown license risks | Clear visibility
 
 | Manual license audits | Automated checking

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-license-checker
 config:
 # License policy
 policy:
 allowed: # Explicitly allowed licenses
 - MIT
 - Apache-2.0
 - BSD-2-Clause
 - BSD-3-Clause
 - ISC
 - 0BSD
 - Unlicense
 - CC0-1.0

 restricted: # Require approval
 - LGPL-2.1
 - LGPL-3.0
 - MPL-2.0
 - EPL-1.0
 - EPL-2.0

 prohibited: # Always block
 - GPL-2.0
 - GPL-3.0
 - AGPL-3.0
 - SSPL-1.0
 - CC-BY-NC-* # Non-commercial
 - BUSL-* # Business source

 unknown_action: warn # allow | warn | deny

 # Scanning scope
 scope:
 package_managers:
 - npm
 - pip
 - cargo
 - go
 - maven
 - nuget
 scan_transitive: true # Check transitive deps
 scan_dev_deps: false # Skip devDependencies

 # Actions
 actions:
 on_prohibited: deny # deny | warn
 on_restricted: ask_user # ask_user | warn
 on_unknown: warn # warn | deny

 # Exceptions
 exceptions:
 packages: # Known OK packages
 - package: "some-gpl-tool"
 reason: "CLI tool, not linked"
 paths: # Paths to skip
 - "test/**"
 - "scripts/**"`
```

#### HookResult

 python
 Copy

`# Prohibited license detected
HookResult(
 action="deny",
 reason="License compliance violation",
 context_injection="""
â›” **License Violation Detected**

Adding dependency `copyleft-lib@2.0.0` would introduce **GPL-3.0** license.

**Why this is blocked:**
GPL-3.0 is a copyleft license that requires derivative works to also be GPL-licensed.
Your project uses MIT license, which is incompatible.

**Options:**
1. Find an alternative package with permissive license
2. Request legal exception (requires approval)
3. Change project license to GPL-compatible

**Alternatives with similar functionality:**
- `permissive-lib` (MIT) - https://github.com/example/permissive-lib
- `free-lib` (Apache-2.0) - https://github.com/example/free-lib
""",
 user_message="â›” Blocked: GPL-3.0 license not allowed",
 user_message_level="error"
)

# Restricted license - ask user
HookResult(
 action="ask_user",
 approval_prompt="""
âš ï¸ **License Requires Approval**

Dependency `lgpl-lib@1.0.0` uses **LGPL-3.0** license.

LGPL is allowed for dynamic linking but requires:
- Providing license notice
- Allowing users to replace the library
- Not modifying the library source

Is this dependency used appropriately?
""",
 approval_options=["Approve (dynamic linking)", "Reject", "Need more info"],
 approval_default="reject"
)`
```

---

### Architecture

 python
 Copy

`class LicenseCheckerHook:
 """Check dependencies for license compliance."""

 def __init__(self, config: LicenseCheckerConfig):
 self.config = config
 self.policy = LicensePolicy(config.policy)
 self.scanners = self._initialize_scanners()
 self.license_db = LicenseDatabase()

 async def __call__(self, event: str, data: dict) -> HookResult:
 # Check on dependency file changes
 if event != "tool:post" or not self._is_dep_file_change(data):
 return HookResult(action="continue")

 file_path = data.get("file_path", "")
 content = data.get("content", "")

 # Detect package manager
 pkg_manager = self._detect_package_manager(file_path)
 if not pkg_manager:
 return HookResult(action="continue")

 # Parse dependencies
 deps = await self._parse_dependencies(pkg_manager, content)

 # Check each dependency
 violations = []
 warnings = []
 approvals_needed = []

 for dep in deps:
 result = await self._check_dependency(dep, pkg_manager)

 if result.status == "prohibited":
 violations.append(result)
 elif result.status == "restricted":
 approvals_needed.append(result)
 elif result.status == "unknown":
 if self.config.policy.unknown_action == "deny":
 violations.append(result)
 else:
 warnings.append(result)

 # Handle results
 if violations:
 return self._deny_violations(violations)
 elif approvals_needed:
 return self._request_approval(approvals_needed)
 elif warnings:
 return self._warn_user(warnings)

 return HookResult(action="continue")

 def _is_dep_file_change(self, data: dict) -> bool:
 """Check if this is a dependency file change."""
 file_path = data.get("file_path", "")
 dep_files = [
 "package.json", "package-lock.json",
 "requirements.txt", "Pipfile", "pyproject.toml",
 "Cargo.toml", "Cargo.lock",
 "go.mod", "go.sum",
 "pom.xml", "build.gradle",
 "*.csproj", "packages.config"
 ]
 return any(
 file_path.endswith(f) or fnmatch.fnmatch(file_path, f)
 for f in dep_files
 )

 async def _check_dependency(
 self,
 dep: Dependency,
 pkg_manager: str
 ) -> LicenseCheckResult:
 """Check a single dependency's license."""

 # Check exceptions first
 if self._is_excepted(dep):
 return LicenseCheckResult(
 dependency=dep,
 status="allowed",
 reason="Exception configured"
 )

 # Get license info
 license_info = await self._get_license(dep, pkg_manager)

 if not license_info or license_info.license == "UNKNOWN":
 return LicenseCheckResult(
 dependency=dep,
 status="unknown",
 license=None,
 reason="Could not determine license"
 )

 # Check against policy
 license_id = self._normalize_license(license_info.license)

 if self.policy.is_prohibited(license_id):
 return LicenseCheckResult(
 dependency=dep,
 status="prohibited",
 license=license_id,
 reason=f"{license_id} is prohibited by policy"
 )

 if self.policy.is_restricted(license_id):
 return LicenseCheckResult(
 dependency=dep,
 status="restricted",
 license=license_id,
 reason=f"{license_id} requires approval"
 )

 if self.policy.is_allowed(license_id):
 return LicenseCheckResult(
 dependency=dep,
 status="allowed",
 license=license_id
 )

 # Not explicitly listed
 return LicenseCheckResult(
 dependency=dep,
 status="unknown",
 license=license_id,
 reason=f"License {license_id} not in policy"
 )

 async def _get_license(
 self,
 dep: Dependency,
 pkg_manager: str
 ) -> LicenseInfo | None:
 """Get license information for dependency."""
 scanner = self.scanners.get(pkg_manager)
 if not scanner:
 return None

 # Check cache first
 cache_key = f"{pkg_manager}:{dep.name}:{dep.version}"
 cached = self.license_db.get(cache_key)
 if cached:
 return cached

 # Fetch from registry
 license_info = await scanner.get_license(dep)

 # Cache result
 if license_info:
 self.license_db.set(cache_key, license_info)

 return license_info

class LicensePolicy:
 """Evaluate licenses against policy."""

 def __init__(self, config: dict):
 self.allowed = set(config.get("allowed", []))
 self.restricted = set(config.get("restricted", []))
 self.prohibited = set(config.get("prohibited", []))

 def is_allowed(self, license_id: str) -> bool:
 """Check if license is explicitly allowed."""
 return self._matches(license_id, self.allowed)

 def is_restricted(self, license_id: str) -> bool:
 """Check if license requires approval."""
 return self._matches(license_id, self.restricted)

 def is_prohibited(self, license_id: str) -> bool:
 """Check if license is prohibited."""
 return self._matches(license_id, self.prohibited)

 def _matches(self, license_id: str, patterns: set) -> bool:
 """Check if license matches any pattern."""
 for pattern in patterns:
 if pattern.endswith("*"):
 if license_id.startswith(pattern[:-1]):
 return True
 elif license_id == pattern:
 return True
 return False

class NpmLicenseScanner:
 """Scan npm packages for licenses."""

 async def get_license(self, dep: Dependency) -> LicenseInfo | None:
 """Get license from npm registry."""
 url = f"https://registry.npmjs.org/{dep.name}/{dep.version}"

 async with aiohttp.ClientSession() as session:
 async with session.get(url) as resp:
 if resp.status != 200:
 return None
 data = await resp.json()

 license_field = data.get("license")
 if isinstance(license_field, dict):
 license_field = license_field.get("type")

 return LicenseInfo(
 package=dep.name,
 version=dep.version,
 license=license_field or "UNKNOWN",
 source="npm-registry"
 )

 async def parse_dependencies(self, content: str) -> list[Dependency]:
 """Parse package.json for dependencies."""
 data = json.loads(content)
 deps = []

 for dep_type in ["dependencies", "devDependencies", "peerDependencies"]:
 if dep_type in data:
 for name, version in data[dep_type].items():
 deps.append(Dependency(
 name=name,
 version=self._resolve_version(version),
 dep_type=dep_type
 ))

 return deps

class PipLicenseScanner:
 """Scan Python packages for licenses."""

 async def get_license(self, dep: Dependency) -> LicenseInfo | None:
 """Get license from PyPI."""
 url = f"https://pypi.org/pypi/{dep.name}/{dep.version}/json"

 async with aiohttp.ClientSession() as session:
 async with session.get(url) as resp:
 if resp.status != 200:
 return None
 data = await resp.json()

 info = data.get("info", {})
 license_field = info.get("license") or self._extract_from_classifiers(
 info.get("classifiers", [])
 )

 return LicenseInfo(
 package=dep.name,
 version=dep.version,
 license=license_field or "UNKNOWN",
 source="pypi"
 )

 def _extract_from_classifiers(self, classifiers: list[str]) -> str | None:
 """Extract license from classifiers."""
 for classifier in classifiers:
 if classifier.startswith("License :: OSI Approved :: "):
 return classifier.split("::")[-1].strip()
 return None`
```

---

### License Categories

#### Permissive (Usually Safe)

 | 
 
 | License | SPDX ID | Notes

 | MIT | MIT | Most permissive
 
 | Apache 2.0 | Apache-2.0 | Patent grant
 
 | BSD 2-Clause | BSD-2-Clause | Minimal restrictions
 
 | BSD 3-Clause | BSD-3-Clause | No endorsement clause
 
 | ISC | ISC | Simplified MIT

#### Weak Copyleft (Caution)

 | 
 
 | License | SPDX ID | Notes

 | LGPL 2.1 | LGPL-2.1 | OK if dynamically linked
 
 | LGPL 3.0 | LGPL-3.0 | OK if dynamically linked
 
 | MPL 2.0 | MPL-2.0 | File-level copyleft
 
 | EPL 2.0 | EPL-2.0 | Module-level copyleft

#### Strong Copyleft (Usually Blocked)

 | 
 
 | License | SPDX ID | Notes

 | GPL 2.0 | GPL-2.0 | Viral copyleft
 
 | GPL 3.0 | GPL-3.0 | Viral copyleft
 
 | AGPL 3.0 | AGPL-3.0 | Network copyleft

#### Problematic

 | 
 
 | License | SPDX ID | Notes

 | SSPL | SSPL-1.0 | MongoDB license
 
 | BSL | BUSL-* | Time-delayed open source
 
 | CC BY-NC | CC-BY-NC-* | Non-commercial only
 
 | Proprietary | - | Requires explicit grant

---

### Examples

#### Example 1: GPL Dependency Blocked

 python
 Copy

`# User adds axios-gpl (fictional) to package.json

# Hook response:
HookResult(
 action="deny",
 reason="GPL-3.0 license prohibited",
 context_injection="""
â›” **License Violation: GPL-3.0**

Package: `axios-gpl@1.0.0`
License: GPL-3.0

**Why blocked:**
GPL-3.0 requires any derivative work to also be licensed under GPL.
Your project (MIT) cannot include GPL dependencies.

**Alternatives:**
- `axios` (MIT) - Same functionality, permissive license
- `node-fetch` (MIT) - Lighter alternative
"""
)`
```

#### Example 2: LGPL Requires Approval

 python
 Copy

`# User adds chart.js which uses LGPL dependency

# Hook asks:
HookResult(
 action="ask_user",
 approval_prompt="""
âš ï¸ **LGPL Dependency Detected**

`chart.js@4.0.0` â†’ `color@4.0.0` (LGPL-2.1)

LGPL is conditionally acceptable if:
âœ“ Used as dynamic library (not modified)
âœ“ License notice included
âœ“ Users can replace the library

Is this usage compliant?
""",
 approval_options=["Approve", "Reject", "Need legal review"]
)`
```

#### Example 3: Unknown License Warning

 python
 Copy

`# Package has no license field

# Hook warns:
HookResult(
 action="inject_context",
 context_injection="""
âš ï¸ **Unknown License Warning**

Package: `mystery-lib@0.5.0`
License: UNKNOWN

Could not determine license from:
- package.json
- LICENSE file
- npm registry

**Risk:** Without explicit license, code is "all rights reserved" by default.

**Recommendations:**
1. Check package repository for LICENSE file
2. Contact maintainer to add license
3. Find alternative with clear license
""",
 user_message="âš ï¸ Warning: mystery-lib has no license",
 user_message_level="warning"
)`
```

---

### Transitive Dependency Scanning

 python
 Copy

`async def scan_transitive(
 self,
 direct_deps: list[Dependency],
 pkg_manager: str
) -> list[TransitiveDep]:
 """Scan transitive dependencies."""

 if pkg_manager == "npm":
 # Use npm ls --json for full tree
 result = await asyncio.create_subprocess_exec(
 "npm", "ls", "--json", "--all",
 stdout=asyncio.subprocess.PIPE
 )
 stdout, _ = await result.communicate()
 tree = json.loads(stdout.decode())
 return self._parse_npm_tree(tree)

 elif pkg_manager == "pip":
 # Use pipdeptree
 result = await asyncio.create_subprocess_exec(
 "pipdeptree", "--json",
 stdout=asyncio.subprocess.PIPE
 )
 stdout, _ = await result.communicate()
 return self._parse_pip_tree(json.loads(stdout.decode()))

 # ... other package managers`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `policy.allowed` | list | [] | Allowed licenses
 
 | `policy.restricted` | list | [] | Licenses needing approval
 
 | `policy.prohibited` | list | [] | Blocked licenses
 
 | `policy.unknown_action` | string | "warn" | Action for unknown
 
 | `scope.scan_transitive` | bool | true | Check transitive deps
 
 | `scope.scan_dev_deps` | bool | false | Include devDependencies
 
 | `actions.on_prohibited` | string | "deny" | Action on prohibited

---

### Security Considerations

- Makes network calls to package registries
 
- Caches license data locally
 
- No sensitive data exposed
 
- Offline mode available with pre-populated cache
 
---

### Dependencies

#### Required

- `aiohttp` - HTTP client
 
- `spdx-tools` - License parsing (optional)
 
#### Optional

- Package manager CLIs for transitive scanning
 
---

### Open Questions

- SBOM generation: Should we generate Software Bill of Materials?
 
- License changes: Alert when dependency changes license?
 
- Legal integration: Connect to legal approval workflow?
 
- Dual licensing: How to handle dual-licensed packages?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Model Router
 hooks

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-hooks-model-router`

### Overview

Intelligent routing of LLM requests to appropriate models based on task complexity, cost optimization, latency requirements, and capabilities. Routes simple tasks to cheaper models while preserving quality for complex work.

#### Value Proposition

 | 
 
 | Without | With

 | All tasks use same expensive model | Smart routing saves 50-70% on costs
 
 | Simple tasks wait for slow models | Fast models for simple tasks
 
 | One-size-fits-all | Task-appropriate model selection

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-model-router
 config:
 # Available models with capabilities
 models:
 high_capability:
 provider: anthropic
 model: claude-3-opus
 capabilities: [reasoning, coding, analysis, creative]
 cost_per_1k: 0.015
 latency_ms: 2000

 balanced:
 provider: anthropic
 model: claude-3-sonnet
 capabilities: [reasoning, coding, analysis, creative]
 cost_per_1k: 0.003
 latency_ms: 1000

 fast:
 provider: anthropic
 model: claude-3-haiku
 capabilities: [simple, formatting, extraction]
 cost_per_1k: 0.00025
 latency_ms: 500

 code_specialized:
 provider: openai
 model: gpt-4-turbo
 capabilities: [coding, debugging]
 cost_per_1k: 0.01
 latency_ms: 1500

 # Routing rules
 routing:
 # Task-based routing
 tasks:
 simple_questions:
 patterns: ["what is", "define", "list", "when was"]
 route_to: fast

 code_generation:
 patterns: ["write.*function", "implement", "create.*class"]
 route_to: balanced

 complex_reasoning:
 patterns: ["analyze", "compare.*and.*contrast", "evaluate"]
 route_to: high_capability

 debugging:
 patterns: ["fix.*bug", "debug", "why.*error"]
 route_to: code_specialized

 # Token-based routing
 tokens:
 - max_input: 1000
 route_to: fast
 - max_input: 10000
 route_to: balanced
 - max_input: 100000
 route_to: high_capability

 # Override: always use specific model for certain contexts
 overrides:
 - context_contains: "IMPORTANT"
 route_to: high_capability
 - context_contains: "quick question"
 route_to: fast

 # Fallback behavior
 fallback:
 model: balanced
 on_error: retry_with_fallback

 # Logging
 log_routing_decisions: true`
```

#### HookResult

 python
 Copy

`# Route to different model
HookResult(
 action="modify",
 data={
 **original_data,
 "model": "claude-3-haiku",
 "provider_config": {"model": "claude-3-haiku-20240307"}
 },
 user_message="Routed to fast model (simple task)"
)`
```

---

### Architecture

 python
 Copy

`class ModelRouterHook:
 """Route requests to appropriate models."""

 def __init__(self, config: ModelRouterConfig):
 self.config = config
 self.models = {name: ModelInfo(**info) for name, info in config.models.items()}
 self.classifier = TaskClassifier(config.routing.tasks)

 async def __call__(self, event: str, data: dict) -> HookResult:
 if event != "provider:request":
 return HookResult(action="continue")

 # Determine best model
 selected_model = await self._route_request(data)

 # If no change needed, continue
 if selected_model is None or selected_model == data.get("model"):
 return HookResult(action="continue")

 # Modify request to use selected model
 model_info = self.models[selected_model]
 return HookResult(
 action="modify",
 data={
 **data,
 "model": model_info.model,
 "provider": model_info.provider,
 },
 user_message=f"Routed to {selected_model} model"
 )

 async def _route_request(self, data: dict) -> str | None:
 """Determine which model to use."""
 messages = data.get("messages", [])

 # Check overrides first
 for override in self.config.routing.overrides:
 if self._matches_override(messages, override):
 return override["route_to"]

 # Classify task
 last_message = messages[-1].get("content", "") if messages else ""
 task_type = self.classifier.classify(last_message)

 if task_type:
 task_config = self.config.routing.tasks.get(task_type)
 if task_config:
 return task_config["route_to"]

 # Token-based routing
 estimated_tokens = self._estimate_tokens(messages)
 for rule in self.config.routing.tokens:
 if estimated_tokens <= rule["max_input"]:
 return rule["route_to"]

 # Fallback
 return self.config.fallback.model

class TaskClassifier:
 """Classify tasks for routing."""

 def __init__(self, task_configs: dict):
 self.patterns = {}
 for task_name, config in task_configs.items():
 self.patterns[task_name] = [
 re.compile(p, re.IGNORECASE)
 for p in config["patterns"]
 ]

 def classify(self, text: str) -> str | None:
 """Classify text into task type."""
 scores = {}

 for task_name, patterns in self.patterns.items():
 score = sum(1 for p in patterns if p.search(text))
 if score > 0:
 scores[task_name] = score

 if scores:
 return max(scores, key=scores.get)
 return None`
```

---

### Routing Strategies

#### 1. Task-Based Routing

 | 
 
 | Task Type | Patterns | Model

 | Simple Q&A | "what is", "define", "when" | Haiku
 
 | Code generation | "write function", "implement" | Sonnet
 
 | Complex analysis | "analyze", "evaluate" | Opus
 
 | Debugging | "fix bug", "debug" | GPT-4

#### 2. Token-Based Routing

 | 
 
 | Input Size | Model | Rationale

 | | Haiku | Simple, short tasks
 
 | 1K - 10K | Sonnet | Medium complexity
 
 | 10K+ | Opus | Long context needs capability

#### 3. Capability-Based Routing

 python
 Copy

`# Route based on required capabilities
CAPABILITY_REQUIREMENTS = {
 "mathematical_reasoning": ["high_capability"],
 "code_review": ["balanced", "code_specialized"],
 "simple_extraction": ["fast"],
 "creative_writing": ["high_capability", "balanced"],
}`
```

---

### Examples

#### Example 1: Simple Question â†’ Fast Model

 python
 Copy

`# Input message: "What is the capital of France?"
# Classification: simple_questions
# Routing decision: fast (claude-3-haiku)

{
 "action": "modify",
 "data": {
 "model": "claude-3-haiku-20240307",
 "provider": "anthropic"
 },
 "user_message": "Routed to fast model (simple task)"
}`
```

#### Example 2: Complex Analysis â†’ High Capability

 python
 Copy

`# Input message: "Analyze the trade-offs between microservices and monolithic architectures for our e-commerce platform"
# Classification: complex_reasoning
# Routing decision: high_capability (claude-3-opus)

{
 "action": "modify",
 "data": {
 "model": "claude-3-opus-20240229",
 "provider": "anthropic"
 },
 "user_message": "Routed to high-capability model (complex analysis)"
}`
```

#### Example 3: Override Takes Priority

 python
 Copy

`# Input message: "IMPORTANT: Quick question - what time is it in Tokyo?"
# Override matched: "IMPORTANT" â†’ high_capability
# Despite being a simple question, override wins

{
 "action": "modify",
 "data": {
 "model": "claude-3-opus-20240229"
 },
 "user_message": "Routed to high-capability model (override: IMPORTANT)"
}`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `models.*` | dict | {} | Available models
 
 | `routing.tasks` | dict | {} | Task-based routing rules
 
 | `routing.tokens` | list | [] | Token-based routing rules
 
 | `routing.overrides` | list | [] | Override rules
 
 | `fallback.model` | string | - | Default model
 
 | `log_routing_decisions` | bool | true | Log decisions

---

### Cost Impact

Typical cost savings with intelligent routing:

 | 
 
 | Scenario | Without Routing | With Routing | Savings

 | 50% simple tasks | $100 | $35 | 65%
 
 | 30% code tasks | $100 | $55 | 45%
 
 | Mixed workload | $100 | $45 | 55%

---

### Security Considerations

- Routing decisions may affect output quality
 
- Override rules should be carefully configured
 
- Sensitive tasks should not be routed to less capable models
 
---

### Dependencies

#### Required

- `re` - Pattern matching (stdlib)
 
#### Optional

- None
 
---

### Open Questions

- Learning: Should routing learn from outcomes?
 
- User override: Allow users to force specific models?
 
- Quality monitoring: Track quality per routing decision?
 
- A/B testing: Compare routing strategies?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Pii Guardian
 hooks

Priority: P0 (Foundation)

Status: Draft

Module: `amplifier-module-hooks-pii-guardian`

### Overview

Detects and redacts personally identifiable information (PII) before it's sent to LLM providers. Protects user privacy and ensures compliance with GDPR, CCPA, and HIPAA regulations.

#### Value Proposition

 | 
 
 | Without | With

 | PII sent to external LLMs | PII redacted before transmission
 
 | Compliance violations | Privacy-by-design
 
 | Data breach risks | Sensitive data never leaves

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-pii-guardian
 config:
 # Detection categories
 detect:
 names: true # Person names
 emails: true # Email addresses
 phones: true # Phone numbers
 ssn: true # Social Security Numbers
 credit_cards: true # Credit card numbers
 addresses: true # Physical addresses
 dates_of_birth: true # Birth dates
 ip_addresses: true # IP addresses
 medical: true # Medical record numbers, conditions
 financial: true # Bank accounts, routing numbers

 # Action on detection
 action: redact # redact | block | warn

 # Redaction style
 redaction:
 style: placeholder # placeholder | hash | mask
 placeholder_format: "[{type}]" # e.g., "[EMAIL]", "[SSN]"

 # Exceptions
 allow:
 patterns:
 - "example@example.com"
 - "test@"
 contexts:
 - "test"
 - "example"
 - "sample"`
```

#### HookResult

 python
 Copy

`# Redact PII before sending to provider
HookResult(
 action="modify",
 data={
 "messages": [
 {
 "role": "user",
 "content": "Process payment for [NAME] at [EMAIL], card ending [CREDIT_CARD_LAST4]"
 }
 ]
 },
 user_message="Redacted 3 PII items before sending to LLM"
)`
```

---

### Architecture

 python
 Copy

`class PIIGuardianHook:
 """Detect and redact PII before LLM transmission."""

 def __init__(self, config: PIIGuardianConfig):
 self.config = config
 self.detectors = self._initialize_detectors()
 self.redactor = PIIRedactor(config.redaction)

 async def __call__(self, event: str, data: dict) -> HookResult:
 # Only process provider requests
 if event != "provider:request":
 return HookResult(action="continue")

 messages = data.get("messages", [])
 redacted_messages = []
 total_redactions = 0

 for message in messages:
 content = message.get("content", "")
 if isinstance(content, str):
 redacted_content, count = self._redact_pii(content)
 redacted_messages.append({**message, "content": redacted_content})
 total_redactions += count
 else:
 redacted_messages.append(message)

 if total_redactions > 0:
 return HookResult(
 action="modify",
 data={**data, "messages": redacted_messages},
 user_message=f"Redacted {total_redactions} PII items"
 )

 return HookResult(action="continue")

 def _redact_pii(self, text: str) -> tuple[str, int]:
 """Detect and redact PII from text."""
 findings = []

 for detector in self.detectors:
 findings.extend(detector.detect(text))

 # Sort by position (reverse) to redact from end to start
 findings.sort(key=lambda f: f.start, reverse=True)

 # Remove duplicates/overlaps
 findings = self._remove_overlaps(findings)

 # Apply redactions
 redacted = text
 for finding in findings:
 redacted = (
 redacted[:finding.start] +
 self.redactor.redact(finding) +
 redacted[finding.end:]
 )

 return redacted, len(findings)

class NameDetector:
 """Detect person names using NER or patterns."""

 def detect(self, text: str) -> list[PIIFinding]:
 findings = []

 # Use spaCy NER if available
 if self.nlp:
 doc = self.nlp(text)
 for ent in doc.ents:
 if ent.label_ == "PERSON":
 findings.append(PIIFinding(
 type="name",
 value=ent.text,
 start=ent.start_char,
 end=ent.end_char,
 confidence=0.9
 ))

 return findings

class EmailDetector:
 """Detect email addresses."""

 PATTERN = re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b')

 def detect(self, text: str) -> list[PIIFinding]:
 findings = []
 for match in self.PATTERN.finditer(text):
 findings.append(PIIFinding(
 type="email",
 value=match.group(),
 start=match.start(),
 end=match.end(),
 confidence=1.0
 ))
 return findings

class CreditCardDetector:
 """Detect credit card numbers."""

 PATTERNS = [
 re.compile(r'\b4[0-9]{12}(?:[0-9]{3})?\b'), # Visa
 re.compile(r'\b5[1-5][0-9]{14}\b'), # Mastercard
 re.compile(r'\b3[47][0-9]{13}\b'), # Amex
 re.compile(r'\b6(?:011|5[0-9]{2})[0-9]{12}\b'), # Discover
 ]

 def detect(self, text: str) -> list[PIIFinding]:
 findings = []
 for pattern in self.PATTERNS:
 for match in pattern.finditer(text):
 # Validate with Luhn algorithm
 if self._luhn_check(match.group()):
 findings.append(PIIFinding(
 type="credit_card",
 value=match.group(),
 start=match.start(),
 end=match.end(),
 confidence=1.0
 ))
 return findings

class PIIRedactor:
 """Apply redaction to PII findings."""

 def redact(self, finding: PIIFinding) -> str:
 if self.config.style == "placeholder":
 return self.config.placeholder_format.format(type=finding.type.upper())
 elif self.config.style == "hash":
 return hashlib.sha256(finding.value.encode()).hexdigest()[:8]
 elif self.config.style == "mask":
 return "*" * len(finding.value)
 return "[REDACTED]"`
```

---

### PII Categories

 | 
 
 | Category | Examples | Pattern Type

 | Names | "John Smith", "MarÃ­a GarcÃ­a" | NER
 
 | Emails | "user@domain.com" | Regex
 
 | Phones | "+1-555-123-4567", "(555) 123-4567" | Regex
 
 | SSN | "123-45-6789" | Regex + validation
 
 | Credit Cards | "4111111111111111" | Regex + Luhn
 
 | Addresses | "123 Main St, City, ST 12345" | NER + Regex
 
 | DOB | "01/15/1990", "January 15, 1990" | Regex
 
 | IP Addresses | "192.168.1.1", "2001:db8::1" | Regex
 
 | Medical | MRN, diagnoses | Pattern matching
 
 | Financial | Bank account, routing numbers | Regex + validation

---

### Examples

#### Example 1: Email and Name Redaction

 python
 Copy

`# Input message to LLM:
"Send confirmation to John Smith at john.smith@company.com"

# After redaction:
"Send confirmation to [NAME] at [EMAIL]"`
```

#### Example 2: Credit Card Redaction

 python
 Copy

`# Input:
"Process payment for card 4111111111111111"

# After redaction:
"Process payment for card [CREDIT_CARD]"`
```

#### Example 3: Medical Data Redaction

 python
 Copy

`# Input:
"Patient MRN 12345678 diagnosed with diabetes"

# After redaction:
"Patient [MEDICAL_ID] diagnosed with [MEDICAL_CONDITION]"`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `detect.*` | bool | true | Enable detection category
 
 | `action` | string | "redact" | redact, block, or warn
 
 | `redaction.style` | string | "placeholder" | How to redact
 
 | `redaction.placeholder_format` | string | "[{type}]" | Placeholder template
 
 | `allow.patterns` | list | [] | Patterns to skip
 
 | `allow.contexts` | list | [] | Contexts that allow PII

---

### Compliance Mapping

 | 
 
 | Regulation | PII Types | Hook Coverage

 | GDPR | Names, emails, addresses, IDs | Full
 
 | CCPA | Personal info, identifiers | Full
 
 | HIPAA | PHI (medical, SSN, etc.) | Full
 
 | PCI-DSS | Card numbers, CVV | Full

---

### Security Considerations

- Redaction happens BEFORE data leaves to LLM
 
- Original data never logged
 
- NER models run locally (no external calls)
 
- False negatives possible - defense in depth recommended
 
---

### Dependencies

#### Required

- `re` - Regex matching (stdlib)
 
#### Optional

- `spacy` - Named entity recognition for names/addresses
 
- `presidio` - Microsoft's PII detection library
 
---

### Open Questions

- Accuracy vs performance: Full NER vs regex-only?
 
- Reversibility: Should we support de-redaction for debugging?
 
- Custom PII types: Allow project-specific PII definitions?
 
- Confidence thresholds: Skip low-confidence detections?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Reviewer Suggester
 hooks

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-hooks-reviewer-suggester`

### Overview

Analyzes code changes and suggests optimal reviewers based on code ownership, expertise, availability, and review load balance. Helps ensure PRs get reviewed by the right people quickly.

#### Value Proposition

 | 
 
 | Without | With

 | Guessing who should review | Data-driven suggestions
 
 | Overloading same reviewers | Balanced review load
 
 | Missing domain experts | Expertise matching
 
 | Slow review assignment | Instant suggestions

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-reviewer-suggester
 config:
 # Data sources
 sources:
 git_blame: true # Use git blame for ownership
 codeowners: true # Use CODEOWNERS file
 review_history: true # Past review patterns
 org_chart: false # Optional: org structure

 # Suggestion criteria
 criteria:
 ownership_weight: 0.4 # How much ownership matters
 expertise_weight: 0.3 # Past changes to similar code
 availability_weight: 0.2 # Current review load
 recency_weight: 0.1 # Recent activity in area

 # Constraints
 constraints:
 min_reviewers: 1
 max_reviewers: 3
 avoid_author: true # Don't suggest PR author
 require_codeowner: true # At least one CODEOWNER
 max_pending_reviews: 5 # Skip overloaded reviewers

 # Integration
 integration:
 platform: github # github | gitlab | azure-devops
 auto_assign: false # Auto-assign or just suggest
 notify: true # Notify suggested reviewers

 # Trigger
 trigger_on:
 - pr_created
 - pr_updated
 - files_changed`
```

#### HookResult

 python
 Copy

`# Suggest reviewers
HookResult(
 action="inject_context",
 context_injection="""
**Suggested Reviewers for This Change**

Based on code ownership and expertise:

1. **@alice** (Score: 0.92)
 - Primary owner of `src/payments/` (CODEOWNERS)
 - 45 commits to payment module in past 6 months
 - Current review load: 2 pending PRs

2. **@bob** (Score: 0.78)
 - Frequent contributor to `src/api/`
 - Reviewed similar changes 12 times
 - Current review load: 3 pending PRs

3. **@carol** (Score: 0.65)
 - Secondary owner of `src/payments/gateway.py`
 - Domain expertise: payment gateways
 - Current review load: 1 pending PR

**Recommendation**: Assign @alice (required: CODEOWNER) + @bob (expertise)
""",
 user_message="Suggested reviewers: @alice, @bob, @carol",
 user_message_level="info"
)`
```

---

### Architecture

 python
 Copy

`class ReviewerSuggesterHook:
 """Suggest optimal code reviewers."""

 def __init__(self, config: ReviewerSuggesterConfig):
 self.config = config
 self.ownership_analyzer = OwnershipAnalyzer(config)
 self.load_balancer = ReviewLoadBalancer(config)
 self.scorer = ReviewerScorer(config.criteria)

 async def __call__(self, event: str, data: dict) -> HookResult:
 # Trigger on relevant events
 if not self._should_trigger(event, data):
 return HookResult(action="continue")

 # Get changed files
 changed_files = await self._get_changed_files(data)
 if not changed_files:
 return HookResult(action="continue")

 # Find candidate reviewers
 candidates = await self._find_candidates(changed_files, data)

 # Score and rank candidates
 scored = await self._score_candidates(candidates, changed_files)

 # Apply constraints
 suggestions = self._apply_constraints(scored, data)

 # Generate suggestion
 return self._generate_suggestion(suggestions, changed_files)

 async def _find_candidates(
 self,
 changed_files: list[str],
 data: dict
 ) -> list[ReviewerCandidate]:
 """Find potential reviewers from multiple sources."""
 candidates = {}

 # CODEOWNERS
 if self.config.sources.codeowners:
 codeowner_reviewers = await self.ownership_analyzer.from_codeowners(
 changed_files
 )
 for reviewer in codeowner_reviewers:
 candidates[reviewer.id] = reviewer
 candidates[reviewer.id].is_codeowner = True

 # Git blame
 if self.config.sources.git_blame:
 blame_reviewers = await self.ownership_analyzer.from_git_blame(
 changed_files
 )
 for reviewer in blame_reviewers:
 if reviewer.id in candidates:
 candidates[reviewer.id].ownership_score += reviewer.ownership_score
 else:
 candidates[reviewer.id] = reviewer

 # Review history
 if self.config.sources.review_history:
 history_reviewers = await self.ownership_analyzer.from_review_history(
 changed_files
 )
 for reviewer in history_reviewers:
 if reviewer.id in candidates:
 candidates[reviewer.id].expertise_score = reviewer.expertise_score
 else:
 candidates[reviewer.id] = reviewer

 return list(candidates.values())

 async def _score_candidates(
 self,
 candidates: list[ReviewerCandidate],
 changed_files: list[str]
 ) -> list[ScoredReviewer]:
 """Score candidates based on criteria."""
 scored = []

 for candidate in candidates:
 # Get current review load
 pending_reviews = await self.load_balancer.get_pending_count(
 candidate.id
 )

 # Calculate availability score (inverse of load)
 max_load = self.config.constraints.max_pending_reviews
 availability = 1.0 - (pending_reviews / max_load) if pending_reviews < max_load else 0

 # Calculate final score
 score = self.scorer.calculate(
 ownership=candidate.ownership_score,
 expertise=candidate.expertise_score,
 availability=availability,
 recency=candidate.recency_score
 )

 scored.append(ScoredReviewer(
 candidate=candidate,
 score=score,
 pending_reviews=pending_reviews,
 breakdown={
 "ownership": candidate.ownership_score,
 "expertise": candidate.expertise_score,
 "availability": availability,
 "recency": candidate.recency_score
 }
 ))

 # Sort by score descending
 return sorted(scored, key=lambda x: x.score, reverse=True)

 def _apply_constraints(
 self,
 scored: list[ScoredReviewer],
 data: dict
 ) -> list[ScoredReviewer]:
 """Apply constraints to suggestions."""
 filtered = []
 author = data.get("author")

 for reviewer in scored:
 # Skip author
 if self.config.constraints.avoid_author and reviewer.candidate.id == author:
 continue

 # Skip overloaded reviewers
 if reviewer.pending_reviews >= self.config.constraints.max_pending_reviews:
 continue

 filtered.append(reviewer)

 # Ensure we have required CODEOWNER
 if self.config.constraints.require_codeowner:
 has_codeowner = any(r.candidate.is_codeowner for r in filtered)
 if not has_codeowner:
 # Find first codeowner regardless of constraints
 for reviewer in scored:
 if reviewer.candidate.is_codeowner and reviewer.candidate.id != author:
 filtered.insert(0, reviewer)
 break

 # Limit to max reviewers
 return filtered[:self.config.constraints.max_reviewers]

class OwnershipAnalyzer:
 """Analyze code ownership from multiple sources."""

 async def from_codeowners(self, files: list[str]) -> list[ReviewerCandidate]:
 """Get owners from CODEOWNERS file."""
 codeowners_path = self._find_codeowners()
 if not codeowners_path:
 return []

 rules = self._parse_codeowners(codeowners_path)
 owners = set()

 for file in files:
 for pattern, file_owners in rules:
 if self._matches_pattern(file, pattern):
 owners.update(file_owners)

 return [
 ReviewerCandidate(id=owner, ownership_score=1.0, is_codeowner=True)
 for owner in owners
 ]

 async def from_git_blame(self, files: list[str]) -> list[ReviewerCandidate]:
 """Analyze git blame for ownership."""
 author_lines = defaultdict(int)
 total_lines = 0

 for file in files:
 blame = await self._run_git_blame(file)
 for line in blame:
 author_lines[line.author] += 1
 total_lines += 1

 return [
 ReviewerCandidate(
 id=author,
 ownership_score=lines / total_lines if total_lines > 0 else 0
 )
 for author, lines in author_lines.items()
 ]

 async def from_review_history(self, files: list[str]) -> list[ReviewerCandidate]:
 """Find reviewers who have reviewed similar files."""
 # Query past reviews touching these files
 past_reviews = await self._query_review_history(files)

 reviewer_counts = defaultdict(int)
 for review in past_reviews:
 reviewer_counts[review.reviewer] += 1

 max_reviews = max(reviewer_counts.values()) if reviewer_counts else 1
 return [
 ReviewerCandidate(
 id=reviewer,
 expertise_score=count / max_reviews
 )
 for reviewer, count in reviewer_counts.items()
 ]

class ReviewerScorer:
 """Calculate weighted reviewer scores."""

 def __init__(self, criteria: dict):
 self.ownership_weight = criteria.get("ownership_weight", 0.4)
 self.expertise_weight = criteria.get("expertise_weight", 0.3)
 self.availability_weight = criteria.get("availability_weight", 0.2)
 self.recency_weight = criteria.get("recency_weight", 0.1)

 def calculate(
 self,
 ownership: float,
 expertise: float,
 availability: float,
 recency: float
 ) -> float:
 """Calculate weighted score."""
 return (
 ownership * self.ownership_weight +
 expertise * self.expertise_weight +
 availability * self.availability_weight +
 recency * self.recency_weight
 )`
```

---

### Data Sources

#### CODEOWNERS Integration

 python
 Copy

`# Parse CODEOWNERS file
# .github/CODEOWNERS or CODEOWNERS

# Example CODEOWNERS:
# * @default-team
# /src/payments/ @alice @bob
# /src/api/ @api-team
# *.py @python-experts

def _parse_codeowners(path: str) -> list[tuple[str, list[str]]]:
 """Parse CODEOWNERS file into rules."""
 rules = []
 with open(path) as f:
 for line in f:
 line = line.strip()
 if not line or line.startswith("#"):
 continue
 parts = line.split()
 pattern = parts[0]
 owners = [p.lstrip("@") for p in parts[1:]]
 rules.append((pattern, owners))
 return rules`
```

#### Git Blame Analysis

 python
 Copy

`async def _run_git_blame(file: str) -> list[BlameLine]:
 """Run git blame and parse output."""
 proc = await asyncio.create_subprocess_exec(
 "git", "blame", "--line-porcelain", file,
 stdout=asyncio.subprocess.PIPE
 )
 stdout, _ = await proc.communicate()

 # Parse porcelain format
 lines = []
 current = {}
 for line in stdout.decode().split("\n"):
 if line.startswith("author "):
 current["author"] = line[7:]
 elif line.startswith("author-mail "):
 current["email"] = line[12:].strip("<>")
 elif line.startswith("\t"):
 # Content line - commit current
 if current:
 lines.append(BlameLine(**current))
 current = {}
 return lines`
```

#### Review History Query

 python
 Copy

`async def _query_review_history(files: list[str]) -> list[PastReview]:
 """Query GitHub/GitLab for past reviews."""
 # GitHub GraphQL query
 query = """
 query($files: [String!]!) {
 repository(owner: $owner, name: $repo) {
 pullRequests(first: 100, states: MERGED) {
 nodes {
 files(first: 100) {
 nodes { path }
 }
 reviews(first: 10) {
 nodes {
 author { login }
 state
 }
 }
 }
 }
 }
 }
 """
 # Filter for PRs touching these files
 # Return reviewers who approved`
```

---

### Examples

#### Example 1: New PR Created

 python
 Copy

`# PR created touching src/payments/gateway.py and src/api/routes.py

# Hook analyzes:
# - CODEOWNERS: @alice owns /src/payments/, @api-team owns /src/api/
# - Git blame: @bob has 60% of lines in gateway.py, @carol has 30%
# - Review history: @alice reviewed 15 PRs in payments, @dave reviewed 8

# Scoring:
# @alice: ownership=1.0, expertise=0.9, availability=0.8, recency=0.7 â†’ 0.91
# @bob: ownership=0.6, expertise=0.5, availability=1.0, recency=0.9 â†’ 0.71
# @api-team/member: ownership=0.5, expertise=0.3, availability=0.6 â†’ 0.44

# Result:
"""
Suggested Reviewers:
1. @alice (CODEOWNER) - Primary owner, high expertise
2. @bob - Significant contributor to gateway.py
"""`
```

#### Example 2: Load Balancing in Action

 python
 Copy

`# Normally @alice would be top suggestion, but she has 5 pending reviews

# Hook adjusts:
# @alice: availability=0.0 (at max load)
# Final score drops significantly

# Result suggests @bob instead:
"""
Suggested Reviewers:
1. @bob - Top available expert (Score: 0.78)
 Note: @alice (CODEOWNER) currently overloaded (5 pending reviews)
2. @carol - Secondary expert (Score: 0.65)
"""`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `sources.*` | bool | true | Data sources to use
 
 | `criteria.*_weight` | float | varies | Scoring weights
 
 | `constraints.min_reviewers` | int | 1 | Minimum suggestions
 
 | `constraints.max_reviewers` | int | 3 | Maximum suggestions
 
 | `constraints.max_pending_reviews` | int | 5 | Load threshold
 
 | `integration.auto_assign` | bool | false | Auto-assign reviewers

---

### Security Considerations

- Requires read access to git history
 
- May need API tokens for review history
 
- Respects repository visibility settings
 
- No sensitive code content exposed
 
---

### Dependencies

#### Required

- `gitpython` - Git operations
 
#### Optional

- `PyGithub` - GitHub API
 
- `python-gitlab` - GitLab API
 
---

### Open Questions

- Team rotation: Should we enforce reviewer rotation for knowledge sharing?
 
- Expertise decay: Should expertise scores decay over time?
 
- Cross-team reviews: Encourage reviews from outside the immediate team?
 
- Learning mode: Track suggestion accuracy and improve?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Secret Detector
 hooks

Priority: P0 (Foundation)

Status: Draft

Module: `amplifier-module-hooks-secret-detector`

### Overview

Specialized hook focused exclusively on secret detection. Lightweight, fast, and critical for preventing credential leaks. Runs on every file write with minimal overhead.

#### Value Proposition

 | 
 
 | Without | With

 | Secrets accidentally committed | Hard block before write
 
 | Security scanning is slow | Optimized for speed, runs on every write
 
 | Generic scanners miss secrets | Purpose-built for credential detection

#### Key Difference from hooks-security-scan

- hooks-secret-detector: Fast, focused, always-on for secret detection
 
- hooks-security-scan: Comprehensive but heavier SAST + secrets + dependencies
 
Use both together: secret-detector as first line of defense, security-scan for deeper analysis.

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-secret-detector
 config:
 # Always block secrets (no severity threshold)
 action: deny # deny | warn

 # Built-in pattern categories
 detect:
 aws: true
 gcp: true
 azure: true
 github: true
 openai: true
 stripe: true
 slack: true
 database: true
 private_keys: true
 generic_secrets: true

 # Custom patterns
 custom_patterns:
 - pattern: "COMPANY_API_[A-Z0-9]{32}"
 name: "Company Internal API Key"

 # Exclusions
 exclude:
 files:
 - "**/*.test.*"
 - "**/fixtures/**"
 - "**/mocks/**"
 patterns:
 - "test_api_key"
 - "example_"
 - "dummy_"
 - "fake_"

 # Allow specific files to contain secrets (use with extreme caution)
 allowed_files:
 - ".env.example" # Only example values`
```

#### HookResult

 python
 Copy

`# Always deny on secret detection
HookResult(
 action="deny",
 reason="""
ðŸš¨ SECRET DETECTED - File write blocked

**AWS Secret Access Key** found at line 15:`
```

aws_secret_access_key = "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"

 text
 Copy

`**How to fix:**
1. Remove the secret from your code
2. Use environment variables:
 ```python
 import os
 aws_secret = os.environ.get('AWS_SECRET_ACCESS_KEY')
 ```
3. If this was intentional test data, prefix with 'test_' or 'example_'

This secret pattern is commonly exploited within minutes of exposure.
"""
)`
```

---

### Architecture

 python
 Copy

`class SecretDetectorHook:
 """Lightweight, fast secret detection hook."""

 # Pre-compiled patterns for speed
 PATTERNS = {
 "aws_access_key": re.compile(r'AKIA[0-9A-Z]{16}'),
 "aws_secret_key": re.compile(r'(?i)aws_secret_access_key\s*[=:]\s*["\']?([A-Za-z0-9/+=]{40})["\']?'),
 "github_token": re.compile(r'ghp_[a-zA-Z0-9]{36}'),
 "github_oauth": re.compile(r'gho_[a-zA-Z0-9]{36}'),
 "openai_key": re.compile(r'sk-[a-zA-Z0-9]{48}'),
 "stripe_live": re.compile(r'sk_live_[a-zA-Z0-9]{24,}'),
 "stripe_test": re.compile(r'sk_test_[a-zA-Z0-9]{24,}'), # Still warn
 "slack_token": re.compile(r'xox[baprs]-[0-9a-zA-Z]{10,}'),
 "private_key": re.compile(r'-----BEGIN\s+(?:RSA\s+|EC\s+|DSA\s+)?PRIVATE\s+KEY-----'),
 "generic_api_key": re.compile(r'(?i)api[_-]?key\s*[=:]\s*["\']([a-zA-Z0-9]{20,})["\']'),
 "generic_secret": re.compile(r'(?i)(?:secret|password|passwd|pwd)\s*[=:]\s*["\']([^"\']{8,})["\']'),
 }

 def __init__(self, config: SecretDetectorConfig):
 self.config = config
 self.patterns = self._build_patterns()
 self.exclusion_patterns = [re.compile(p) for p in config.exclude.patterns]

 async def __call__(self, event: str, data: dict) -> HookResult:
 # Only process file writes
 if event != "tool:pre" or not self._is_file_write(data):
 return HookResult(action="continue")

 file_path = data.get("file_path", "")
 content = data.get("content", "")

 # Check if file is excluded
 if self._is_excluded_file(file_path):
 return HookResult(action="continue")

 # Scan for secrets
 secrets = self._detect_secrets(content, file_path)

 if not secrets:
 return HookResult(action="continue")

 # Block the write
 return HookResult(
 action="deny",
 reason=self._format_denial(secrets, file_path)
 )

 def _detect_secrets(self, content: str, file_path: str) -> list[DetectedSecret]:
 secrets = []
 lines = content.split('\n')

 for line_num, line in enumerate(lines, 1):
 for pattern_name, pattern in self.patterns.items():
 match = pattern.search(line)
 if match:
 # Check if excluded by pattern
 if self._is_excluded_value(match.group()):
 continue

 secrets.append(DetectedSecret(
 type=pattern_name,
 line_number=line_num,
 line_content=line.strip(),
 match=match.group()
 ))

 return secrets

 def _is_excluded_value(self, value: str) -> bool:
 """Check if the matched value is in exclusion list."""
 for pattern in self.exclusion_patterns:
 if pattern.search(value):
 return True
 return False

 def _format_denial(self, secrets: list[DetectedSecret], file_path: str) -> str:
 """Format denial message with actionable guidance."""
 lines = ["ðŸš¨ SECRET DETECTED - File write blocked\n"]

 for secret in secrets:
 lines.append(f"**{self._friendly_name(secret.type)}** at line {secret.line_number}:")
 # Mask most of the secret
 masked = self._mask_secret(secret.match)
 lines.append(f"```\n{masked}\n```\n")

 lines.append("**How to fix:**")
 lines.append("1. Remove the secret from your code")
 lines.append("2. Use environment variables instead")
 lines.append("3. If this is test data, prefix with 'test_' or 'example_'")

 return "\n".join(lines)

 def _mask_secret(self, secret: str) -> str:
 """Mask secret for display, showing only first/last few chars."""
 if len(secret) <= 8:
 return "*" * len(secret)
 return secret[:4] + "*" * (len(secret) - 8) + secret[-4:]`
```

---

### Secret Pattern Coverage

 | 
 
 | Category | Patterns | Examples

 | AWS | Access Key ID, Secret Key, Session Token | `AKIA...`, `aws_secret_access_key=...`
 
 | GCP | Service Account Key, API Key | `AIza...`, JSON key files
 
 | Azure | Storage Key, Connection String | `DefaultEndpointsProtocol=...`
 
 | GitHub | PAT, OAuth, App Token | `ghp_...`, `gho_...`, `ghs_...`
 
 | OpenAI | API Key | `sk-...`
 
 | Stripe | Live/Test Keys | `sk_live_...`, `rk_live_...`
 
 | Slack | Bot, User, App Tokens | `xoxb-...`, `xoxp-...`
 
 | Database | Connection Strings | `postgres://user:pass@...`
 
 | Private Keys | RSA, EC, DSA | `-----BEGIN PRIVATE KEY-----`
 
 | Generic | API keys, passwords, secrets | `api_key=...`, `password=...`

---

### Examples

#### Example 1: AWS Key Detection

 python
 Copy

`# Attempting to write:
# src/config.py containing:
# AWS_ACCESS_KEY = "AKIAIOSFODNN7EXAMPLE"

# Hook returns:
{
 "action": "deny",
 "reason": """
ðŸš¨ SECRET DETECTED - File write blocked

**AWS Access Key ID** at line 1:`
```

AKIA************MPLE

 text
 Copy

`**How to fix:**
1. Remove the secret from your code
2. Use environment variables instead:
 ```python
 import os
 AWS_ACCESS_KEY = os.environ.get('AWS_ACCESS_KEY_ID')
 ```
3. If this is test data, use AWS's documented example keys

AWS credentials are actively scanned on GitHub and can be exploited within minutes.
"""
}`
```

#### Example 2: Test Data Exclusion

 python
 Copy

`# Attempting to write:
# tests/fixtures/config.py containing:
# test_api_key = "test_sk_1234567890"

# Hook returns:
{
 "action": "continue"
}

# Allowed because:
# 1. File is in tests/fixtures/ (excluded path)
# 2. Value starts with "test_" (excluded pattern)`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `action` | string | "deny" | deny or warn
 
 | `detect.*` | bool | true | Enable specific pattern categories
 
 | `custom_patterns` | list | [] | Additional patterns to detect
 
 | `exclude.files` | list | [] | Glob patterns for files to skip
 
 | `exclude.patterns` | list | [] | Value patterns to ignore
 
 | `allowed_files` | list | [] | Files that may contain secrets

---

### Security Considerations

- Patterns must be kept updated as providers change formats
 
- False positives should be handled via exclusions, not disabled detection
 
- Masked output prevents exposure in logs
 
- `allowed_files` should be used very sparingly
 
---

### Dependencies

#### Required

- `re` - Regex matching (stdlib)
 
#### Optional

- None (intentionally minimal)
 
---

### Open Questions

- Pattern updates: How to distribute pattern updates?
 
- Entropy analysis: Add entropy-based detection for unknown patterns?
 
- Git integration: Also scan git history for past leaks?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Security Scan
 hooks

Priority: P0 (Foundation)

Status: Draft

Module: `amplifier-module-hooks-security-scan`

### Overview

Real-time security scanning of code as it's written. Detects vulnerabilities, secrets, and security anti-patterns before they're committed. Can block dangerous operations or inject warnings for the agent to address.

#### Value Proposition

 | 
 
 | Without | With

 | Security issues found in PR review | Caught immediately as code is written
 
 | Secrets committed accidentally | Blocked before file write
 
 | Security debt accumulates | Issues fixed in the same session

#### Trigger Events

 | 
 
 | Event | Action | Purpose

 | `tool:pre` (file write) | Scan content before write | Block if critical vulnerability
 
 | `tool:post` (file write) | Scan and report | Inject feedback for agent to fix
 
 | `session:start` | Scan existing codebase | Baseline security context

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-security-scan
 config:
 # Scan modes
 mode: block # block | warn | report
 severity_threshold: high # Block/warn at this level and above

 # Scanners to enable
 scanners:
 secrets: true # API keys, passwords, tokens
 sast: true # Static analysis (SQL injection, XSS, etc.)
 dependencies: true # Known vulnerable dependencies
 patterns: true # Custom anti-patterns

 # Secret detection
 secrets:
 patterns:
 - "aws_access_key_id"
 - "api[_-]?key"
 - "password\\s*=\\s*[\"'][^\"']+[\"']"
 - "-----BEGIN.*PRIVATE KEY-----"
 allow_patterns:
 - "test_api_key"
 - "example_password"

 # SAST rules
 sast:
 rules:
 - sql_injection
 - xss
 - path_traversal
 - command_injection
 - insecure_deserialization

 # Actions
 actions:
 critical:
 action: deny
 message: "Critical security vulnerability detected"
 high:
 action: inject_context
 message: "Security issue found - please fix"
 medium:
 action: inject_context
 suppress_output: true
 low:
 action: continue`
```

#### HookResult Actions

 python
 Copy

`# Block dangerous writes
HookResult(
 action="deny",
 reason="AWS credentials detected in file. Remove before saving."
)

# Inject feedback for agent to fix
HookResult(
 action="inject_context",
 context_injection="""
Security scan found issues in your code:

1. **SQL Injection (HIGH)** at line 42:
 ```python
 query = f"SELECT * FROM users WHERE id = {user_id}"
 ```
 Fix: Use parameterized queries

2. **Hardcoded secret (CRITICAL)** at line 15:
 ```python
 API_KEY = "sk_live_..."
 ```
 Fix: Use environment variable

Please fix these issues before proceeding.
""",
 user_message="Found 2 security issues",
 user_message_level="warning"
)`
```

---

### Architecture

#### Scanner Components

 python
 Copy

`class SecurityScanHook:
 """Real-time security scanning hook."""

 def __init__(self, config: SecurityScanConfig):
 self.config = config
 self.scanners = []

 if config.scanners.secrets:
 self.scanners.append(SecretScanner(config.secrets))
 if config.scanners.sast:
 self.scanners.append(SASTScanner(config.sast))
 if config.scanners.dependencies:
 self.scanners.append(DependencyScanner())
 if config.scanners.patterns:
 self.scanners.append(PatternScanner(config.patterns))

 async def __call__(self, event: str, data: dict) -> HookResult:
 if event == "tool:pre" and self._is_file_write(data):
 return await self._scan_before_write(data)

 if event == "tool:post" and self._is_file_write(data):
 return await self._scan_after_write(data)

 return HookResult(action="continue")

 async def _scan_before_write(self, data: dict) -> HookResult:
 content = data.get("content", "")
 file_path = data.get("file_path", "")

 findings = await self._scan(content, file_path)

 # Block critical issues
 critical = [f for f in findings if f.severity == "critical"]
 if critical and self.config.mode == "block":
 return HookResult(
 action="deny",
 reason=self._format_critical_findings(critical)
 )

 return HookResult(action="continue")

 async def _scan_after_write(self, data: dict) -> HookResult:
 content = data.get("content", "")
 file_path = data.get("file_path", "")

 findings = await self._scan(content, file_path)

 if not findings:
 return HookResult(action="continue")

 # Filter by threshold
 reportable = [f for f in findings
 if self._severity_meets_threshold(f.severity)]

 if not reportable:
 return HookResult(action="continue")

 return HookResult(
 action="inject_context",
 context_injection=self._format_findings(reportable),
 user_message=f"Security scan: {len(reportable)} issue(s) found",
 user_message_level="warning" if any(f.severity in ("high", "critical") for f in reportable) else "info"
 )

 async def _scan(self, content: str, file_path: str) -> list[Finding]:
 findings = []
 for scanner in self.scanners:
 scanner_findings = await scanner.scan(content, file_path)
 findings.extend(scanner_findings)
 return findings`
```

#### Secret Scanner

 python
 Copy

`class SecretScanner:
 """Detect secrets and credentials in code."""

 DEFAULT_PATTERNS = [
 # AWS
 (r'AKIA[0-9A-Z]{16}', 'AWS Access Key ID'),
 (r'aws_secret_access_key\s*=\s*["\'][^"\']+["\']', 'AWS Secret Key'),

 # Generic
 (r'api[_-]?key\s*[=:]\s*["\'][^"\']{10,}["\']', 'API Key'),
 (r'password\s*[=:]\s*["\'][^"\']+["\']', 'Hardcoded Password'),
 (r'secret\s*[=:]\s*["\'][^"\']{10,}["\']', 'Hardcoded Secret'),

 # Private keys
 (r'-----BEGIN\s+(?:RSA\s+)?PRIVATE\s+KEY-----', 'Private Key'),

 # Tokens
 (r'ghp_[a-zA-Z0-9]{36}', 'GitHub Personal Access Token'),
 (r'sk-[a-zA-Z0-9]{48}', 'OpenAI API Key'),
 (r'xox[baprs]-[0-9a-zA-Z]{10,}', 'Slack Token'),
 ]

 async def scan(self, content: str, file_path: str) -> list[Finding]:
 findings = []

 for pattern, name in self.patterns:
 matches = re.finditer(pattern, content, re.IGNORECASE)
 for match in matches:
 # Skip if in allow list
 if self._is_allowed(match.group(), file_path):
 continue

 line_num = content[:match.start()].count('\n') + 1
 findings.append(Finding(
 type="secret",
 severity="critical",
 title=f"{name} detected",
 location=f"{file_path}:{line_num}",
 code_snippet=self._get_snippet(content, match),
 recommendation="Remove secret and use environment variables"
 ))

 return findings`
```

#### SAST Scanner

 python
 Copy

`class SASTScanner:
 """Static Application Security Testing."""

 RULES = {
 "sql_injection": {
 "patterns": [
 r'execute\s*\(\s*["\'].*%s',
 r'execute\s*\(\s*f["\']',
 r'cursor\.execute\s*\(\s*["\'].*\+',
 ],
 "severity": "high",
 "message": "Potential SQL injection",
 "fix": "Use parameterized queries"
 },
 "xss": {
 "patterns": [
 r'innerHTML\s*=\s*[^"\'`]',
 r'document\.write\s*\(',
 r'dangerouslySetInnerHTML',
 ],
 "severity": "high",
 "message": "Potential XSS vulnerability",
 "fix": "Sanitize user input before rendering"
 },
 "command_injection": {
 "patterns": [
 r'os\.system\s*\(',
 r'subprocess\.\w+\s*\([^)]*shell\s*=\s*True',
 r'eval\s*\(',
 r'exec\s*\(',
 ],
 "severity": "critical",
 "message": "Potential command injection",
 "fix": "Avoid shell=True, sanitize inputs, use subprocess with list args"
 },
 "path_traversal": {
 "patterns": [
 r'open\s*\([^)]*\+',
 r'Path\s*\([^)]*\+',
 ],
 "severity": "high",
 "message": "Potential path traversal",
 "fix": "Validate and sanitize file paths"
 }
 }

 async def scan(self, content: str, file_path: str) -> list[Finding]:
 findings = []

 # Determine applicable rules based on file type
 applicable_rules = self._get_applicable_rules(file_path)

 for rule_name, rule in applicable_rules.items():
 for pattern in rule["patterns"]:
 matches = re.finditer(pattern, content)
 for match in matches:
 line_num = content[:match.start()].count('\n') + 1
 findings.append(Finding(
 type="sast",
 severity=rule["severity"],
 title=rule["message"],
 location=f"{file_path}:{line_num}",
 code_snippet=self._get_snippet(content, match),
 recommendation=rule["fix"]
 ))

 return findings`
```

---

### Examples

#### Example 1: Block Secret Commit

 python
 Copy

`# Event: tool:pre (Write file)
# Data: {"file_path": "src/config.py", "content": "API_KEY = 'sk_live_...'"}

# Hook returns:
{
 "action": "deny",
 "reason": """
Cannot write file: Critical security issue detected.

**OpenAI API Key detected** at line 1:`
```

API_KEY = 'sk_live_...'

 text
 Copy

`Remove the secret and use an environment variable instead:`
```

import os

API_KEY = os.environ.get('OPENAI_API_KEY')

 text
 Copy

`"""
}

# Result: File write is blocked, agent sees denial reason`
```

#### Example 2: Inject Fix Suggestions

 python
 Copy

`# Event: tool:post (Write file completed)
# Data: {"file_path": "src/db.py", "content": "...SQL with string formatting..."}

# Hook returns:
{
 "action": "inject_context",
 "context_injection": """
Security scan found issues in src/db.py:

**SQL Injection (HIGH)** at line 42:`
```

cursor.execute(f"SELECT * FROM users WHERE id = {user_id}")

 text
 Copy

`**Fix**: Use parameterized queries:`
```

cursor.execute("SELECT * FROM users WHERE id = %s", (user_id,))

 text
 Copy

`Please fix this issue.
""",
 "user_message": "Security: 1 high severity issue in src/db.py",
 "user_message_level": "warning"
}

# Result: Agent sees feedback, fixes the code in next turn`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `mode` | string | "warn" | block, warn, or report only
 
 | `severity_threshold` | string | "medium" | Minimum severity to act on
 
 | `scanners.secrets` | bool | true | Enable secret detection
 
 | `scanners.sast` | bool | true | Enable SAST scanning
 
 | `scanners.dependencies` | bool | false | Enable dependency scanning
 
 | `secrets.patterns` | list | (defaults) | Additional regex patterns
 
 | `secrets.allow_patterns` | list | [] | Patterns to ignore (e.g., test data)

---

### Security Considerations

- Scans may reveal sensitive patterns (handled carefully)
 
- Allow patterns should be restricted to test/example data
 
- SAST rules have false positive potential - tune per project
 
---

### Dependencies

#### Required

- `re` - Regex matching (stdlib)
 
#### Optional

- `semgrep` - Advanced SAST rules
 
- `bandit` - Python-specific security scanning
 
- `safety` - Dependency vulnerability scanning
 
---

### Open Questions

- SAST depth: Include tree-sitter parsing for more accurate analysis?
 
- Custom rules: Allow project-specific security rules?
 
- Remediation automation: Auto-fix simple issues?
 
- Integration: Connect to enterprise security tools?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Standup Logger
 hooks

Priority: P2 (Nice to Have)

Status: Draft

Module: `amplifier-module-hooks-standup-logger`

### Overview

Automatically captures work activity from AI sessions and generates concise standup summaries. Enables async standups by providing clear, structured updates of what was accomplished, in progress, and blocked.

#### Value Proposition

 | 
 
 | Without | With

 | Manual standup note-taking | Auto-generated summaries
 
 | Forgetting what you worked on | Complete activity capture
 
 | Inconsistent update formats | Structured, readable updates
 
 | Time spent writing updates | Focus on actual work

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-standup-logger
 config:
 # What to capture
 capture:
 file_changes: true # Files created/modified
 tool_usage: true # Tools invoked and results
 decisions: true # Key decisions made
 blockers: true # Issues encountered
 completions: true # Tasks completed

 # Summarization
 summary:
 format: structured # structured | narrative | bullet
 max_length: 500 # Max chars per summary
 include_metrics: true # Include time/token stats
 group_by: task # task | time | file

 # Storage
 storage:
 type: file # file | notion | slack | jira
 path: "~/.amplifier/standups/"
 daily_rollup: true # Combine sessions into daily log

 # Integration
 integration:
 auto_post: false # Auto-post to channel
 slack_channel: "#team-standups"
 schedule: "09:00" # When to post daily rollup

 # Privacy
 privacy:
 exclude_patterns: # Don't mention these files
 - "*.env"
 - "*secret*"
 anonymize_paths: false # Hash sensitive paths`
```

#### HookResult

 python
 Copy

`# At session end, generate summary
HookResult(
 action="inject_context",
 context_injection="", # No injection needed
 user_message="""
ðŸ“‹ Session Summary (45 min)

**Completed:**
- Fixed payment timeout bug in gateway.py
- Added retry logic with exponential backoff
- Updated tests (3 new test cases)

**In Progress:**
- Refactoring error handling in api/routes.py

**Files Changed:** 4 files, +127/-34 lines

Logged to: ~/.amplifier/standups/2024-01-15.md
""",
 user_message_level="info"
)`
```

---

### Architecture

 python
 Copy

`class StandupLoggerHook:
 """Capture and summarize work for standups."""

 CAPTURED_EVENTS = [
 "session:start",
 "session:end",
 "tool:post",
 "prompt:submit",
 "prompt:complete",
 ]

 def __init__(self, config: StandupLoggerConfig):
 self.config = config
 self.storage = StandupStorage(config.storage)
 self.summarizer = WorkSummarizer(config.summary)

 # Session activity tracking
 self.current_session: SessionActivity | None = None

 async def __call__(self, event: str, data: dict) -> HookResult:
 if event == "session:start":
 self._start_tracking(data)
 return HookResult(action="continue")

 if event == "session:end":
 return await self._finalize_session(data)

 if event in self.CAPTURED_EVENTS:
 self._track_activity(event, data)

 return HookResult(action="continue")

 def _start_tracking(self, data: dict) -> None:
 """Initialize session tracking."""
 self.current_session = SessionActivity(
 session_id=data.get("session_id"),
 start_time=datetime.utcnow(),
 activities=[],
 files_changed=set(),
 tools_used={},
 decisions=[],
 blockers=[]
 )

 def _track_activity(self, event: str, data: dict) -> None:
 """Track activity during session."""
 if not self.current_session:
 return

 if event == "tool:post":
 self._track_tool_usage(data)
 elif event == "prompt:submit":
 self._extract_intent(data)
 elif event == "prompt:complete":
 self._extract_outcomes(data)

 def _track_tool_usage(self, data: dict) -> None:
 """Track tool invocations."""
 tool = data.get("tool", "")

 # Track file changes
 if tool in ("filesystem:write", "filesystem:edit"):
 file_path = data.get("file_path", "")
 if not self._should_exclude(file_path):
 self.current_session.files_changed.add(file_path)
 self.current_session.activities.append(Activity(
 type="file_change",
 description=f"Modified {Path(file_path).name}",
 timestamp=datetime.utcnow(),
 metadata={"path": file_path, "operation": "write"}
 ))

 # Track tool usage counts
 tool_name = tool.split(":")[0] if ":" in tool else tool
 self.current_session.tools_used[tool_name] = (
 self.current_session.tools_used.get(tool_name, 0) + 1
 )

 def _extract_intent(self, data: dict) -> None:
 """Extract user intent from prompts."""
 prompt = data.get("prompt", "")

 # Look for task markers
 if any(marker in prompt.lower() for marker in ["fix", "bug", "error"]):
 self.current_session.activities.append(Activity(
 type="task_start",
 description=f"Working on: {self._summarize_prompt(prompt)}",
 timestamp=datetime.utcnow()
 ))

 def _extract_outcomes(self, data: dict) -> None:
 """Extract outcomes from responses."""
 response = data.get("response", "")

 # Look for completion indicators
 completion_patterns = [
 r"(fixed|resolved|completed|done|finished)",
 r"(implemented|added|created|updated)",
 ]

 for pattern in completion_patterns:
 if re.search(pattern, response.lower()):
 self.current_session.activities.append(Activity(
 type="completion",
 description=self._extract_completion(response),
 timestamp=datetime.utcnow()
 ))
 break

 # Look for blockers
 blocker_patterns = [
 r"(blocked|can't|unable to|need access|waiting for)",
 r"(error|failed|issue|problem)",
 ]

 for pattern in blocker_patterns:
 if re.search(pattern, response.lower()):
 self.current_session.blockers.append(
 self._extract_blocker(response)
 )
 break

 async def _finalize_session(self, data: dict) -> HookResult:
 """Generate and store session summary."""
 if not self.current_session:
 return HookResult(action="continue")

 self.current_session.end_time = datetime.utcnow()
 self.current_session.duration = (
 self.current_session.end_time - self.current_session.start_time
 )

 # Generate summary
 summary = await self.summarizer.summarize(self.current_session)

 # Store summary
 await self.storage.store(summary)

 # Reset tracking
 session = self.current_session
 self.current_session = None

 return HookResult(
 action="continue",
 user_message=self._format_user_message(summary),
 user_message_level="info"
 )

 def _format_user_message(self, summary: SessionSummary) -> str:
 """Format summary for user display."""
 duration = summary.duration.total_seconds() / 60

 msg = [f"ðŸ“‹ Session Summary ({duration:.0f} min)", ""]

 if summary.completed:
 msg.append("**Completed:**")
 for item in summary.completed[:5]:
 msg.append(f"- {item}")
 msg.append("")

 if summary.in_progress:
 msg.append("**In Progress:**")
 for item in summary.in_progress[:3]:
 msg.append(f"- {item}")
 msg.append("")

 if summary.blockers:
 msg.append("**Blockers:**")
 for item in summary.blockers[:3]:
 msg.append(f"- âš ï¸ {item}")
 msg.append("")

 if summary.files_changed:
 msg.append(f"**Files Changed:** {len(summary.files_changed)} files")

 return "\n".join(msg)

class WorkSummarizer:
 """Summarize session activity into standup format."""

 async def summarize(self, session: SessionActivity) -> SessionSummary:
 """Generate structured summary from activities."""

 # Group activities by type
 completions = [a for a in session.activities if a.type == "completion"]
 in_progress = [a for a in session.activities if a.type == "task_start"]

 # Deduplicate and clean
 completed_items = list(set(c.description for c in completions))
 in_progress_items = list(set(
 p.description for p in in_progress
 if p.description not in completed_items
 ))

 return SessionSummary(
 session_id=session.session_id,
 date=session.start_time.date(),
 duration=session.duration,
 completed=completed_items,
 in_progress=in_progress_items,
 blockers=session.blockers,
 files_changed=list(session.files_changed),
 tools_used=session.tools_used,
 metrics=SessionMetrics(
 duration_minutes=session.duration.total_seconds() / 60,
 files_changed=len(session.files_changed),
 tool_calls=sum(session.tools_used.values())
 )
 )

class StandupStorage:
 """Store standup summaries."""

 async def store(self, summary: SessionSummary) -> None:
 """Store summary to configured backend."""
 if self.config.type == "file":
 await self._store_file(summary)
 elif self.config.type == "notion":
 await self._store_notion(summary)
 elif self.config.type == "slack":
 await self._post_slack(summary)

 async def _store_file(self, summary: SessionSummary) -> None:
 """Store as markdown file."""
 date_str = summary.date.isoformat()
 path = Path(self.config.path).expanduser() / f"{date_str}.md"

 # Append to daily file
 content = self._format_markdown(summary)

 async with aiofiles.open(path, "a") as f:
 await f.write(content + "\n\n---\n\n")

 def _format_markdown(self, summary: SessionSummary) -> str:
 """Format summary as markdown."""
 lines = [
 f"## Session: {summary.session_id[:8]}",
 f"**Time:** {summary.duration.total_seconds() / 60:.0f} minutes",
 "",
 ]

 if summary.completed:
 lines.append("### Completed")
 for item in summary.completed:
 lines.append(f"- {item}")
 lines.append("")

 if summary.in_progress:
 lines.append("### In Progress")
 for item in summary.in_progress:
 lines.append(f"- {item}")
 lines.append("")

 if summary.blockers:
 lines.append("### Blockers")
 for item in summary.blockers:
 lines.append(f"- âš ï¸ {item}")
 lines.append("")

 if summary.files_changed:
 lines.append("### Files Changed")
 for f in summary.files_changed[:10]:
 lines.append(f"- `{f}`")

 return "\n".join(lines)

 async def get_daily_rollup(self, date: date) -> list[SessionSummary]:
 """Get all summaries for a date."""
 path = Path(self.config.path).expanduser() / f"{date.isoformat()}.md"
 if not path.exists():
 return []
 # Parse and return summaries
 ...`
```

---

### Summary Formats

#### Structured Format (Default)

 markdown
 Copy

`## Session: abc123
**Time:** 45 minutes

### Completed
- Fixed payment timeout bug in gateway.py
- Added retry logic with exponential backoff
- Updated tests (3 new test cases)

### In Progress
- Refactoring error handling

### Files Changed
- `src/payments/gateway.py`
- `src/payments/retry.py`
- `tests/test_gateway.py``
```

#### Narrative Format

 markdown
 Copy

`## Session Summary

Spent 45 minutes working on the payment timeout bug. Fixed the issue
by adding exponential backoff retry logic to the gateway. Added 3 new
test cases to cover the retry scenarios. Started refactoring the error
handling in the API routes but didn't complete it.

Changed 3 files in the payments module.`
```

#### Bullet Format

 markdown
 Copy

`- [45 min] Payment timeout bug
 - âœ… Fixed gateway.py timeout
 - âœ… Added retry logic
 - âœ… Added tests
 - ðŸ”„ Error handling refactor (in progress)`
```

---

### Daily Rollup

 python
 Copy

`class DailyRollupGenerator:
 """Generate daily standup from session summaries."""

 async def generate(self, date: date) -> DailyRollup:
 """Combine session summaries into daily rollup."""
 summaries = await self.storage.get_daily_rollup(date)

 all_completed = []
 all_in_progress = []
 all_blockers = []
 all_files = set()
 total_duration = timedelta()

 for summary in summaries:
 all_completed.extend(summary.completed)
 all_in_progress.extend(summary.in_progress)
 all_blockers.extend(summary.blockers)
 all_files.update(summary.files_changed)
 total_duration += summary.duration

 # Remove duplicates, prioritize completions
 in_progress_final = [
 item for item in set(all_in_progress)
 if item not in all_completed
 ]

 return DailyRollup(
 date=date,
 sessions=len(summaries),
 total_duration=total_duration,
 completed=list(set(all_completed)),
 in_progress=in_progress_final,
 blockers=list(set(all_blockers)),
 files_changed=list(all_files)
 )`
```

---

### Examples

#### Example 1: Bug Fix Session

 python
 Copy

`# Session activities:
# 1. User: "Fix the payment timeout bug"
# 2. Read files, found issue
# 3. Modified gateway.py
# 4. Added retry logic
# 5. Ran tests, fixed failures
# 6. Session end

# Generated summary:
"""
ðŸ“‹ Session Summary (32 min)

**Completed:**
- Fixed payment timeout bug in gateway.py
- Implemented exponential backoff retry
- Added 3 test cases for retry scenarios

**Files Changed:** 3 files
- src/payments/gateway.py
- src/payments/retry.py
- tests/test_gateway.py

Logged to: ~/.amplifier/standups/2024-01-15.md
"""`
```

#### Example 2: Session with Blockers

 python
 Copy

`# Session had issues:

# Generated summary:
"""
ðŸ“‹ Session Summary (25 min)

**In Progress:**
- Updating database schema for user profiles

**Blockers:**
- âš ï¸ Need DBA approval for migration
- âš ï¸ Missing access to production database

**Files Changed:** 1 file
- migrations/0042_user_profile.py

Logged to: ~/.amplifier/standups/2024-01-15.md
"""`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `capture.*` | bool | true | What to capture
 
 | `summary.format` | string | "structured" | Summary format
 
 | `summary.max_length` | int | 500 | Max summary length
 
 | `storage.type` | string | "file" | Storage backend
 
 | `storage.daily_rollup` | bool | true | Combine into daily
 
 | `integration.auto_post` | bool | false | Auto-post to Slack

---

### Security Considerations

- Excludes sensitive file patterns by default
 
- Can anonymize paths if needed
 
- No code content stored, only summaries
 
- Local storage by default
 
---

### Dependencies

#### Required

- `aiofiles` - File operations
 
#### Optional

- `slack_sdk` - Slack integration
 
- `notion-client` - Notion integration
 
---

### Open Questions

- AI summarization: Use LLM to generate better summaries?
 
- Team aggregation: Combine team standups into digest?
 
- Metrics tracking: Track productivity trends over time?
 
- Smart grouping: Better task grouping algorithms?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Style Enforcer
 hooks

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-hooks-style-enforcer`

### Overview

Automatically runs linters and formatters on code as it's written, injecting feedback for the agent to fix issues immediately. Ensures all generated code meets team style standards without manual intervention.

#### Value Proposition

 | 
 
 | Without | With

 | Linting issues found in CI | Fixed during generation
 
 | Style debates in PR reviews | Automated enforcement
 
 | Inconsistent code style | Consistent from creation

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-style-enforcer
 config:
 # Linters by language
 linters:
 python:
 enabled: true
 tools:
 - name: ruff
 command: "ruff check --fix {file}"
 auto_fix: true
 - name: black
 command: "black --check {file}"
 auto_fix_command: "black {file}"
 - name: mypy
 command: "mypy {file}"
 auto_fix: false

 typescript:
 enabled: true
 tools:
 - name: eslint
 command: "eslint {file}"
 auto_fix_command: "eslint --fix {file}"
 - name: prettier
 command: "prettier --check {file}"
 auto_fix_command: "prettier --write {file}"

 go:
 enabled: true
 tools:
 - name: gofmt
 command: "gofmt -l {file}"
 auto_fix_command: "gofmt -w {file}"
 - name: golint
 command: "golint {file}"

 # Behavior
 behavior:
 run_on: post # pre | post (after file write)
 auto_fix: true # Auto-apply fixes when possible
 inject_feedback: true # Tell agent about remaining issues
 fail_on_error: false # Don't block writes on lint errors

 # Feedback settings
 feedback:
 max_issues: 10 # Limit issues in feedback
 include_suggestions: true # Include fix suggestions
 severity_threshold: warning # error | warning | info`
```

#### HookResult Actions

 python
 Copy

`# After auto-fixing, inject remaining issues
HookResult(
 action="inject_context",
 context_injection="""
Style check results for src/payments/gateway.py:

**Auto-fixed:**
- Formatted with black
- Fixed 3 ruff issues (unused imports, line length)

**Remaining issues (please fix):**
1. Line 42: mypy error: Argument 1 to "process" has incompatible type "str"; expected "int"
2. Line 67: mypy error: Missing return statement

Please address the type errors above.
""",
 user_message="Style: auto-fixed 4 issues, 2 type errors need attention",
 user_message_level="warning"
)`
```

---

### Architecture

 python
 Copy

`class StyleEnforcerHook:
 """Enforce code style with linters and formatters."""

 def __init__(self, config: StyleEnforcerConfig):
 self.config = config
 self.linters = self._initialize_linters()

 async def __call__(self, event: str, data: dict) -> HookResult:
 # Only process file writes
 if event != "tool:post" or not self._is_code_write(data):
 return HookResult(action="continue")

 file_path = data.get("file_path", "")
 language = self._detect_language(file_path)

 if not language or language not in self.config.linters:
 return HookResult(action="continue")

 # Run linters
 results = await self._run_linters(file_path, language)

 # Auto-fix if configured
 auto_fixed = []
 if self.config.behavior.auto_fix:
 auto_fixed = await self._apply_auto_fixes(file_path, language)

 # Collect remaining issues
 remaining = [r for r in results if not r.auto_fixed]

 # Filter by severity
 remaining = self._filter_by_severity(remaining)

 # Generate feedback
 if auto_fixed or remaining:
 return self._generate_feedback(file_path, auto_fixed, remaining)

 return HookResult(action="continue")

 async def _run_linters(self, file_path: str, language: str) -> list[LintResult]:
 """Run all configured linters for language."""
 results = []
 linter_config = self.config.linters[language]

 for tool in linter_config.tools:
 command = tool.command.format(file=file_path)
 try:
 proc = await asyncio.create_subprocess_shell(
 command,
 stdout=asyncio.subprocess.PIPE,
 stderr=asyncio.subprocess.PIPE
 )
 stdout, stderr = await proc.communicate()

 if proc.returncode != 0:
 issues = self._parse_output(tool.name, stdout.decode(), stderr.decode())
 results.extend(issues)
 except Exception as e:
 # Log but don't fail on linter errors
 pass

 return results

 async def _apply_auto_fixes(self, file_path: str, language: str) -> list[str]:
 """Apply auto-fixes from formatters."""
 fixed = []
 linter_config = self.config.linters[language]

 for tool in linter_config.tools:
 if tool.auto_fix and tool.auto_fix_command:
 command = tool.auto_fix_command.format(file=file_path)
 try:
 proc = await asyncio.create_subprocess_shell(command)
 await proc.wait()
 if proc.returncode == 0:
 fixed.append(tool.name)
 except Exception:
 pass

 return fixed

 def _generate_feedback(
 self,
 file_path: str,
 auto_fixed: list[str],
 remaining: list[LintResult]
 ) -> HookResult:
 """Generate feedback for agent."""
 lines = [f"Style check results for {file_path}:", ""]

 if auto_fixed:
 lines.append("**Auto-fixed:**")
 for tool in auto_fixed:
 lines.append(f"- Applied {tool}")
 lines.append("")

 if remaining:
 lines.append(f"**Remaining issues ({len(remaining)}):**")
 for i, issue in enumerate(remaining[:self.config.feedback.max_issues], 1):
 lines.append(f"{i}. Line {issue.line}: {issue.tool}: {issue.message}")
 if self.config.feedback.include_suggestions and issue.suggestion:
 lines.append(f" Suggestion: {issue.suggestion}")
 lines.append("")
 lines.append("Please fix these issues.")

 severity = "warning" if any(r.severity == "error" for r in remaining) else "info"

 return HookResult(
 action="inject_context",
 context_injection="\n".join(lines),
 user_message=f"Style: {len(auto_fixed)} auto-fixed, {len(remaining)} need attention",
 user_message_level=severity
 )

 def _parse_output(self, tool: str, stdout: str, stderr: str) -> list[LintResult]:
 """Parse linter output into structured results."""
 # Each linter has different output format
 parsers = {
 "ruff": self._parse_ruff,
 "black": self._parse_black,
 "mypy": self._parse_mypy,
 "eslint": self._parse_eslint,
 "prettier": self._parse_prettier,
 }

 parser = parsers.get(tool, self._parse_generic)
 return parser(stdout, stderr)

 def _parse_ruff(self, stdout: str, stderr: str) -> list[LintResult]:
 """Parse ruff output."""
 results = []
 for line in stdout.split("\n"):
 # Format: file.py:10:5: E501 Line too long
 match = re.match(r".*:(\d+):\d+: (\w+) (.+)", line)
 if match:
 results.append(LintResult(
 tool="ruff",
 line=int(match.group(1)),
 code=match.group(2),
 message=match.group(3),
 severity="warning",
 auto_fixable=match.group(2) not in ["E999"] # Syntax errors not auto-fixable
 ))
 return results`
```

---

### Supported Linters

 | 
 
 | Language | Tool | Auto-fix | Purpose

 | Python | ruff | Yes | Fast linter (replaces flake8, isort)
 
 | Python | black | Yes | Code formatter
 
 | Python | mypy | No | Type checker
 
 | TypeScript | eslint | Yes | Linter
 
 | TypeScript | prettier | Yes | Formatter
 
 | Go | gofmt | Yes | Formatter
 
 | Go | golint | No | Linter
 
 | Rust | rustfmt | Yes | Formatter
 
 | Rust | clippy | Partial | Linter

---

### Examples

#### Example 1: Python Auto-Fix + Type Errors

 python
 Copy

`# Agent writes file with style issues and type errors
# Hook runs ruff, black, mypy

# After auto-fix:
"""
Style check results for src/calculator.py:

**Auto-fixed:**
- Applied black (formatting)
- Applied ruff (removed unused import, fixed line length)

**Remaining issues (2):**
1. Line 15: mypy: Argument "x" to "add" has incompatible type "str"; expected "int"
2. Line 23: mypy: Missing return type annotation for function "calculate"

Please fix these type errors.
"""

# Agent addresses type errors in next turn`
```

#### Example 2: All Issues Auto-Fixed

 python
 Copy

`# Only formatting issues, all auto-fixable

{
 "action": "inject_context",
 "context_injection": """
Style check results for src/utils.py:

**Auto-fixed:**
- Applied prettier (formatting)
- Applied eslint (3 issues fixed)

All issues resolved automatically.
""",
 "user_message": "Style: auto-fixed 4 issues",
 "user_message_level": "info"
}`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `linters..enabled` | bool | true | Enable for language
 
 | `linters..tools` | list | [] | Tools to run
 
 | `behavior.run_on` | string | "post" | When to run
 
 | `behavior.auto_fix` | bool | true | Auto-apply fixes
 
 | `behavior.inject_feedback` | bool | true | Inject remaining issues
 
 | `feedback.max_issues` | int | 10 | Max issues to show
 
 | `feedback.severity_threshold` | string | "warning" | Min severity

---

### Security Considerations

- Linters execute on written files (code execution risk minimal)
 
- Auto-fix modifies files (intended behavior)
 
- Tool commands should be hardcoded, not user-configurable
 
---

### Dependencies

#### Required

- Language-specific linters installed in environment
 
#### Optional

- None (linters are external tools)
 
---

### Open Questions

- Linter conflicts: What if black and ruff disagree?
 
- Performance: Skip linting for large files?
 
- Custom rules: Support project-specific lint configs?
 
- Pre vs post: Should we lint before write to prevent bad code?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Ticket Linker
 hooks

Priority: P0 (Foundation)

Status: Draft

Module: `amplifier-module-hooks-ticket-linker`

### Overview

Automatically loads JIRA/GitHub issue context based on the current git branch. Injects ticket information into the agent's context at session start, ensuring work is always connected to its tracking ticket.

#### Value Proposition

 | 
 
 | Without | With

 | Manually look up ticket for context | Automatic context from branch name
 
 | Forget to link work to tickets | Always-on ticket awareness
 
 | Context switching to find requirements | Requirements injected at session start
 
 | "What was I working on?" | Full ticket context on resume

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-ticket-linker
 config:
 # Ticket systems
 jira:
 enabled: true
 base_url: "${JIRA_URL}"
 auth_token: "${JIRA_TOKEN}"
 project_keys: ["PROJ", "PLATFORM", "SEC"]

 github:
 enabled: true
 auth_token: "${GITHUB_TOKEN}"

 # Branch patterns to extract ticket
 branch_patterns:
 - "^(?P<key>[A-Z]+-\\d+)" # PROJ-123-description
 - "^feature/(?P<key>[A-Z]+-\\d+)" # feature/PROJ-123-description
 - "^fix/(?P<key>[A-Z]+-\\d+)" # fix/PROJ-123-description
 - "^(?P<key>\\d+)-" # 123-description (GitHub issue)

 # What to include in context
 include:
 summary: true
 description: true
 acceptance_criteria: true
 comments: false # Can be verbose
 linked_issues: true
 status: true
 assignee: true

 # Context injection
 context:
 role: system # system | user
 max_length: 2000 # Truncate if too long`
```

#### HookResult

 python
 Copy

`# At session:start, inject ticket context
HookResult(
 action="inject_context",
 context_injection="""
## Current Work Context

**Ticket**: PROJ-456 - Add retry logic to payment gateway
**Status**: In Progress
**Assignee**: alice

### Description
Implement exponential backoff retry for payment API calls to handle gateway timeouts during peak load.

### Acceptance Criteria
- [ ] Retry up to 3 times with exponential backoff
- [ ] Log each retry attempt
- [ ] Add circuit breaker for repeated failures
- [ ] Update metrics dashboard

### Related Issues
- PROJ-400: Payment gateway timeout errors (parent)
- PROJ-455: Add payment metrics dashboard
""",
 context_injection_role="system",
 suppress_output=True,
 user_message="Loaded context for PROJ-456"
)`
```

---

### Architecture

 python
 Copy

`class TicketLinkerHook:
 """Auto-load ticket context at session start."""

 def __init__(self, config: TicketLinkerConfig):
 self.config = config
 self.jira = JiraClient(config.jira) if config.jira.enabled else None
 self.github = GitHubClient(config.github) if config.github.enabled else None
 self.patterns = [re.compile(p) for p in config.branch_patterns]

 async def __call__(self, event: str, data: dict) -> HookResult:
 if event != "session:start":
 return HookResult(action="continue")

 # Get current branch
 branch = await self._get_current_branch()
 if not branch:
 return HookResult(action="continue")

 # Extract ticket key from branch name
 ticket_key = self._extract_ticket_key(branch)
 if not ticket_key:
 return HookResult(action="continue")

 # Fetch ticket details
 ticket = await self._fetch_ticket(ticket_key)
 if not ticket:
 return HookResult(
 action="continue",
 user_message=f"Could not load ticket {ticket_key}"
 )

 # Format context
 context = self._format_context(ticket)

 return HookResult(
 action="inject_context",
 context_injection=context,
 context_injection_role=self.config.context.role,
 suppress_output=True,
 user_message=f"Loaded context for {ticket_key}: {ticket.summary[:50]}..."
 )

 def _extract_ticket_key(self, branch: str) -> str | None:
 """Extract ticket key from branch name using patterns."""
 for pattern in self.patterns:
 match = pattern.search(branch)
 if match:
 return match.group("key")
 return None

 async def _fetch_ticket(self, key: str) -> Ticket | None:
 """Fetch ticket from appropriate system."""
 # Try JIRA first (if key looks like JIRA format)
 if self.jira and re.match(r'[A-Z]+-\d+', key):
 try:
 return await self.jira.get_issue(key)
 except Exception:
 pass

 # Try GitHub (if numeric)
 if self.github and key.isdigit():
 try:
 return await self.github.get_issue(int(key))
 except Exception:
 pass

 return None

 def _format_context(self, ticket: Ticket) -> str:
 """Format ticket as context string."""
 lines = [
 "## Current Work Context",
 "",
 f"**Ticket**: {ticket.key} - {ticket.summary}",
 f"**Status**: {ticket.status}",
 ]

 if self.config.include.assignee and ticket.assignee:
 lines.append(f"**Assignee**: {ticket.assignee}")

 if self.config.include.description and ticket.description:
 lines.extend(["", "### Description", ticket.description])

 if self.config.include.acceptance_criteria and ticket.acceptance_criteria:
 lines.extend(["", "### Acceptance Criteria"])
 for criterion in ticket.acceptance_criteria:
 status = "x" if criterion.done else " "
 lines.append(f"- [{status}] {criterion.text}")

 if self.config.include.linked_issues and ticket.linked_issues:
 lines.extend(["", "### Related Issues"])
 for linked in ticket.linked_issues:
 lines.append(f"- {linked.key}: {linked.summary} ({linked.relationship})")

 # Truncate if too long
 context = "\n".join(lines)
 if len(context) > self.config.context.max_length:
 context = context[:self.config.context.max_length] + "\n\n[Truncated]"

 return context`
```

---

### Branch Pattern Examples

 | 
 
 | Branch Name | Pattern | Extracted Key

 | `PROJ-123-add-retry` | `^(?P[A-Z]+-\\d+)` | PROJ-123
 
 | `feature/PROJ-456-new-ui` | `^feature/(?P[A-Z]+-\\d+)` | PROJ-456
 
 | `fix/SEC-789-xss-patch` | `^fix/(?P[A-Z]+-\\d+)` | SEC-789
 
 | `123-github-issue` | `^(?P\\d+)-` | 123
 
 | `bugfix/PLATFORM-100` | `^bugfix/(?P[A-Z]+-\\d+)` | PLATFORM-100

---

### Examples

#### Example 1: JIRA Ticket Context

 python
 Copy

`# Session starts on branch: feature/PROJ-456-payment-retry

# Hook fetches JIRA ticket and returns:
{
 "action": "inject_context",
 "context_injection": """
## Current Work Context

**Ticket**: PROJ-456 - Add retry logic to payment gateway
**Status**: In Progress
**Assignee**: alice

### Description
Implement exponential backoff retry for payment API calls to handle gateway timeouts during peak load. This addresses the 5% payment failure rate observed during Black Friday.

### Acceptance Criteria
- [ ] Retry up to 3 times with exponential backoff
- [ ] Log each retry attempt with correlation ID
- [ ] Add circuit breaker for repeated failures
- [ ] Update Grafana dashboard with retry metrics
- [ ] Add unit tests for retry logic

### Related Issues
- PROJ-400: Payment gateway timeout errors (parent epic)
- PROJ-455: Add payment metrics dashboard (blocks)
""",
 "context_injection_role": "system",
 "suppress_output": true,
 "user_message": "Loaded context for PROJ-456: Add retry logic to payment gateway"
}`
```

#### Example 2: GitHub Issue Context

 python
 Copy

`# Session starts on branch: 789-fix-auth-bug

# Hook fetches GitHub issue #789 and returns:
{
 "action": "inject_context",
 "context_injection": """
## Current Work Context

**Issue**: #789 - Session timeout not respecting remember-me setting
**Status**: Open
**Assignee**: bob
**Labels**: bug, priority:high, auth

### Description
Users with "remember me" checked are still being logged out after 30 minutes. Expected behavior is 30 day session.

### Linked PRs
- #785: Initial remember-me implementation (merged)
""",
 "user_message": "Loaded context for #789"
}`
```

#### Example 3: No Ticket Found

 python
 Copy

`# Session starts on branch: main

# Hook returns (no injection, just continue):
{
 "action": "continue"
}

# No ticket pattern matched in branch name`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `jira.enabled` | bool | false | Enable JIRA integration
 
 | `jira.base_url` | string | - | JIRA instance URL
 
 | `jira.auth_token` | string | - | JIRA API token
 
 | `jira.project_keys` | list | [] | Valid project keys
 
 | `github.enabled` | bool | false | Enable GitHub integration
 
 | `branch_patterns` | list | (defaults) | Regex patterns for extraction
 
 | `include.*` | bool | varies | What ticket fields to include
 
 | `context.role` | string | "system" | Injection role
 
 | `context.max_length` | int | 2000 | Max context length

---

### Security Considerations

- API tokens stored securely in environment
 
- Ticket content may contain sensitive information
 
- Context injection respects session permissions
 
---

### Dependencies

#### Required

- `httpx` - HTTP client for API calls
 
#### Optional

- `jira` - Official JIRA client
 
- `PyGithub` - GitHub API client
 
---

### Open Questions

- Multiple tickets: What if branch references multiple tickets?
 
- Caching: Cache ticket data to avoid repeated API calls?
 
- Updates: Re-fetch if ticket was updated during session?
 
- Custom fields: Support JIRA custom fields?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Token Budget
 hooks

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-hooks-token-budget`

### Overview

Enforce token usage limits at session, user, and project levels. Prevents runaway costs from expensive LLM operations and enables usage-based quotas.

#### Value Proposition

 | 
 
 | Without | With

 | Unlimited token consumption | Controlled spending
 
 | Surprise LLM bills | Predictable costs
 
 | No per-user limits | Fair usage allocation
 
 | Single runaway session can be costly | Session-level caps

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-token-budget
 config:
 # Budget levels (all optional)
 budgets:
 # Per-session limit
 session:
 max_tokens: 100000 # Total tokens per session
 max_requests: 50 # Max LLM requests per session
 warn_at_percent: 80 # Warn when 80% consumed

 # Per-user limit (daily)
 user:
 daily_tokens: 500000
 daily_requests: 200
 reset_time: "00:00" # UTC
 warn_at_percent: 90

 # Per-project limit (monthly)
 project:
 monthly_tokens: 10000000
 monthly_cost_usd: 500.00
 warn_at_percent: 75

 # Actions when budget exceeded
 on_exceed:
 session: deny # deny | warn | continue
 user: deny
 project: warn

 # Cost tracking
 cost:
 track: true
 # Token costs per model (per 1M tokens)
 pricing:
 claude-3-opus: {input: 15.00, output: 75.00}
 claude-3-sonnet: {input: 3.00, output: 15.00}
 gpt-4-turbo: {input: 10.00, output: 30.00}
 gpt-4o: {input: 5.00, output: 15.00}

 # Storage for tracking
 storage:
 type: file # file | redis | database
 path: "${HOME}/.amplifier/budgets/"`
```

#### HookResult Actions

 python
 Copy

`# Warn approaching limit
HookResult(
 action="inject_context",
 context_injection="âš ï¸ Token budget: 82% consumed (82,000 / 100,000 tokens). Consider wrapping up soon.",
 user_message="Budget warning: 82% of session tokens used",
 user_message_level="warning"
)

# Deny when exceeded
HookResult(
 action="deny",
 reason="Session token budget exceeded (100,000 tokens). Start a new session to continue."
)`
```

---

### Architecture

 python
 Copy

`class TokenBudgetHook:
 """Enforce token usage budgets."""

 def __init__(self, config: TokenBudgetConfig):
 self.config = config
 self.storage = BudgetStorage(config.storage)
 self.pricing = config.cost.pricing if config.cost.track else {}

 # Session-level tracking (in-memory)
 self.session_usage: dict[str, Usage] = {}

 async def __call__(self, event: str, data: dict) -> HookResult:
 session_id = data.get("session_id")
 user_id = data.get("user_id")

 # Pre-request: Check budgets before allowing
 if event == "provider:request":
 return await self._check_budgets(session_id, user_id, data)

 # Post-response: Track usage
 if event == "provider:response":
 await self._track_usage(session_id, user_id, data)
 return await self._check_warnings(session_id, user_id)

 return HookResult(action="continue")

 async def _check_budgets(
 self,
 session_id: str,
 user_id: str | None,
 data: dict
 ) -> HookResult:
 """Check if request would exceed any budget."""

 # Estimate tokens for this request
 estimated = self._estimate_request_tokens(data)

 # Check session budget
 if self.config.budgets.session:
 session_usage = self._get_session_usage(session_id)
 if session_usage.tokens + estimated > self.config.budgets.session.max_tokens:
 if self.config.on_exceed.session == "deny":
 return HookResult(
 action="deny",
 reason=f"Session token budget exceeded ({session_usage.tokens:,} / {self.config.budgets.session.max_tokens:,})"
 )

 # Check user budget
 if self.config.budgets.user and user_id:
 user_usage = await self.storage.get_user_usage(user_id)
 if user_usage.daily_tokens + estimated > self.config.budgets.user.daily_tokens:
 if self.config.on_exceed.user == "deny":
 return HookResult(
 action="deny",
 reason=f"Daily user token budget exceeded. Resets at {self.config.budgets.user.reset_time} UTC."
 )

 # Check project budget
 if self.config.budgets.project:
 project_usage = await self.storage.get_project_usage()
 if project_usage.monthly_tokens + estimated > self.config.budgets.project.monthly_tokens:
 if self.config.on_exceed.project == "deny":
 return HookResult(
 action="deny",
 reason="Monthly project token budget exceeded."
 )

 return HookResult(action="continue")

 async def _track_usage(
 self,
 session_id: str,
 user_id: str | None,
 data: dict
 ) -> None:
 """Track token usage from response."""
 usage = data.get("usage", {})
 input_tokens = usage.get("input_tokens", 0)
 output_tokens = usage.get("output_tokens", 0)
 total_tokens = input_tokens + output_tokens

 model = data.get("model", "unknown")
 cost = self._calculate_cost(model, input_tokens, output_tokens)

 # Update session usage
 session_usage = self._get_session_usage(session_id)
 session_usage.tokens += total_tokens
 session_usage.requests += 1
 session_usage.cost += cost

 # Update persistent storage
 if user_id:
 await self.storage.add_user_usage(user_id, total_tokens, cost)
 await self.storage.add_project_usage(total_tokens, cost)

 async def _check_warnings(
 self,
 session_id: str,
 user_id: str | None
 ) -> HookResult:
 """Check if any budget is approaching limit."""
 warnings = []

 # Session warning
 if self.config.budgets.session:
 session_usage = self._get_session_usage(session_id)
 percent = (session_usage.tokens / self.config.budgets.session.max_tokens) * 100
 if percent >= self.config.budgets.session.warn_at_percent:
 warnings.append(f"Session: {percent:.0f}% ({session_usage.tokens:,} / {self.config.budgets.session.max_tokens:,} tokens)")

 # User warning
 if self.config.budgets.user and user_id:
 user_usage = await self.storage.get_user_usage(user_id)
 percent = (user_usage.daily_tokens / self.config.budgets.user.daily_tokens) * 100
 if percent >= self.config.budgets.user.warn_at_percent:
 warnings.append(f"Daily: {percent:.0f}% of daily limit")

 if warnings:
 return HookResult(
 action="inject_context",
 context_injection=f"âš ï¸ Token budget warnings:\n" + "\n".join(f"- {w}" for w in warnings),
 suppress_output=True,
 user_message=f"Budget: {'; '.join(warnings)}",
 user_message_level="warning"
 )

 return HookResult(action="continue")

 def _calculate_cost(self, model: str, input_tokens: int, output_tokens: int) -> float:
 """Calculate cost for token usage."""
 if model not in self.pricing:
 return 0.0

 pricing = self.pricing[model]
 input_cost = (input_tokens / 1_000_000) * pricing["input"]
 output_cost = (output_tokens / 1_000_000) * pricing["output"]
 return input_cost + output_cost

class BudgetStorage:
 """Persistent storage for budget tracking."""

 async def get_user_usage(self, user_id: str) -> UserUsage:
 """Get user's current usage, resetting if new day."""
 data = await self._read_user_file(user_id)

 # Check if we need to reset (new day)
 if data and data["date"] != self._today():
 data = None

 if not data:
 return UserUsage(daily_tokens=0, daily_cost=0.0)

 return UserUsage(**data)

 async def add_user_usage(self, user_id: str, tokens: int, cost: float) -> None:
 """Add usage to user's daily total."""
 usage = await self.get_user_usage(user_id)
 usage.daily_tokens += tokens
 usage.daily_cost += cost
 await self._write_user_file(user_id, {
 "date": self._today(),
 "daily_tokens": usage.daily_tokens,
 "daily_cost": usage.daily_cost
 })`
```

---

### Examples

#### Example 1: Session Limit Warning

 python
 Copy

`# After 82,000 tokens in session with 100,000 limit:
{
 "action": "inject_context",
 "context_injection": "âš ï¸ Token budget warnings:\n- Session: 82% (82,000 / 100,000 tokens)",
 "user_message": "Budget: Session: 82% (82,000 / 100,000 tokens)",
 "user_message_level": "warning"
}`
```

#### Example 2: Session Limit Exceeded

 python
 Copy

`# Request would exceed session limit:
{
 "action": "deny",
 "reason": "Session token budget exceeded (100,000 / 100,000 tokens). Start a new session to continue."
}`
```

#### Example 3: Cost Tracking

 python
 Copy

`# After response with usage data:
# Model: claude-3-sonnet
# Input: 5,000 tokens, Output: 2,000 tokens
# Cost: (5000/1M * $3) + (2000/1M * $15) = $0.015 + $0.030 = $0.045`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `budgets.session.max_tokens` | int | none | Session token limit
 
 | `budgets.session.max_requests` | int | none | Session request limit
 
 | `budgets.user.daily_tokens` | int | none | Daily per-user limit
 
 | `budgets.project.monthly_tokens` | int | none | Monthly project limit
 
 | `budgets.*.warn_at_percent` | int | 80 | Warning threshold
 
 | `on_exceed.*` | string | "deny" | Action when exceeded
 
 | `cost.track` | bool | true | Track costs
 
 | `cost.pricing` | dict | {} | Model pricing

---

### Storage Schema

 json
 Copy

`// User usage file: ~/.amplifier/budgets/users/{user_id}.json
{
 "date": "2024-01-15",
 "daily_tokens": 45000,
 "daily_cost": 1.35,
 "daily_requests": 23
}

// Project usage file: ~/.amplifier/budgets/project.json
{
 "month": "2024-01",
 "monthly_tokens": 2500000,
 "monthly_cost": 125.50,
 "monthly_requests": 1250
}`
```

---

### Security Considerations

- Budget data stored securely
 
- User quotas prevent abuse
 
- Cost tracking enables chargeback
 
---

### Dependencies

#### Required

- `aiofiles` - Async file operations
 
#### Optional

- `redis` - For distributed budget tracking
 
---

### Open Questions

- Distributed tracking: How to share budgets across instances?
 
- Quota inheritance: Project limits vs team limits vs user limits?
 
- Alerting: Notify admins when project budget is low?
 
- Rollover: Allow unused quota to roll over?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Hooks Usage Analytics
 hooks

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-hooks-usage-analytics`

### Overview

Collects usage metrics for analysis, optimization, and reporting. Tracks patterns like model usage, tool frequency, session duration, and task types to inform decisions about AI tooling investments.

#### Value Proposition

 | 
 
 | Without | With

 | No visibility into AI usage | Comprehensive analytics
 
 | Can't justify AI investment | ROI data for stakeholders
 
 | Unknown optimization opportunities | Data-driven improvements
 
 | No usage patterns visible | Understand team behavior

---

### Contract

#### Hook Configuration

 yaml
 Copy

`hooks:
 - module: hooks-usage-analytics
 config:
 # What to track
 metrics:
 sessions:
 enabled: true
 track: [duration, turns, outcome]

 tokens:
 enabled: true
 track: [input, output, by_model, by_task]

 tools:
 enabled: true
 track: [frequency, duration, success_rate]

 tasks:
 enabled: true
 classify: true # Auto-classify task types

 costs:
 enabled: true
 pricing: "${PRICING_CONFIG}"

 # Aggregation
 aggregation:
 intervals: [hourly, daily, weekly, monthly]
 dimensions: [user, team, project, model, task_type]

 # Storage
 storage:
 type: file # file | database | datadog | prometheus
 path: "${HOME}/.amplifier/analytics/"

 # Privacy
 privacy:
 anonymize_users: false
 exclude_content: true # Don't store prompts/responses
 aggregate_only: false # Only store aggregates, not raw events

 # Export
 export:
 enabled: true
 format: json # json | csv | parquet
 schedule: daily`
```

#### Events Captured

 python
 Copy

`# All events are captured with standard fields:
{
 "timestamp": "2024-01-15T10:30:00Z",
 "session_id": "sess-123",
 "user_id": "alice", # Optional, anonymizable
 "project": "payment-service",
 "event_type": "...",
 "data": {...}
}`
```

---

### Architecture

 python
 Copy

`class UsageAnalyticsHook:
 """Collect and aggregate usage metrics."""

 CAPTURED_EVENTS = [
 "session:start",
 "session:end",
 "provider:request",
 "provider:response",
 "tool:pre",
 "tool:post",
 "tool:error",
 "prompt:submit",
 "prompt:complete",
 ]

 def __init__(self, config: UsageAnalyticsConfig):
 self.config = config
 self.storage = AnalyticsStorage(config.storage)
 self.aggregator = MetricsAggregator(config.aggregation)
 self.classifier = TaskClassifier() if config.metrics.tasks.classify else None

 # In-memory session tracking
 self.sessions: dict[str, SessionMetrics] = {}

 async def __call__(self, event: str, data: dict) -> HookResult:
 if event not in self.CAPTURED_EVENTS:
 return HookResult(action="continue")

 # Extract metrics
 metrics = self._extract_metrics(event, data)

 # Apply privacy settings
 metrics = self._apply_privacy(metrics)

 # Store raw event (if not aggregate_only)
 if not self.config.privacy.aggregate_only:
 await self.storage.store_event(metrics)

 # Update aggregates
 await self.aggregator.update(metrics)

 # Session-level tracking
 self._update_session(event, data, metrics)

 # Always continue - analytics is observational
 return HookResult(action="continue")

 def _extract_metrics(self, event: str, data: dict) -> dict:
 """Extract relevant metrics from event."""
 base = {
 "timestamp": datetime.utcnow().isoformat(),
 "session_id": data.get("session_id"),
 "user_id": data.get("user_id"),
 "event_type": event,
 }

 # Event-specific extraction
 if event == "provider:response":
 usage = data.get("usage", {})
 base.update({
 "model": data.get("model"),
 "provider": data.get("provider"),
 "input_tokens": usage.get("input_tokens", 0),
 "output_tokens": usage.get("output_tokens", 0),
 "latency_ms": data.get("latency_ms"),
 })

 # Calculate cost
 if self.config.metrics.costs.enabled:
 base["cost_usd"] = self._calculate_cost(
 data.get("model"),
 usage.get("input_tokens", 0),
 usage.get("output_tokens", 0)
 )

 elif event == "tool:post":
 base.update({
 "tool": data.get("tool"),
 "operation": data.get("operation"),
 "duration_ms": data.get("duration_ms"),
 "success": data.get("success", True),
 })

 elif event == "prompt:submit":
 if self.classifier:
 base["task_type"] = self.classifier.classify(data.get("prompt", ""))

 return base

 def _update_session(self, event: str, data: dict, metrics: dict) -> None:
 """Update session-level metrics."""
 session_id = data.get("session_id")
 if not session_id:
 return

 if event == "session:start":
 self.sessions[session_id] = SessionMetrics(
 start_time=datetime.utcnow(),
 turns=0,
 total_tokens=0,
 total_cost=0.0,
 tools_used=set(),
 models_used=set()
 )

 elif session_id in self.sessions:
 session = self.sessions[session_id]

 if event == "prompt:complete":
 session.turns += 1

 if event == "provider:response":
 session.total_tokens += metrics.get("input_tokens", 0) + metrics.get("output_tokens", 0)
 session.total_cost += metrics.get("cost_usd", 0)
 if metrics.get("model"):
 session.models_used.add(metrics["model"])

 if event == "tool:post":
 if metrics.get("tool"):
 session.tools_used.add(metrics["tool"])

 if event == "session:end":
 session.end_time = datetime.utcnow()
 session.duration_seconds = (session.end_time - session.start_time).total_seconds()
 # Store session summary
 asyncio.create_task(self._store_session_summary(session_id, session))

class MetricsAggregator:
 """Aggregate metrics across dimensions."""

 async def update(self, metrics: dict) -> None:
 """Update all relevant aggregations."""
 timestamp = datetime.fromisoformat(metrics["timestamp"])

 for interval in self.config.intervals:
 bucket = self._get_bucket(timestamp, interval)

 for dimension in self.config.dimensions:
 key = self._get_dimension_key(metrics, dimension)
 if key:
 await self._increment_counters(bucket, dimension, key, metrics)

 async def _increment_counters(
 self,
 bucket: str,
 dimension: str,
 key: str,
 metrics: dict
 ) -> None:
 """Increment counters for this bucket/dimension/key."""
 counter_key = f"{bucket}:{dimension}:{key}"

 # Token counters
 if "input_tokens" in metrics:
 await self.storage.increment(f"{counter_key}:input_tokens", metrics["input_tokens"])
 await self.storage.increment(f"{counter_key}:output_tokens", metrics["output_tokens"])

 # Request counters
 if metrics["event_type"] == "provider:response":
 await self.storage.increment(f"{counter_key}:requests", 1)

 # Cost counters
 if "cost_usd" in metrics:
 await self.storage.increment_float(f"{counter_key}:cost_usd", metrics["cost_usd"])`
```

---

### Metrics Schema

#### Session Metrics

 python
 Copy

`@dataclass
class SessionMetrics:
 session_id: str
 user_id: str | None
 project: str | None

 start_time: datetime
 end_time: datetime | None
 duration_seconds: float

 turns: int # User/assistant exchanges
 total_tokens: int
 total_cost: float

 models_used: set[str]
 tools_used: set[str]
 task_types: list[str] # Classified task types

 outcome: str | None # success | abandoned | error`
```

#### Aggregated Metrics

 python
 Copy

`@dataclass
class AggregatedMetrics:
 period: str # "2024-01-15", "2024-W03", "2024-01"
 dimension: str # user | team | project | model
 dimension_value: str

 # Counts
 sessions: int
 requests: int
 tool_calls: int

 # Tokens
 input_tokens: int
 output_tokens: int
 total_tokens: int

 # Costs
 total_cost_usd: float
 avg_cost_per_session: float

 # Performance
 avg_latency_ms: float
 p95_latency_ms: float

 # Usage patterns
 top_tools: list[tuple[str, int]] # [(tool, count), ...]
 top_models: list[tuple[str, int]]
 top_task_types: list[tuple[str, int]]`
```

---

### Examples

#### Example 1: Daily Summary

 json
 Copy

`{
 "period": "2024-01-15",
 "dimension": "team",
 "dimension_value": "platform",

 "sessions": 45,
 "requests": 892,
 "tool_calls": 234,

 "input_tokens": 1250000,
 "output_tokens": 450000,
 "total_tokens": 1700000,

 "total_cost_usd": 52.30,
 "avg_cost_per_session": 1.16,

 "avg_latency_ms": 1250,
 "p95_latency_ms": 3200,

 "top_tools": [
 ["filesystem:read", 89],
 ["codebase_search", 45],
 ["bash", 34]
 ],
 "top_models": [
 ["claude-3-sonnet", 650],
 ["claude-3-opus", 242]
 ],
 "top_task_types": [
 ["code_generation", 28],
 ["debugging", 12],
 ["analysis", 5]
 ]
}`
```

#### Example 2: User Leaderboard

 json
 Copy

`{
 "period": "2024-01",
 "dimension": "user",
 "leaderboard": [
 {"user": "alice", "sessions": 120, "cost": 245.50, "tokens": 5200000},
 {"user": "bob", "sessions": 95, "cost": 189.20, "tokens": 4100000},
 {"user": "carol", "sessions": 78, "cost": 156.80, "tokens": 3400000}
 ]
}`
```

---

### Visualization / Export

#### Dashboard Data Points

- Time series: Tokens, costs, sessions over time
 
- Breakdowns: By model, tool, task type, user
 
- Trends: Week-over-week changes
 
- Alerts: Unusual spikes in usage/cost
 
#### Export Formats

 python
 Copy

`# CSV export
async def export_csv(period: str) -> str:
 """Export metrics as CSV."""
 data = await storage.get_period_metrics(period)
 return csv_format(data)

# JSON export for dashboards
async def export_json(period: str) -> dict:
 """Export metrics as JSON."""
 return await storage.get_period_metrics(period)

# Prometheus metrics
async def export_prometheus() -> str:
 """Export as Prometheus metrics."""
 metrics = await storage.get_current_metrics()
 return prometheus_format(metrics)`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `metrics.*.enabled` | bool | true | Enable metric category
 
 | `aggregation.intervals` | list | [daily] | Aggregation intervals
 
 | `aggregation.dimensions` | list | [user,project] | Aggregation dimensions
 
 | `storage.type` | string | "file" | Storage backend
 
 | `privacy.anonymize_users` | bool | false | Hash user IDs
 
 | `privacy.exclude_content` | bool | true | Don't store prompts
 
 | `privacy.aggregate_only` | bool | false | Only store aggregates
 
 | `export.schedule` | string | "daily" | Export schedule

---

### Security Considerations

- User IDs can be anonymized
 
- Prompt content excluded by default
 
- Aggregates can be used instead of raw events
 
- Storage should be access-controlled
 
---

### Dependencies

#### Required

- `aiofiles` - File operations
 
#### Optional

- `prometheus_client` - Prometheus export
 
- `datadog` - DataDog integration
 
- `pandas` - Data analysis
 
---

### Open Questions

- Retention: How long to keep raw events vs aggregates?
 
- Real-time: Stream metrics to dashboards?
 
- Alerting: Integrate with alerting systems?
 
- Benchmarking: Compare teams/projects?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Collection Enterprise Dev
 collections

Priority: P0 (Critical Path)

Status: Draft

Module: `amplifier-collection-enterprise-dev`

### Overview

A comprehensive collection of tools, hooks, and configurations for enterprise software development teams. Provides security-first defaults, compliance features, and integrations with common enterprise tools.

#### Value Proposition

 | 
 
 | Without | With

 | Manual module assembly | Pre-configured enterprise stack
 
 | Security afterthought | Security-first defaults
 
 | Compliance gaps | Built-in audit and compliance
 
 | Integration complexity | Ready-to-use enterprise integrations

---

### Collection Contents

 yaml
 Copy

`collection:
 name: enterprise-dev
 version: "1.0.0"
 description: "Enterprise-grade AI development toolkit"

 # Included modules
 modules:

 # ===== PROVIDERS =====
 providers:
 - module: provider-anthropic
 config:
 default_model: claude-sonnet-4-5
 max_tokens: 8192

 - module: provider-azure-openai # Enterprise Azure option
 config:
 api_version: "2024-02-15-preview"
 deployment_name: "${AZURE_OPENAI_DEPLOYMENT}"

 # ===== TOOLS =====
 tools:
 # Core development
 - module: tool-filesystem
 config:
 allowed_paths: ["${WORKSPACE}"]
 audit_all_writes: true

 - module: tool-bash
 config:
 allowed_commands: ["git", "npm", "python", "docker"]
 blocked_commands: ["rm -rf", "curl|sh"]
 timeout: 30s

 # Enterprise tools (from specs)
 - module: tool-codebase-search
 config:
 include_semantic: true
 include_docs: true
 include_tickets: true

 - module: tool-pr-context
 config:
 platform: github-enterprise
 include_reviews: true

 - module: tool-jira-ops
 config:
 server: "${JIRA_SERVER}"
 project_filter: ["${JIRA_PROJECTS}"]
 allowed_operations: [read, create, update, link]

 - module: tool-git-advanced
 config:
 enable_blame: true
 enable_bisect: false # Potentially dangerous
 audit_commands: true

 - module: tool-test-runner
 config:
 frameworks: [pytest, jest, go-test]
 coverage_threshold: 80

 - module: tool-dependency-graph
 config:
 languages: [python, typescript, go]
 include_external: true

 - module: tool-slack-search
 config:
 channels: ["${ALLOWED_SLACK_CHANNELS}"]
 exclude_dm: true

 - module: tool-metrics-query
 config:
 providers: [datadog, prometheus]
 max_lookback: 7d

 # ===== HOOKS =====
 hooks:
 # Security (P0 - Always enabled)
 - module: hooks-secret-detector
 config:
 action: deny # Block secrets
 patterns: enterprise # Enterprise patterns
 audit: true

 - module: hooks-security-scan
 config:
 scan_on_write: true
 severity_threshold: medium
 block_high: true

 - module: hooks-pii-guardian
 config:
 redact_patterns: [email, phone, ssn, credit_card]
 action: redact # Redact before sending to LLM

 - module: hooks-license-checker
 config:
 policy:
 allowed: [MIT, Apache-2.0, BSD-*]
 prohibited: [GPL-*, AGPL-*]
 action: deny

 # Compliance
 - module: hooks-audit-trail
 config:
 storage: "${AUDIT_LOG_PATH}"
 include_all_events: true
 retention_days: 365

 - module: hooks-approval-workflow
 config:
 require_approval_for:
 - "production/*"
 - "*.env*"
 - "secrets/*"
 escalation_channel: "#security-approvals"

 # Quality
 - module: hooks-style-enforcer
 config:
 auto_fix: true
 tools:
 python: [ruff, black, mypy]
 typescript: [eslint, prettier]

 - module: hooks-breaking-change
 config:
 check_api: true
 check_database: true
 action: warn

 # Productivity
 - module: hooks-ticket-linker
 config:
 platforms: [jira, github]
 auto_load_context: true

 - module: hooks-reviewer-suggester
 config:
 use_codeowners: true
 max_reviewers: 3

 # Observability
 - module: hooks-logging
 config:
 level: info
 format: json
 include_token_usage: true
 include_latency: true

 - module: hooks-usage-analytics
 config:
 track_costs: true
 track_tokens: true
 aggregation: [user, team, project]

 # ===== ORCHESTRATORS =====
 orchestrators:
 default: loop-streaming
 options:
 - loop-streaming
 - loop-basic

 # ===== CONTEXTS =====
 contexts:
 default: context-persistent
 config:
 storage: "${STATE_PATH}"
 max_history: 100

 # Collection-level configuration
 config:
 # Security defaults
 security:
 require_approval_for_production: true
 block_secrets: true
 audit_all_operations: true

 # Enterprise integrations
 integrations:
 sso:
 provider: okta
 required: true
 vault:
 enabled: true
 path: "secret/amplifier"

 # Defaults
 defaults:
 timeout: 120s
 max_tokens: 8192
 temperature: 0.3`
```

---

### Profile Hierarchy

The collection provides layered profiles for different use cases:

 yaml
 Copy

`profiles:
 # Base enterprise profile (always applied)
 base:
 description: "Core enterprise security and compliance"
 hooks:
 - hooks-secret-detector
 - hooks-security-scan
 - hooks-audit-trail
 - hooks-pii-guardian
 - hooks-logging

 # Development profile (extends base)
 development:
 extends: base
 description: "Day-to-day development work"
 tools:
 - tool-filesystem
 - tool-bash
 - tool-codebase-search
 - tool-git-advanced
 - tool-test-runner
 hooks:
 - hooks-style-enforcer
 - hooks-ticket-linker

 # Review profile (extends base)
 review:
 extends: base
 description: "Code review and PR work"
 tools:
 - tool-pr-context
 - tool-codebase-search
 - tool-dependency-graph
 hooks:
 - hooks-breaking-change
 - hooks-reviewer-suggester
 - hooks-license-checker

 # Incident profile (extends base)
 incident:
 extends: base
 description: "Incident response"
 tools:
 - tool-metrics-query
 - tool-git-advanced
 - tool-slack-search
 hooks:
 - hooks-approval-workflow # For production changes
 config:
 timeout: 300s # Longer timeout for investigation

 # Full profile (all modules)
 full:
 extends: base
 description: "All enterprise modules"
 tools: all
 hooks: all`
```

---

### Installation

 bash
 Copy

`# Install collection
amplifier collection install enterprise-dev

# Use specific profile
amplifier --profile enterprise-dev:development

# Or set as default
amplifier config set default-collection enterprise-dev
amplifier config set default-profile development`
```

---

### Configuration Requirements

#### Environment Variables

 bash
 Copy

`# Required
WORKSPACE=/path/to/project
AUDIT_LOG_PATH=/var/log/amplifier/audit
STATE_PATH=~/.amplifier/state

# Enterprise integrations
JIRA_SERVER=https://company.atlassian.net
JIRA_PROJECTS=PROJ,PLAT,INFRA
ALLOWED_SLACK_CHANNELS=engineering,platform,incidents

# Optional (for specific modules)
AZURE_OPENAI_ENDPOINT=https://company.openai.azure.com
AZURE_OPENAI_DEPLOYMENT=gpt-4
DD_API_KEY=xxx
DD_APP_KEY=xxx`
```

#### Secret Management

 yaml
 Copy

`# Vault integration for secrets
vault:
 enabled: true
 address: "${VAULT_ADDR}"
 auth_method: kubernetes # or token, ldap, oidc
 secret_paths:
 anthropic: "secret/ai/anthropic"
 azure: "secret/ai/azure-openai"
 jira: "secret/integrations/jira"
 github: "secret/integrations/github"`
```

---

### Security Posture

#### Default Security Controls

 | 
 
 | Control | Default | Configurable

 | Secret detection | Block | Yes (warn mode)
 
 | Security scanning | Block high severity | Yes
 
 | PII redaction | Redact before LLM | Yes
 
 | License checking | Block GPL | Yes
 
 | Audit logging | All events | Log level only
 
 | Production approval | Required | No (enterprise)

#### Compliance Features

- SOC 2: Audit trail, access controls, encryption
 
- GDPR: PII detection and redaction
 
- HIPAA: PHI patterns in PII guardian
 
- PCI-DSS: Credit card detection, audit logs
 
---

### Enterprise Integrations

#### SSO Integration

 yaml
 Copy

`sso:
 provider: okta # okta | azure-ad | onelogin
 client_id: "${OKTA_CLIENT_ID}"
 issuer: "${OKTA_ISSUER}"
 scopes: [openid, profile, groups]

 # Map groups to permissions
 group_mapping:
 "Engineering": ["development", "review"]
 "Security": ["development", "review", "incident"]
 "Platform": ["development", "review", "incident", "admin"]`
```

#### SIEM Integration

 yaml
 Copy

`siem:
 enabled: true
 provider: splunk # splunk | elastic | datadog
 endpoint: "${SPLUNK_HEC_ENDPOINT}"

 # Events to forward
 events:
 - "audit:*"
 - "security:*"
 - "approval:*"

 # Format
 format: json
 include_context: false # Don't send prompt content`
```

---

### Usage Examples

#### Example 1: Daily Development

 bash
 Copy

`# Start development session
amplifier --profile enterprise-dev:development

# Tools available:
# - Codebase search (semantic + docs + tickets)
# - Git operations (with audit)
# - Test runner
# - File operations (workspace only)

# Hooks active:
# - Secret detection (blocks)
# - Style enforcement (auto-fix)
# - Ticket linking (auto-context)
# - Security scanning (warns)`
```

#### Example 2: Code Review

 bash
 Copy

`# Review a PR
amplifier --profile enterprise-dev:review

> Review PR #1234

# Automatically:
# - Fetches PR context
# - Checks for breaking changes
# - Scans for security issues
# - Suggests reviewers
# - Checks license compliance`
```

#### Example 3: Incident Response

 bash
 Copy

`# Incident mode with elevated permissions
amplifier --profile enterprise-dev:incident

> Investigate payment failures

# Available:
# - Metrics queries (up to 7d lookback)
# - Git history analysis
# - Slack search for context
# - Production file access (with approval)`
```

---

### Customization

#### Extending the Collection

 yaml
 Copy

`# company-config.yaml
extends: enterprise-dev

# Add company-specific modules
modules:
 tools:
 - module: tool-internal-api
 config:
 endpoint: https://api.internal.company.com

 hooks:
 - module: hooks-company-policy
 config:
 policy_file: ./company-policy.yaml

# Override defaults
config:
 security:
 additional_secret_patterns:
 - name: internal_api_key
 pattern: "COMPANY_[A-Z0-9]{32}"

 integrations:
 ticketing:
 platform: internal # Use internal system instead of Jira`
```

#### Disabling Modules

 yaml
 Copy

`# For specific use case, disable certain hooks
profiles:
 sandbox:
 extends: development
 disabled:
 - hooks-approval-workflow # No approvals in sandbox
 - hooks-audit-trail # No audit in sandbox
 config:
 security:
 require_approval_for_production: false`
```

---

### Metrics & Reporting

#### Built-in Dashboards

The collection provides data for:

- Usage Dashboard: Tokens, costs, sessions by team/user
 
- Security Dashboard: Blocked secrets, vulnerabilities found
 
- Compliance Dashboard: Approval rates, audit coverage
 
- Productivity Dashboard: Time saved, code generated
 
#### Export Formats

 bash
 Copy

`# Export usage data
amplifier analytics export --format csv --period month

# Export audit logs
amplifier audit export --format json --days 30

# Generate compliance report
amplifier compliance report --standard soc2`
```

---

### Dependencies

#### Required External Services

- Git repository (GitHub Enterprise / GitLab / Azure DevOps)
 
- Ticketing system (Jira / Azure Boards)
 
- Secret management (Vault / AWS Secrets Manager)
 
#### Optional Services

- Observability (Datadog / Prometheus / New Relic)
 
- Chat (Slack / Teams)
 
- SSO (Okta / Azure AD)
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Collection Platform Team
 collections

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-collection-platform-team`

### Overview

Specialized collection for platform engineering and infrastructure teams. Focuses on multi-service architecture, infrastructure-as-code, reliability engineering, and cross-cutting concerns.

#### Value Proposition

 | 
 
 | Without | With

 | Service sprawl complexity | Unified multi-service tools
 
 | Manual dependency tracking | Automated service graph
 
 | Incident chaos | Structured response workflow
 
 | Config drift | Infrastructure validation

---

### Collection Contents

 yaml
 Copy

`collection:
 name: platform-team
 version: "1.0.0"
 description: "Platform engineering and SRE toolkit"

 extends: enterprise-dev # Inherits enterprise security

 # Platform-specific modules
 modules:

 # ===== TOOLS =====
 tools:
 # Multi-service operations
 - module: tool-service-graph
 config:
 discovery:
 kubernetes: true
 terraform: true
 consul: true
 include_dependencies: true
 include_health: true

 - module: tool-multi-repo-search
 config:
 repositories: "${PLATFORM_REPOS}"
 include_configs: true
 include_iac: true

 # Infrastructure
 - module: tool-terraform-ops
 config:
 workspaces: ["${TF_WORKSPACES}"]
 allowed_operations: [plan, validate, state]
 apply_require_approval: true

 - module: tool-kubernetes-ops
 config:
 contexts: ["${K8S_CONTEXTS}"]
 namespaces: ["${K8S_NAMESPACES}"]
 allowed_operations: [get, describe, logs, exec]
 blocked_operations: [delete, edit]

 - module: tool-helm-ops
 config:
 repositories: ["${HELM_REPOS}"]
 operations: [list, status, template, diff]
 install_require_approval: true

 # Observability
 - module: tool-metrics-query
 config:
 providers:
 prometheus:
 url: "${PROMETHEUS_URL}"
 queries: platform-queries.yaml
 datadog:
 api_key: "${DD_API_KEY}"
 cloudwatch:
 regions: ["${AWS_REGIONS}"]
 max_lookback: 30d # Longer for capacity planning

 - module: tool-log-aggregator
 config:
 providers:
 elasticsearch:
 url: "${ES_URL}"
 indices: ["logs-*", "traces-*"]
 loki:
 url: "${LOKI_URL}"
 max_entries: 5000

 - module: tool-trace-analyzer
 config:
 provider: jaeger # jaeger | zipkin | datadog
 url: "${JAEGER_URL}"
 include_dependencies: true

 # Dependencies and health
 - module: tool-dependency-graph
 config:
 scope: multi-repo
 include_infrastructure: true
 include_network: true

 - module: tool-health-checker
 config:
 services: "${PLATFORM_SERVICES}"
 checks: [http, tcp, grpc]
 include_dependencies: true

 # Database operations
 - module: tool-database-ops
 config:
 connections: "${DB_CONNECTIONS}"
 allowed_operations: [query, explain, schema]
 ddl_require_approval: true
 max_rows: 1000

 # ===== HOOKS =====
 hooks:
 # Platform-specific security
 - module: hooks-iac-validator
 config:
 validate_terraform: true
 validate_kubernetes: true
 validate_helm: true
 policies:
 - no_public_ingress
 - require_resource_limits
 - require_security_context

 - module: hooks-blast-radius
 config:
 warn_threshold: 10 # Services affected
 block_threshold: 50
 require_approval_above: 20

 # Change management
 - module: hooks-change-window
 config:
 windows:
 - name: maintenance
 cron: "0 2 * * 0" # Sunday 2 AM
 duration: 4h
 - name: freeze
 dates: ["2024-12-20:2025-01-05"]
 production_changes: maintenance_only

 - module: hooks-rollback-ready
 config:
 require_rollback_plan: true
 verify_previous_version: true

 # Incident support
 - module: hooks-runbook-linker
 config:
 runbook_path: docs/runbooks/
 auto_suggest: true
 link_to_alerts: true

 - module: hooks-incident-auto-context
 config:
 include_recent_deploys: true
 include_related_alerts: true
 include_service_health: true
 lookback: 24h

 # Capacity and cost
 - module: hooks-resource-estimator
 config:
 estimate_cpu: true
 estimate_memory: true
 estimate_cost: true
 warn_high_cost: true

 # ===== SCENARIO TOOLS =====
 scenarios:
 - module: incident-responder
 config:
 auto_gather_context: true
 services_scope: platform

 - module: capacity-planner
 config:
 forecast_days: 90
 include_cost_projection: true

 # Platform-specific profiles
 profiles:
 # Infrastructure work
 infrastructure:
 tools:
 - tool-terraform-ops
 - tool-kubernetes-ops
 - tool-helm-ops
 - tool-service-graph
 hooks:
 - hooks-iac-validator
 - hooks-blast-radius
 - hooks-change-window
 config:
 require_approval_for:
 - "*.tf"
 - "*.yaml" # K8s manifests
 - "values*.yaml" # Helm values

 # Incident response
 incident:
 tools:
 - tool-metrics-query
 - tool-log-aggregator
 - tool-trace-analyzer
 - tool-service-graph
 - tool-health-checker
 hooks:
 - hooks-runbook-linker
 - hooks-incident-auto-context
 scenarios:
 - incident-responder
 config:
 elevated_permissions: true
 audit_level: verbose

 # Capacity planning
 capacity:
 tools:
 - tool-metrics-query
 - tool-service-graph
 - tool-dependency-graph
 hooks:
 - hooks-resource-estimator
 scenarios:
 - capacity-planner
 config:
 metrics_lookback: 90d

 # Service development
 service-dev:
 extends: ../enterprise-dev:development
 tools:
 - tool-service-graph
 - tool-multi-repo-search
 - tool-health-checker
 hooks:
 - hooks-blast-radius`
```

---

### Service Graph Tool

A key differentiator for platform teams:

 yaml
 Copy

`tool-service-graph:
 description: "Map and analyze service dependencies"

 capabilities:
 # Discovery
 discover_from:
 - kubernetes_services
 - terraform_state
 - consul_catalog
 - manual_config

 # Analysis
 analyze:
 - dependency_chains
 - blast_radius
 - single_points_of_failure
 - cyclic_dependencies

 # Visualization
 outputs:
 - ascii_diagram
 - mermaid
 - graphviz
 - interactive_html

 # Example output
 example_output: |
 Service Dependency Graph for: payment-service

 payment-service
 â”œâ”€â”€ auth-service (direct)
 â”‚ â””â”€â”€ redis-cache (direct)
 â”œâ”€â”€ database (direct)
 â”‚ â””â”€â”€ postgres-primary (RDS)
 â”œâ”€â”€ notification-service (async)
 â”‚ â”œâ”€â”€ sns-topic
 â”‚ â””â”€â”€ email-provider (external)
 â””â”€â”€ stripe-api (external)

 Blast Radius: 12 services
 Single Points of Failure: postgres-primary
 Cyclic Dependencies: None`
```

---

### Infrastructure Validation Hook

 yaml
 Copy

`hooks-iac-validator:
 description: "Validate infrastructure-as-code before apply"

 policies:
 # Kubernetes
 kubernetes:
 - name: require_resource_limits
 description: "All containers must have CPU/memory limits"
 severity: error

 - name: require_security_context
 description: "Pods must have security context"
 severity: error

 - name: no_privileged_containers
 description: "No privileged containers allowed"
 severity: error

 - name: require_liveness_probe
 description: "Services must have liveness probes"
 severity: warning

 # Terraform
 terraform:
 - name: no_public_s3
 description: "S3 buckets must not be public"
 severity: error

 - name: encryption_at_rest
 description: "Databases must have encryption"
 severity: error

 - name: require_tags
 description: "Resources must have cost allocation tags"
 severity: warning

 # Helm
 helm:
 - name: no_latest_tag
 description: "Image tags must be explicit versions"
 severity: error

 example_output: |
 ðŸ” IaC Validation Results

 âŒ FAILED: require_resource_limits
 File: deployment.yaml
 Line: 45
 Container 'app' missing resource limits

 âš ï¸ WARNING: require_liveness_probe
 File: deployment.yaml
 Line: 42
 Container 'app' missing liveness probe

 âœ… PASSED: no_privileged_containers
 âœ… PASSED: require_security_context`
```

---

### Blast Radius Analysis

 yaml
 Copy

`hooks-blast-radius:
 description: "Analyze impact of changes on dependent services"

 analysis:
 # Direct impacts
 direct:
 - services_calling_this
 - services_this_calls
 - shared_databases
 - shared_queues

 # Indirect impacts
 indirect:
 - cascading_dependencies
 - feature_flag_consumers
 - config_consumers

 thresholds:
 warning: 10 # Warn if >10 services affected
 approval: 20 # Require approval if >20
 block: 50 # Block if >50

 example_output: |
 ðŸŽ¯ Blast Radius Analysis: payment-service changes

 Direct Impact (5 services):
 â”œâ”€â”€ checkout-service (calls payment API)
 â”œâ”€â”€ refund-service (calls payment API)
 â”œâ”€â”€ reporting-service (reads payment DB)
 â”œâ”€â”€ notification-service (listens to events)
 â””â”€â”€ admin-dashboard (calls payment API)

 Indirect Impact (7 services):
 â”œâ”€â”€ mobile-app â†’ checkout-service
 â”œâ”€â”€ web-app â†’ checkout-service
 â”œâ”€â”€ customer-support â†’ admin-dashboard
 â””â”€â”€ ... (4 more)

 Total Blast Radius: 12 services
 Risk Level: MEDIUM

 âš ï¸ Recommend: Deploy during maintenance window`
```

---

### Incident Response Workflow

 yaml
 Copy

`incident-responder:
 # Platform-optimized configuration
 config:
 # Auto-gather platform context
 auto_context:
 recent_deployments:
 lookback: 24h
 all_services: true # Not just affected service

 service_health:
 include_dependencies: true
 depth: 3 # 3 levels of dependencies

 metrics:
 queries:
 - error_rate
 - latency_p99
 - saturation
 - traffic

 alerts:
 providers: [pagerduty, datadog]
 lookback: 4h

 # Platform-specific diagnosis
 diagnosis:
 approaches:
 - service_dependency_analysis
 - deployment_correlation
 - resource_exhaustion
 - cascading_failure

 # Remediation options
 remediation:
 actions:
 - type: rollback
 scope: single_service
 require_approval: true

 - type: scale
 scope: single_service
 limits:
 max_replicas: 10

 - type: circuit_breaker
 scope: dependency
 require_approval: false

 - type: traffic_shift
 scope: cluster
 require_approval: true`
```

---

### Change Window Enforcement

 yaml
 Copy

`hooks-change-window:
 description: "Enforce change windows for production"

 windows:
 # Regular maintenance
 maintenance:
 schedule: "0 2 * * 0" # Sunday 2 AM UTC
 duration: 4h
 allowed:
 - infrastructure
 - config
 - deployments

 # Feature releases
 release:
 schedule: "0 10 * * 2,4" # Tue/Thu 10 AM UTC
 duration: 2h
 allowed:
 - deployments
 blocked:
 - database_migrations

 # Freeze periods
 freeze:
 dates:
 - start: "2024-11-28"
 end: "2024-12-02"
 reason: "Black Friday"
 - start: "2024-12-20"
 end: "2025-01-05"
 reason: "Holiday freeze"
 allowed:
 - hotfixes # With P1 approval
 approval_required: p1_manager

 enforcement:
 production:
 outside_window: block
 message: |
 ðŸš« Change blocked: Outside maintenance window

 Next maintenance window: Sunday 2:00 AM UTC
 Or request emergency change approval from P1 manager

 staging:
 outside_window: warn`
```

---

### Usage Examples

#### Example 1: Infrastructure Change

 bash
 Copy

`amplifier --profile platform-team:infrastructure

> Review this Terraform change for the payment-service database

# Automatically:
# 1. Validates Terraform syntax
# 2. Checks IaC policies
# 3. Analyzes blast radius
# 4. Checks change window
# 5. Requires approval if significant`
```

#### Example 2: Incident Investigation

 bash
 Copy

`amplifier --profile platform-team:incident

> payment-service is returning 500 errors

# Automatically:
# 1. Gathers recent deployments (all services)
# 2. Pulls error logs from affected services
# 3. Checks service dependencies
# 4. Correlates with metrics
# 5. Suggests runbooks
# 6. Analyzes blast radius of potential fixes`
```

#### Example 3: Capacity Planning

 bash
 Copy

`amplifier --profile platform-team:capacity

> Forecast capacity needs for Q2

# Uses:
# - 90-day metrics history
# - Service dependency graph
# - Current resource utilization
# - Growth projections
# Produces:
# - Resource forecasts
# - Cost projections
# - Scaling recommendations`
```

---

### Dependencies

#### Required

- Kubernetes cluster access
 
- Terraform state backend
 
- Observability stack (Prometheus/Datadog)
 
- Log aggregation (ES/Loki)
 
#### Optional

- Service mesh (Istio/Linkerd)
 
- Tracing (Jaeger/Zipkin)
 
- Consul service discovery
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Collection Product Team
 collections

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-collection-product-team`

### Overview

Optimized collection for product development teams building user-facing features. Focuses on feature development workflow, product quality, user feedback integration, and rapid iteration.

#### Value Proposition

 | 
 
 | Without | With

 | Context scattered across tools | Unified product context
 
 | Feature specs lost in docs | Living specifications
 
 | Manual acceptance testing | Automated validation
 
 | Slow feedback loops | Rapid iteration support

---

### Collection Contents

 yaml
 Copy

`collection:
 name: product-team
 version: "1.0.0"
 description: "Product development toolkit"

 extends: enterprise-dev # Inherits enterprise security

 # Product-specific modules
 modules:

 # ===== TOOLS =====
 tools:
 # Product context
 - module: tool-product-context
 config:
 sources:
 jira:
 project: "${JIRA_PROJECT}"
 issue_types: [Story, Bug, Epic]
 figma:
 team_id: "${FIGMA_TEAM}"
 auto_fetch_designs: true
 confluence:
 space: "${CONFLUENCE_SPACE}"
 labels: [prd, spec, design]
 analytics:
 provider: amplitude
 project: "${AMPLITUDE_PROJECT}"

 - module: tool-user-feedback
 config:
 sources:
 zendesk:
 enabled: true
 views: ["${ZENDESK_VIEWS}"]
 intercom:
 enabled: true
 app_reviews:
 ios: "${APP_STORE_ID}"
 android: "${PLAY_STORE_ID}"
 sentiment_analysis: true
 auto_categorize: true

 - module: tool-feature-flag
 config:
 provider: launchdarkly # launchdarkly | split | flagsmith
 project: "${LD_PROJECT}"
 environments: [development, staging, production]
 allowed_operations: [read, create, toggle]
 rollout_require_approval: true

 - module: tool-analytics-query
 config:
 providers:
 amplitude:
 api_key: "${AMPLITUDE_API_KEY}"
 project: "${AMPLITUDE_PROJECT}"
 mixpanel:
 token: "${MIXPANEL_TOKEN}"
 max_lookback: 90d

 - module: tool-a11y-checker
 config:
 standards: [WCAG2.1-AA]
 check_on_preview: true

 # Core development (from enterprise-dev)
 - module: tool-codebase-search
 config:
 include_figma: true
 include_specs: true

 - module: tool-test-runner
 config:
 frameworks: [jest, playwright, cypress]
 include_e2e: true
 visual_regression: true

 - module: tool-pr-context
 config:
 include_linked_issues: true
 include_figma_links: true
 include_analytics_impact: true

 # ===== HOOKS =====
 hooks:
 # Product quality
 - module: hooks-acceptance-validator
 config:
 source: jira # Read AC from JIRA stories
 auto_check: true
 link_to_tests: true

 - module: hooks-design-diff
 config:
 figma_integration: true
 warn_on_deviation: true
 tolerance: 5px

 - module: hooks-i18n-checker
 config:
 check_hardcoded_strings: true
 check_missing_translations: true
 default_locale: en
 required_locales: [en, es, fr, de, ja]

 - module: hooks-a11y-validator
 config:
 check_on_component_write: true
 standards: [WCAG2.1-AA]
 severity: warning

 # Feature development
 - module: hooks-feature-context
 config:
 auto_load:
 - linked_story
 - acceptance_criteria
 - design_specs
 - related_feedback

 - module: hooks-flag-awareness
 config:
 detect_flag_usage: true
 warn_stale_flags: true
 stale_threshold: 30d

 # User impact
 - module: hooks-user-impact
 config:
 estimate_affected_users: true
 check_analytics_events: true
 warn_missing_tracking: true

 - module: hooks-rollout-guard
 config:
 require_staged_rollout: true
 stages: [1%, 10%, 50%, 100%]
 auto_rollback_threshold:
 error_rate_increase: 10%
 conversion_drop: 5%

 # Collaboration
 - module: hooks-design-handoff
 config:
 check_figma_status: true
 require_design_approval: true
 track_implementation_status: true

 # ===== SCENARIO TOOLS =====
 scenarios:
 - module: feature-planner
 config:
 include_user_impact: true
 include_analytics_plan: true
 output_format: [tech_spec, jira_tickets, test_plan]

 - module: pr-reviewer
 config:
 check_acceptance_criteria: true
 check_design_match: true
 check_analytics_events: true
 suggest_qa_steps: true

 # Product team profiles
 profiles:
 # Feature development
 feature:
 description: "Building new features"
 tools:
 - tool-product-context
 - tool-codebase-search
 - tool-feature-flag
 - tool-test-runner
 hooks:
 - hooks-feature-context
 - hooks-acceptance-validator
 - hooks-design-diff
 - hooks-i18n-checker
 - hooks-a11y-validator
 - hooks-user-impact

 # Bug fixing
 bugfix:
 description: "Fixing user-reported issues"
 tools:
 - tool-user-feedback
 - tool-analytics-query
 - tool-codebase-search
 - tool-test-runner
 hooks:
 - hooks-feature-context
 - hooks-user-impact

 # Feature launch
 launch:
 description: "Rolling out features"
 tools:
 - tool-feature-flag
 - tool-analytics-query
 - tool-a11y-checker
 hooks:
 - hooks-rollout-guard
 - hooks-flag-awareness
 - hooks-user-impact
 config:
 require_staged_rollout: true

 # Design implementation
 design:
 description: "Implementing designs"
 tools:
 - tool-product-context # Figma access
 - tool-codebase-search
 - tool-a11y-checker
 hooks:
 - hooks-design-diff
 - hooks-design-handoff
 - hooks-a11y-validator
 - hooks-i18n-checker`
```

---

### Product Context Tool

Unified view of all product information:

 yaml
 Copy

`tool-product-context:
 description: "Unified product context from all sources"

 sources:
 jira:
 # Pull story details
 fetch:
 - summary
 - description
 - acceptance_criteria
 - linked_issues
 - comments
 - attachments

 figma:
 # Pull design context
 fetch:
 - frames
 - components
 - design_tokens
 - comments
 - version_history

 confluence:
 # Pull specifications
 fetch:
 - prd_documents
 - technical_specs
 - decision_logs

 analytics:
 # Pull usage data
 fetch:
 - related_events
 - funnel_data
 - user_segments

 example_output: |
 ðŸ“‹ Product Context: PROJ-1234 "Add dark mode toggle"

 ðŸ“ Story Details:
 - Epic: User Preferences (PROJ-100)
 - Sprint: Sprint 23
 - Priority: High
 - Story Points: 5

 âœ… Acceptance Criteria:
 1. Toggle visible in settings menu
 2. Preference persists across sessions
 3. System preference detection
 4. Smooth transition animation

 ðŸŽ¨ Design:
 - Figma: Dark Mode Settings (v3.2)
 - Components: Toggle, ColorScheme
 - Design Tokens: colors.dark.*

 ðŸ“Š Analytics Context:
 - Related events: settings_opened, theme_changed
 - Current dark mode usage: 34% of users
 - Feature requests: 156 in past 90 days

 ðŸ”— Related:
 - PRD: confluence.com/dark-mode-spec
 - Tech Spec: confluence.com/dark-mode-tech
 - Related bugs: PROJ-890, PROJ-912`
```

---

### Acceptance Criteria Validator

 yaml
 Copy

`hooks-acceptance-validator:
 description: "Validate implementation against acceptance criteria"

 process:
 # 1. Extract AC from story
 extract_from:
 - jira_description
 - jira_custom_field
 - linked_confluence

 # 2. Match to tests
 test_mapping:
 auto_detect: true
 patterns:
 - "test.*should.*{criterion}"
 - "it.*{criterion}"

 # 3. Check coverage
 report:
 - criteria_with_tests
 - criteria_without_tests
 - suggested_test_cases

 example_output: |
 âœ… Acceptance Criteria Validation

 Story: PROJ-1234 "Add dark mode toggle"

 Coverage Report:
 âœ… AC1: "Toggle visible in settings menu"
 â†’ test/settings.spec.ts:45 "should show dark mode toggle"

 âœ… AC2: "Preference persists across sessions"
 â†’ test/settings.spec.ts:67 "should persist preference"

 âš ï¸ AC3: "System preference detection"
 â†’ No matching test found
 ðŸ’¡ Suggested: Add test for prefers-color-scheme detection

 âœ… AC4: "Smooth transition animation"
 â†’ test/theme.spec.ts:23 "should animate theme transition"

 Coverage: 3/4 (75%)
 Action Required: Add test for AC3`
```

---

### Design Diff Hook

 yaml
 Copy

`hooks-design-diff:
 description: "Compare implementation to Figma designs"

 process:
 # 1. Detect component changes
 trigger_on:
 - "src/components/**/*.tsx"
 - "src/components/**/*.css"

 # 2. Find linked Figma
 figma_linking:
 by_comment: true # Look for Figma URLs in code
 by_story: true # Check linked JIRA story
 by_name: true # Match component names

 # 3. Compare
 comparison:
 visual_diff: true
 spacing_check: true
 color_check: true
 typography_check: true
 responsive_check: true

 # 4. Report
 tolerance:
 spacing: 4px
 color: 5% # Color difference
 font_size: 2px

 example_output: |
 ðŸŽ¨ Design Comparison: Button.tsx

 Figma Frame: "Primary Button" (v3.2)

 Differences Found:
 âš ï¸ Padding: Expected 16px, found 14px (diff: 2px)
 âš ï¸ Border radius: Expected 8px, found 6px (diff: 2px)
 âœ… Colors: Match
 âœ… Typography: Match
 âœ… Hover state: Match

 Overall: 2 minor deviations
 Design approval: @sarah (designer) notified

 ðŸ’¡ Tip: Use design tokens for consistent spacing`
```

---

### User Impact Analysis

 yaml
 Copy

`hooks-user-impact:
 description: "Estimate user impact of changes"

 analysis:
 # Affected users
 user_estimation:
 from_analytics: true
 events_to_check:
 - page_views
 - feature_usage
 - api_calls

 # Impact assessment
 impact_factors:
 - user_count
 - session_frequency
 - revenue_correlation
 - support_ticket_volume

 example_output: |
 ðŸ‘¥ User Impact Analysis

 Change: PaymentForm.tsx modifications

 Estimated Impact:
 â”œâ”€â”€ Daily Active Users: ~45,000 (12% of DAU)
 â”œâ”€â”€ Monthly Transactions: ~120,000
 â”œâ”€â”€ Revenue Touch: $2.3M/month flows through
 â””â”€â”€ Support Tickets: 34/month related to payments

 Risk Assessment: HIGH
 - Core revenue path
 - High user visibility

 Recommendations:
 1. âœ… Feature flag rollout (staged)
 2. âœ… A/B test conversion impact
 3. âœ… Monitor error rates closely
 4. âš ï¸ Consider QA sign-off`
```

---

### Rollout Guard

 yaml
 Copy

`hooks-rollout-guard:
 description: "Ensure safe feature rollouts"

 stages:
 # Progressive rollout
 - name: canary
 percentage: 1%
 duration: 1h
 metrics:
 error_rate: < 0.1%
 latency_p99: < 500ms

 - name: early_adopters
 percentage: 10%
 duration: 24h
 metrics:
 error_rate: < 0.5%
 conversion: > -2%

 - name: wide_release
 percentage: 50%
 duration: 48h
 metrics:
 error_rate: < 1%
 conversion: > -1%

 - name: full_release
 percentage: 100%
 metrics:
 stable

 auto_rollback:
 triggers:
 - error_rate_spike: 10%
 - conversion_drop: 5%
 - latency_increase: 100%

 actions:
 - disable_flag
 - notify_team
 - create_incident

 example_output: |
 ðŸš€ Rollout Guard: dark-mode-enabled

 Current Stage: early_adopters (10%)
 Duration: 18h of 24h required

 Metrics:
 âœ… Error rate: 0.12% (threshold: < 0.5%)
 âœ… Latency p99: 234ms (threshold: < 500ms)
 âš ï¸ Conversion: -1.8% (threshold: > -2%)

 Status: MONITORING
 Next stage: wide_release (50%) in 6h

 âš ï¸ Note: Conversion slightly down - monitor closely`
```

---

### Feature Flag Awareness

 yaml
 Copy

`hooks-flag-awareness:
 description: "Track and manage feature flags in code"

 detection:
 # Find flag usage
 patterns:
 - "launchDarkly.variation"
 - "useFeatureFlag"
 - "isEnabled"

 # Track flag lifecycle
 lifecycle:
 - created
 - in_development
 - testing
 - rolling_out
 - fully_enabled
 - cleanup_needed

 warnings:
 stale_flags:
 threshold: 30d
 message: "Flag {name} has been at 100% for {days} days - consider cleanup"

 unused_flags:
 threshold: 14d
 message: "Flag {name} not referenced in code - may be obsolete"

 example_output: |
 ðŸš© Feature Flag Status

 Active in this file: src/components/Header.tsx

 1. dark-mode-enabled (IN_DEVELOPMENT)
 Created: 5 days ago
 Rollout: 10%
 Owner: @alice

 2. new-navigation (STALE âš ï¸)
 Created: 45 days ago
 Rollout: 100% for 32 days
 ðŸ’¡ Consider removing flag and cleaning up code

 3. redesigned-header (FULLY_ENABLED)
 Rollout: 100%
 All environments enabled

 Cleanup candidates: 2 flags`
```

---

### Usage Examples

#### Example 1: Feature Development

 bash
 Copy

`amplifier --profile product-team:feature

> Implement PROJ-1234 dark mode toggle

# Automatically loads:
# - Story details and AC
# - Figma designs
# - Related analytics
# - Existing theme code

# As you code:
# - Validates against AC
# - Compares to Figma
# - Checks i18n
# - Validates a11y`
```

#### Example 2: Bug Investigation

 bash
 Copy

`amplifier --profile product-team:bugfix

> Investigate checkout failures from user feedback

# Automatically:
# - Pulls related support tickets
# - Queries analytics for error patterns
# - Finds related code
# - Suggests root causes`
```

#### Example 3: Feature Launch

 bash
 Copy

`amplifier --profile product-team:launch

> Roll out dark mode feature

# Guides through:
# - Staged rollout setup
# - Metrics monitoring
# - A/B test configuration
# - Rollback planning`
```

---

### Dependencies

#### Required

- JIRA/Linear for stories
 
- Analytics platform (Amplitude/Mixpanel)
 
- Feature flag service
 
#### Optional

- Figma API access
 
- Support platform (Zendesk/Intercom)
 
- Visual testing (Percy/Chromatic)
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Integration Api Server
 integrations

Priority: P0 (Foundation)

Status: Draft

Module: `amplifier-api-server`

### Overview

HTTP REST/GraphQL API server wrapping Amplifier capabilities. Enables any integration - web apps, automation platforms (Zapier, n8n), custom applications, and third-party tools. The foundation that enables all other integrations.

#### Why P0?

This is foundational infrastructure. Once an API server exists:

- Web Dashboard can call it
 
- Browser Extension can call it
 
- Mobile apps can call it
 
- Any third-party integration becomes possible
 
#### Value Proposition

 | 
 
 | Without | With

 | CLI-only access | HTTP API for any client
 
 | Local execution only | Remote/hosted execution
 
 | Manual integrations | Zapier/n8n/webhook automation
 
 | Single-user | Multi-tenant capable

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Server â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ REST API â”‚ â”‚ GraphQL API â”‚ â”‚ WebSocket â”‚ â”‚
â”‚ â”‚ /v1/* â”‚ â”‚ /graphql â”‚ â”‚ /ws â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Request Router â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Auth â”‚ â”‚ Rate â”‚ â”‚ Usage â”‚ â”‚
â”‚ â”‚ Middleware â”‚ â”‚ Limiting â”‚ â”‚ Tracking â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Amplifier Core â”‚ â”‚
â”‚ â”‚ (Session Mgmt) â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### API Design

#### REST API

#### Sessions

 bash
 Copy

`# Create session
POST /v1/sessions
{
 "profile": "enterprise-dev:development",
 "context": {
 "project": "my-project",
 "branch": "feature/auth"
 }
}

Response:
{
 "session_id": "sess_abc123",
 "created_at": "2025-01-15T10:30:00Z",
 "profile": "enterprise-dev:development",
 "status": "active"
}

# Execute prompt
POST /v1/sessions/{session_id}/execute
{
 "prompt": "Explain the authentication flow",
 "stream": false
}

Response:
{
 "request_id": "req_xyz789",
 "response": "The authentication flow works as follows...",
 "usage": {
 "prompt_tokens": 150,
 "completion_tokens": 450,
 "total_tokens": 600
 },
 "tool_calls": [
 {"tool": "codebase-search", "query": "auth", "results": 12}
 ]
}

# Stream execution
POST /v1/sessions/{session_id}/execute
{
 "prompt": "Generate a detailed report",
 "stream": true
}

Response: Server-Sent Events
event: token
data: {"content": "The"}

event: token
data: {"content": " report"}

event: tool_call
data: {"tool": "search", "status": "started"}

event: complete
data: {"usage": {...}}

# Get session history
GET /v1/sessions/{session_id}/messages

# Close session
DELETE /v1/sessions/{session_id}`
```

#### Profiles & Collections

 bash
 Copy

`# List profiles
GET /v1/profiles

Response:
{
 "profiles": [
 {"name": "foundation:base", "source": "bundled"},
 {"name": "enterprise-dev:development", "source": "collection"}
 ]
}

# List collections
GET /v1/collections

# Install collection
POST /v1/collections
{
 "source": "git+https://github.com/org/amplifier-collection-custom@main"
}`
```

#### Tools

 bash
 Copy

`# List available tools
GET /v1/tools

# Execute tool directly (no session)
POST /v1/tools/{tool_name}/execute
{
 "input": {...}
}`
```

#### GraphQL API

 graphql
 Copy

`type Query {
 sessions: [Session!]!
 session(id: ID!): Session
 profiles: [Profile!]!
 collections: [Collection!]!
 tools: [Tool!]!
}

type Mutation {
 createSession(profile: String!, context: JSON): Session!
 execute(sessionId: ID!, prompt: String!): ExecutionResult!
 closeSession(sessionId: ID!): Boolean!
 installCollection(source: String!): Collection!
}

type Subscription {
 executionStream(sessionId: ID!, requestId: ID!): StreamEvent!
}

type Session {
 id: ID!
 profile: String!
 status: SessionStatus!
 messages: [Message!]!
 createdAt: DateTime!
}

type ExecutionResult {
 requestId: ID!
 response: String!
 usage: Usage!
 toolCalls: [ToolCall!]!
}

type StreamEvent {
 type: EventType!
 content: String
 toolCall: ToolCall
 usage: Usage
}`
```

#### WebSocket API

For real-time streaming and bidirectional communication:

 javascript
 Copy

`// Connect
ws = new WebSocket('wss://api.example.com/ws');

// Authenticate
ws.send(JSON.stringify({
 type: 'auth',
 token: 'api_key_xxx'
}));

// Create session
ws.send(JSON.stringify({
 type: 'session.create',
 profile: 'enterprise-dev:development'
}));

// Execute with streaming
ws.send(JSON.stringify({
 type: 'execute',
 session_id: 'sess_abc123',
 prompt: 'Analyze this code...'
}));

// Receive events
ws.onmessage = (event) => {
 const data = JSON.parse(event.data);
 switch(data.type) {
 case 'token':
 // Streaming token
 break;
 case 'tool_call':
 // Tool execution update
 break;
 case 'complete':
 // Execution complete
 break;
 }
};`
```

---

### Authentication & Authorization

#### Authentication Methods

 yaml
 Copy

`auth:
 methods:
 # API Key (simple)
 - type: api_key
 header: X-API-Key

 # Bearer Token (JWT)
 - type: bearer
 issuer: https://auth.example.com
 audience: amplifier-api

 # OAuth2
 - type: oauth2
 provider: github
 scopes: [read:user, repo]`
```

#### Authorization Model

 yaml
 Copy

`authorization:
 # Role-based access
 roles:
 admin:
 - "*"
 developer:
 - "sessions:*"
 - "profiles:read"
 - "tools:execute"
 readonly:
 - "sessions:read"
 - "profiles:read"

 # Resource-level permissions
 resources:
 sessions:
 - create
 - read
 - execute
 - delete
 profiles:
 - read
 - write
 collections:
 - read
 - install
 - remove`
```

---

### Rate Limiting & Quotas

 yaml
 Copy

`rate_limiting:
 # Per-user limits
 default:
 requests_per_minute: 60
 tokens_per_day: 100000
 concurrent_sessions: 5

 # Tier-based
 tiers:
 free:
 requests_per_minute: 10
 tokens_per_day: 10000
 pro:
 requests_per_minute: 100
 tokens_per_day: 500000
 enterprise:
 requests_per_minute: 1000
 tokens_per_day: unlimited

 # Response headers
 headers:
 X-RateLimit-Limit: "60"
 X-RateLimit-Remaining: "45"
 X-RateLimit-Reset: "1705312800"`
```

---

### Implementation

#### Server Setup (FastAPI)

 python
 Copy

`# server.py
from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from amplifier_core import AmplifierSession
from .auth import verify_api_key, get_current_user
from .sessions import SessionManager
from .rate_limit import RateLimiter

app = FastAPI(
 title="Amplifier API",
 version="1.0.0",
 description="HTTP API for Amplifier AI Agent Framework"
)

# Middleware
app.add_middleware(
 CORSMiddleware,
 allow_origins=["*"],
 allow_methods=["*"],
 allow_headers=["*"]
)

session_manager = SessionManager()
rate_limiter = RateLimiter()

@app.post("/v1/sessions")
async def create_session(
 request: CreateSessionRequest,
 user: User = Depends(get_current_user)
):
 """Create a new Amplifier session."""

 # Check rate limits
 await rate_limiter.check(user.id, "sessions:create")

 # Create session
 session = await session_manager.create(
 user_id=user.id,
 profile=request.profile,
 context=request.context
 )

 return SessionResponse(
 session_id=session.id,
 created_at=session.created_at,
 profile=request.profile,
 status="active"
 )

@app.post("/v1/sessions/{session_id}/execute")
async def execute(
 session_id: str,
 request: ExecuteRequest,
 user: User = Depends(get_current_user)
):
 """Execute a prompt in a session."""

 session = await session_manager.get(session_id, user.id)
 if not session:
 raise HTTPException(404, "Session not found")

 # Check rate limits
 await rate_limiter.check(user.id, "sessions:execute")

 if request.stream:
 return StreamingResponse(
 session.execute_stream(request.prompt),
 media_type="text/event-stream"
 )
 else:
 result = await session.execute(request.prompt)
 return ExecutionResponse(
 request_id=result.request_id,
 response=result.response,
 usage=result.usage,
 tool_calls=result.tool_calls
 )

@app.get("/v1/profiles")
async def list_profiles(user: User = Depends(get_current_user)):
 """List available profiles."""

 from amplifier_profiles import ProfileLoader

 loader = ProfileLoader(search_paths=get_search_paths(user))
 profiles = loader.list_profiles()

 return {"profiles": profiles}`
```

#### Session Manager

 python
 Copy

`# sessions.py
from amplifier_core import AmplifierSession
from amplifier_profiles import ProfileLoader
import asyncio
from typing import AsyncIterator

class SessionManager:
 """Manages Amplifier sessions for API users."""

 def __init__(self):
 self.sessions: dict[str, ManagedSession] = {}
 self.cleanup_task = asyncio.create_task(self._cleanup_loop())

 async def create(
 self,
 user_id: str,
 profile: str,
 context: dict | None = None
 ) -> ManagedSession:
 """Create a new managed session."""

 # Load profile
 loader = ProfileLoader(search_paths=self._get_paths(user_id))
 profile_config = loader.load_profile(profile)

 # Create Amplifier session
 amplifier_session = AmplifierSession(config=profile_config.to_mount_plan())
 await amplifier_session.__aenter__()

 # Wrap in managed session
 session = ManagedSession(
 id=generate_session_id(),
 user_id=user_id,
 amplifier_session=amplifier_session,
 created_at=datetime.utcnow()
 )

 self.sessions[session.id] = session
 return session

 async def get(self, session_id: str, user_id: str) -> ManagedSession | None:
 """Get session if owned by user."""

 session = self.sessions.get(session_id)
 if session and session.user_id == user_id:
 session.last_accessed = datetime.utcnow()
 return session
 return None

 async def close(self, session_id: str, user_id: str) -> bool:
 """Close a session."""

 session = await self.get(session_id, user_id)
 if session:
 await session.amplifier_session.__aexit__(None, None, None)
 del self.sessions[session_id]
 return True
 return False

 async def _cleanup_loop(self):
 """Clean up idle sessions."""

 while True:
 await asyncio.sleep(60)

 now = datetime.utcnow()
 idle_threshold = timedelta(minutes=30)

 for session_id, session in list(self.sessions.items()):
 if now - session.last_accessed > idle_threshold:
 await self.close(session_id, session.user_id)

class ManagedSession:
 """Wrapper around AmplifierSession with metadata."""

 def __init__(
 self,
 id: str,
 user_id: str,
 amplifier_session: AmplifierSession,
 created_at: datetime
 ):
 self.id = id
 self.user_id = user_id
 self.amplifier_session = amplifier_session
 self.created_at = created_at
 self.last_accessed = created_at
 self.messages: list[dict] = []

 async def execute(self, prompt: str) -> ExecutionResult:
 """Execute prompt and return result."""

 self.messages.append({"role": "user", "content": prompt})

 response = await self.amplifier_session.execute(prompt)

 self.messages.append({"role": "assistant", "content": response.text})

 return ExecutionResult(
 request_id=generate_request_id(),
 response=response.text,
 usage=response.usage,
 tool_calls=response.tool_calls
 )

 async def execute_stream(self, prompt: str) -> AsyncIterator[str]:
 """Execute prompt with streaming."""

 self.messages.append({"role": "user", "content": prompt})

 full_response = ""

 async for event in self.amplifier_session.execute_stream(prompt):
 if event.type == "token":
 full_response += event.content
 yield f"event: token\ndata: {json.dumps({'content': event.content})}\n\n"
 elif event.type == "tool_call":
 yield f"event: tool_call\ndata: {json.dumps(event.data)}\n\n"

 self.messages.append({"role": "assistant", "content": full_response})

 yield f"event: complete\ndata: {json.dumps({'usage': event.usage})}\n\n"`
```

---

### Deployment Options

#### Docker

 dockerfile
 Copy

`FROM python:3.12-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "amplifier_api_server:app", "--host", "0.0.0.0", "--port", "8000"]`
```

#### Kubernetes

 yaml
 Copy

`apiVersion: apps/v1
kind: Deployment
metadata:
 name: amplifier-api
spec:
 replicas: 3
 selector:
 matchLabels:
 app: amplifier-api
 template:
 metadata:
 labels:
 app: amplifier-api
 spec:
 containers:
 - name: api
 image: amplifier-api-server:latest
 ports:
 - containerPort: 8000
 env:
 - name: AMPLIFIER_API_KEY
 valueFrom:
 secretKeyRef:
 name: amplifier-secrets
 key: api-key
 resources:
 requests:
 memory: "256Mi"
 cpu: "250m"
 limits:
 memory: "1Gi"
 cpu: "1000m"
---
apiVersion: v1
kind: Service
metadata:
 name: amplifier-api
spec:
 selector:
 app: amplifier-api
 ports:
 - port: 80
 targetPort: 8000
 type: LoadBalancer`
```

---

### Configuration

 yaml
 Copy

`# config.yaml
server:
 host: 0.0.0.0
 port: 8000
 workers: 4

api:
 version: v1
 base_path: /v1

auth:
 type: api_key # api_key | bearer | oauth2

rate_limiting:
 enabled: true
 backend: redis # memory | redis
 redis_url: redis://localhost:6379

sessions:
 max_per_user: 10
 idle_timeout: 30m
 max_duration: 24h

logging:
 level: info
 format: json

metrics:
 enabled: true
 endpoint: /metrics

cors:
 allowed_origins: ["*"]
 allowed_methods: ["GET", "POST", "DELETE"]`
```

---

### SDK Generation

The API is designed for automatic SDK generation:

 bash
 Copy

`# Generate OpenAPI spec
amplifier-api-server openapi > openapi.json

# Generate TypeScript SDK
npx openapi-typescript-codegen --input openapi.json --output ./sdk/typescript

# Generate Python SDK
openapi-python-client generate --path openapi.json --output ./sdk/python`
```

---

### Events

 | 
 
 | Event | Description | Data

 | `api:request` | API request received | method, path, user_id
 
 | `api:response` | API response sent | status, duration_ms
 
 | `api:error` | API error occurred | error, status
 
 | `session:created` | Session created via API | session_id, user_id
 
 | `session:executed` | Prompt executed | session_id, tokens
 
 | `rate_limit:exceeded` | Rate limit hit | user_id, limit

---

### Open Questions

- Multi-tenancy: Shared infrastructure vs isolated?
 
- Billing integration: How to track usage for billing?
 
- Webhook support: Async notifications for long-running tasks?
 
- File uploads: Support for file context (documents, images)?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Integration Browser Extension
 integrations

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-browser-extension`

### Overview

Browser extension (Chrome, Firefox, Edge) providing Amplifier assistance where developers already work: GitHub PRs, GitLab MRs, Stack Overflow, documentation sites, and any web page with code. Context-aware AI assistance without leaving the browser.

#### Value Proposition

 | 
 
 | Without | With

 | Copy code to terminal, run Amplifier, copy back | Inline assistance on any page
 
 | Context-switch between tools | AI where you already work
 
 | Manual code review | PR review in GitHub UI
 
 | Generic web AI | Codebase-aware with local context

---

### Features

#### 1. GitHub PR Review Assistant

Inline PR review assistance directly in GitHub UI.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pull Request #234: Add payment processing â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ Files changed (12) [Amplifier: Review PR â–¼] â”‚
â”‚ â”‚
â”‚ src/payments/processor.ts +142 -23 â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚ 45 â”‚ async processPayment(order: Order) { â”‚
â”‚ â”‚ 46 â”‚+ const validated = await this.validate(order); â”‚
â”‚ â”‚ 47 â”‚+ if (!validated) { â”‚
â”‚ â”‚ 48 â”‚+ throw new Error("Invalid order"); â”‚
â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ â”‚ â”‚ ðŸ¤– Amplifier â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ âš ï¸ Generic error message may leak validation â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ details. Consider using a custom error type: â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ ```ts â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ throw new ValidationError(validated.errors); â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ ``` â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ [Add Comment] [Dismiss] [Ask Follow-up] â”‚ â”‚
â”‚ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ 49 â”‚+ } â”‚
â”‚ â”‚ 50 â”‚+ return this.stripe.charge(order.total); â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 2. Code Explanation Popup

Select any code on any page for instant explanation.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stack Overflow: How to implement retry logic â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ const retry = async (fn, retries = 3) => { â”‚â”‚
â”‚ â”‚ for (let i = 0; i < retries; i++) { â”‚â”‚
â”‚ â”‚ try { â”‚â”‚
â”‚ â”‚ return await fn(); â† [selected text] â”‚â”‚
â”‚ â”‚ } catch (e) { â”‚â”‚
â”‚ â”‚ if (i === retries - 1) throw e; â”‚â”‚
â”‚ â”‚ await new Promise(r => setTimeout(r, 1000 * 2 ** i)); â”‚â”‚
â”‚ â”‚ } â”‚â”‚
â”‚ â”‚ } â”‚â”‚
â”‚ â”‚ }; â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ðŸ¤– Amplifier [Ã—] â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ This is an **exponential backoff retry** pattern: â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â€¢ Attempts the function up to 3 times â”‚ â”‚
â”‚ â”‚ â€¢ On failure, waits exponentially: 1s â†’ 2s â†’ 4s â”‚ â”‚
â”‚ â”‚ â€¢ The `2 ** i` creates the exponential growth â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ **In your codebase**: Similar pattern in â”‚ â”‚
â”‚ â”‚ `src/utils/network.ts:45` but with jitter. â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ [Copy] [Explain More] [Find in Codebase] â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 3. Documentation Helper

Contextual assistance when reading documentation.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ React Docs: useEffect Hook â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ useEffect lets you synchronize a component with an external system.â”‚
â”‚ â”‚
â”‚ useEffect(setup, dependencies?) â”‚
â”‚ â”‚
â”‚ Parameters: â”‚
â”‚ â€¢ setup: Function with your Effect's logic... â”‚
â”‚ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ ðŸ¤– Amplifier Assistant [Expand] â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ In **your codebase**, useEffect is used in: â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ â€¢ `UserDashboard.tsx` - fetching user data â”‚
â”‚ â”‚ â€¢ `PaymentForm.tsx` - Stripe integration â”‚
â”‚ â”‚ â€¢ `NotificationBell.tsx` - WebSocket subscription â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ [Show Examples] [Ask Question] â”‚
â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 4. GitLab MR Assistant

Same functionality for GitLab Merge Requests.

#### 5. Sidebar Chat

Persistent sidebar for extended conversations.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”
â”‚ Any Web Page â”‚ ðŸ¤–â”‚
â”‚ â”‚ â”‚
â”‚ [Page content...] â”‚ A â”‚
â”‚ â”‚ m â”‚
â”‚ â”‚ p â”‚
â”‚ â”‚ l â”‚
â”‚ â”‚ i â”‚
â”‚ â”‚ f â”‚
â”‚ â”‚ i â”‚
â”‚ â”‚ e â”‚
â”‚ â”‚ r â”‚
â”‚ â”‚ â”‚
â”‚ â”‚[â–¶]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”˜

[Click â–¶ to expand]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Any Web Page â”‚ ðŸ¤– Chat â”‚
â”‚ â”‚ â”‚
â”‚ [Page content...] â”‚ How does â”‚
â”‚ â”‚ this code â”‚
â”‚ â”‚ compare â”‚
â”‚ â”‚ to our â”‚
â”‚ â”‚ impl? â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ [Send] â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ Based on â”‚
â”‚ â”‚ your code â”‚
â”‚ â”‚ base... â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Browser Extension â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Content â”‚ â”‚ Background â”‚ â”‚ Popup/ â”‚ â”‚
â”‚ â”‚ Scripts â”‚ â”‚ Service â”‚ â”‚ Sidebar â”‚ â”‚
â”‚ â”‚ (per page) â”‚ â”‚ Worker â”‚ â”‚ UI â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Message Bridge â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Local CLI â”‚ â”‚ API Server â”‚ â”‚ Local â”‚ â”‚
â”‚ â”‚ (Native â”‚ â”‚ (Remote) â”‚ â”‚ Storage â”‚ â”‚
â”‚ â”‚ Messaging)â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Site-Specific Features

#### GitHub Integration

 typescript
 Copy

`// Content script for github.com
const githubFeatures = {
 // PR review
 prReview: {
 selector: '.js-diff-progressive-container',
 actions: ['review_file', 'review_line', 'suggest_fix']
 },

 // Issue assistance
 issues: {
 selector: '.js-issue-body',
 actions: ['analyze_issue', 'suggest_solution', 'find_related']
 },

 // Code browsing
 codeView: {
 selector: '.blob-code',
 actions: ['explain', 'find_usages', 'suggest_improvements']
 },

 // Search enhancement
 search: {
 selector: '.search-results',
 actions: ['filter_by_context', 'explain_results']
 }
};`
```

#### GitLab Integration

 typescript
 Copy

`// Content script for gitlab.com
const gitlabFeatures = {
 mrReview: {
 selector: '.diff-content',
 actions: ['review_file', 'review_line', 'suggest_fix']
 },

 issues: {
 selector: '.description',
 actions: ['analyze_issue', 'suggest_solution']
 },

 pipelines: {
 selector: '.ci-job-trace',
 actions: ['explain_failure', 'suggest_fix']
 }
};`
```

#### Stack Overflow Integration

 typescript
 Copy

`// Content script for stackoverflow.com
const stackOverflowFeatures = {
 questions: {
 selector: '.question',
 actions: ['relate_to_codebase', 'find_existing_solution']
 },

 answers: {
 selector: '.answer',
 actions: ['evaluate_for_codebase', 'adapt_to_style']
 },

 codeBlocks: {
 selector: 'pre code',
 actions: ['explain', 'compare_to_codebase', 'adapt']
 }
};`
```

---

### Implementation

#### Manifest V3 Structure

 json
 Copy

`// manifest.json
{
 "manifest_version": 3,
 "name": "Amplifier",
 "version": "1.0.0",
 "description": "AI-powered code assistance in your browser",

 "permissions": [
 "storage",
 "activeTab",
 "contextMenus",
 "sidePanel",
 "nativeMessaging"
 ],

 "host_permissions": [
 "https://github.com/*",
 "https://gitlab.com/*",
 "https://*.gitlab.io/*",
 "https://stackoverflow.com/*",
 "https://docs.microsoft.com/*"
 ],

 "background": {
 "service_worker": "background.js",
 "type": "module"
 },

 "content_scripts": [
 {
 "matches": ["https://github.com/*"],
 "js": ["content/github.js"],
 "css": ["content/github.css"]
 },
 {
 "matches": ["https://gitlab.com/*", "https://*.gitlab.io/*"],
 "js": ["content/gitlab.js"],
 "css": ["content/gitlab.css"]
 },
 {
 "matches": ["https://stackoverflow.com/*"],
 "js": ["content/stackoverflow.js"],
 "css": ["content/stackoverflow.css"]
 },
 {
 "matches": ["<all_urls>"],
 "js": ["content/universal.js"],
 "css": ["content/universal.css"]
 }
 ],

 "side_panel": {
 "default_path": "sidepanel.html"
 },

 "action": {
 "default_popup": "popup.html",
 "default_icon": {
 "16": "icons/icon16.png",
 "48": "icons/icon48.png",
 "128": "icons/icon128.png"
 }
 },

 "icons": {
 "16": "icons/icon16.png",
 "48": "icons/icon48.png",
 "128": "icons/icon128.png"
 },

 "commands": {
 "explain-selection": {
 "suggested_key": {
 "default": "Ctrl+Shift+E",
 "mac": "Command+Shift+E"
 },
 "description": "Explain selected code"
 },
 "open-sidebar": {
 "suggested_key": {
 "default": "Ctrl+Shift+A",
 "mac": "Command+Shift+A"
 },
 "description": "Open Amplifier sidebar"
 }
 }
}`
```

#### Background Service Worker

 typescript
 Copy

`// background.js
import { AmplifierClient } from './lib/client';

const client = new AmplifierClient();

// Handle messages from content scripts
chrome.runtime.onMessage.addListener((message, sender, sendResponse) => {
 if (message.type === 'execute') {
 handleExecute(message, sender).then(sendResponse);
 return true; // Will respond asynchronously
 }

 if (message.type === 'review_pr') {
 handlePRReview(message, sender).then(sendResponse);
 return true;
 }

 if (message.type === 'explain_code') {
 handleExplainCode(message, sender).then(sendResponse);
 return true;
 }
});

async function handleExecute(message, sender) {
 const { prompt, context } = message;

 // Add page context
 const fullContext = {
 ...context,
 url: sender.tab?.url,
 title: sender.tab?.title
 };

 try {
 const result = await client.execute({
 prompt,
 context: fullContext
 });
 return { success: true, response: result.response };
 } catch (error) {
 return { success: false, error: error.message };
 }
}

async function handlePRReview(message, sender) {
 const { prUrl, diff } = message;

 const result = await client.execute({
 prompt: `Review this pull request for issues:\n\nURL: ${prUrl}\n\nDiff:\n${diff}`,
 profile: 'enterprise-dev:review',
 context: {
 type: 'pr_review',
 url: prUrl
 }
 });

 return { success: true, review: result.response };
}

async function handleExplainCode(message, sender) {
 const { code, language, pageContext } = message;

 const result = await client.execute({
 prompt: `Explain this ${language || 'code'}:\n\n${code}`,
 context: {
 type: 'code_explanation',
 page: pageContext
 }
 });

 return { success: true, explanation: result.response };
}

// Context menu
chrome.contextMenus.create({
 id: 'amplifier-explain',
 title: 'Explain with Amplifier',
 contexts: ['selection']
});

chrome.contextMenus.onClicked.addListener((info, tab) => {
 if (info.menuItemId === 'amplifier-explain') {
 chrome.tabs.sendMessage(tab.id, {
 type: 'explain_selection',
 selection: info.selectionText
 });
 }
});`
```

#### GitHub Content Script

 typescript
 Copy

`// content/github.js
import { createPopup, createInlineWidget } from '../lib/ui';

// Detect PR page
if (window.location.pathname.includes('/pull/')) {
 initPRReview();
}

function initPRReview() {
 // Add review button to PR header
 const prHeader = document.querySelector('.gh-header-actions');
 if (prHeader) {
 const reviewButton = document.createElement('button');
 reviewButton.className = 'btn btn-sm';
 reviewButton.innerHTML = 'ðŸ¤– Amplifier Review';
 reviewButton.onclick = startPRReview;
 prHeader.prepend(reviewButton);
 }

 // Add inline review on diff lines
 observeDiffLines();
}

async function startPRReview() {
 const prUrl = window.location.href;
 const diff = extractDiff();

 const response = await chrome.runtime.sendMessage({
 type: 'review_pr',
 prUrl,
 diff
 });

 if (response.success) {
 displayReviewResults(response.review);
 }
}

function observeDiffLines() {
 // Watch for diff content to load
 const observer = new MutationObserver((mutations) => {
 mutations.forEach((mutation) => {
 mutation.addedNodes.forEach((node) => {
 if (node.classList?.contains('blob-code-addition') ||
 node.classList?.contains('blob-code-deletion')) {
 addLineActions(node);
 }
 });
 });
 });

 observer.observe(document.body, {
 childList: true,
 subtree: true
 });
}

function addLineActions(lineElement) {
 const actionButton = document.createElement('button');
 actionButton.className = 'amplifier-line-action';
 actionButton.innerHTML = 'ðŸ¤–';
 actionButton.title = 'Analyze with Amplifier';
 actionButton.onclick = (e) => {
 e.stopPropagation();
 analyzeLineContext(lineElement);
 };

 lineElement.prepend(actionButton);
}

async function analyzeLineContext(lineElement) {
 const code = extractLineContext(lineElement);

 const response = await chrome.runtime.sendMessage({
 type: 'explain_code',
 code,
 language: detectLanguage(),
 pageContext: {
 file: getCurrentFile(),
 line: getCurrentLine(lineElement),
 pr: getPRNumber()
 }
 });

 if (response.success) {
 createInlineWidget(lineElement, response.explanation);
 }
}

// Universal code selection handler
document.addEventListener('mouseup', async (e) => {
 const selection = window.getSelection().toString().trim();

 if (selection.length > 10 && looksLikeCode(selection)) {
 // Show quick action popup
 const popup = createPopup({
 x: e.pageX,
 y: e.pageY,
 actions: [
 { label: 'Explain', action: () => explainSelection(selection) },
 { label: 'Find in codebase', action: () => findInCodebase(selection) },
 { label: 'Improve', action: () => suggestImprovement(selection) }
 ]
 });
 }
});

function looksLikeCode(text) {
 // Heuristics to detect code
 const codeIndicators = [
 /function\s+\w+/,
 /const\s+\w+\s*=/,
 /let\s+\w+\s*=/,
 /var\s+\w+\s*=/,
 /class\s+\w+/,
 /import\s+.*from/,
 /=>/,
 /\{\s*\n/,
 /\)\s*\{/
 ];

 return codeIndicators.some(pattern => pattern.test(text));
}`
```

#### Sidebar Panel

 html
 Copy

`<!-- sidepanel.html -->
<!DOCTYPE html>
<html>
<head>
 <link rel="stylesheet" href="sidepanel.css">
</head>
<body>
 <div id="amplifier-sidebar">
 <header>
 <h1>ðŸ¤– Amplifier</h1>
 <button id="settings-btn">âš™ï¸</button>
 </header>

 <div id="context-info">
 <span id="page-type">GitHub PR</span>
 <span id="connection-status">â— Connected</span>
 </div>

 <div id="chat-messages"></div>

 <div id="chat-input-container">
 <textarea id="chat-input" placeholder="Ask about this page..."></textarea>
 <button id="send-btn">Send</button>
 </div>

 <div id="quick-actions">
 <button data-action="explain-page">Explain Page</button>
 <button data-action="review-code">Review Code</button>
 <button data-action="find-related">Find Related</button>
 </div>
 </div>

 <script src="sidepanel.js" type="module"></script>
</body>
</html>`
```

---

### Connection Modes

#### 1. Local CLI (Native Messaging)

Direct connection to local Amplifier CLI:

 json
 Copy

`// com.amplifier.native.json (Native messaging host)
{
 "name": "com.amplifier.native",
 "description": "Amplifier Native Messaging Host",
 "path": "/usr/local/bin/amplifier-native-host",
 "type": "stdio",
 "allowed_origins": [
 "chrome-extension://[extension-id]/"
 ]
}`
```

#### 2. API Server (Remote)

Connect to hosted Amplifier API:

 typescript
 Copy

`// lib/client.ts
class AmplifierClient {
 private mode: 'native' | 'api';
 private apiUrl?: string;
 private apiKey?: string;

 async connect() {
 const settings = await chrome.storage.sync.get(['mode', 'apiUrl', 'apiKey']);

 this.mode = settings.mode || 'api';
 this.apiUrl = settings.apiUrl;
 this.apiKey = settings.apiKey;
 }

 async execute(request: ExecuteRequest): Promise<ExecuteResponse> {
 if (this.mode === 'native') {
 return this.executeNative(request);
 } else {
 return this.executeApi(request);
 }
 }

 private async executeNative(request: ExecuteRequest) {
 return new Promise((resolve, reject) => {
 chrome.runtime.sendNativeMessage(
 'com.amplifier.native',
 request,
 (response) => {
 if (chrome.runtime.lastError) {
 reject(new Error(chrome.runtime.lastError.message));
 } else {
 resolve(response);
 }
 }
 );
 });
 }

 private async executeApi(request: ExecuteRequest) {
 const response = await fetch(`${this.apiUrl}/v1/sessions/execute`, {
 method: 'POST',
 headers: {
 'Content-Type': 'application/json',
 'X-API-Key': this.apiKey
 },
 body: JSON.stringify(request)
 });

 return response.json();
 }
}`
```

---

### Configuration

 typescript
 Copy

`// Extension settings
interface ExtensionSettings {
 // Connection
 mode: 'native' | 'api';
 apiUrl?: string;
 apiKey?: string;

 // Features
 features: {
 githubPrReview: boolean;
 gitlabMrReview: boolean;
 codeExplanation: boolean;
 documentationHelper: boolean;
 sidebar: boolean;
 };

 // UI
 ui: {
 theme: 'light' | 'dark' | 'system';
 sidebarPosition: 'left' | 'right';
 popupDelay: number;
 };

 // Privacy
 privacy: {
 sendPageContent: boolean;
 sendSelectionOnly: boolean;
 excludedDomains: string[];
 };

 // Keyboard shortcuts
 shortcuts: {
 explain: string;
 openSidebar: string;
 review: string;
 };
}`
```

---

### Privacy & Security

#### Content Handling

 typescript
 Copy

`// Only send what's necessary
function sanitizeContext(context: PageContext): SanitizedContext {
 return {
 // Never send full page HTML
 url: context.url,
 title: context.title,

 // Only selected code/text
 selection: context.selection,

 // Metadata only
 language: context.language,
 fileType: context.fileType,

 // No cookies, local storage, or sensitive data
 };
}

// Exclude sensitive sites
const EXCLUDED_DOMAINS = [
 'mail.google.com',
 'online.banking.*',
 '*.1password.com',
 '*.lastpass.com'
];`
```

#### Permissions

Request only necessary permissions:

- `activeTab`: Only access current tab when user invokes
 
- `storage`: Save user settings
 
- `contextMenus`: Right-click menu
 
- `sidePanel`: Sidebar chat
 
---

### Events

 | 
 
 | Event | Description | Data

 | `extension:installed` | Extension installed | version
 
 | `extension:activated` | Extension activated on page | url, site_type
 
 | `pr:review_started` | PR review initiated | pr_url
 
 | `code:explained` | Code explanation shown | language, length
 
 | `sidebar:opened` | Sidebar opened | page_type

---

### Open Questions

- Codebase context: How to efficiently sync local codebase context?
 
- Rate limiting: Per-site or global limits?
 
- Offline mode: Cache explanations for offline viewing?
 
- Team features: Shared reviews, team settings?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Integration Electron App
 integrations

Priority: P2 (Enhancement)

Status: Draft

Module: `amplifier-desktop`

### Overview

Standalone Electron desktop application for Amplifier. Full-featured GUI experience with offline capability, system tray integration, global hotkeys, native file access, and seamless local CLI integration. Cross-platform (macOS, Windows, Linux).

#### Value Proposition

 | 
 
 | Without | With

 | Terminal-only interface | Rich GUI experience
 
 | Must be online | Offline-capable with local models
 
 | No system integration | Tray, hotkeys, notifications
 
 | Web browser required | Native app performance

---

### Features

#### 1. Main Chat Interface

Full-featured chat with rich rendering.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âš¡ Amplifier â”€ â–¡ Ã— â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ Sessions â”‚ Session: Code Analysis â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ Profile: enterprise-dev â€¢ claude-sonnet â”‚
â”‚ â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚ â— Code â”‚ â”‚
â”‚ â”‚ Analysis â”‚ ðŸ‘¤ You 10:30 AM â”‚
â”‚ â”‚ â”‚ How does the authentication system work? â”‚
â”‚ â”‚ â—‹ PR Review â”‚ â”‚
â”‚ â”‚ #234 â”‚ ðŸ¤– Amplifier 10:31 AM â”‚
â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ â—‹ Incident â”‚ â”‚ The authentication system uses JWT tokens: â”‚ â”‚
â”‚ â”‚ 2025-01-15 â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ **1. Login Flow** â”‚ â”‚
â”‚ â”‚ + New â”‚ â”‚ ```typescript â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ // src/auth/login.ts:23 â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ async function login(creds: Credentials) { â”‚ â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”‚ const user = await validate(creds); â”‚ â”‚
â”‚ â”‚ Collections â”‚ â”‚ return generateJWT(user); â”‚ â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”‚ } â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ ``` â”‚ â”‚
â”‚ â”‚ ðŸ“¦ enterpriseâ”‚ â”‚ â”‚ â”‚
â”‚ â”‚ ðŸ“¦ foundationâ”‚ â”‚ [Open in Editor] [Copy] [Explain More] â”‚ â”‚
â”‚ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚ â”‚ â”‚ Ask about your code... [ðŸ“Ž] [â†µ] â”‚ â”‚
â”‚ â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 2. System Tray Integration

Quick access from system tray.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ¤– â† [System Tray Icon] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ðŸ” Quick Query âŒ˜+Space â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚ Recent Sessions â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ Code Analysis â”‚ â”‚
â”‚ â”‚ â”œâ”€â”€ PR Review #234 â”‚ â”‚
â”‚ â”‚ â””â”€â”€ Incident 2025-01-15 â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚ â—‹ Status: Connected â”‚ â”‚
â”‚ â”‚ â—‹ Profile: enterprise-dev â”‚ â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚ â”‚ Open Amplifier â”‚ â”‚
â”‚ â”‚ Settings â”‚ â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”‚
â”‚ â”‚ Quit â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 3. Quick Query Spotlight

Global hotkey for instant queries.

 text
 Copy

`[Press âŒ˜+Space anywhere]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”‚
â”‚ ðŸ¤– Amplifier Quick Query â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ How does the payment retry logic work? â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â”‚ Recent: â”‚
â”‚ â€¢ What tests cover UserService? â”‚
â”‚ â€¢ Explain the caching strategy â”‚
â”‚ â€¢ Find dead code in src/utils â”‚
â”‚ â”‚
â”‚ [â†µ to search] [âŽ‹ to close] [âŒ˜+â†µ open in main window] â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 4. Project Workspace

Multi-project support with workspace management.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Workspaces [+] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ ðŸ“ payment-service â”‚â”‚
â”‚ â”‚ /Users/dev/projects/payment-service â”‚â”‚
â”‚ â”‚ Profile: enterprise-dev:backend â”‚â”‚
â”‚ â”‚ Last active: 2 hours ago â”‚â”‚
â”‚ â”‚ [Open] [Configure] [Remove] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ ðŸ“ frontend-app â”‚â”‚
â”‚ â”‚ /Users/dev/projects/frontend-app â”‚â”‚
â”‚ â”‚ Profile: enterprise-dev:frontend â”‚â”‚
â”‚ â”‚ Last active: Yesterday â”‚â”‚
â”‚ â”‚ [Open] [Configure] [Remove] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ ðŸ“ infrastructure â”‚â”‚
â”‚ â”‚ /Users/dev/projects/infra â”‚â”‚
â”‚ â”‚ Profile: platform-team:terraform â”‚â”‚
â”‚ â”‚ Last active: 3 days ago â”‚â”‚
â”‚ â”‚ [Open] [Configure] [Remove] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ [+ Add Workspace] â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 5. Offline Mode

Local model support for offline operation.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âš¡ Amplifier [Offline Mode] â”€ â–¡ Ã— â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ âš ï¸ Offline Mode Active â”‚
â”‚ Using local model: codellama-13b â”‚
â”‚ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ ðŸ‘¤ You 10:30 AM â”‚
â”‚ Explain this function: â”‚
â”‚ ```ts â”‚
â”‚ function processPayment(order: Order) { ... } â”‚
â”‚ ``` â”‚
â”‚ â”‚
â”‚ ðŸ¤– Amplifier (Local) 10:31 AM â”‚
â”‚ This function processes a payment for an order... â”‚
â”‚ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ [Reconnect] [Switch to Online] â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 6. Collection Manager

Visual collection management.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Collections [âš™ï¸] [+] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ Installed â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ðŸ“¦ enterprise-dev v1.2.0 â”‚ â”‚
â”‚ â”‚ Enterprise development tools and profiles â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ Profiles: base, development, review, ci â”‚ â”‚
â”‚ â”‚ Agents: zen-architect, bug-hunter, code-reviewer â”‚ â”‚
â”‚ â”‚ Tools: codebase-search, pr-context, jira-ops â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ [Update Available: v1.3.0] [Configure] [Remove] â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ðŸ“¦ foundation v2.0.0 â”‚ â”‚
â”‚ â”‚ Core profiles and base configurations â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ Profiles: base, minimal â”‚ â”‚
â”‚ â”‚ Agents: general-assistant â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ [Up to date] â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â”‚ Browse Collections â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ [Search collections...] â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Electron App â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Main Process â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ Window â”‚ â”‚ Tray â”‚ â”‚ Hotkey â”‚ â”‚ IPC â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ Manager â”‚ â”‚ Manager â”‚ â”‚ Manager â”‚ â”‚ Handler â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â–¼ â–¼ â–¼ â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ Amplifier â”‚ â”‚ Local â”‚ â”‚ File â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ CLI â”‚ â”‚ Models â”‚ â”‚ System â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ IPC â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Renderer Process â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ Chat â”‚ â”‚ Workspaceâ”‚ â”‚Collectionâ”‚ â”‚ Settings â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ View â”‚ â”‚ View â”‚ â”‚ View â”‚ â”‚ View â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚ React + TypeScript â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Tech Stack

 yaml
 Copy

`electron:
 version: 28.x
 builder: electron-builder

frontend:
 framework: React 18
 language: TypeScript
 styling: Tailwind CSS
 state: Zustand
 routing: React Router

backend:
 ipc: electron-ipc
 storage: electron-store
 cli: child_process spawn

local_models:
 runtime: llama.cpp / Ollama
 models:
 - codellama-13b
 - mistral-7b

auto_update:
 provider: electron-updater
 source: GitHub Releases`
```

---

### Implementation

#### Main Process

 typescript
 Copy

`// src/main/index.ts
import {
 app,
 BrowserWindow,
 Tray,
 Menu,
 globalShortcut,
 ipcMain,
 nativeTheme
} from 'electron';
import { spawn } from 'child_process';
import Store from 'electron-store';
import { autoUpdater } from 'electron-updater';

const store = new Store();
let mainWindow: BrowserWindow | null = null;
let tray: Tray | null = null;
let quickQueryWindow: BrowserWindow | null = null;

// App lifecycle
app.whenReady().then(() => {
 createMainWindow();
 createTray();
 registerGlobalShortcuts();
 checkForUpdates();
});

app.on('window-all-closed', () => {
 if (process.platform !== 'darwin') {
 app.quit();
 }
});

// Main window
function createMainWindow() {
 mainWindow = new BrowserWindow({
 width: 1200,
 height: 800,
 minWidth: 800,
 minHeight: 600,
 titleBarStyle: 'hiddenInset',
 webPreferences: {
 preload: path.join(__dirname, 'preload.js'),
 contextIsolation: true,
 nodeIntegration: false
 }
 });

 if (isDev) {
 mainWindow.loadURL('http://localhost:3000');
 } else {
 mainWindow.loadFile('dist/index.html');
 }

 mainWindow.on('close', (event) => {
 if (store.get('minimizeToTray', true)) {
 event.preventDefault();
 mainWindow?.hide();
 }
 });
}

// System tray
function createTray() {
 tray = new Tray(path.join(__dirname, 'assets/tray-icon.png'));

 const contextMenu = Menu.buildFromTemplate([
 {
 label: 'Quick Query',
 accelerator: 'CmdOrCtrl+Space',
 click: () => showQuickQuery()
 },
 { type: 'separator' },
 {
 label: 'Recent Sessions',
 submenu: getRecentSessionsMenu()
 },
 { type: 'separator' },
 {
 label: `Status: ${getConnectionStatus()}`,
 enabled: false
 },
 {
 label: `Profile: ${store.get('currentProfile', 'default')}`,
 enabled: false
 },
 { type: 'separator' },
 {
 label: 'Open Amplifier',
 click: () => mainWindow?.show()
 },
 {
 label: 'Settings',
 click: () => {
 mainWindow?.show();
 mainWindow?.webContents.send('navigate', '/settings');
 }
 },
 { type: 'separator' },
 {
 label: 'Quit',
 click: () => app.quit()
 }
 ]);

 tray.setToolTip('Amplifier');
 tray.setContextMenu(contextMenu);

 tray.on('click', () => {
 mainWindow?.show();
 });
}

// Global shortcuts
function registerGlobalShortcuts() {
 // Quick query spotlight
 globalShortcut.register('CmdOrCtrl+Space', () => {
 showQuickQuery();
 });

 // Toggle main window
 globalShortcut.register('CmdOrCtrl+Shift+A', () => {
 if (mainWindow?.isVisible()) {
 mainWindow.hide();
 } else {
 mainWindow?.show();
 }
 });
}

// Quick query window
function showQuickQuery() {
 if (quickQueryWindow) {
 quickQueryWindow.show();
 quickQueryWindow.focus();
 return;
 }

 quickQueryWindow = new BrowserWindow({
 width: 600,
 height: 400,
 frame: false,
 transparent: true,
 alwaysOnTop: true,
 skipTaskbar: true,
 resizable: false,
 webPreferences: {
 preload: path.join(__dirname, 'preload.js'),
 contextIsolation: true
 }
 });

 quickQueryWindow.loadFile('dist/quick-query.html');

 quickQueryWindow.on('blur', () => {
 quickQueryWindow?.hide();
 });
}

// IPC handlers
ipcMain.handle('amplifier:execute', async (event, { prompt, profile, context }) => {
 return executeAmplifier(prompt, profile, context);
});

ipcMain.handle('amplifier:execute-stream', async (event, { prompt, profile, context }) => {
 const process = spawn('amplifier', ['run', '--output-format', 'json', prompt], {
 env: { ...process.env, AMPLIFIER_PROFILE: profile }
 });

 process.stdout.on('data', (data) => {
 event.sender.send('amplifier:stream-data', data.toString());
 });

 process.on('close', (code) => {
 event.sender.send('amplifier:stream-end', { code });
 });
});

ipcMain.handle('collections:list', async () => {
 return executeAmplifierCommand(['collection', 'list', '--json']);
});

ipcMain.handle('collections:install', async (event, { source }) => {
 return executeAmplifierCommand(['collection', 'add', source]);
});

ipcMain.handle('profiles:list', async () => {
 return executeAmplifierCommand(['profile', 'list', '--json']);
});

// Amplifier CLI wrapper
async function executeAmplifier(prompt: string, profile: string, context: any) {
 return new Promise((resolve, reject) => {
 const args = ['run', '--output-format', 'json'];
 if (profile) args.push('--profile', profile);
 args.push(prompt);

 const process = spawn('amplifier', args, {
 env: {
 ...process.env,
 AMPLIFIER_CONTEXT: JSON.stringify(context)
 }
 });

 let stdout = '';
 let stderr = '';

 process.stdout.on('data', (data) => stdout += data);
 process.stderr.on('data', (data) => stderr += data);

 process.on('close', (code) => {
 if (code === 0) {
 resolve(JSON.parse(stdout));
 } else {
 reject(new Error(stderr));
 }
 });
 });
}

// Auto updater
function checkForUpdates() {
 autoUpdater.checkForUpdatesAndNotify();

 autoUpdater.on('update-available', () => {
 mainWindow?.webContents.send('update:available');
 });

 autoUpdater.on('update-downloaded', () => {
 mainWindow?.webContents.send('update:ready');
 });
}`
```

#### Preload Script

 typescript
 Copy

`// src/main/preload.ts
import { contextBridge, ipcRenderer } from 'electron';

contextBridge.exposeInMainWorld('amplifier', {
 // Execution
 execute: (prompt: string, profile?: string, context?: any) =>
 ipcRenderer.invoke('amplifier:execute', { prompt, profile, context }),

 executeStream: (prompt: string, profile?: string, context?: any) => {
 ipcRenderer.invoke('amplifier:execute-stream', { prompt, profile, context });
 return {
 onData: (callback: (data: string) => void) => {
 ipcRenderer.on('amplifier:stream-data', (_, data) => callback(data));
 },
 onEnd: (callback: (result: any) => void) => {
 ipcRenderer.on('amplifier:stream-end', (_, result) => callback(result));
 }
 };
 },

 // Collections
 listCollections: () => ipcRenderer.invoke('collections:list'),
 installCollection: (source: string) =>
 ipcRenderer.invoke('collections:install', { source }),

 // Profiles
 listProfiles: () => ipcRenderer.invoke('profiles:list'),

 // Navigation
 onNavigate: (callback: (path: string) => void) => {
 ipcRenderer.on('navigate', (_, path) => callback(path));
 },

 // Updates
 onUpdateAvailable: (callback: () => void) => {
 ipcRenderer.on('update:available', callback);
 },
 onUpdateReady: (callback: () => void) => {
 ipcRenderer.on('update:ready', callback);
 },
 installUpdate: () => ipcRenderer.invoke('update:install')
});`
```

#### Renderer - Chat Component

 typescript
 Copy

`// src/renderer/components/Chat.tsx
import React, { useState, useRef, useEffect } from 'react';
import { useStore } from '../store';
import { MessageList } from './MessageList';
import { ChatInput } from './ChatInput';
import { SessionSidebar } from './SessionSidebar';

export function Chat() {
 const [input, setInput] = useState('');
 const [isStreaming, setIsStreaming] = useState(false);
 const messagesEndRef = useRef<HTMLDivElement>(null);

 const {
 currentSession,
 messages,
 addMessage,
 updateLastMessage,
 profile
 } = useStore();

 const handleSend = async () => {
 if (!input.trim()) return;

 const userMessage = { role: 'user', content: input };
 addMessage(userMessage);
 setInput('');
 setIsStreaming(true);

 // Add placeholder for assistant message
 addMessage({ role: 'assistant', content: '' });

 // Stream response
 const stream = window.amplifier.executeStream(input, profile, {
 session_id: currentSession?.id
 });

 let fullContent = '';

 stream.onData((data: string) => {
 try {
 const parsed = JSON.parse(data);
 if (parsed.content) {
 fullContent += parsed.content;
 updateLastMessage({ role: 'assistant', content: fullContent });
 }
 } catch {
 // Partial JSON, ignore
 }
 });

 stream.onEnd(() => {
 setIsStreaming(false);
 });
 };

 useEffect(() => {
 messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
 }, [messages]);

 return (
 <div className="flex h-full">
 <SessionSidebar />

 <div className="flex-1 flex flex-col">
 <div className="flex-1 overflow-y-auto p-4">
 <MessageList messages={messages} isStreaming={isStreaming} />
 <div ref={messagesEndRef} />
 </div>

 <ChatInput
 value={input}
 onChange={setInput}
 onSend={handleSend}
 disabled={isStreaming}
 />
 </div>
 </div>
 );
}`
```

#### Quick Query Window

 typescript
 Copy

`// src/renderer/QuickQuery.tsx
import React, { useState, useEffect } from 'react';

export function QuickQuery() {
 const [query, setQuery] = useState('');
 const [recentQueries, setRecentQueries] = useState<string[]>([]);

 useEffect(() => {
 // Load recent queries from store
 const recent = JSON.parse(localStorage.getItem('recentQueries') || '[]');
 setRecentQueries(recent);

 // Focus input
 document.getElementById('query-input')?.focus();

 // Handle escape
 const handleKeyDown = (e: KeyboardEvent) => {
 if (e.key === 'Escape') {
 window.close();
 }
 };

 window.addEventListener('keydown', handleKeyDown);
 return () => window.removeEventListener('keydown', handleKeyDown);
 }, []);

 const handleSubmit = async (e: React.FormEvent) => {
 e.preventDefault();

 if (!query.trim()) return;

 // Save to recent
 const newRecent = [query, ...recentQueries.slice(0, 4)];
 localStorage.setItem('recentQueries', JSON.stringify(newRecent));

 // Execute and show in main window
 // For now, open main window with query
 window.amplifier.execute(query);
 window.close();
 };

 return (
 <div className="quick-query-container">
 <div className="quick-query-header">
 ðŸ¤– Amplifier Quick Query
 </div>

 <form onSubmit={handleSubmit}>
 <input
 id="query-input"
 type="text"
 value={query}
 onChange={(e) => setQuery(e.target.value)}
 placeholder="Ask about your code..."
 className="quick-query-input"
 />
 </form>

 {recentQueries.length > 0 && (
 <div className="recent-queries">
 <div className="recent-label">Recent:</div>
 {recentQueries.map((q, i) => (
 <button
 key={i}
 className="recent-item"
 onClick={() => {
 setQuery(q);
 handleSubmit(new Event('submit') as any);
 }}
 >
 â€¢ {q}
 </button>
 ))}
 </div>
 )}

 <div className="quick-query-footer">
 [â†µ to search] [âŽ‹ to close] [âŒ˜+â†µ open in main window]
 </div>
 </div>
 );
}`
```

---

### Offline Mode

#### Local Model Integration

 typescript
 Copy

`// src/main/local-models.ts
import { spawn } from 'child_process';
import path from 'path';

export class LocalModelManager {
 private ollamaProcess: ChildProcess | null = null;
 private modelsPath: string;

 constructor() {
 this.modelsPath = path.join(app.getPath('userData'), 'models');
 }

 async startOllama(): Promise<void> {
 this.ollamaProcess = spawn('ollama', ['serve'], {
 env: { ...process.env, OLLAMA_MODELS: this.modelsPath }
 });
 }

 async executeLocal(prompt: string, model: string = 'codellama'): Promise<string> {
 const response = await fetch('http://localhost:11434/api/generate', {
 method: 'POST',
 headers: { 'Content-Type': 'application/json' },
 body: JSON.stringify({
 model,
 prompt,
 stream: false
 })
 });

 const data = await response.json();
 return data.response;
 }

 async downloadModel(model: string): Promise<void> {
 return new Promise((resolve, reject) => {
 const process = spawn('ollama', ['pull', model]);
 process.on('close', (code) => {
 if (code === 0) resolve();
 else reject(new Error(`Failed to download ${model}`));
 });
 });
 }

 getAvailableModels(): string[] {
 // List downloaded models
 return ['codellama', 'mistral'];
 }

 async stop(): Promise<void> {
 this.ollamaProcess?.kill();
 }
}`
```

---

### Distribution

#### Build Configuration

 yaml
 Copy

`# electron-builder.yml
appId: com.amplifier.desktop
productName: Amplifier
directories:
 output: dist
 buildResources: build

files:
 - dist/**/*
 - package.json

mac:
 category: public.app-category.developer-tools
 icon: build/icon.icns
 hardenedRuntime: true
 gatekeeperAssess: false
 entitlements: build/entitlements.mac.plist
 entitlementsInherit: build/entitlements.mac.plist
 target:
 - dmg
 - zip

win:
 icon: build/icon.ico
 target:
 - nsis
 - portable

linux:
 icon: build/icon.png
 category: Development
 target:
 - AppImage
 - deb
 - rpm

nsis:
 oneClick: false
 allowToChangeInstallationDirectory: true

publish:
 provider: github
 owner: microsoft
 repo: amplifier-desktop`
```

#### Auto-Update

 typescript
 Copy

`// Auto-update configuration
import { autoUpdater } from 'electron-updater';

autoUpdater.autoDownload = true;
autoUpdater.autoInstallOnAppQuit = true;

// Check for updates every 4 hours
setInterval(() => {
 autoUpdater.checkForUpdates();
}, 4 * 60 * 60 * 1000);`
```

---

### Configuration

 yaml
 Copy

`# App settings (electron-store)
settings:
 general:
 startOnLogin: true
 minimizeToTray: true
 theme: system # light | dark | system

 shortcuts:
 quickQuery: CmdOrCtrl+Space
 toggleWindow: CmdOrCtrl+Shift+A
 newSession: CmdOrCtrl+N

 amplifier:
 defaultProfile: enterprise-dev
 cliPath: /usr/local/bin/amplifier

 offline:
 enabled: true
 defaultModel: codellama
 autoDownloadModels: true

 updates:
 autoCheck: true
 autoInstall: true`
```

---

### Events

 | 
 
 | Event | Description | Data

 | `desktop:query_sent` | Query submitted | source (main/quick)
 
 | `desktop:session_created` | New session | session_id, project
 
 | `desktop:offline_mode` | Switched to offline | model
 
 | `desktop:update_installed` | App updated | version

---

### Open Questions

- Code indexing: Local embedding for offline semantic search?
 
- Plugin system: Allow third-party plugins?
 
- Cloud sync: Sync sessions across devices?
 
- IDE integration: Deep links to open files in IDE?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Integration Git Hooks
 integrations

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-git-hooks`

### Overview

Git hooks integration for automated AI assistance during git workflows: pre-commit review, commit message generation, pre-push validation, and merge request preparation. Zero-friction quality gates powered by Amplifier.

#### Value Proposition

 | 
 
 | Without | With

 | Manual code review before commit | Automated pre-commit analysis
 
 | Writing commit messages manually | AI-generated contextual messages
 
 | Forgetting to check before push | Automated pre-push validation
 
 | Manual PR description writing | Auto-generated PR descriptions

---

### Hook Types

#### 1. Pre-Commit Hook

Analyze staged changes before commit.

 bash
 Copy

`# .git/hooks/pre-commit
#!/bin/bash

# Run Amplifier pre-commit analysis
amplifier hooks pre-commit

# Exit code determines if commit proceeds`
```

Analysis includes:

- Security vulnerabilities (secrets, injection risks)
 
- Code quality issues (complexity, duplication)
 
- Style violations (based on project config)
 
- Breaking changes detection
 
- Test coverage impact
 
Output:

 text
 Copy

`ðŸ¤– Amplifier Pre-Commit Analysis
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Analyzing 3 staged files...

âœ… src/api/users.ts
 No issues found

âš ï¸ src/payments/processor.ts
 Line 45: Potential SQL injection risk
 Line 89: Missing error handling for network timeout

 Suggested fixes:
 1. Use parameterized queries (line 45)
 2. Add try-catch with timeout handling (line 89)

âŒ src/auth/login.ts
 Line 12: Hardcoded API key detected
 BLOCKING: Cannot commit secrets

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Summary: 1 blocked, 1 warning, 1 passed

[a]ccept warnings and commit
[f]ix issues (opens editor)
[c]ancel commit`
```

#### 2. Commit-Msg Hook

Generate or enhance commit messages.

 bash
 Copy

`# .git/hooks/commit-msg
#!/bin/bash

# Generate commit message from staged changes
amplifier hooks commit-msg "$1"`
```

Modes:

 bash
 Copy

`# Mode 1: Generate from scratch (empty message)
git commit
# â†’ Amplifier generates message based on diff

# Mode 2: Enhance existing (message provided)
git commit -m "fix auth"
# â†’ Amplifier expands: "fix(auth): resolve token expiration handling..."

# Mode 3: Validate only (with --no-enhance flag)
git commit -m "WIP"
# â†’ Amplifier warns about non-conventional message`
```

Generated message format:

 text
 Copy

`feat(payments): add retry logic for failed transactions

- Implement exponential backoff for Stripe API calls
- Add configurable max retry attempts (default: 3)
- Log retry attempts for debugging
- Update error handling to distinguish retryable errors

Closes #234`
```

#### 3. Pre-Push Hook

Validate before pushing to remote.

 bash
 Copy

`# .git/hooks/pre-push
#!/bin/bash

# Run Amplifier pre-push validation
amplifier hooks pre-push "$@"`
```

Validations:

- All tests pass
 
- No WIP commits
 
- No force-push to protected branches
 
- Breaking changes require version bump
 
- Documentation updated for API changes
 
Output:

 text
 Copy

`ðŸ¤– Amplifier Pre-Push Validation
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Checking 5 commits to push to origin/main...

âœ… Tests: All 142 tests passing
âœ… Commits: No WIP or fixup commits
âœ… Branch: Not force-pushing to protected branch

âš ï¸ Breaking Changes Detected:
 - Removed `getUserById` from UserService API
 - Changed return type of `processPayment`

 Recommendations:
 1. Bump major version (currently 2.3.1 â†’ 3.0.0)
 2. Update CHANGELOG.md
 3. Add migration guide

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[p]ush anyway (with warnings)
[c]ancel push`
```

#### 4. Prepare-Commit-Msg Hook

Prepare PR/MR descriptions.

 bash
 Copy

`# .git/hooks/prepare-commit-msg
#!/bin/bash

# When creating merge commit or PR
if [ "$2" = "merge" ]; then
 amplifier hooks prepare-merge "$1"
fi`
```

Generated PR description:

 markdown
 Copy

`## Summary

This PR adds retry logic for failed payment transactions to improve
reliability when the Stripe API experiences intermittent issues.

## Changes

- **src/payments/processor.ts**: Added `RetryStrategy` class with
 exponential backoff
- **src/payments/errors.ts**: New `RetryableError` type for
 distinguishing recoverable failures
- **tests/payments/**: Added 12 new test cases for retry scenarios

## Testing

- [x] Unit tests for retry logic
- [x] Integration tests with mock Stripe API
- [ ] Manual testing in staging environment

## Related

- Closes #234
- Related to #198 (error handling improvements)

---
ðŸ¤– Generated by Amplifier`
```

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Git Hooks System â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ pre-commit â”‚ â”‚ commit-msg â”‚ â”‚ pre-push â”‚ â”‚
â”‚ â”‚ (shell) â”‚ â”‚ (shell) â”‚ â”‚ (shell) â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ amplifier hooks â”‚ â”‚
â”‚ â”‚ (CLI command) â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Git Diff â”‚ â”‚ Config â”‚ â”‚ Amplifier â”‚ â”‚
â”‚ â”‚ Analysis â”‚ â”‚ Loading â”‚ â”‚ Session â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Installation

#### Quick Setup

 bash
 Copy

`# Initialize hooks in current repository
amplifier hooks init

# This creates:
# - .git/hooks/pre-commit
# - .git/hooks/commit-msg
# - .git/hooks/pre-push
# - .git/hooks/prepare-commit-msg
# - .amplifier/hooks.yaml (configuration)`
```

#### Manual Setup

 bash
 Copy

`# Install individual hooks
amplifier hooks install pre-commit
amplifier hooks install commit-msg
amplifier hooks install pre-push`
```

#### With Husky

 json
 Copy

`// package.json
{
 "husky": {
 "hooks": {
 "pre-commit": "amplifier hooks pre-commit",
 "commit-msg": "amplifier hooks commit-msg $HUSKY_GIT_PARAMS",
 "pre-push": "amplifier hooks pre-push"
 }
 }
}`
```

#### With pre-commit framework

 yaml
 Copy

`# .pre-commit-config.yaml
repos:
 - repo: https://github.com/microsoft/amplifier-hooks
 rev: v1.0.0
 hooks:
 - id: amplifier-pre-commit
 name: Amplifier Pre-Commit Analysis
 stages: [commit]

 - id: amplifier-commit-msg
 name: Amplifier Commit Message
 stages: [commit-msg]`
```

---

### Configuration

 yaml
 Copy

`# .amplifier/hooks.yaml
hooks:
 # Global settings
 enabled: true
 profile: enterprise-dev:hooks # Or use default

 pre-commit:
 enabled: true
 # What to check
 checks:
 - security # Secrets, vulnerabilities
 - quality # Code smells, complexity
 - style # Linting violations
 - breaking # Breaking change detection

 # Behavior
 block_on:
 - security:critical
 - security:high

 warn_on:
 - security:medium
 - quality:high
 - breaking:any

 # Files to check
 include:
 - "src/**/*.ts"
 - "src/**/*.py"

 exclude:
 - "**/*.test.ts"
 - "**/fixtures/**"

 # Performance
 max_files: 50
 timeout: 30s

 commit-msg:
 enabled: true

 # Generation mode
 mode: enhance # generate | enhance | validate

 # Format
 format: conventional # conventional | angular | custom
 max_length: 72
 require_scope: false
 require_body: false

 # Enhancement
 enhance:
 expand_abbreviations: true
 add_issue_references: true
 suggest_scope: true

 pre-push:
 enabled: true

 checks:
 - tests # Run test suite
 - wip_commits # No WIP/fixup commits
 - force_push # Warn on force push
 - breaking # Breaking change validation

 # Protected branches
 protected_branches:
 - main
 - master
 - release/*

 # Require for protected branches
 require:
 - tests_pass
 - no_wip
 - changelog_updated

 prepare-commit-msg:
 enabled: true

 # When to generate
 triggers:
 - merge
 - squash

 # Template
 template: |
 ## Summary
 {summary}

 ## Changes
 {changes}

 ## Testing
 {testing}

 ---
 ðŸ¤– Generated by Amplifier`
```

---

### Implementation

#### CLI Commands

 python
 Copy

`# amplifier_app_cli/commands/hooks.py
import click
from pathlib import Path

@click.group()
def hooks():
 """Git hooks integration."""
 pass

@hooks.command()
def init():
 """Initialize Amplifier hooks in current repository."""

 git_dir = find_git_dir()
 if not git_dir:
 click.echo("Error: Not a git repository")
 return 1

 hooks_dir = git_dir / "hooks"

 # Create hook scripts
 for hook_name in ["pre-commit", "commit-msg", "pre-push", "prepare-commit-msg"]:
 hook_path = hooks_dir / hook_name
 hook_path.write_text(generate_hook_script(hook_name))
 hook_path.chmod(0o755)

 # Create config
 config_dir = Path.cwd() / ".amplifier"
 config_dir.mkdir(exist_ok=True)
 (config_dir / "hooks.yaml").write_text(DEFAULT_HOOKS_CONFIG)

 click.echo("âœ… Amplifier hooks initialized")
 click.echo(f" Config: .amplifier/hooks.yaml")

@hooks.command("pre-commit")
def pre_commit():
 """Run pre-commit analysis."""

 config = load_hooks_config()
 if not config.get("pre-commit", {}).get("enabled", True):
 return 0

 # Get staged files
 staged_files = get_staged_files()
 if not staged_files:
 return 0

 # Filter files
 files_to_check = filter_files(staged_files, config["pre-commit"])

 # Run analysis
 results = run_pre_commit_analysis(files_to_check, config["pre-commit"])

 # Display results
 display_pre_commit_results(results)

 # Determine exit code
 if has_blocking_issues(results, config["pre-commit"]["block_on"]):
 return 1

 if has_warnings(results, config["pre-commit"]["warn_on"]):
 # Interactive prompt
 choice = click.prompt(
 "[a]ccept warnings, [f]ix issues, [c]ancel",
 type=click.Choice(["a", "f", "c"])
 )
 if choice == "c":
 return 1
 if choice == "f":
 open_editor_with_fixes(results)
 return 1

 return 0

@hooks.command("commit-msg")
@click.argument("msg_file", type=click.Path(exists=True))
def commit_msg(msg_file: str):
 """Generate or enhance commit message."""

 config = load_hooks_config()
 if not config.get("commit-msg", {}).get("enabled", True):
 return 0

 # Read current message
 msg_path = Path(msg_file)
 current_msg = msg_path.read_text().strip()

 # Get staged diff
 diff = get_staged_diff()

 # Determine mode
 mode = config["commit-msg"].get("mode", "enhance")

 if not current_msg or mode == "generate":
 # Generate new message
 new_msg = generate_commit_message(diff, config["commit-msg"])
 elif mode == "enhance":
 # Enhance existing
 new_msg = enhance_commit_message(current_msg, diff, config["commit-msg"])
 else:
 # Validate only
 issues = validate_commit_message(current_msg, config["commit-msg"])
 if issues:
 display_commit_message_issues(issues)
 return 1
 return 0

 # Write message
 msg_path.write_text(new_msg)

 # Show preview
 click.echo(f"\nðŸ“ Commit message:\n{new_msg}\n")

 return 0

def generate_commit_message(diff: str, config: dict) -> str:
 """Generate commit message using Amplifier."""

 from amplifier_core import AmplifierSession

 prompt = f"""Generate a commit message for this diff.

Format: {config.get('format', 'conventional')}
Max length (first line): {config.get('max_length', 72)}

Diff:
{diff}

Generate a clear, concise commit message following the format.
"""

 session_config = get_hooks_session_config(config)

 async def run():
 async with AmplifierSession(config=session_config) as session:
 response = await session.execute(prompt)
 return response.text

 return asyncio.run(run())

def run_pre_commit_analysis(files: list[Path], config: dict) -> list[AnalysisResult]:
 """Run pre-commit analysis on files."""

 from amplifier_core import AmplifierSession

 results = []

 for file in files:
 content = file.read_text()
 diff = get_file_diff(file)

 prompt = f"""Analyze this code change for issues.

Check for:
{format_checks(config.get('checks', []))}

File: {file}
Language: {detect_language(file)}

Diff:
{diff}

Full file (for context):
{content}

Report any issues found with line numbers and severity.
"""

 session_config = get_hooks_session_config(config)

 async def run():
 async with AmplifierSession(config=session_config) as session:
 response = await session.execute(prompt)
 return parse_analysis_response(response.text, file)

 results.append(asyncio.run(run()))

 return results`
```

#### Hook Script Generator

 python
 Copy

`def generate_hook_script(hook_name: str) -> str:
 """Generate shell script for git hook."""

 return f"""#!/bin/bash
# Amplifier {hook_name} hook
# Generated by: amplifier hooks init

# Skip if AMPLIFIER_SKIP_HOOKS is set
if [ -n "$AMPLIFIER_SKIP_HOOKS" ]; then
 exit 0
fi

# Check if amplifier is available
if ! command -v amplifier &> /dev/null; then
 echo "Warning: amplifier not found, skipping hook"
 exit 0
fi

# Run the hook
amplifier hooks {hook_name.replace('-', '_')} "$@"
exit $?
"""`
```

---

### Usage Examples

#### Basic Workflow

 bash
 Copy

`# Make some changes
vim src/payments/processor.ts

# Stage changes
git add src/payments/processor.ts

# Commit (triggers hooks)
git commit
# â†’ Pre-commit analysis runs
# â†’ Commit message generated/enhanced
# â†’ Commit proceeds if checks pass

# Push (triggers hooks)
git push
# â†’ Pre-push validation runs
# â†’ Push proceeds if checks pass`
```

#### Skip Hooks Temporarily

 bash
 Copy

`# Skip all hooks
AMPLIFIER_SKIP_HOOKS=1 git commit -m "WIP"

# Skip specific hook
git commit --no-verify -m "WIP"

# Skip with reason (logged)
AMPLIFIER_SKIP_REASON="urgent hotfix" git push --no-verify`
```

#### Interactive Mode

 bash
 Copy

`# Force interactive mode
amplifier hooks pre-commit --interactive

# Non-interactive (CI mode)
amplifier hooks pre-commit --no-interactive`
```

---

### CI Integration

#### GitHub Actions

 yaml
 Copy

`# .github/workflows/amplifier-hooks.yml
name: Amplifier Hooks

on:
 pull_request:
 types: [opened, synchronize]

jobs:
 analyze:
 runs-on: ubuntu-latest
 steps:
 - uses: actions/checkout@v4
 with:
 fetch-depth: 0

 - name: Setup Amplifier
 run: pip install amplifier

 - name: Run Pre-Commit Analysis
 run: |
 amplifier hooks pre-commit \
 --no-interactive \
 --output json > analysis.json

 - name: Post Review Comments
 uses: actions/github-script@v7
 with:
 script: |
 const analysis = require('./analysis.json');
 // Post comments on PR`
```

#### GitLab CI

 yaml
 Copy

`# .gitlab-ci.yml
amplifier-analysis:
 stage: test
 script:
 - pip install amplifier
 - amplifier hooks pre-commit --no-interactive --ci
 allow_failure: true
 artifacts:
 reports:
 codequality: amplifier-report.json`
```

---

### Events

 | 
 
 | Event | Description | Data

 | `hooks:pre_commit:start` | Pre-commit started | files_count
 
 | `hooks:pre_commit:complete` | Pre-commit finished | issues, blocked
 
 | `hooks:commit_msg:generated` | Message generated | mode, format
 
 | `hooks:pre_push:start` | Pre-push started | commits_count
 
 | `hooks:pre_push:complete` | Pre-push finished | checks, passed

---

### Open Questions

- Performance: Cache analysis results for unchanged files?
 
- Team settings: Shared hooks config in repo vs local override?
 
- Bypass logging: Track when/why hooks are bypassed?
 
- Custom checks: Allow custom check plugins?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Integration Github Actions
 integrations

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-integration-github-actions`

### Overview

GitHub Actions integration for running Amplifier in CI/CD pipelines. Provides pre-built actions for code review, PR analysis, documentation generation, and custom AI-powered workflows.

#### Value Proposition

 | 
 
 | Without | With

 | Manual AI-assisted reviews | Automated PR feedback
 
 | No CI/CD AI integration | Native Actions support
 
 | Complex setup | Drop-in action
 
 | Token management | Secure secrets handling

---

### Actions Available

#### 1. amplifier/pr-review-action

Automated PR review with configurable depth.

 yaml
 Copy

`name: PR Review
on:
 pull_request:
 types: [opened, synchronize]

jobs:
 review:
 runs-on: ubuntu-latest
 steps:
 - uses: actions/checkout@v4
 with:
 fetch-depth: 0

 - uses: amplifier/pr-review-action@v1
 with:
 # Required
 github-token: ${{ secrets.GITHUB_TOKEN }}
 anthropic-api-key: ${{ secrets.ANTHROPIC_API_KEY }}

 # Optional configuration
 depth: standard # quick | standard | thorough
 checks:
 security: true
 code-quality: true
 breaking-changes: true
 test-coverage: true

 # Output
 post-comment: true
 request-changes: auto # auto | manual | never
 fail-on-critical: true

 # Custom prompts (optional)
 custom-instructions: |
 Pay special attention to:
 - SQL injection vulnerabilities
 - Authentication bypasses
 - Our coding standards in CONTRIBUTING.md`
```

#### 2. amplifier/code-analysis-action

Deep code analysis without PR context.

 yaml
 Copy

`- uses: amplifier/code-analysis-action@v1
 with:
 anthropic-api-key: ${{ secrets.ANTHROPIC_API_KEY }}

 # What to analyze
 paths:
 - src/
 - lib/

 # Analysis types
 analysis:
 - security
 - complexity
 - architecture
 - dependencies

 # Output
 output-format: sarif # sarif | json | markdown
 output-file: analysis.sarif

 # Thresholds
 fail-on-high-severity: true
 complexity-threshold: 15`
```

#### 3. amplifier/doc-generator-action

Generate or update documentation.

 yaml
 Copy

`- uses: amplifier/doc-generator-action@v1
 with:
 anthropic-api-key: ${{ secrets.ANTHROPIC_API_KEY }}

 # What to document
 source-paths:
 - src/
 output-path: docs/

 # Generation options
 mode: update # generate | update | verify
 types:
 - api-reference
 - code-comments
 - readme-sections

 # Git operations
 create-commit: true
 commit-message: "docs: auto-update documentation"`
```

#### 4. amplifier/custom-action

Run custom Amplifier scenarios.

 yaml
 Copy

`- uses: amplifier/custom-action@v1
 with:
 anthropic-api-key: ${{ secrets.ANTHROPIC_API_KEY }}

 # Custom scenario
 scenario: ./scenarios/tech-debt-scan.yaml

 # Or inline prompt
 prompt: |
 Analyze the codebase for architectural improvements.
 Focus on the payment module.

 # Configuration
 profile: enterprise-dev
 collection: enterprise-dev

 # Output
 output-file: ${{ github.workspace }}/analysis.md`
```

---

### Architecture

 yaml
 Copy

`# Action structure
action.yml:
 name: "Amplifier PR Review"
 description: "AI-powered code review"

 inputs:
 github-token:
 required: true
 anthropic-api-key:
 required: true
 depth:
 default: "standard"
 # ... more inputs

 runs:
 using: "docker"
 image: "ghcr.io/amplifier/actions:v1"
 env:
 GITHUB_TOKEN: ${{ inputs.github-token }}
 ANTHROPIC_API_KEY: ${{ inputs.anthropic-api-key }}

# Docker image contents
FROM python:3.11-slim

# Install Amplifier
RUN pip install amplifier-cli amplifier-collection-enterprise

# Install action runner
COPY entrypoint.py /entrypoint.py
ENTRYPOINT ["python", "/entrypoint.py"]`
```

---

### Implementation

 python
 Copy

`# entrypoint.py - Action entry point

import os
import json
import asyncio
from pathlib import Path

from amplifier import AmplifierSession
from github import Github

async def main():
 """Main action entry point."""

 # Load inputs
 inputs = load_inputs()

 # Initialize GitHub client
 gh = Github(os.environ["GITHUB_TOKEN"])
 repo = gh.get_repo(os.environ["GITHUB_REPOSITORY"])

 # Get PR context
 pr = None
 if "pull_request" in os.environ.get("GITHUB_EVENT_NAME", ""):
 event = json.loads(Path(os.environ["GITHUB_EVENT_PATH"]).read_text())
 pr = repo.get_pull(event["pull_request"]["number"])

 # Initialize Amplifier
 config = build_config(inputs)

 async with AmplifierSession(config=config) as session:
 # Execute based on action type
 if inputs["action_type"] == "pr-review":
 result = await run_pr_review(session, pr, inputs)
 elif inputs["action_type"] == "code-analysis":
 result = await run_code_analysis(session, inputs)
 elif inputs["action_type"] == "doc-generator":
 result = await run_doc_generator(session, inputs)
 else:
 result = await run_custom(session, inputs)

 # Process output
 await process_output(result, gh, repo, pr, inputs)

async def run_pr_review(
 session: AmplifierSession,
 pr: PullRequest,
 inputs: dict
) -> ReviewResult:
 """Run PR review scenario."""

 # Load PR context
 diff = pr.get_files()
 comments = pr.get_comments()

 # Build review prompt
 prompt = build_review_prompt(pr, diff, comments, inputs)

 # Execute review
 result = await session.execute(prompt)

 return ReviewResult(
 summary=result.response,
 issues=extract_issues(result),
 recommendation=extract_recommendation(result)
 )

async def process_output(
 result: Result,
 gh: Github,
 repo: Repository,
 pr: PullRequest | None,
 inputs: dict
) -> None:
 """Process action output."""

 # Post PR comment
 if inputs.get("post_comment") and pr:
 comment_body = format_comment(result)
 pr.create_issue_comment(comment_body)

 # Request changes if configured
 if inputs.get("request_changes") == "auto" and pr:
 if result.has_blocking_issues:
 pr.create_review(
 body=result.summary,
 event="REQUEST_CHANGES"
 )
 elif result.recommendation == "approve":
 pr.create_review(
 body=result.summary,
 event="APPROVE"
 )

 # Set outputs
 set_output("review-result", json.dumps(result.to_dict()))
 set_output("has-issues", str(result.has_issues).lower())

 # Fail action if critical issues
 if inputs.get("fail_on_critical") and result.has_critical_issues:
 print(f"::error::Critical issues found in review")
 exit(1)

 # Write SARIF if code analysis
 if inputs.get("output_format") == "sarif":
 sarif = convert_to_sarif(result)
 Path(inputs["output_file"]).write_text(json.dumps(sarif))

 # Upload to GitHub Code Scanning
 upload_sarif(gh, repo, sarif)

def format_comment(result: ReviewResult) -> str:
 """Format result as GitHub comment."""

 lines = [
 "## ðŸ¤– Amplifier Code Review",
 "",
 f"**Recommendation**: {result.recommendation_emoji} {result.recommendation}",
 "",
 "### Summary",
 result.summary,
 "",
 ]

 if result.issues:
 lines.extend([
 "### Issues Found",
 "",
 ])

 for issue in result.issues:
 emoji = {"critical": "ðŸ”´", "high": "ðŸŸ ", "medium": "ðŸŸ¡", "low": "ðŸŸ¢"}[issue.severity]
 lines.append(f"- {emoji} **{issue.title}** ({issue.file}:{issue.line})")
 lines.append(f" {issue.description}")
 lines.append("")

 lines.extend([
 "---",
 "*Generated by [Amplifier](https://github.com/microsoft/amplifier)*"
 ])

 return "\n".join(lines)`
```

---

### Configuration Reference

#### PR Review Action

 | 
 
 | Input | Type | Required | Default | Description

 | `github-token` | string | Yes | - | GitHub token
 
 | `anthropic-api-key` | string | Yes | - | Anthropic API key
 
 | `depth` | string | No | "standard" | Review depth
 
 | `checks.security` | bool | No | true | Security check
 
 | `checks.code-quality` | bool | No | true | Quality check
 
 | `checks.breaking-changes` | bool | No | true | Breaking changes
 
 | `checks.test-coverage` | bool | No | true | Coverage check
 
 | `post-comment` | bool | No | true | Post as comment
 
 | `request-changes` | string | No | "auto" | Request changes behavior
 
 | `fail-on-critical` | bool | No | true | Fail on critical
 
 | `custom-instructions` | string | No | "" | Custom review instructions

#### Outputs

 | 
 
 | Output | Description

 | `review-result` | JSON result object
 
 | `has-issues` | Whether issues were found
 
 | `recommendation` | approve/request_changes/comment
 
 | `issue-count` | Number of issues

---

### Security

#### Secret Handling

 yaml
 Copy

`# Required secrets (set in repo settings)
secrets:
 ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

# Optional: Use GitHub App for enhanced permissions
secrets:
 APP_ID: ${{ secrets.AMPLIFIER_APP_ID }}
 APP_PRIVATE_KEY: ${{ secrets.AMPLIFIER_APP_PRIVATE_KEY }}

# Token permissions
permissions:
 contents: read
 pull-requests: write
 security-events: write # For SARIF upload`
```

#### Rate Limiting

 yaml
 Copy

`# Built-in rate limiting
rate-limiting:
 max-reviews-per-hour: 10
 max-tokens-per-review: 50000
 concurrent-reviews: 3`
```

---

### Example Workflows

#### Complete PR Pipeline

 yaml
 Copy

`name: PR Pipeline
on:
 pull_request:
 types: [opened, synchronize]

jobs:
 review:
 runs-on: ubuntu-latest
 outputs:
 has-issues: ${{ steps.review.outputs.has-issues }}

 steps:
 - uses: actions/checkout@v4
 with:
 fetch-depth: 0

 - id: review
 uses: amplifier/pr-review-action@v1
 with:
 github-token: ${{ secrets.GITHUB_TOKEN }}
 anthropic-api-key: ${{ secrets.ANTHROPIC_API_KEY }}
 depth: thorough
 fail-on-critical: false # Don't fail yet

 - name: Upload SARIF
 if: always()
 uses: github/codeql-action/upload-sarif@v2
 with:
 sarif_file: review-results.sarif

 security-gate:
 needs: review
 if: needs.review.outputs.has-issues == 'true'
 runs-on: ubuntu-latest
 steps:
 - name: Security Review Required
 run: |
 echo "::warning::AI review found issues - security team review required"
 # Could notify security team via Slack, etc.`
```

#### Scheduled Analysis

 yaml
 Copy

`name: Weekly Code Health
on:
 schedule:
 - cron: '0 8 * * 1' # Monday 8 AM

jobs:
 analysis:
 runs-on: ubuntu-latest
 steps:
 - uses: actions/checkout@v4

 - uses: amplifier/code-analysis-action@v1
 with:
 anthropic-api-key: ${{ secrets.ANTHROPIC_API_KEY }}
 paths: [src/]
 analysis: [security, complexity, architecture]
 output-format: markdown
 output-file: reports/weekly-health.md

 - name: Create Issue
 uses: actions/github-script@v6
 with:
 script: |
 const fs = require('fs');
 const report = fs.readFileSync('reports/weekly-health.md', 'utf8');
 await github.rest.issues.create({
 owner: context.repo.owner,
 repo: context.repo.repo,
 title: `Weekly Code Health Report - ${new Date().toISOString().split('T')[0]}`,
 body: report,
 labels: ['code-health', 'automated']
 });`
```

---

### Self-Hosted Runner Support

 yaml
 Copy

`# For enterprise with self-hosted runners
jobs:
 review:
 runs-on: self-hosted
 container:
 image: ghcr.io/amplifier/actions:v1
 credentials:
 username: ${{ github.actor }}
 password: ${{ secrets.GITHUB_TOKEN }}

 steps:
 - uses: amplifier/pr-review-action@v1
 with:
 # Use Azure OpenAI instead of Anthropic
 provider: azure-openai
 azure-endpoint: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
 azure-api-key: ${{ secrets.AZURE_OPENAI_KEY }}`
```

---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Integration Mobile Companion
 integrations

Priority: P2 (Enhancement)

Status: Draft

Module: `amplifier-mobile`

### Overview

Mobile companion app (iOS/Android) for Amplifier. Quick queries on the go, notification handling for CI/CD events, code review approvals, and session continuity between desktop and mobile.

#### Value Proposition

 | 
 
 | Without | With

 | Must be at desk for queries | Quick answers anywhere
 
 | Miss CI alerts until back | Real-time notifications
 
 | PR reviews wait for desktop | Approve/comment from phone
 
 | Context lost between devices | Seamless session continuity

---

### Features

#### 1. Quick Query Interface

Fast, voice-enabled queries about your codebase.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â† Amplifier âš™ï¸ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ ðŸŽ¤ "How does auth work?" â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ Recent Queries â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ How does payment retry work? â”‚â”‚
â”‚ â”‚ 2 hours ago â€¢ myproject â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ What tests cover UserService? â”‚â”‚
â”‚ â”‚ Yesterday â€¢ myproject â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ Explain the caching strategy â”‚â”‚
â”‚ â”‚ 2 days ago â€¢ other-project â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ â”‚
â”‚ [Projects â–¼] [ðŸŽ¤ Ask] â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 2. Query Results View

Mobile-optimized response display.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â† Query Results ðŸ“‹ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ How does authentication work? â”‚
â”‚ myproject â€¢ Just now â”‚
â”‚ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ The auth system uses JWT tokens: â”‚
â”‚ â”‚
â”‚ **1. Login Flow** â”‚
â”‚ User credentials validated against â”‚
â”‚ database, JWT issued with 24h expiry. â”‚
â”‚ â”‚
â”‚ ðŸ“„ src/auth/login.ts:23 â”‚
â”‚ â”‚
â”‚ **2. Token Validation** â”‚
â”‚ Middleware extracts and validates â”‚
â”‚ token on each request. â”‚
â”‚ â”‚
â”‚ ðŸ“„ src/auth/middleware.ts:45 â”‚
â”‚ â”‚
â”‚ **3. Refresh Logic** â”‚
â”‚ Tokens refreshed automatically before â”‚
â”‚ expiration via refresh endpoint. â”‚
â”‚ â”‚
â”‚ ðŸ“„ src/auth/refresh.ts:12 â”‚
â”‚ â”‚
â”‚ [View on Desktop] [Share] [Copy] â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 3. Notification Center

CI/CD alerts, PR updates, and system notifications.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â† Notifications Clear â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ Today â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ âŒ Build Failed â”‚â”‚
â”‚ â”‚ myproject â€¢ main â€¢ 10 min ago â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ Test suite failed: 3 failures â”‚â”‚
â”‚ â”‚ [View Details] [Ask Amplifier] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ ðŸ”” Review Requested â”‚â”‚
â”‚ â”‚ PR #234 â€¢ @alice â€¢ 30 min ago â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ "Add payment retry logic" â”‚â”‚
â”‚ â”‚ [Quick Review] [Open PR] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ âœ… Deploy Complete â”‚â”‚
â”‚ â”‚ myproject â€¢ staging â€¢ 1 hour ago â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ v2.3.1 deployed successfully â”‚â”‚
â”‚ â”‚ [View Logs] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ Yesterday â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ ... â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 4. Quick PR Review

Mobile-optimized PR review interface.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â† PR #234 ðŸ”— â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ Add payment retry logic â”‚
â”‚ @alice â†’ main â€¢ +142 -23 â”‚
â”‚ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ ðŸ¤– Amplifier Summary â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ This PR adds exponential backoff â”‚
â”‚ retry logic for Stripe API calls. â”‚
â”‚ â”‚
â”‚ **Key Changes:** â”‚
â”‚ â€¢ New RetryStrategy class â”‚
â”‚ â€¢ 3 retries with 1s base delay â”‚
â”‚ â€¢ Jitter to prevent thundering herd â”‚
â”‚ â”‚
â”‚ **Concerns:** â”‚
â”‚ âš ï¸ Missing test for max retry case â”‚
â”‚ âš ï¸ Consider adding circuit breaker â”‚
â”‚ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ Files (3) â”‚
â”‚ â”œâ”€â”€ src/payments/processor.ts +45 â”‚
â”‚ â”œâ”€â”€ src/payments/retry.ts +89 â”‚
â”‚ â””â”€â”€ tests/payments/retry.test.ts +8 â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ [âœ… Approve] [ðŸ’¬ Comment] [âŒ Deny] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 5. Session Continuity

Continue desktop sessions on mobile.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â† Active Sessions ðŸ”„ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ Desktop Sessions â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ ðŸ’» MacBook Pro â”‚â”‚
â”‚ â”‚ myproject â€¢ Active now â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ "Analyzing payment module..." â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ [Continue Here] [View Only] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ ðŸ–¥ï¸ Work Desktop â”‚â”‚
â”‚ â”‚ other-project â€¢ 2 hours ago â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ Last: "Generate API docs" â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ [Resume] [View History] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ Mobile Sessions â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ ðŸ“± This Device â”‚â”‚
â”‚ â”‚ myproject â€¢ 10 min ago â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ [New Session] [Continue] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mobile App â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ React Native / Flutter â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ Query â”‚ â”‚ Notifi- â”‚ â”‚ PR â”‚ â”‚ Session â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ Screen â”‚ â”‚ cations â”‚ â”‚ Review â”‚ â”‚ Manager â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Amplifier SDK â”‚ â”‚
â”‚ â”‚ (TypeScript) â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ API Server â”‚ â”‚ Push â”‚ â”‚ Local â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ Service â”‚ â”‚ Storage â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Tech Stack

 yaml
 Copy

`app:
 framework: React Native # or Flutter
 language: TypeScript
 state: Zustand
 navigation: React Navigation

api:
 client: Generated from OpenAPI
 auth: OAuth2 + Biometric

notifications:
 ios: APNs
 android: FCM

offline:
 storage: AsyncStorage / SQLite
 sync: Background sync API

voice:
 ios: Speech Framework
 android: SpeechRecognizer`
```

---

### Implementation

#### App Structure (React Native)

 text
 Copy

`src/
â”œâ”€â”€ App.tsx
â”œâ”€â”€ screens/
â”‚ â”œâ”€â”€ HomeScreen.tsx
â”‚ â”œâ”€â”€ QueryScreen.tsx
â”‚ â”œâ”€â”€ QueryResultScreen.tsx
â”‚ â”œâ”€â”€ NotificationsScreen.tsx
â”‚ â”œâ”€â”€ PRReviewScreen.tsx
â”‚ â”œâ”€â”€ SessionsScreen.tsx
â”‚ â””â”€â”€ SettingsScreen.tsx
â”œâ”€â”€ components/
â”‚ â”œâ”€â”€ QueryInput.tsx
â”‚ â”œâ”€â”€ QueryResult.tsx
â”‚ â”œâ”€â”€ NotificationCard.tsx
â”‚ â”œâ”€â”€ PRSummary.tsx
â”‚ â”œâ”€â”€ SessionCard.tsx
â”‚ â””â”€â”€ VoiceButton.tsx
â”œâ”€â”€ services/
â”‚ â”œâ”€â”€ amplifier.ts
â”‚ â”œâ”€â”€ notifications.ts
â”‚ â”œâ”€â”€ voice.ts
â”‚ â””â”€â”€ sync.ts
â”œâ”€â”€ stores/
â”‚ â”œâ”€â”€ queryStore.ts
â”‚ â”œâ”€â”€ notificationStore.ts
â”‚ â””â”€â”€ sessionStore.ts
â””â”€â”€ utils/
 â”œâ”€â”€ api.ts
 â””â”€â”€ storage.ts`
```

#### Query Screen

 typescript
 Copy

`// screens/QueryScreen.tsx
import React, { useState } from 'react';
import {
 View,
 TextInput,
 FlatList,
 TouchableOpacity,
 Text,
 StyleSheet
} from 'react-native';
import { useNavigation } from '@react-navigation/native';
import { VoiceButton } from '../components/VoiceButton';
import { useQueryStore } from '../stores/queryStore';
import { amplifier } from '../services/amplifier';

export function QueryScreen() {
 const [query, setQuery] = useState('');
 const [isLoading, setIsLoading] = useState(false);
 const navigation = useNavigation();
 const { recentQueries, addQuery } = useQueryStore();

 const handleSubmit = async () => {
 if (!query.trim()) return;

 setIsLoading(true);
 try {
 const result = await amplifier.execute({
 prompt: query,
 context: { type: 'mobile_query' }
 });

 addQuery({
 query,
 result: result.response,
 timestamp: new Date(),
 project: amplifier.currentProject
 });

 navigation.navigate('QueryResult', { result });
 } finally {
 setIsLoading(false);
 }
 };

 const handleVoiceResult = (transcript: string) => {
 setQuery(transcript);
 // Auto-submit voice queries
 handleSubmit();
 };

 return (
 <View style={styles.container}>
 <View style={styles.inputContainer}>
 <TextInput
 style={styles.input}
 value={query}
 onChangeText={setQuery}
 placeholder="Ask about your codebase..."
 multiline
 returnKeyType="send"
 onSubmitEditing={handleSubmit}
 />
 <VoiceButton onResult={handleVoiceResult} />
 </View>

 <Text style={styles.sectionTitle}>Recent Queries</Text>

 <FlatList
 data={recentQueries}
 keyExtractor={item => item.id}
 renderItem={({ item }) => (
 <TouchableOpacity
 style={styles.recentItem}
 onPress={() => navigation.navigate('QueryResult', { result: item })}
 >
 <Text style={styles.queryText}>{item.query}</Text>
 <Text style={styles.metaText}>
 {item.project} â€¢ {formatTimeAgo(item.timestamp)}
 </Text>
 </TouchableOpacity>
 )}
 />

 <TouchableOpacity
 style={[styles.askButton, isLoading && styles.askButtonDisabled]}
 onPress={handleSubmit}
 disabled={isLoading}
 >
 <Text style={styles.askButtonText}>
 {isLoading ? 'Asking...' : 'ðŸŽ¤ Ask'}
 </Text>
 </TouchableOpacity>
 </View>
 );
}`
```

#### Voice Input Component

 typescript
 Copy

`// components/VoiceButton.tsx
import React, { useState } from 'react';
import { TouchableOpacity, StyleSheet, Animated } from 'react-native';
import Voice from '@react-native-voice/voice';

interface VoiceButtonProps {
 onResult: (transcript: string) => void;
}

export function VoiceButton({ onResult }: VoiceButtonProps) {
 const [isListening, setIsListening] = useState(false);
 const pulseAnim = new Animated.Value(1);

 const startListening = async () => {
 setIsListening(true);

 // Start pulse animation
 Animated.loop(
 Animated.sequence([
 Animated.timing(pulseAnim, {
 toValue: 1.2,
 duration: 500,
 useNativeDriver: true
 }),
 Animated.timing(pulseAnim, {
 toValue: 1,
 duration: 500,
 useNativeDriver: true
 })
 ])
 ).start();

 Voice.onSpeechResults = (e) => {
 const transcript = e.value?.[0] || '';
 stopListening();
 onResult(transcript);
 };

 Voice.onSpeechError = () => {
 stopListening();
 };

 await Voice.start('en-US');
 };

 const stopListening = async () => {
 setIsListening(false);
 pulseAnim.stopAnimation();
 await Voice.stop();
 };

 return (
 <Animated.View style={{ transform: [{ scale: pulseAnim }] }}>
 <TouchableOpacity
 style={[
 styles.voiceButton,
 isListening && styles.voiceButtonActive
 ]}
 onPress={isListening ? stopListening : startListening}
 >
 <Text style={styles.voiceIcon}>ðŸŽ¤</Text>
 </TouchableOpacity>
 </Animated.View>
 );
}`
```

#### Notification Service

 typescript
 Copy

`// services/notifications.ts
import messaging from '@react-native-firebase/messaging';
import PushNotification from 'react-native-push-notification';
import { amplifier } from './amplifier';

export class NotificationService {
 async initialize() {
 // Request permission
 const authStatus = await messaging().requestPermission();

 if (authStatus === messaging.AuthorizationStatus.AUTHORIZED) {
 // Get FCM token
 const token = await messaging().getToken();
 await this.registerToken(token);

 // Handle token refresh
 messaging().onTokenRefresh(token => this.registerToken(token));

 // Handle foreground messages
 messaging().onMessage(async remoteMessage => {
 this.handleNotification(remoteMessage);
 });

 // Handle background messages
 messaging().setBackgroundMessageHandler(async remoteMessage => {
 this.handleNotification(remoteMessage);
 });
 }
 }

 async registerToken(token: string) {
 await amplifier.api.post('/v1/notifications/register', {
 token,
 platform: Platform.OS
 });
 }

 handleNotification(message: any) {
 const { type, data } = message.data;

 switch (type) {
 case 'build_failed':
 PushNotification.localNotification({
 title: 'âŒ Build Failed',
 message: `${data.project} â€¢ ${data.branch}`,
 data: { type, ...data }
 });
 break;

 case 'review_requested':
 PushNotification.localNotification({
 title: 'ðŸ”” Review Requested',
 message: `PR #${data.pr_number}: ${data.title}`,
 data: { type, ...data }
 });
 break;

 case 'deploy_complete':
 PushNotification.localNotification({
 title: 'âœ… Deploy Complete',
 message: `${data.project} â€¢ ${data.environment}`,
 data: { type, ...data }
 });
 break;
 }
 }
}`
```

#### PR Review Screen

 typescript
 Copy

`// screens/PRReviewScreen.tsx
import React, { useState, useEffect } from 'react';
import {
 View,
 ScrollView,
 Text,
 TouchableOpacity,
 TextInput,
 StyleSheet
} from 'react-native';
import { amplifier } from '../services/amplifier';

export function PRReviewScreen({ route }) {
 const { prNumber, repoUrl } = route.params;
 const [pr, setPR] = useState(null);
 const [aiSummary, setAISummary] = useState(null);
 const [comment, setComment] = useState('');
 const [isLoading, setIsLoading] = useState(true);

 useEffect(() => {
 loadPR();
 }, []);

 const loadPR = async () => {
 setIsLoading(true);

 // Load PR details
 const prData = await amplifier.api.get(`/v1/github/pr/${prNumber}`);
 setPR(prData);

 // Get AI summary
 const summary = await amplifier.execute({
 prompt: `Summarize this PR for mobile review:\n\n${prData.diff}`,
 profile: 'enterprise-dev:mobile-review'
 });
 setAISummary(summary.response);

 setIsLoading(false);
 };

 const handleApprove = async () => {
 await amplifier.api.post(`/v1/github/pr/${prNumber}/approve`, {
 comment: comment || 'Approved via Amplifier Mobile'
 });
 navigation.goBack();
 };

 const handleComment = async () => {
 await amplifier.api.post(`/v1/github/pr/${prNumber}/comment`, {
 body: comment
 });
 setComment('');
 };

 const handleRequestChanges = async () => {
 await amplifier.api.post(`/v1/github/pr/${prNumber}/request-changes`, {
 comment
 });
 navigation.goBack();
 };

 if (isLoading) {
 return <LoadingScreen />;
 }

 return (
 <ScrollView style={styles.container}>
 <View style={styles.header}>
 <Text style={styles.title}>{pr.title}</Text>
 <Text style={styles.meta}>
 @{pr.author} â†’ {pr.base} â€¢ +{pr.additions} -{pr.deletions}
 </Text>
 </View>

 <View style={styles.aiSummary}>
 <Text style={styles.sectionTitle}>ðŸ¤– Amplifier Summary</Text>
 <Text style={styles.summaryText}>{aiSummary}</Text>
 </View>

 <View style={styles.files}>
 <Text style={styles.sectionTitle}>Files ({pr.files.length})</Text>
 {pr.files.map(file => (
 <TouchableOpacity
 key={file.path}
 style={styles.fileItem}
 onPress={() => navigation.navigate('FileDiff', { file })}
 >
 <Text style={styles.fileName}>{file.path}</Text>
 <Text style={styles.fileChanges}>+{file.additions}</Text>
 </TouchableOpacity>
 ))}
 </View>

 <View style={styles.commentBox}>
 <TextInput
 style={styles.commentInput}
 value={comment}
 onChangeText={setComment}
 placeholder="Add a comment..."
 multiline
 />
 </View>

 <View style={styles.actions}>
 <TouchableOpacity
 style={[styles.actionButton, styles.approveButton]}
 onPress={handleApprove}
 >
 <Text style={styles.actionButtonText}>âœ… Approve</Text>
 </TouchableOpacity>

 <TouchableOpacity
 style={[styles.actionButton, styles.commentButton]}
 onPress={handleComment}
 >
 <Text style={styles.actionButtonText}>ðŸ’¬ Comment</Text>
 </TouchableOpacity>

 <TouchableOpacity
 style={[styles.actionButton, styles.denyButton]}
 onPress={handleRequestChanges}
 >
 <Text style={styles.actionButtonText}>âŒ Request Changes</Text>
 </TouchableOpacity>
 </View>
 </ScrollView>
 );
}`
```

---

### Notification Types

 | 
 
 | Type | Trigger | Actions

 | `build_failed` | CI build fails | View details, Ask Amplifier
 
 | `build_success` | CI build passes | View logs
 
 | `review_requested` | PR review assigned | Quick review, Open PR
 
 | `review_approved` | PR approved | View PR
 
 | `deploy_started` | Deployment begins | View progress
 
 | `deploy_complete` | Deployment finishes | View logs
 
 | `deploy_failed` | Deployment fails | View error, Ask Amplifier
 
 | `mention` | Mentioned in comment | View context, Reply
 
 | `session_update` | Desktop session update | Continue session

---

### Offline Support

 typescript
 Copy

`// Offline-first architecture
const offlineConfig = {
 // Cache queries for offline viewing
 queryCaching: {
 enabled: true,
 maxItems: 100,
 maxAge: '7d'
 },

 // Queue actions when offline
 actionQueue: {
 enabled: true,
 syncOnReconnect: true
 },

 // Sync desktop sessions
 sessionSync: {
 enabled: true,
 backgroundSync: true,
 syncInterval: '5m'
 }
};`
```

---

### Security

 yaml
 Copy

`security:
 auth:
 - oauth2 (GitHub, Google)
 - biometric (Face ID, fingerprint)
 - api_key

 data:
 - encrypted_storage (Keychain/Keystore)
 - no_code_cache (queries only)
 - auto_logout: 24h

 network:
 - certificate_pinning: true
 - min_tls: 1.3`
```

---

### Events

 | 
 
 | Event | Description | Data

 | `mobile:query_sent` | Query submitted | query, voice
 
 | `mobile:notification_received` | Push received | type
 
 | `mobile:pr_reviewed` | PR action taken | action, pr
 
 | `mobile:session_continued` | Session resumed | session_id

---

### Open Questions

- Offline queries: Pre-cache common queries per project?
 
- Widget support: iOS widgets for quick status?
 
- Watch app: Apple Watch / Wear OS companion?
 
- Code viewing: How to display code diffs effectively on mobile?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Integration Observability
 integrations

Priority: P2 (Medium Value)

Status: Draft

Module: `amplifier-integration-observability`

### Overview

Unified observability integration connecting Amplifier to monitoring platforms (Datadog, Prometheus, Grafana, New Relic, etc.). Enables AI-powered analysis of metrics, logs, and traces during incident response and proactive monitoring.

#### Value Proposition

 | 
 
 | Without | With

 | Manual metric correlation | AI-driven anomaly detection
 
 | Siloed observability data | Unified query interface
 
 | Reactive incident response | Proactive issue identification
 
 | Context switching between tools | Single AI interface

---

### Features

#### 1. Unified Metrics Query

Query metrics across multiple platforms with natural language.

 python
 Copy

`# Natural language query
"Show me the error rate for payment-api in the last hour"

# Amplifier translates to appropriate platform queries:
# Datadog: avg:payment_api.error_rate{service:payment-api}.rollup(avg, 60)
# Prometheus: rate(payment_api_errors_total{service="payment-api"}[1h])
# New Relic: SELECT average(errorRate) FROM Transaction WHERE appName='payment-api'

# Returns unified response:
{
 "metric": "error_rate",
 "service": "payment-api",
 "time_range": "1h",
 "data_points": [...],
 "summary": {
 "current": 0.02,
 "average": 0.015,
 "trend": "increasing",
 "anomaly_detected": True
 }
}`
```

#### 2. Log Analysis

AI-powered log search and analysis.

 python
 Copy

`# Query logs across platforms
async with AmplifierSession(config=OBSERVABILITY_CONFIG) as session:
 result = await session.execute(
 prompt="Find errors related to database connections in the last 30 minutes",
 tools=["tool-log-query"]
 )

# Result:
"""
Found 47 database connection errors across 3 services:

**payment-api** (32 errors)
- Pattern: "Connection pool exhausted" at 14:23-14:28 UTC
- Affected endpoints: /api/payments, /api/refunds

**user-service** (12 errors)
- Pattern: "Connection timeout after 30s"
- Started after payment-api errors

**order-service** (3 errors)
- Pattern: "Unable to acquire connection"
- Isolated incidents, likely cascade effect

**Root Cause Analysis:**
The connection pool in payment-api reached capacity at 14:23 UTC.
This coincides with traffic spike (3x normal) from marketing campaign.

**Recommended Actions:**
1. Increase payment-api connection pool size
2. Add connection pool metrics alerting
3. Review query efficiency in /api/payments endpoint
"""`
```

#### 3. Trace Analysis

Distributed trace correlation and analysis.

 python
 Copy

`# Analyze slow traces
async with AmplifierSession(config=TRACE_CONFIG) as session:
 result = await session.execute(
 prompt="Why are checkout requests taking over 5 seconds?",
 tools=["tool-trace-query"]
 )

# Result with trace visualization:
"""
**Slow Checkout Analysis** (traces > 5s in last hour)

Sample trace: `trace-id-abc123`
Total duration: 7.2s`
```

checkout-api â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 1.2s (17%)

 â””â”€ inventory â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 5.8s (81%) â† Bottleneck

 â””â”€ db â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 4.1s (57%)

 â””â”€ payment â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆ 0.2s (3%)

 text
 Copy

`**Analysis:**
- Inventory service is the bottleneck (81% of total time)
- Database queries in inventory taking 4.1s average
- Query: `SELECT * FROM inventory WHERE sku IN (...)` - scanning 2M rows

**Recommendations:**
1. Add index on `inventory.sku` column
2. Implement inventory caching for frequently accessed SKUs
3. Consider pagination for bulk inventory checks
"""`
```

#### 4. Anomaly Detection

Proactive anomaly detection with AI analysis.

 python
 Copy

`# Configure anomaly detection
config = {
 "anomaly_detection": {
 "enabled": True,
 "metrics": [
 "error_rate",
 "latency_p99",
 "throughput",
 "cpu_usage",
 "memory_usage"
 ],
 "sensitivity": "medium", # low | medium | high
 "notification_channel": "slack:#observability-alerts"
 }
}

# Automatic anomaly report:
"""
ðŸ” **Anomaly Detected** - payment-api

**Metric:** latency_p99
**Current:** 2.3s (normal: 0.4s)
**Started:** 14:15 UTC (25 minutes ago)
**Severity:** High

**Correlated Events:**
- 14:12 UTC: Deployment `payment-api@v2.4.1`
- 14:13 UTC: Config change in Redis cluster
- 14:14 UTC: Traffic spike +40%

**AI Analysis:**
The latency increase correlates strongly with the Redis config change.
The new configuration reduced connection pool from 100 to 20.

**Suggested Investigation:**
1. Check Redis connection metrics
2. Review config change in `redis-cluster-config@v1.2.3`
3. Consider rollback if latency doesn't recover

[View Dashboard](link) | [Start Investigation](link)
"""`
```

#### 5. Dashboard Generation

AI-generated dashboards based on service architecture.

 python
 Copy

`# Generate dashboard from service description
async with AmplifierSession(config=DASHBOARD_CONFIG) as session:
 result = await session.execute(
 prompt="Create a dashboard for our payment processing service",
 context={
 "service": "payment-api",
 "dependencies": ["postgres", "redis", "stripe-api"],
 "key_metrics": ["throughput", "error_rate", "latency"]
 }
 )

# Result: Dashboard configuration
{
 "title": "Payment API Dashboard",
 "panels": [
 {
 "title": "Request Throughput",
 "type": "timeseries",
 "query": "rate(payment_api_requests_total[5m])"
 },
 {
 "title": "Error Rate",
 "type": "gauge",
 "query": "rate(payment_api_errors_total[5m]) / rate(payment_api_requests_total[5m])",
 "thresholds": [0.01, 0.05]
 },
 {
 "title": "P99 Latency",
 "type": "timeseries",
 "query": "histogram_quantile(0.99, payment_api_latency_bucket)"
 },
 {
 "title": "Dependency Health",
 "type": "status",
 "targets": ["postgres", "redis", "stripe-api"]
 }
 ]
}`
```

#### 6. Incident Context Enrichment

Automatically enrich incident data with observability context.

 python
 Copy

`# When incident is triggered, gather observability context
async def enrich_incident_context(incident: dict) -> dict:
 """Gather comprehensive observability context for incident."""

 service = incident["service"]
 start_time = incident["started_at"]

 context = {}

 # Get metrics around incident start
 context["metrics"] = await query_metrics(
 service=service,
 start=start_time - timedelta(minutes=30),
 end=start_time + timedelta(minutes=10)
 )

 # Get error logs
 context["error_logs"] = await query_logs(
 service=service,
 level="error",
 start=start_time - timedelta(minutes=5),
 limit=100
 )

 # Get recent traces with errors
 context["error_traces"] = await query_traces(
 service=service,
 status="error",
 start=start_time - timedelta(minutes=5),
 limit=20
 )

 # Get recent deployments
 context["deployments"] = await query_deployments(
 service=service,
 start=start_time - timedelta(hours=2)
 )

 # Get correlated alerts
 context["alerts"] = await query_alerts(
 service=service,
 start=start_time - timedelta(minutes=10)
 )

 return context`
```

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Observability Integration â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Unified Query Layer â”‚ â”‚
â”‚ â”‚ â€¢ Natural language â†’ Platform-specific queries â”‚ â”‚
â”‚ â”‚ â€¢ Result normalization and aggregation â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Datadog â”‚ â”‚Prometheusâ”‚ â”‚ Grafana â”‚ â”‚
â”‚ â”‚ Adapter â”‚ â”‚ Adapter â”‚ â”‚ Adapter â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ New Relicâ”‚ â”‚ Loki â”‚ â”‚ Jaeger â”‚ â”‚
â”‚ â”‚ Adapter â”‚ â”‚ Adapter â”‚ â”‚ Adapter â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Analysis Engine â”‚ â”‚
â”‚ â”‚ â€¢ Anomaly detection â€¢ Correlation â€¢ Root cause analysis â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Platform Adapters

#### Datadog Adapter

 python
 Copy

`# adapters/datadog.py

from datadog_api_client import ApiClient, Configuration
from datadog_api_client.v1.api import metrics_api, logs_api

class DatadogAdapter:
 """Adapter for Datadog APIs."""

 def __init__(self, config: DatadogConfig):
 self.config = config
 self.api_config = Configuration()
 self.api_config.api_key["apiKeyAuth"] = config.api_key
 self.api_config.api_key["appKeyAuth"] = config.app_key

 async def query_metrics(
 self,
 query: str,
 start: datetime,
 end: datetime
 ) -> MetricsResult:
 """Query Datadog metrics."""

 with ApiClient(self.api_config) as client:
 api = metrics_api.MetricsApi(client)
 response = api.query_metrics(
 query=query,
 _from=int(start.timestamp()),
 to=int(end.timestamp())
 )

 return self._normalize_metrics(response)

 async def query_logs(
 self,
 query: str,
 start: datetime,
 end: datetime,
 limit: int = 100
 ) -> LogsResult:
 """Query Datadog logs."""

 with ApiClient(self.api_config) as client:
 api = logs_api.LogsApi(client)
 response = api.list_logs(
 body={
 "filter": {
 "query": query,
 "from": start.isoformat(),
 "to": end.isoformat()
 },
 "page": {"limit": limit}
 }
 )

 return self._normalize_logs(response)

 def translate_query(self, natural_query: str, context: dict) -> str:
 """Translate natural language to Datadog query."""

 # Use AI to translate
 # This would call Amplifier to do the translation
 pass

 def _normalize_metrics(self, response) -> MetricsResult:
 """Normalize Datadog metrics to unified format."""

 return MetricsResult(
 source="datadog",
 data_points=[
 DataPoint(
 timestamp=datetime.fromtimestamp(p[0] / 1000),
 value=p[1]
 )
 for series in response.series
 for p in series.pointlist
 ],
 metadata={
 "query": response.query,
 "unit": response.series[0].unit if response.series else None
 }
 )`
```

#### Prometheus Adapter

 python
 Copy

`# adapters/prometheus.py

import aiohttp

class PrometheusAdapter:
 """Adapter for Prometheus API."""

 def __init__(self, config: PrometheusConfig):
 self.config = config
 self.base_url = config.url

 async def query_metrics(
 self,
 query: str,
 start: datetime,
 end: datetime,
 step: str = "1m"
 ) -> MetricsResult:
 """Query Prometheus metrics."""

 async with aiohttp.ClientSession() as session:
 async with session.get(
 f"{self.base_url}/api/v1/query_range",
 params={
 "query": query,
 "start": start.timestamp(),
 "end": end.timestamp(),
 "step": step
 }
 ) as response:
 data = await response.json()

 return self._normalize_metrics(data)

 async def query_instant(self, query: str) -> MetricsResult:
 """Query current metric value."""

 async with aiohttp.ClientSession() as session:
 async with session.get(
 f"{self.base_url}/api/v1/query",
 params={"query": query}
 ) as response:
 data = await response.json()

 return self._normalize_instant(data)

 def translate_query(self, natural_query: str, context: dict) -> str:
 """Translate natural language to PromQL."""

 # Common translations
 translations = {
 "error_rate": 'rate({service}_errors_total{{service="{service}"}}[{window}])',
 "latency_p99": 'histogram_quantile(0.99, rate({service}_latency_bucket{{service="{service}"}}[{window}]))',
 "throughput": 'rate({service}_requests_total{{service="{service}"}}[{window}])',
 }

 # Would use AI for complex translations
 pass

 def _normalize_metrics(self, data: dict) -> MetricsResult:
 """Normalize Prometheus response to unified format."""

 result = data.get("data", {}).get("result", [])
 if not result:
 return MetricsResult(source="prometheus", data_points=[])

 return MetricsResult(
 source="prometheus",
 data_points=[
 DataPoint(
 timestamp=datetime.fromtimestamp(float(p[0])),
 value=float(p[1]),
 labels=series.get("metric", {})
 )
 for series in result
 for p in series.get("values", [])
 ],
 metadata={
 "result_type": data.get("data", {}).get("resultType")
 }
 )`
```

#### Grafana Adapter

 python
 Copy

`# adapters/grafana.py

class GrafanaAdapter:
 """Adapter for Grafana API."""

 def __init__(self, config: GrafanaConfig):
 self.config = config
 self.base_url = config.url
 self.api_key = config.api_key

 async def query_dashboard(
 self,
 dashboard_uid: str,
 panel_id: int,
 start: datetime,
 end: datetime
 ) -> MetricsResult:
 """Query specific dashboard panel."""

 headers = {"Authorization": f"Bearer {self.api_key}"}

 async with aiohttp.ClientSession() as session:
 async with session.get(
 f"{self.base_url}/api/dashboards/uid/{dashboard_uid}",
 headers=headers
 ) as response:
 dashboard = await response.json()

 # Find panel and execute its queries
 panel = self._find_panel(dashboard, panel_id)
 return await self._execute_panel_queries(panel, start, end)

 async def create_dashboard(
 self,
 config: DashboardConfig
 ) -> dict:
 """Create a new Grafana dashboard."""

 headers = {
 "Authorization": f"Bearer {self.api_key}",
 "Content-Type": "application/json"
 }

 dashboard_json = self._build_dashboard(config)

 async with aiohttp.ClientSession() as session:
 async with session.post(
 f"{self.base_url}/api/dashboards/db",
 headers=headers,
 json={"dashboard": dashboard_json}
 ) as response:
 return await response.json()

 async def list_dashboards(
 self,
 folder_id: int | None = None,
 tag: str | None = None
 ) -> list[dict]:
 """List available dashboards."""

 headers = {"Authorization": f"Bearer {self.api_key}"}
 params = {}
 if folder_id:
 params["folderIds"] = folder_id
 if tag:
 params["tag"] = tag

 async with aiohttp.ClientSession() as session:
 async with session.get(
 f"{self.base_url}/api/search",
 headers=headers,
 params=params
 ) as response:
 return await response.json()`
```

---

### Unified Query Interface

 python
 Copy

`# query/unified.py

class UnifiedObservabilityQuery:
 """Unified interface for querying observability data."""

 def __init__(self, adapters: dict[str, Adapter]):
 self.adapters = adapters

 async def query_metrics(
 self,
 natural_query: str,
 context: QueryContext
 ) -> UnifiedResult:
 """Query metrics using natural language."""

 # Parse natural query
 parsed = await self._parse_query(natural_query, context)

 # Execute on relevant platforms
 results = []
 for platform in parsed.target_platforms:
 adapter = self.adapters.get(platform)
 if adapter:
 platform_query = adapter.translate_query(
 natural_query, context.to_dict()
 )
 result = await adapter.query_metrics(
 platform_query,
 parsed.start_time,
 parsed.end_time
 )
 results.append(result)

 # Aggregate and normalize
 return self._aggregate_results(results)

 async def query_logs(
 self,
 natural_query: str,
 context: QueryContext
 ) -> UnifiedResult:
 """Query logs using natural language."""

 parsed = await self._parse_query(natural_query, context)

 results = []
 for platform in self._get_log_platforms():
 adapter = self.adapters.get(platform)
 if adapter and hasattr(adapter, "query_logs"):
 result = await adapter.query_logs(
 parsed.translated_query,
 parsed.start_time,
 parsed.end_time
 )
 results.append(result)

 return self._aggregate_log_results(results)

 async def query_traces(
 self,
 trace_id: str | None = None,
 service: str | None = None,
 operation: str | None = None,
 start: datetime | None = None,
 end: datetime | None = None,
 status: str | None = None
 ) -> list[Trace]:
 """Query distributed traces."""

 results = []
 for platform in self._get_trace_platforms():
 adapter = self.adapters.get(platform)
 if adapter and hasattr(adapter, "query_traces"):
 result = await adapter.query_traces(
 trace_id=trace_id,
 service=service,
 operation=operation,
 start=start,
 end=end,
 status=status
 )
 results.extend(result)

 return self._deduplicate_traces(results)

 async def _parse_query(
 self,
 natural_query: str,
 context: QueryContext
 ) -> ParsedQuery:
 """Parse natural language query into structured form."""

 # Use AI to parse the query
 async with AmplifierSession(config=QUERY_PARSER_CONFIG) as session:
 result = await session.execute(
 prompt=f"""Parse this observability query:
 Query: {natural_query}
 Context: {context.to_dict()}

 Extract:
 - Target metrics/logs/traces
 - Time range
 - Filters (service, environment, etc.)
 - Aggregations
 """,
 )

 return ParsedQuery.from_ai_response(result)`
```

---

### Analysis Engine

#### Anomaly Detection

 python
 Copy

`# analysis/anomaly.py

class AnomalyDetector:
 """Detect anomalies in metrics data."""

 def __init__(self, config: AnomalyConfig):
 self.config = config
 self.baseline_window = config.baseline_window
 self.sensitivity = config.sensitivity

 async def detect(
 self,
 metric_data: MetricsResult,
 context: dict
 ) -> list[Anomaly]:
 """Detect anomalies in metric data."""

 anomalies = []

 # Statistical anomaly detection
 stats_anomalies = self._detect_statistical_anomalies(metric_data)
 anomalies.extend(stats_anomalies)

 # Pattern-based detection
 pattern_anomalies = self._detect_pattern_anomalies(metric_data)
 anomalies.extend(pattern_anomalies)

 # AI-enhanced detection for complex patterns
 ai_anomalies = await self._detect_ai_anomalies(metric_data, context)
 anomalies.extend(ai_anomalies)

 # Deduplicate and rank
 return self._rank_anomalies(anomalies)

 def _detect_statistical_anomalies(
 self,
 data: MetricsResult
 ) -> list[Anomaly]:
 """Detect anomalies using statistical methods."""

 values = [p.value for p in data.data_points]
 if len(values) < 10:
 return []

 mean = statistics.mean(values)
 stdev = statistics.stdev(values)

 threshold_multiplier = {
 "low": 3,
 "medium": 2.5,
 "high": 2
 }[self.sensitivity]

 threshold = mean + (stdev * threshold_multiplier)

 anomalies = []
 for point in data.data_points:
 if point.value > threshold:
 anomalies.append(Anomaly(
 timestamp=point.timestamp,
 metric=data.metadata.get("metric_name"),
 value=point.value,
 expected_range=(mean - stdev, mean + stdev),
 severity=self._calculate_severity(point.value, mean, stdev),
 detection_method="statistical"
 ))

 return anomalies

 async def _detect_ai_anomalies(
 self,
 data: MetricsResult,
 context: dict
 ) -> list[Anomaly]:
 """Use AI to detect complex anomaly patterns."""

 async with AmplifierSession(config=ANOMALY_CONFIG) as session:
 result = await session.execute(
 prompt=f"""Analyze this metric data for anomalies:

 Data: {data.to_summary()}
 Context: {context}

 Look for:
 - Sudden spikes or drops
 - Trend changes
 - Seasonal pattern violations
 - Correlation anomalies with other metrics

 Return structured anomaly data.
 """,
 )

 return self._parse_ai_anomalies(result)

class CorrelationAnalyzer:
 """Analyze correlations between metrics and events."""

 async def correlate_with_deployments(
 self,
 anomaly: Anomaly,
 service: str
 ) -> list[Correlation]:
 """Find deployments that correlate with anomaly."""

 # Get deployments in time window
 deployments = await self.deployment_adapter.get_deployments(
 service=service,
 start=anomaly.timestamp - timedelta(hours=2),
 end=anomaly.timestamp
 )

 correlations = []
 for deployment in deployments:
 time_diff = (anomaly.timestamp - deployment.timestamp).total_seconds()
 if 0 < time_diff < 3600: # Within 1 hour after deployment
 correlations.append(Correlation(
 event_type="deployment",
 event=deployment,
 time_offset=time_diff,
 confidence=self._calculate_confidence(time_diff)
 ))

 return correlations

 async def correlate_with_config_changes(
 self,
 anomaly: Anomaly,
 service: str
 ) -> list[Correlation]:
 """Find config changes that correlate with anomaly."""

 config_changes = await self.config_adapter.get_changes(
 service=service,
 start=anomaly.timestamp - timedelta(hours=1),
 end=anomaly.timestamp
 )

 correlations = []
 for change in config_changes:
 time_diff = (anomaly.timestamp - change.timestamp).total_seconds()
 if 0 < time_diff < 1800: # Within 30 minutes
 correlations.append(Correlation(
 event_type="config_change",
 event=change,
 time_offset=time_diff,
 confidence=self._calculate_confidence(time_diff)
 ))

 return correlations`
```

#### Root Cause Analysis

 python
 Copy

`# analysis/root_cause.py

class RootCauseAnalyzer:
 """Analyze root cause of incidents using observability data."""

 async def analyze(
 self,
 incident: dict,
 context: ObservabilityContext
 ) -> RootCauseReport:
 """Perform root cause analysis."""

 # Gather all relevant data
 metrics = context.metrics
 logs = context.error_logs
 traces = context.error_traces
 deployments = context.deployments
 config_changes = context.config_changes

 # Use AI for root cause analysis
 async with AmplifierSession(config=RCA_CONFIG) as session:
 result = await session.execute(
 prompt=f"""Analyze this incident and determine root cause:

 Incident: {incident}

 Metrics (around incident time):
 {self._summarize_metrics(metrics)}

 Error Logs:
 {self._summarize_logs(logs)}

 Error Traces:
 {self._summarize_traces(traces)}

 Recent Deployments:
 {self._summarize_deployments(deployments)}

 Recent Config Changes:
 {self._summarize_config_changes(config_changes)}

 Provide:
 1. Most likely root cause
 2. Evidence supporting this conclusion
 3. Alternative hypotheses
 4. Recommended remediation steps
 5. Preventive measures for the future
 """,
 )

 return self._parse_rca_result(result)

 def _summarize_metrics(self, metrics: dict) -> str:
 """Summarize metrics for AI analysis."""

 summaries = []
 for metric_name, data in metrics.items():
 trend = self._calculate_trend(data)
 anomalies = self._find_anomalies(data)
 summaries.append(
 f"{metric_name}: trend={trend}, anomalies={len(anomalies)}"
 )
 return "\n".join(summaries)`
```

---

### Configuration

 yaml
 Copy

`# .amplifier/integrations/observability.yaml
observability:
 enabled: true

 # Platform configurations
 platforms:
 datadog:
 enabled: true
 api_key: ${DATADOG_API_KEY}
 app_key: ${DATADOG_APP_KEY}
 site: "datadoghq.com" # or datadoghq.eu

 prometheus:
 enabled: true
 url: "http://prometheus.monitoring.svc:9090"
 # Optional authentication
 auth:
 type: bearer
 token: ${PROMETHEUS_TOKEN}

 grafana:
 enabled: true
 url: "https://grafana.example.com"
 api_key: ${GRAFANA_API_KEY}

 loki:
 enabled: true
 url: "http://loki.monitoring.svc:3100"

 jaeger:
 enabled: true
 url: "http://jaeger.monitoring.svc:16686"

 # Anomaly detection configuration
 anomaly_detection:
 enabled: true
 sensitivity: medium # low | medium | high
 baseline_window: 7d # Historical data for baseline
 metrics:
 - name: "error_rate"
 threshold: 0.05 # 5% error rate
 alert_channel: "slack:#alerts"
 - name: "latency_p99"
 threshold: 2.0 # 2 seconds
 alert_channel: "slack:#alerts"
 - name: "throughput"
 change_threshold: 50 # 50% change
 alert_channel: "slack:#alerts"

 # Dashboard generation
 dashboards:
 auto_generate: true
 output_platform: grafana
 folder: "Amplifier Generated"
 refresh_interval: "30s"

 # Query settings
 query:
 default_time_range: 1h
 max_time_range: 7d
 max_data_points: 1000
 cache_ttl: 60s

 # Correlation settings
 correlation:
 deployment_window: 2h # Look back 2 hours for deployments
 config_change_window: 1h # Look back 1 hour for config changes
 alert_window: 30m # Look for related alerts

 # Export settings
 export:
 enabled: true
 formats:
 - json
 - csv
 retention: 30d`
```

---

### Tools

#### tool-metrics-query

 yaml
 Copy

`# tools/tool-metrics-query.yaml
name: tool-metrics-query
description: Query metrics from observability platforms

parameters:
 query:
 type: string
 description: Natural language query or platform-specific query
 required: true
 platform:
 type: string
 enum: [datadog, prometheus, grafana, auto]
 default: auto
 start_time:
 type: string
 description: Start time (ISO8601 or relative like "1h ago")
 default: "1h ago"
 end_time:
 type: string
 description: End time
 default: "now"
 aggregation:
 type: string
 enum: [avg, sum, min, max, count]
 default: avg

returns:
 type: object
 properties:
 data_points:
 type: array
 description: Time series data
 summary:
 type: object
 description: Statistical summary
 anomalies:
 type: array
 description: Detected anomalies`
```

#### tool-log-query

 yaml
 Copy

`# tools/tool-log-query.yaml
name: tool-log-query
description: Query logs from observability platforms

parameters:
 query:
 type: string
 description: Natural language or platform-specific log query
 required: true
 platform:
 type: string
 enum: [datadog, loki, cloudwatch, auto]
 default: auto
 start_time:
 type: string
 default: "30m ago"
 end_time:
 type: string
 default: "now"
 limit:
 type: integer
 default: 100
 level:
 type: string
 enum: [debug, info, warn, error, fatal, all]
 default: all

returns:
 type: object
 properties:
 logs:
 type: array
 description: Log entries
 patterns:
 type: array
 description: Detected patterns
 summary:
 type: object
 description: Log analysis summary`
```

#### tool-trace-query

 yaml
 Copy

`# tools/tool-trace-query.yaml
name: tool-trace-query
description: Query distributed traces

parameters:
 trace_id:
 type: string
 description: Specific trace ID to retrieve
 service:
 type: string
 description: Filter by service name
 operation:
 type: string
 description: Filter by operation name
 status:
 type: string
 enum: [ok, error, all]
 default: all
 min_duration:
 type: string
 description: Minimum trace duration (e.g., "1s", "500ms")
 start_time:
 type: string
 default: "1h ago"
 end_time:
 type: string
 default: "now"
 limit:
 type: integer
 default: 20

returns:
 type: object
 properties:
 traces:
 type: array
 description: Trace data with spans
 analysis:
 type: object
 description: Trace analysis (bottlenecks, patterns)`
```

---

### Security

#### Credentials Management

 yaml
 Copy

`# Secrets should be managed via environment variables or secret manager
observability:
 platforms:
 datadog:
 api_key: ${DATADOG_API_KEY} # From environment
 app_key: ${DATADOG_APP_KEY}

 prometheus:
 auth:
 type: bearer
 token_secret: vault://secret/prometheus/token # From Vault`
```

#### Access Control

 python
 Copy

`# security/access.py

class ObservabilityAccessControl:
 """Control access to observability data."""

 def __init__(self, config: AccessConfig):
 self.config = config

 async def can_query(
 self,
 user: str,
 query_type: str,
 scope: dict
 ) -> bool:
 """Check if user can execute query."""

 # Get user's allowed scopes
 user_scopes = await self.get_user_scopes(user)

 # Check service access
 if scope.get("service"):
 if scope["service"] not in user_scopes.get("services", []):
 return False

 # Check environment access
 if scope.get("environment"):
 if scope["environment"] not in user_scopes.get("environments", []):
 return False

 # Check query type permissions
 allowed_queries = user_scopes.get("query_types", ["metrics", "logs"])
 if query_type not in allowed_queries:
 return False

 return True

 async def redact_sensitive_data(
 self,
 data: dict,
 user: str
 ) -> dict:
 """Redact sensitive data based on user permissions."""

 # Redact PII from logs if user doesn't have PII access
 if not await self.has_pii_access(user):
 data = self._redact_pii(data)

 # Redact secrets
 data = self._redact_secrets(data)

 return data`
```

---

### Events

 | 
 
 | Event | Description | Data

 | `observability:query:start` | Query started | query, platforms
 
 | `observability:query:complete` | Query completed | query, results, duration
 
 | `observability:anomaly:detected` | Anomaly detected | metric, value, severity
 
 | `observability:correlation:found` | Correlation found | anomaly, correlated_event
 
 | `observability:rca:complete` | Root cause analysis complete | incident, root_cause
 
 | `observability:dashboard:created` | Dashboard generated | dashboard_id, platform

---

### Dependencies

#### Required

- Platform-specific API clients (datadog-api-client, prometheus-api-client, etc.)
 
- aiohttp for async HTTP requests
 
- Statistics libraries for anomaly detection
 
#### Optional

- Machine learning libraries for advanced anomaly detection
 
- Visualization libraries for dashboard generation
 
---

### Open Questions

- Data retention: How long to cache observability data locally?
 
- Cost management: Rate limiting for expensive platform queries?
 
- Multi-tenancy: Support multiple observability stacks per environment?
 
- Alerting integration: Integrate with PagerDuty/OpsGenie for anomaly alerts?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Integration Obsidian Plugin
 integrations

Priority: P2 (Enhancement)

Status: Draft

Module: `amplifier-obsidian-plugin`

### Overview

Obsidian plugin connecting your knowledge base to your codebase through Amplifier. Generate documentation from code, link notes to source files, capture technical decisions, and query your combined knowledge (notes + code) with AI assistance.

#### Value Proposition

 | 
 
 | Without | With

 | Separate knowledge and code | Unified knowledge graph
 
 | Manual documentation updates | Auto-generated from code
 
 | Lost architectural decisions | Captured and linked
 
 | Search notes OR code | Query both simultaneously

---

### Features

#### 1. Code-to-Documentation Generation

Generate markdown documentation from codebase.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Obsidian: Architecture Notes â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ # Payment Processing Architecture â”‚
â”‚ â”‚
â”‚ [ðŸ¤– Generate from Code] â”‚
â”‚ â”‚
â”‚ > Generated from `src/payments/` on 2025-01-15 â”‚
â”‚ â”‚
â”‚ ## Overview â”‚
â”‚ â”‚
â”‚ The payment system handles transaction processing through â”‚
â”‚ Stripe integration with retry logic and fraud detection. â”‚
â”‚ â”‚
â”‚ ## Components â”‚
â”‚ â”‚
â”‚ - [[PaymentProcessor]] - Core processing logic â”‚
â”‚ - [[StripeGateway]] - Stripe API integration â”‚
â”‚ - [[FraudDetector]] - Fraud signal analysis â”‚
â”‚ â”‚
â”‚ ## Data Flow â”‚
â”‚ â”‚
â”‚ ```mermaid â”‚
â”‚ graph LR â”‚
â”‚ A[Order] --> B[Validator] â”‚
â”‚ B --> C[FraudDetector] â”‚
â”‚ C --> D[PaymentProcessor] â”‚
â”‚ D --> E[StripeGateway] â”‚
â”‚ ``` â”‚
â”‚ â”‚
â”‚ ## Source Links â”‚
â”‚ - `src/payments/processor.ts:45` [[#^processor-entry]] â”‚
â”‚ - `src/payments/gateway.ts:12` [[#^gateway-init]] â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 2. Codebase Query from Notes

Ask questions about your codebase from within Obsidian.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Obsidian: Technical Queries â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ # How does authentication work? â”‚
â”‚ â”‚
â”‚ ```amplifier â”‚
â”‚ query: How does the authentication flow work in this codebase? â”‚
â”‚ include: src/auth/** â”‚
â”‚ ``` â”‚
â”‚ â”‚
â”‚ > ðŸ¤– **Amplifier Response** (generated 2025-01-15 10:30) â”‚
â”‚ > â”‚
â”‚ > The authentication system uses JWT tokens with the following â”‚
â”‚ > flow: â”‚
â”‚ > â”‚
â”‚ > 1. **Login** (`src/auth/login.ts:23`) â”‚
â”‚ > - Validates credentials against database â”‚
â”‚ > - Generates JWT with 24h expiration â”‚
â”‚ > â”‚
â”‚ > 2. **Middleware** (`src/auth/middleware.ts:45`) â”‚
â”‚ > - Extracts token from Authorization header â”‚
â”‚ > - Validates signature and expiration â”‚
â”‚ > â”‚
â”‚ > 3. **Refresh** (`src/auth/refresh.ts:12`) â”‚
â”‚ > - Issues new token before expiration â”‚
â”‚ > â”‚
â”‚ > See also: [[Authentication ADR-003]] â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 3. Decision Capture

Capture architectural decisions linked to code.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Obsidian: ADR-005 Retry Strategy â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ # ADR-005: Exponential Backoff for Payment Retries â”‚
â”‚ â”‚
â”‚ **Status**: Accepted â”‚
â”‚ **Date**: 2025-01-15 â”‚
â”‚ **Deciders**: @alice, @bob â”‚
â”‚ â”‚
â”‚ ## Context â”‚
â”‚ â”‚
â”‚ Payment API calls to Stripe occasionally fail due to rate â”‚
â”‚ limiting and transient network issues. â”‚
â”‚ â”‚
â”‚ ```amplifier-context â”‚
â”‚ related_code: â”‚
â”‚ - src/payments/processor.ts â”‚
â”‚ - src/payments/retry.ts â”‚
â”‚ issue: #234 â”‚
â”‚ ``` â”‚
â”‚ â”‚
â”‚ ## Decision â”‚
â”‚ â”‚
â”‚ Implement exponential backoff with jitter: â”‚
â”‚ - Base delay: 1 second â”‚
â”‚ - Max retries: 3 â”‚
â”‚ - Jitter: Â±20% â”‚
â”‚ â”‚
â”‚ ## Implementation â”‚
â”‚ â”‚
â”‚ [ðŸ¤– View Implementation Status] â”‚
â”‚ â”‚
â”‚ > âœ… `src/payments/retry.ts` - Retry logic implemented â”‚
â”‚ > âœ… `src/payments/processor.ts:89` - Integrated with processor â”‚
â”‚ > âš ï¸ Tests pending for edge cases â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 4. Combined Knowledge Search

Search across notes AND codebase simultaneously.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Obsidian: Amplifier Search â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ ðŸ” Search: "payment validation" [Notes + Code] â”‚
â”‚ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ ðŸ“ Notes (3) â”‚
â”‚ â”œâ”€â”€ [[Payment Processing Architecture]] â”‚
â”‚ â”‚ "...validation occurs in PaymentValidator before..." â”‚
â”‚ â”œâ”€â”€ [[ADR-002 Validation Strategy]] â”‚
â”‚ â”‚ "...decided to validate at API boundary..." â”‚
â”‚ â””â”€â”€ [[Q4 Payment Improvements]] â”‚
â”‚ "...improve validation error messages..." â”‚
â”‚ â”‚
â”‚ ðŸ’» Code (5) â”‚
â”‚ â”œâ”€â”€ src/payments/validator.ts:23 â”‚
â”‚ â”‚ `export class PaymentValidator { validate(order)...` â”‚
â”‚ â”œâ”€â”€ src/payments/processor.ts:45 â”‚
â”‚ â”‚ `const validated = await this.validator.validate...` â”‚
â”‚ â”œâ”€â”€ src/api/payments.ts:12 â”‚
â”‚ â”‚ `// Validate payment request before processing` â”‚
â”‚ â”œâ”€â”€ tests/payments/validator.test.ts:34 â”‚
â”‚ â”‚ `describe('PaymentValidator', () => {...` â”‚
â”‚ â””â”€â”€ src/types/payment.ts:8 â”‚
â”‚ `interface ValidationResult { valid: boolean...` â”‚
â”‚ â”‚
â”‚ ðŸ¤– AI Summary â”‚
â”‚ "Payment validation is handled by PaymentValidator class, â”‚
â”‚ following the ADR-002 decision to validate at API boundaries. â”‚
â”‚ Currently 5 files implement validation logic..." â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 5. Code Block Sync

Keep code blocks in notes synchronized with actual code.

 markdown
 Copy

`# Example Usage

This code block is synced with the actual source:`
```

// Amplifier will update this block when source changes

async processPayment(order: Order): Promise
 {

 const validated = await this.validator.validate(order);

 if (!validated.valid) {

 throw new ValidationError(validated.errors);

 }

 return this.gateway.charge(order.total);

}

 text
 Copy

`> âš ï¸ Source changed on 2025-01-15. [View diff] [Update block]`
```

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Obsidian Plugin â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Doc â”‚ â”‚ Query â”‚ â”‚ Sync â”‚ â”‚
â”‚ â”‚ Generator â”‚ â”‚ Interface â”‚ â”‚ Manager â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Amplifier â”‚ â”‚
â”‚ â”‚ Connector â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Local CLI â”‚ â”‚ API Server â”‚ â”‚ File â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ Watcher â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Plugin Structure

 text
 Copy

`amplifier-obsidian-plugin/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ main.ts # Plugin entry point
â”‚ â”œâ”€â”€ settings.ts # Settings management
â”‚ â”œâ”€â”€ connector.ts # Amplifier connection
â”‚ â”œâ”€â”€ features/
â”‚ â”‚ â”œâ”€â”€ doc-generator.ts # Documentation generation
â”‚ â”‚ â”œâ”€â”€ query-interface.ts # Codebase queries
â”‚ â”‚ â”œâ”€â”€ decision-capture.ts # ADR management
â”‚ â”‚ â”œâ”€â”€ combined-search.ts # Unified search
â”‚ â”‚ â””â”€â”€ code-sync.ts # Code block sync
â”‚ â”œâ”€â”€ ui/
â”‚ â”‚ â”œâ”€â”€ search-modal.ts # Search UI
â”‚ â”‚ â”œâ”€â”€ query-view.ts # Query results
â”‚ â”‚ â””â”€â”€ settings-tab.ts # Settings UI
â”‚ â””â”€â”€ utils/
â”‚ â”œâ”€â”€ markdown.ts # Markdown processing
â”‚ â””â”€â”€ code-parser.ts # Code reference parsing
â”œâ”€â”€ styles.css
â”œâ”€â”€ manifest.json
â””â”€â”€ package.json`
```

---

### Implementation

#### Plugin Entry Point

 typescript
 Copy

`// src/main.ts
import { Plugin, MarkdownPostProcessorContext } from 'obsidian';
import { AmplifierConnector } from './connector';
import { DocGenerator } from './features/doc-generator';
import { QueryInterface } from './features/query-interface';
import { CombinedSearch } from './features/combined-search';
import { CodeSync } from './features/code-sync';
import { AmplifierSettingTab, AmplifierSettings } from './settings';

export default class AmplifierPlugin extends Plugin {
 settings: AmplifierSettings;
 connector: AmplifierConnector;

 async onload() {
 await this.loadSettings();

 // Initialize connector
 this.connector = new AmplifierConnector(this.settings);
 await this.connector.connect();

 // Initialize features
 const docGenerator = new DocGenerator(this.connector);
 const queryInterface = new QueryInterface(this.connector);
 const combinedSearch = new CombinedSearch(this.connector);
 const codeSync = new CodeSync(this.connector, this.app.vault);

 // Register commands
 this.addCommand({
 id: 'generate-docs',
 name: 'Generate Documentation from Code',
 callback: () => docGenerator.generate()
 });

 this.addCommand({
 id: 'query-codebase',
 name: 'Query Codebase',
 callback: () => queryInterface.openQueryModal()
 });

 this.addCommand({
 id: 'combined-search',
 name: 'Search Notes + Code',
 callback: () => combinedSearch.openSearchModal()
 });

 this.addCommand({
 id: 'sync-code-blocks',
 name: 'Sync Code Blocks in Current Note',
 callback: () => codeSync.syncCurrentNote()
 });

 // Register markdown processors
 this.registerMarkdownCodeBlockProcessor(
 'amplifier',
 (source, el, ctx) => queryInterface.processQueryBlock(source, el, ctx)
 );

 this.registerMarkdownCodeBlockProcessor(
 'amplifier-context',
 (source, el, ctx) => docGenerator.processContextBlock(source, el, ctx)
 );

 // Settings tab
 this.addSettingTab(new AmplifierSettingTab(this.app, this));

 // Ribbon icon
 this.addRibbonIcon('bot', 'Amplifier', () => {
 combinedSearch.openSearchModal();
 });
 }

 async onunload() {
 await this.connector.disconnect();
 }

 async loadSettings() {
 this.settings = Object.assign({}, DEFAULT_SETTINGS, await this.loadData());
 }

 async saveSettings() {
 await this.saveData(this.settings);
 }
}`
```

#### Documentation Generator

 typescript
 Copy

`// src/features/doc-generator.ts
import { Modal, Notice, TFile } from 'obsidian';
import { AmplifierConnector } from '../connector';

export class DocGenerator {
 constructor(private connector: AmplifierConnector) {}

 async generate() {
 const modal = new GenerateDocsModal(this.connector);
 modal.open();
 }

 async generateFromPath(codePath: string, options: GenerateOptions): Promise<string> {
 const response = await this.connector.execute({
 prompt: `Generate comprehensive markdown documentation for the code at ${codePath}.

Include:
- Overview and purpose
- Component descriptions with links
- Data flow diagrams (mermaid)
- Source file references
- Related concepts

Format for Obsidian with [[wiki links]] for components.`,
 context: {
 type: 'doc_generation',
 code_path: codePath,
 options
 }
 });

 return response.response;
 }

 async processContextBlock(
 source: string,
 el: HTMLElement,
 ctx: MarkdownPostProcessorContext
 ) {
 // Parse context block
 const context = parseYaml(source);

 // Create UI for viewing related code
 const container = el.createDiv({ cls: 'amplifier-context' });

 if (context.related_code) {
 const codeList = container.createEl('ul');
 for (const codePath of context.related_code) {
 const item = codeList.createEl('li');
 item.createEl('a', {
 text: codePath,
 href: `vscode://file/${codePath}`
 });

 // Add status indicator
 const status = await this.checkImplementationStatus(codePath);
 item.createSpan({
 text: status.implemented ? ' âœ…' : ' âš ï¸',
 cls: status.implemented ? 'status-done' : 'status-pending'
 });
 }
 }
 }
}`
```

#### Query Interface

 typescript
 Copy

`// src/features/query-interface.ts
import { Modal, TextAreaComponent } from 'obsidian';
import { AmplifierConnector } from '../connector';

export class QueryInterface {
 constructor(private connector: AmplifierConnector) {}

 openQueryModal() {
 new QueryModal(this.connector).open();
 }

 async processQueryBlock(
 source: string,
 el: HTMLElement,
 ctx: MarkdownPostProcessorContext
 ) {
 const container = el.createDiv({ cls: 'amplifier-query' });

 // Parse query block
 const lines = source.split('\n');
 const queryLine = lines.find(l => l.startsWith('query:'));
 const includeLine = lines.find(l => l.startsWith('include:'));

 const query = queryLine?.replace('query:', '').trim();
 const include = includeLine?.replace('include:', '').trim();

 if (!query) {
 container.createEl('p', { text: 'No query specified' });
 return;
 }

 // Check for cached response
 const cacheKey = `query:${query}:${include}`;
 const cached = await this.getCache(cacheKey);

 if (cached) {
 this.renderResponse(container, cached);
 return;
 }

 // Show loading
 const loading = container.createEl('p', { text: 'ðŸ¤– Querying codebase...' });

 try {
 const response = await this.connector.execute({
 prompt: query,
 context: {
 type: 'codebase_query',
 include_pattern: include
 }
 });

 loading.remove();
 this.renderResponse(container, response.response);

 // Cache response
 await this.setCache(cacheKey, response.response);
 } catch (error) {
 loading.remove();
 container.createEl('p', {
 text: `Error: ${error.message}`,
 cls: 'amplifier-error'
 });
 }
 }

 private renderResponse(container: HTMLElement, response: string) {
 const responseEl = container.createDiv({ cls: 'amplifier-response' });

 // Add timestamp
 responseEl.createEl('small', {
 text: `Generated ${new Date().toLocaleDateString()}`,
 cls: 'amplifier-timestamp'
 });

 // Render markdown response
 MarkdownRenderer.renderMarkdown(
 response,
 responseEl,
 '',
 null
 );

 // Add refresh button
 const refreshBtn = responseEl.createEl('button', {
 text: 'ðŸ”„ Refresh',
 cls: 'amplifier-refresh'
 });
 refreshBtn.onclick = () => this.refreshQuery(container);
 }
}

class QueryModal extends Modal {
 private query: string = '';
 private result: string = '';

 constructor(private connector: AmplifierConnector) {
 super(connector.app);
 }

 onOpen() {
 const { contentEl } = this;

 contentEl.createEl('h2', { text: 'ðŸ¤– Query Codebase' });

 // Query input
 new TextAreaComponent(contentEl)
 .setPlaceholder('Ask about your codebase...')
 .onChange(value => this.query = value);

 // Submit button
 const submitBtn = contentEl.createEl('button', { text: 'Query' });
 submitBtn.onclick = () => this.executeQuery();

 // Results area
 this.resultEl = contentEl.createDiv({ cls: 'query-results' });
 }

 async executeQuery() {
 this.resultEl.empty();
 this.resultEl.createEl('p', { text: 'Querying...' });

 try {
 const response = await this.connector.execute({
 prompt: this.query,
 context: { type: 'codebase_query' }
 });

 this.resultEl.empty();
 MarkdownRenderer.renderMarkdown(
 response.response,
 this.resultEl,
 '',
 null
 );
 } catch (error) {
 this.resultEl.empty();
 this.resultEl.createEl('p', {
 text: `Error: ${error.message}`,
 cls: 'error'
 });
 }
 }
}`
```

#### Combined Search

 typescript
 Copy

`// src/features/combined-search.ts
import { FuzzySuggestModal, TFile } from 'obsidian';
import { AmplifierConnector } from '../connector';

interface SearchResult {
 type: 'note' | 'code';
 title: string;
 excerpt: string;
 path: string;
 line?: number;
}

export class CombinedSearch {
 constructor(private connector: AmplifierConnector) {}

 openSearchModal() {
 new CombinedSearchModal(this.connector).open();
 }

 async search(query: string): Promise<{
 notes: SearchResult[];
 code: SearchResult[];
 summary: string;
 }> {
 // Search notes locally
 const notes = await this.searchNotes(query);

 // Search code via Amplifier
 const codeResponse = await this.connector.execute({
 prompt: `Search the codebase for: "${query}"

Return results as JSON array with fields:
- path: file path
- line: line number
- excerpt: relevant code snippet
- relevance: why this matches`,
 context: { type: 'code_search' }
 });

 const code = this.parseCodeResults(codeResponse.response);

 // Generate AI summary
 const summaryResponse = await this.connector.execute({
 prompt: `Summarize these search results for "${query}":

Notes found: ${notes.length}
${notes.map(n => `- ${n.title}: ${n.excerpt}`).join('\n')}

Code found: ${code.length}
${code.map(c => `- ${c.path}:${c.line}: ${c.excerpt}`).join('\n')}

Provide a brief summary connecting these results.`,
 context: { type: 'search_summary' }
 });

 return {
 notes,
 code,
 summary: summaryResponse.response
 };
 }
}`
```

---

### Configuration

 yaml
 Copy

`# Amplifier settings in Obsidian
connection:
 mode: local # local | api
 api_url: https://api.amplifier.example.com
 api_key: xxx

codebase:
 root: /path/to/project
 include:
 - src/**
 - lib/**
 exclude:
 - node_modules/**
 - dist/**

features:
 doc_generation: true
 query_interface: true
 combined_search: true
 code_sync: true
 decision_capture: true

sync:
 auto_sync: false
 check_interval: 300 # seconds

cache:
 enabled: true
 ttl: 3600 # seconds`
```

---

### Code Block Syntax

#### Query Block

 markdown
 Copy

``
```

query: How does the payment system handle retries?

include: src/payments/**

profile: enterprise-dev:analysis

 text
 Copy

``
```

#### Context Block

 markdown
 Copy

``
```

related_code:

 - src/payments/processor.ts

 - src/payments/retry.ts

issue: #234

decision: ADR-005

 text
 Copy

``
```

#### Synced Code Block

 markdown
 Copy

``
```

// Code here will be kept in sync

 text
 Copy

``
```

---

### Events

 | 
 
 | Event | Description | Data

 | `obsidian:doc_generated` | Documentation created | path, source
 
 | `obsidian:query_executed` | Query completed | query, results_count
 
 | `obsidian:search_combined` | Combined search done | query, notes, code
 
 | `obsidian:code_synced` | Code block synced | file, lines

---

### Open Questions

- Bidirectional sync: Should code changes update notes automatically?
 
- Graph integration: Visualize code-note relationships in graph view?
 
- Version control: Track documentation versions with code versions?
 
- Collaboration: Share queries and results across team?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Integration Slack
 integrations

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-integration-slack`

### Overview

Slack app integration providing AI-powered assistance directly within team conversations. Enables code questions, incident response, PR notifications, and interactive workflows without leaving Slack.

#### Value Proposition

 | 
 
 | Without | With

 | Context switching to IDE/terminal | AI assistance in Slack
 
 | Manual incident notifications | Automated alerts with context
 
 | Separate tools for collaboration | Unified team AI interface
 
 | No audit trail in conversations | Integrated team knowledge

---

### Features

#### 1. Direct Message Assistant

Personal AI assistant for code questions.

 text
 Copy

`User: @Amplifier How does our payment retry logic work?

Amplifier: Based on the codebase analysis:

**Payment Retry Logic** (`src/services/payment/retry.ts`)

The retry mechanism uses exponential backoff:

1. **Initial attempt** - Direct charge via Stripe
2. **On failure** - Wait 2^attempt seconds (max 5 attempts)
3. **Retry conditions**:
 - Network errors: Always retry
 - Rate limits: Retry with backoff
 - Card declined: No retry, notify user`
```

const RETRY_CONFIG = {

 maxAttempts: 5,

 baseDelay: 1000,

 maxDelay: 32000,

 retryableErrors: ['network_error', 'rate_limit']

};

 text
 Copy

`Want me to explain any specific part?`
```

#### 2. Channel Integration

Team-wide AI assistance in public channels.

 text
 Copy

`#engineering channel:

Sarah: @Amplifier What's the status of PR #1234?

Amplifier: **PR #1234: Add user authentication**

ðŸ“Š **Status**: Ready for review
ðŸ‘¤ **Author**: @john
ðŸ“ **Changes**: +423 / -89 lines across 12 files

**AI Review Summary**:
- âœ… Security: No issues found
- âš ï¸ Code Quality: 2 suggestions
- âœ… Tests: Coverage increased to 87%

**Suggested Reviewers**: @alice (auth expert), @bob (security)

[View PR](https://github.com/org/repo/pull/1234) | [Full Review](link)`
```

#### 3. Incident Response Bot

Automated incident assistance.

 text
 Copy

`#incidents channel:

ðŸš¨ **Incident Alert** (triggered by PagerDuty)
Service: payment-api
Status: HIGH_ERROR_RATE
Started: 5 minutes ago

Amplifier: ðŸ” **Investigating incident...**

**Initial Analysis**:
- Error rate spiked from 0.1% to 15% at 14:23 UTC
- Affected endpoint: POST /api/payments
- Recent deployment: `payment-api@v2.3.1` (deployed 14:20 UTC)

**Likely Cause**:
Database connection pool exhaustion. `payment-api@v2.3.1`
increased pool size from 10 to 50, but RDS max_connections is 100.

**Recommended Actions**:
1. ðŸ”„ Rollback to `payment-api@v2.3.0`
2. ðŸ“Š Monitor error rate recovery
3. ðŸ”§ Increase RDS max_connections before redeploying

React with âœ… to execute rollback, âŒ to dismiss.`
```

#### 4. PR Notifications

Smart PR lifecycle notifications.

 yaml
 Copy

`# Notification triggers
notifications:
 pr_opened:
 channel: "#code-review"
 include_ai_summary: true
 mention_suggested_reviewers: true

 pr_review_completed:
 channel: "#code-review"
 include_ai_summary: true

 pr_merged:
 channel: "#deployments"
 include_changelog_entry: true

 ci_failed:
 channel: "#ci-alerts"
 include_ai_diagnosis: true`
```

 text
 Copy

`#code-review channel:

ðŸ“¬ **New PR: Implement rate limiting** (#1456)
Author: @alice | +156 / -23 | 4 files

**AI Summary**: Adds Redis-based rate limiting to API endpoints.
Implements token bucket algorithm with configurable limits per user tier.

**Key Changes**:
- New `RateLimiter` middleware
- Redis integration for distributed counting
- Configuration via environment variables

**Suggested Reviewers**: @bob (API), @carol (Redis)

[Review PR](link) | [View Changes](link)`
```

#### 5. Slash Commands

Interactive commands for common workflows.

 text
 Copy

`/amplifier review https://github.com/org/repo/pull/1234
/amplifier search "payment retry logic"
/amplifier explain src/services/auth.ts
/amplifier incident start "API latency spike"
/amplifier deploy staging payment-api`
```

#### 6. Interactive Workflows

Button-based workflows for approvals and actions.

 text
 Copy

`Amplifier: ðŸš€ **Deployment Request**

Service: `payment-api`
Version: `v2.3.2`
Environment: `staging`
Requested by: @john

**Pre-deployment Checks**:
- âœ… Tests passing
- âœ… Security scan clean
- âœ… No breaking changes detected

[Approve] [Reject] [Request Changes]

---

@alice clicked [Approve]

Amplifier: âœ… Deployment approved by @alice
Deploying `payment-api@v2.3.2` to staging...

Deployment complete!
ðŸ”— https://staging.example.com/api/health`
```

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Slack Integration â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Event â”‚ â”‚ Slash â”‚ â”‚ Interactive â”‚ â”‚
â”‚ â”‚ Handler â”‚ â”‚ Commands â”‚ â”‚ Components â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Request Router â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Context â”‚ â”‚ Amplifier â”‚ â”‚ Response â”‚ â”‚
â”‚ â”‚ Builder â”‚ â”‚ Session â”‚ â”‚ Formatter â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Notification Service (webhooks, scheduled, event-driven) â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Implementation

#### Event Handler

 python
 Copy

`# handlers/events.py

from slack_bolt import App
from slack_bolt.adapter.socket_mode import SocketModeHandler
from amplifier import AmplifierSession

app = App(token=os.environ["SLACK_BOT_TOKEN"])

@app.event("app_mention")
async def handle_mention(event, say, client):
 """Handle @Amplifier mentions in channels."""

 user = event["user"]
 channel = event["channel"]
 text = event["text"]
 thread_ts = event.get("thread_ts", event["ts"])

 # Remove bot mention from text
 query = remove_mention(text)

 # Build context from thread history
 context = await build_thread_context(client, channel, thread_ts)

 # Get channel-specific configuration
 config = get_channel_config(channel)

 # Execute with Amplifier
 async with AmplifierSession(config=config) as session:
 result = await session.execute(
 prompt=query,
 context={
 "slack_channel": channel,
 "slack_user": user,
 "thread_context": context
 }
 )

 # Format and send response
 blocks = format_response_blocks(result)
 await say(blocks=blocks, thread_ts=thread_ts)

@app.event("message")
async def handle_dm(event, say):
 """Handle direct messages to the bot."""

 # Only handle DMs
 if event.get("channel_type") != "im":
 return

 user = event["user"]
 text = event["text"]

 # Get user-specific context
 user_context = await get_user_context(user)

 # Execute with Amplifier
 async with AmplifierSession(config=DM_CONFIG) as session:
 result = await session.execute(
 prompt=text,
 context={
 "user": user,
 "user_projects": user_context.get("projects"),
 "user_repositories": user_context.get("repositories")
 }
 )

 # Send response
 await say(text=result.response)`
```

#### Slash Commands

 python
 Copy

`# handlers/commands.py

@app.command("/amplifier")
async def handle_command(ack, command, respond):
 """Handle /amplifier slash commands."""

 await ack() # Acknowledge immediately

 text = command["text"]
 user = command["user_id"]
 channel = command["channel_id"]

 # Parse command
 parts = text.split(maxsplit=1)
 action = parts[0] if parts else "help"
 args = parts[1] if len(parts) > 1 else ""

 # Route to handler
 handlers = {
 "review": handle_review_command,
 "search": handle_search_command,
 "explain": handle_explain_command,
 "incident": handle_incident_command,
 "deploy": handle_deploy_command,
 "help": handle_help_command
 }

 handler = handlers.get(action, handle_unknown_command)
 await handler(respond, user, channel, args)

async def handle_review_command(respond, user, channel, args):
 """Handle /amplifier review <pr_url>"""

 pr_url = args.strip()

 if not pr_url:
 await respond("Usage: `/amplifier review <pr_url>`")
 return

 # Show loading state
 await respond({
 "response_type": "in_channel",
 "text": f"ðŸ” Analyzing PR: {pr_url}..."
 })

 # Execute PR review
 async with AmplifierSession(config=PR_REVIEW_CONFIG) as session:
 result = await session.execute(
 prompt="Review this PR",
 context={"pr_url": pr_url}
 )

 # Format as Slack blocks
 blocks = format_pr_review_blocks(result)

 await respond({
 "response_type": "in_channel",
 "blocks": blocks
 })

async def handle_incident_command(respond, user, channel, args):
 """Handle /amplifier incident <action> [args]"""

 parts = args.split(maxsplit=1)
 action = parts[0] if parts else "help"
 details = parts[1] if len(parts) > 1 else ""

 if action == "start":
 # Create incident channel
 incident_id = generate_incident_id()
 incident_channel = await create_incident_channel(incident_id, details)

 # Start incident response workflow
 async with AmplifierSession(config=INCIDENT_CONFIG) as session:
 result = await session.execute(
 prompt=f"Start incident response: {details}",
 context={
 "incident_id": incident_id,
 "reported_by": user,
 "description": details
 }
 )

 await respond({
 "response_type": "in_channel",
 "blocks": [
 {
 "type": "section",
 "text": {
 "type": "mrkdwn",
 "text": f"ðŸš¨ Incident `{incident_id}` created\n"
 f"Channel: <#{incident_channel}>"
 }
 }
 ]
 })`
```

#### Interactive Components

 python
 Copy

`# handlers/interactions.py

@app.action("approve_deployment")
async def handle_deployment_approval(ack, body, client):
 """Handle deployment approval button click."""

 await ack()

 user = body["user"]["id"]
 deployment_id = body["actions"][0]["value"]

 # Verify user has approval permission
 if not await can_approve_deployment(user, deployment_id):
 await client.chat_postEphemeral(
 channel=body["channel"]["id"],
 user=user,
 text="âŒ You don't have permission to approve this deployment."
 )
 return

 # Update message to show approval
 await client.chat_update(
 channel=body["channel"]["id"],
 ts=body["message"]["ts"],
 blocks=format_approved_deployment_blocks(deployment_id, user)
 )

 # Execute deployment
 async with AmplifierSession(config=DEPLOY_CONFIG) as session:
 result = await session.execute(
 prompt="Execute approved deployment",
 context={
 "deployment_id": deployment_id,
 "approved_by": user
 }
 )

 # Post deployment result
 await client.chat_postMessage(
 channel=body["channel"]["id"],
 thread_ts=body["message"]["ts"],
 blocks=format_deployment_result_blocks(result)
 )

@app.action("rollback_deployment")
async def handle_rollback(ack, body, client):
 """Handle rollback button click during incident."""

 await ack()

 user = body["user"]["id"]
 rollback_info = json.loads(body["actions"][0]["value"])

 # Require confirmation for production
 if rollback_info["environment"] == "production":
 await show_rollback_confirmation_modal(client, body, rollback_info)
 return

 # Execute rollback
 await execute_rollback(client, body, rollback_info, user)`
```

#### Notification Service

 python
 Copy

`# services/notifications.py

class SlackNotificationService:
 """Send notifications to Slack channels."""

 def __init__(self, client: WebClient, config: NotificationConfig):
 self.client = client
 self.config = config

 async def notify_pr_opened(self, pr_data: dict) -> None:
 """Notify channel of new PR with AI summary."""

 channel = self.config.get_channel("pr_opened")
 if not channel:
 return

 # Generate AI summary if enabled
 summary = None
 if self.config.include_ai_summary:
 async with AmplifierSession(config=SUMMARY_CONFIG) as session:
 summary = await session.execute(
 prompt="Summarize this PR for team review",
 context={"pr": pr_data}
 )

 # Build notification blocks
 blocks = self._build_pr_opened_blocks(pr_data, summary)

 # Send notification
 await self.client.chat_postMessage(
 channel=channel,
 blocks=blocks
 )

 async def notify_incident(
 self,
 incident: dict,
 analysis: dict | None = None
 ) -> str:
 """Notify incidents channel and return message ts for threading."""

 channel = self.config.get_channel("incidents")

 blocks = self._build_incident_blocks(incident, analysis)

 response = await self.client.chat_postMessage(
 channel=channel,
 blocks=blocks
 )

 return response["ts"]

 async def notify_ci_failure(self, build_data: dict) -> None:
 """Notify of CI failure with AI diagnosis."""

 channel = self.config.get_channel("ci_failed")
 if not channel:
 return

 # Generate AI diagnosis
 diagnosis = None
 if self.config.include_ai_diagnosis:
 async with AmplifierSession(config=CI_DIAGNOSIS_CONFIG) as session:
 diagnosis = await session.execute(
 prompt="Diagnose this CI failure",
 context={"build": build_data}
 )

 blocks = self._build_ci_failure_blocks(build_data, diagnosis)

 await self.client.chat_postMessage(
 channel=channel,
 blocks=blocks
 )

 def _build_pr_opened_blocks(
 self,
 pr_data: dict,
 summary: dict | None
 ) -> list[dict]:
 """Build Slack blocks for PR opened notification."""

 blocks = [
 {
 "type": "header",
 "text": {
 "type": "plain_text",
 "text": f"ðŸ“¬ New PR: {pr_data['title']}"
 }
 },
 {
 "type": "section",
 "fields": [
 {"type": "mrkdwn", "text": f"*Author:* <@{pr_data['author_slack']}>"},
 {"type": "mrkdwn", "text": f"*Changes:* +{pr_data['additions']} / -{pr_data['deletions']}"},
 {"type": "mrkdwn", "text": f"*Files:* {pr_data['changed_files']}"},
 {"type": "mrkdwn", "text": f"*Branch:* `{pr_data['head_branch']}`"}
 ]
 }
 ]

 if summary:
 blocks.append({
 "type": "section",
 "text": {
 "type": "mrkdwn",
 "text": f"*AI Summary:*\n{summary.response[:500]}"
 }
 })

 # Suggested reviewers
 if pr_data.get("suggested_reviewers"):
 reviewers = ", ".join(
 f"<@{r['slack_id']}>" for r in pr_data["suggested_reviewers"]
 )
 blocks.append({
 "type": "section",
 "text": {
 "type": "mrkdwn",
 "text": f"*Suggested Reviewers:* {reviewers}"
 }
 })

 blocks.append({
 "type": "actions",
 "elements": [
 {
 "type": "button",
 "text": {"type": "plain_text", "text": "Review PR"},
 "url": pr_data["url"],
 "action_id": "view_pr"
 },
 {
 "type": "button",
 "text": {"type": "plain_text", "text": "AI Review"},
 "action_id": "request_ai_review",
 "value": json.dumps({"pr_url": pr_data["url"]})
 }
 ]
 })

 return blocks`
```

#### Context Builder

 python
 Copy

`# services/context.py

async def build_thread_context(
 client: WebClient,
 channel: str,
 thread_ts: str
) -> dict:
 """Build context from Slack thread history."""

 # Get thread messages
 response = await client.conversations_replies(
 channel=channel,
 ts=thread_ts,
 limit=20
 )

 messages = response.get("messages", [])

 # Extract relevant context
 context = {
 "thread_summary": summarize_thread(messages),
 "participants": extract_participants(messages),
 "mentioned_files": extract_file_mentions(messages),
 "mentioned_prs": extract_pr_mentions(messages),
 "mentioned_issues": extract_issue_mentions(messages)
 }

 return context

async def get_user_context(user_id: str) -> dict:
 """Get user-specific context for personalized responses."""

 # Get user's recent activity
 recent_prs = await get_user_recent_prs(user_id)
 recent_commits = await get_user_recent_commits(user_id)
 assigned_issues = await get_user_assigned_issues(user_id)

 # Get user's team and repositories
 team_info = await get_user_team(user_id)

 return {
 "recent_prs": recent_prs,
 "recent_commits": recent_commits,
 "assigned_issues": assigned_issues,
 "team": team_info.get("team"),
 "repositories": team_info.get("repositories"),
 "role": team_info.get("role")
 }`
```

---

### Configuration

#### App Manifest

 yaml
 Copy

`# manifest.yaml
display_information:
 name: Amplifier
 description: AI-powered code assistant
 background_color: "#4A154B"

features:
 bot_user:
 display_name: Amplifier
 always_online: true
 slash_commands:
 - command: /amplifier
 description: AI-powered code assistance
 usage_hint: "[review|search|explain|incident|deploy] [args]"

oauth_config:
 scopes:
 bot:
 - app_mentions:read
 - channels:history
 - channels:read
 - chat:write
 - commands
 - files:read
 - groups:history
 - groups:read
 - im:history
 - im:read
 - im:write
 - reactions:read
 - reactions:write
 - users:read
 - users:read.email

settings:
 event_subscriptions:
 bot_events:
 - app_mention
 - message.im
 - message.channels
 - reaction_added
 interactivity:
 is_enabled: true
 socket_mode_enabled: true`
```

#### Integration Configuration

 yaml
 Copy

`# .amplifier/integrations/slack.yaml
slack:
 enabled: true

 # Authentication
 auth:
 bot_token: ${SLACK_BOT_TOKEN}
 app_token: ${SLACK_APP_TOKEN} # For socket mode
 signing_secret: ${SLACK_SIGNING_SECRET}

 # Channel mappings
 channels:
 code_review: "#code-review"
 incidents: "#incidents"
 deployments: "#deployments"
 ci_alerts: "#ci-alerts"
 general_support: "#engineering"

 # Feature configuration
 features:
 direct_messages: true
 channel_mentions: true
 slash_commands: true
 interactive_components: true

 # AI features per channel type
 ai_summaries:
 pr_notifications: true
 incident_alerts: true
 ci_failures: true

 # Incident response
 incidents:
 auto_create_channel: true
 channel_prefix: "inc-"
 invite_oncall: true
 post_runbook_links: true

 # Notification rules
 notifications:
 pr_opened:
 enabled: true
 channel: code_review
 include_ai_summary: true
 mention_suggested_reviewers: true
 min_lines_changed: 10 # Skip trivial PRs

 pr_merged:
 enabled: true
 channel: deployments
 include_changelog: true

 ci_failed:
 enabled: true
 channel: ci_alerts
 include_ai_diagnosis: true
 only_main_branch: true

 incident_triggered:
 enabled: true
 channel: incidents
 auto_investigate: true

 # Rate limiting
 rate_limits:
 mentions_per_minute: 30
 slash_commands_per_minute: 60
 notifications_per_minute: 20

 # User mapping
 user_mapping:
 source: ldap # ldap | github | manual
 github_to_slack:
 johndoe: U01234567
 janedoe: U01234568`
```

---

### Security

#### Access Control

 python
 Copy

`# security/access.py

class SlackAccessControl:
 """Control access to Amplifier features in Slack."""

 def __init__(self, config: AccessConfig):
 self.config = config

 async def can_use_feature(
 self,
 user_id: str,
 feature: str,
 channel_id: str
 ) -> bool:
 """Check if user can use feature in channel."""

 # Get user info
 user_groups = await self.get_user_groups(user_id)
 channel_type = await self.get_channel_type(channel_id)

 # Check feature-specific rules
 rules = self.config.get_feature_rules(feature)

 # Allow if user is in allowed groups
 if rules.allowed_groups:
 if not any(g in user_groups for g in rules.allowed_groups):
 return False

 # Check channel restrictions
 if rules.allowed_channels:
 if channel_id not in rules.allowed_channels:
 return False

 # Check channel type restrictions
 if rules.allowed_channel_types:
 if channel_type not in rules.allowed_channel_types:
 return False

 return True

 async def can_approve_deployment(
 self,
 user_id: str,
 deployment: dict
 ) -> bool:
 """Check if user can approve deployment."""

 environment = deployment.get("environment")
 service = deployment.get("service")

 # Get approval rules for environment
 rules = self.config.get_approval_rules(environment)

 # Check if user is in approvers list
 user_groups = await self.get_user_groups(user_id)

 for required_group in rules.required_groups:
 if required_group in user_groups:
 return True

 # Check service-specific owners
 if service in rules.service_owners:
 if user_id in rules.service_owners[service]:
 return True

 return False`
```

#### Audit Logging

 python
 Copy

`# security/audit.py

class SlackAuditLogger:
 """Log all Slack interactions for audit."""

 async def log_interaction(
 self,
 interaction_type: str,
 user_id: str,
 channel_id: str,
 details: dict
 ) -> None:
 """Log Slack interaction."""

 await self.emit_event("slack:interaction", {
 "type": interaction_type,
 "user_id": user_id,
 "channel_id": channel_id,
 "timestamp": datetime.utcnow().isoformat(),
 "details": details
 })

 async def log_deployment_approval(
 self,
 user_id: str,
 deployment_id: str,
 approved: bool,
 reason: str | None = None
 ) -> None:
 """Log deployment approval decision."""

 await self.emit_event("slack:deployment_approval", {
 "user_id": user_id,
 "deployment_id": deployment_id,
 "approved": approved,
 "reason": reason,
 "timestamp": datetime.utcnow().isoformat()
 })`
```

---

### Response Formatting

#### Block Builders

 python
 Copy

`# formatters/blocks.py

def format_code_block(code: str, language: str = "") -> dict:
 """Format code as Slack code block."""
 return {
 "type": "section",
 "text": {
 "type": "mrkdwn",
 "text": f"```{language}\n{code}\n```"
 }
 }

def format_file_reference(file_path: str, line: int | None = None) -> str:
 """Format file reference with optional line number."""
 if line:
 return f"`{file_path}:{line}`"
 return f"`{file_path}`"

def format_error_response(error: str, suggestion: str | None = None) -> list[dict]:
 """Format error response blocks."""
 blocks = [
 {
 "type": "section",
 "text": {
 "type": "mrkdwn",
 "text": f"âŒ {error}"
 }
 }
 ]

 if suggestion:
 blocks.append({
 "type": "context",
 "elements": [
 {
 "type": "mrkdwn",
 "text": f"ðŸ’¡ {suggestion}"
 }
 ]
 })

 return blocks

def truncate_for_slack(text: str, max_length: int = 3000) -> str:
 """Truncate text to fit Slack's limits."""
 if len(text) <= max_length:
 return text
 return text[:max_length - 20] + "\n\n... (truncated)"`
```

---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Integration Tauri Desktop
 integrations

### Overview

Amplifier Desktop is a Tauri-based native desktop application providing a full-featured AI coding assistant. It uses a three-tier architecture with WebSocket streaming for real-time communication between the React frontend and Python sidecar.

Value Proposition:

- Native desktop experience with system tray, notifications, keyboard shortcuts
 
- Offline-capable with local providers (Ollama)
 
- Real-time streaming UI with thinking blocks and tool execution visualization
 
- Cross-platform: macOS, Windows, Linux
 
---

### Architecture

#### Three-Tier Design

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TAURI SHELL (Rust) â”‚
â”‚ - Window management, system tray, native menus â”‚
â”‚ - Sidecar process management (spawn, health check, restart) â”‚
â”‚ - SQLite database (conversations, messages, settings) â”‚
â”‚ - IPC bridge between frontend and native APIs â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ â”‚
 â–¼ â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ REACT FRONTEND (TS) â”‚ â”‚ PYTHON SIDECAR (FastAPI) â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ - Zustand state management â”‚â—„â”€â–ºâ”‚ - AmplifierSession orchestration â”‚
â”‚ - WebSocket client â”‚WS â”‚ - Provider loading (local/cached)â”‚
â”‚ - Markdown rendering â”‚ â”‚ - Tool execution â”‚
â”‚ - Thinking/tool UI â”‚ â”‚ - Hook event emission â”‚
â”‚ - Settings/profiles UI â”‚ â”‚ - Memory extraction â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Component Locations

 | 
 
 | Layer | Directory | Key Files

 | Tauri Shell | `src-tauri/` | `lib.rs`, `main.rs`, `Cargo.toml`
 
 | React Frontend | `src/` | `App.tsx`, `components/`, `hooks/`, `lib/`
 
 | Python Sidecar | `sidecar/` | `server.py`, `local_modules.py`, `config.py`

---

### Streaming Architecture

#### Data Flow

 text
 Copy

`User Input â†’ WebSocket â†’ Sidecar â†’ AmplifierSession â†’ Provider
 â”‚
 â–¼
UI Update â† WebSocket â† Hooks â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Streaming Events`
```

#### WebSocket Message Protocol

Client â†’ Server (Request Types)

 | 
 
 | Type | Purpose | Payload

 | `prompt` | Send user message | `{content, images?, history?, conversationId}`
 
 | `cancel` | Stop execution | `{conversationId}`
 
 | `clear` | Reset session | `{}`
 
 | `settings` | Sync settings | `{}` (triggers backend reload)

Server â†’ Client (Response Types)

 | 
 
 | Type | Purpose | Payload

 | `delta` | Incremental text content | `{content: string, conversationId}`
 
 | `thinking` | Extended thinking content | `{content: string, conversationId}`
 
 | `tool_start` | Tool execution begins | `{content: toolName, metadata: {input, call_id}}`
 
 | `tool_end` | Tool execution complete | `{content: toolName, metadata: {output, success}}`
 
 | `done` | Response complete | `{content: response, metadata: {tokens, cost}}`
 
 | `error` | Error occurred | `{content: errorMessage}`
 
 | `cancelled` | Execution stopped | `{content: "Execution stopped by user"}`

#### Hook-to-WebSocket Mapping

The sidecar registers hooks on `AmplifierSession.coordinator.hooks` that convert provider events to WebSocket messages:

 python
 Copy

`# server.py - Hook Registration
hooks.register("content_block:delta", on_content_delta) â†’ type="delta"
hooks.register("thinking:delta", on_thinking_delta) â†’ type="thinking"
hooks.register("tool:pre", on_tool_pre) â†’ type="tool_start"
hooks.register("tool:post", on_tool_post) â†’ type="tool_end"`
```

#### Streaming vs Non-Streaming Providers

 | 
 
 | Provider Source | Streaming Support | Event Emission

 | Local (`sidecar/providers/`) | Yes | Emits `content_block:delta` during API streaming
 
 | Cached (`~/.amplifier/module-cache/`) | No | Returns complete response

Non-Streaming Fallback:

When using cached providers (Amplifier mode), the sidecar extracts content from the complete response and sends synthetic delta messages:

 python
 Copy

`# server.py - Fallback for non-streaming providers
if response and not self._streaming_happened:
 if response_thinking:
 await self._send(websocket, StreamMessage(type="thinking", content=response_thinking))
 if response_text:
 await self._send(websocket, StreamMessage(type="delta", content=response_text))`
```

---

### Frontend State Management

#### Zustand Store (`src/lib/store.ts`)

 typescript
 Copy

`interface ChatState {
 conversations: Conversation[];
 currentConversationId: string | null;

 // Actions for streaming
 addMessage: (msg: Message) => void;
 appendToMessage: (id: string, delta: string) => void;
 appendThinking: (id: string, delta: string) => void;
 addToolCall: (msgId: string, toolCall: ToolCall) => void;
 updateToolCall: (msgId: string, callId: string, update: Partial<ToolCall>) => void;
 updateMessage: (id: string, update: Partial<Message>) => void;
}

interface Message {
 id: string;
 role: 'user' | 'assistant';
 content: string; // Accumulated from 'delta' messages
 thinking?: string; // Accumulated from 'thinking' messages
 toolCalls?: ToolCall[]; // From tool_start/tool_end
 isStreaming: boolean; // True while receiving
 contentParts?: ContentBlock[]; // Structured blocks from 'done'
}`
```

#### Message Accumulation Flow

 text
 Copy

`1. User submits prompt
 â””â”€â–º addMessage({id: streamingId, role: 'assistant', isStreaming: true, content: ''})

2. Delta arrives
 â””â”€â–º appendToMessage(streamingId, delta.content)
 â””â”€â–º UI re-renders with accumulated content

3. Thinking arrives
 â””â”€â–º appendThinking(streamingId, thinking.content)
 â””â”€â–º ThinkingBlock expands

4. Tool starts
 â””â”€â–º addToolCall(streamingId, {name, input, status: 'running'})
 â””â”€â–º ToolCallDisplay shows spinner

5. Tool ends
 â””â”€â–º updateToolCall(streamingId, callId, {output, status: 'complete'})
 â””â”€â–º ToolCallDisplay shows result

6. Done arrives
 â””â”€â–º updateMessage(streamingId, {isStreaming: false, contentParts})
 â””â”€â–º Final render with all content`
```

---

### UI Components

#### Component Hierarchy

 text
 Copy

`ChatContainer
â”œâ”€â”€ MessageList
â”‚ â””â”€â”€ ChatMessage (for each message)
â”‚ â”œâ”€â”€ ThinkingBlock (collapsible)
â”‚ â”œâ”€â”€ ToolCallDisplay[] (for each tool call)
â”‚ â”‚ â”œâ”€â”€ Tool name + input preview
â”‚ â”‚ â”œâ”€â”€ Spinner (while running)
â”‚ â”‚ â””â”€â”€ Output (when complete)
â”‚ â””â”€â”€ MarkdownRenderer (main content)
â”‚ â”œâ”€â”€ Code blocks with syntax highlighting
â”‚ â”œâ”€â”€ Tables, lists, headings
â”‚ â””â”€â”€ Inline code, links
â”œâ”€â”€ ChatInput
â”‚ â”œâ”€â”€ Textarea with Ctrl+Enter submit
â”‚ â”œâ”€â”€ Image attachment button
â”‚ â””â”€â”€ Send/Cancel button
â””â”€â”€ StatusBar
 â””â”€â”€ Token count, cost estimate, model info`
```

#### Key Component Files

 | 
 
 | Component | File | Purpose

 | ChatMessage | `src/components/ChatMessage.tsx` | Message container, role-based styling
 
 | ThinkingBlock | `src/components/ThinkingBlock.tsx` | Collapsible thinking content
 
 | ToolCallDisplay | `src/components/ToolCallDisplay.tsx` | Tool execution visualization
 
 | MarkdownRenderer | `src/components/MarkdownRenderer.tsx` | react-markdown with plugins
 
 | ChatInput | `src/components/ChatInput.tsx` | User input with image support

---

### Provider Configuration

#### Execution Modes

 | 
 
 | Mode | Provider Source | Use Case

 | `local` | `sidecar/providers/` | Development, offline, custom providers
 
 | `amplifier` | `~/.amplifier/module-cache/` | Production, versioned modules
 
 | `hybrid` | Cache preferred, local fallback | Recommended default

#### Extended Thinking

Extended thinking (Claude's internal reasoning) requires:

- Model support: Opus 4.5, Sonnet 4.5 with thinking capability
 
- Provider configuration: `extended_thinking=True` kwarg
 
- UI handling: ThinkingBlock component renders collapsed by default

 python
 Copy

`# local_modules.py - Enable thinking for capable models
if reasoning_cap:
 provider_kwargs["extended_thinking"] = True
 provider_kwargs["thinking_budget_tokens"] = 8192
return await provider.complete(request, **provider_kwargs)`
```

---

### Session Management

#### Session Pool (`server.py`)

Sessions are cached per conversation with config-based invalidation:

 python
 Copy

`class SessionPool:
 sessions: dict[str, AmplifierSession]

 async def get_or_create_session(self, conversation_id, websocket, provider, model):
 # Hash current config
 config_hash = hash(provider + model + settings_json)

 existing = self.sessions.get(conversation_id)
 if existing and existing._config_hash == config_hash:
 # Reuse session, update websocket reference
 self._websocket = websocket
 return existing

 # Create new session
 session = AmplifierSession(config, loader=LocalLoader(...))
 await session.initialize()
 self.sessions[conversation_id] = session
 return session`
```

#### Context Restoration

When switching conversations, message history is restored to the session:

 python
 Copy

`async def restore_context(self, session, history):
 for msg in history:
 session.coordinator.context.add_message(
 role=msg.role,
 content=msg.content,
 tool_calls=msg.tool_calls
 )`
```

---

### Settings & Profiles

#### Settings Hierarchy

 text
 Copy

`1. Profile settings (from active profile YAML)
2. Global settings (~/.amplifier/settings.yaml)
3. Environment variables
4. Defaults (hardcoded)`
```

#### Profile Format

 yaml
 Copy

`# ~/.amplifier/profiles/dev.md
---
name: dev
version: "1.0"
description: Development profile

providers:
 - module: provider-anthropic
 config:
 model: claude-opus-4-5-20251101

tools:
 - module: tool-filesystem
 - module: tool-bash
 - module: tool-grep

session:
 max_iterations: 100
 temperature: 0.7
---

# Profile documentation in markdown body`
```

---

### Build & Distribution

#### PyInstaller Bundling

The Python sidecar is bundled as a native binary:

 bash
 Copy

`# scripts/bundle-sidecar.cjs
pyinstaller sidecar.spec --distpath src-tauri/binaries/`
```

#### Sidecar Naming Convention

Tauri requires platform-specific naming:

- macOS ARM: `amplifier-sidecar-aarch64-apple-darwin`
 
- macOS Intel: `amplifier-sidecar-x86_64-apple-darwin`
 
- Windows: `amplifier-sidecar-x86_64-pc-windows-msvc.exe`
 
- Linux: `amplifier-sidecar-x86_64-unknown-linux-gnu`
 
---

### Testing

#### Frontend Tests (Vitest)

 bash
 Copy

`npm run test:frontend
# Covers: store actions, WebSocket handling, component rendering`
```

#### Backend Tests (pytest)

 bash
 Copy

`cd sidecar && uv run pytest tests/ -v
# Covers: API endpoints, session management, tool execution`
```

#### Integration Testing

 bash
 Copy

`npm run dev:all # Start full stack
# Manual testing: send prompts, verify streaming, check tool calls`
```

---

### Decisions & Trade-offs

#### Streaming (Resolved 2025-12-10)

Decision: Keep the non-streaming fallback approach for cached providers.

Rationale:

- Cached providers use `messages.create()` API (non-streaming) vs local's `messages.stream()`
 
- Current workarounds emit synthetic delta messages after response completes
 
- Content appears BEFORE "done" message, maintaining responsive UX
 
- Thinking signatures and tool calls work correctly
 
- No upstream changes required to amplifier-core
 
Trade-off: Text appears all at once (not character-by-character) in Amplifier mode. This is acceptable because:

- Response still appears before completion message
 
- Consistent architecture across all cached providers
 
- Future improvement possible via upstream contribution
 
---

### Comparison: Desktop vs CLI

Key differences between `amplifier-desktop` and `amplifier-app-cli`:

 | 
 
 | Aspect | Desktop | CLI

 | Architecture | Three-tier (React + Tauri + Python) | Single Python process
 
 | Session | Custom LocalOrchestrator | Direct AmplifierSession
 
 | Module Loading | LocalLoader (local/cached modes) | Module resolver (git+, collections)
 
 | Providers | Bundled + module-cache | Entry points from packages
 
 | Config | 2-scope JSON | 3-scope YAML with profiles
 
 | Agent Delegation | Not implemented | Full sub-session support
 
 | Memory | SQLite with auto-extraction | Not built-in
 
 | MCP | Full client | Not built-in

#### Desktop-Exclusive Features

- React GUI with real-time streaming
 
- MCP tool integration
 
- Memory system with auto-extraction
 
- Voice input/output
 
- Artifacts panel
 
#### CLI-Exclusive Features

- Profile/collection system
 
- Agent delegation (sub-sessions)
 
- Plan mode (read-only)
 
- @mentions for context loading
 
- Module-based extensibility
 
#### Convergence Opportunities

- Add profile system to Desktop
 
- Add agent delegation to Desktop
 
- Add MCP to CLI
 
- Add memory system to CLI
 
---

### Open Questions

- Session persistence: Should sessions survive app restart? Currently they're recreated.
 
- Multi-window support: How to handle multiple chat windows with separate sessions?
 
- Offline mode: Full offline support requires local embeddings for memory search.

 Integration Teams Bot
 integrations

Priority: P2 (Enhancement)

Status: Draft

Module: `amplifier-teams-bot`

### Overview

Microsoft Teams bot for enterprise team collaboration with Amplifier. Query codebases in team channels, get AI assistance in meetings, share code explanations, and integrate with enterprise workflows (Azure DevOps, SharePoint).

#### Value Proposition

 | 
 
 | Without | With

 | Switch to terminal for AI help | Ask in Teams where you work
 
 | Share screenshots of code | Interactive code explanations
 
 | Manual incident triage | AI-assisted investigation
 
 | Siloed knowledge | Team-shared AI insights

---

### Features

#### 1. Channel Queries

Ask Amplifier questions in team channels.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ #engineering-backend â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ ðŸ‘¤ Alice Chen 10:30 AM â”‚
â”‚ @Amplifier How does the payment retry logic work? â”‚
â”‚ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ ðŸ¤– Amplifier 10:30 AM â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ **Payment Retry Logic** â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ The payment system uses exponential backoff for retries: â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ 1. **Initial attempt** â†’ If fails, wait 1s â”‚â”‚
â”‚ â”‚ 2. **Retry 1** â†’ If fails, wait 2s â”‚â”‚
â”‚ â”‚ 3. **Retry 2** â†’ If fails, wait 4s â”‚â”‚
â”‚ â”‚ 4. **Final retry** â†’ If fails, raise alert â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ ðŸ“„ Source: `src/payments/retry.ts:45` â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ [View Code] [Ask Follow-up] [Share to Thread] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ ðŸ‘¤ Bob Smith 10:32 AM â”‚
â”‚ @Amplifier What happens if all retries fail? â”‚
â”‚ â”‚
â”‚ ðŸ¤– Amplifier 10:32 AM â”‚
â”‚ When all retries are exhausted: â”‚
â”‚ 1. Transaction marked as `FAILED` â”‚
â”‚ 2. Alert sent to #payments-alerts â”‚
â”‚ 3. Customer notified via email â”‚
â”‚ ... â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 2. Direct Message Assistant

Private AI assistance via DM.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chat with Amplifier â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ ðŸ‘¤ You 2:15 PM â”‚
â”‚ I'm getting a weird error in the auth module. Can you help? â”‚
â”‚ â”‚
â”‚ ðŸ¤– Amplifier 2:15 PM â”‚
â”‚ I'd be happy to help! Can you share more details: â”‚
â”‚ â”‚
â”‚ 1. What error message are you seeing? â”‚
â”‚ 2. Which file/function is causing it? â”‚
â”‚ 3. Any recent changes to the auth module? â”‚
â”‚ â”‚
â”‚ Or you can paste the error/stacktrace directly. â”‚
â”‚ â”‚
â”‚ ðŸ‘¤ You 2:16 PM â”‚
â”‚ ``` â”‚
â”‚ Error: Token expired at validateToken (auth/middleware.ts:45) â”‚
â”‚ ``` â”‚
â”‚ â”‚
â”‚ ðŸ¤– Amplifier 2:16 PM â”‚
â”‚ I found the issue. Looking at `auth/middleware.ts:45`: â”‚
â”‚ â”‚
â”‚ The token expiration check uses system time which can drift. â”‚
â”‚ There's a known issue (#892) about this. â”‚
â”‚ â”‚
â”‚ **Quick fix:** â”‚
â”‚ Add clock skew tolerance in `config/auth.ts`: â”‚
â”‚ ```ts â”‚
â”‚ clockTolerance: 30 // seconds â”‚
â”‚ ``` â”‚
â”‚ â”‚
â”‚ [View Issue #892] [Apply Fix] [Explain More] â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 3. Incident Response

AI-assisted incident investigation in dedicated channels.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ #incident-2025-01-15-payment-outage â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ ðŸš¨ PagerDuty 3:00 PM â”‚
â”‚ ALERT: Payment processing failure rate > 50% â”‚
â”‚ Severity: P1 | Service: payment-api | Region: us-east-1 â”‚
â”‚ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ ðŸ‘¤ On-Call Engineer 3:01 PM â”‚
â”‚ @Amplifier /incident analyze â”‚
â”‚ â”‚
â”‚ ðŸ¤– Amplifier 3:01 PM â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ ðŸ” **Incident Analysis** â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ **Timeline:** â”‚â”‚
â”‚ â”‚ â€¢ 2:55 PM - Error rate started climbing â”‚â”‚
â”‚ â”‚ â€¢ 2:58 PM - Stripe API latency spike detected â”‚â”‚
â”‚ â”‚ â€¢ 3:00 PM - Alert triggered â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ **Probable Cause:** â”‚â”‚
â”‚ â”‚ Stripe API returning 503 errors. Retry logic exhausting â”‚â”‚
â”‚ â”‚ but circuit breaker not triggering. â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ **Recent Changes:** â”‚â”‚
â”‚ â”‚ â€¢ PR #234 merged 2 hours ago (payment retry logic) â”‚â”‚
â”‚ â”‚ â€¢ No config changes in last 24h â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ **Recommended Actions:** â”‚â”‚
â”‚ â”‚ 1. Enable circuit breaker: `config/payments.ts:12` â”‚â”‚
â”‚ â”‚ 2. Check Stripe status page â”‚â”‚
â”‚ â”‚ 3. Consider rollback of PR #234 â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ [View Metrics] [Recent PRs] [Rollback PR #234] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ ðŸ‘¤ On-Call Engineer 3:02 PM â”‚
â”‚ @Amplifier Show me the circuit breaker config â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 4. Meeting Assistant

AI assistance during Teams meetings.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Meeting: Architecture Review - Payment System â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ [Video Call in Progress] â”‚
â”‚ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Meeting Chat â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚
â”‚ ðŸ‘¤ Alice 2:30 PM â”‚
â”‚ @Amplifier Can you show the current payment flow diagram? â”‚
â”‚ â”‚
â”‚ ðŸ¤– Amplifier 2:30 PM â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ **Payment Flow** (generated from codebase) â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
â”‚ â”‚ â”‚ Request â”‚â”€â”€â”€â–¶â”‚ Validate â”‚â”€â”€â”€â–¶â”‚ Process â”‚ â”‚â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚â”‚
â”‚ â”‚ â”‚ â”‚â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
â”‚ â”‚ â–¼ â–¼ â–¼ â”‚â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
â”‚ â”‚ â”‚ Stripe â”‚ â”‚ PayPal â”‚ â”‚ Manual â”‚ â”‚â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ [Share to Meeting] [Download] [Update] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ ðŸ‘¤ Bob 2:32 PM â”‚
â”‚ @Amplifier What's the error rate for each payment method? â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 5. Azure DevOps Integration

Connect with Azure DevOps work items and pipelines.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ #project-alpha â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ ðŸ‘¤ PM 11:00 AM â”‚
â”‚ @Amplifier What's the status of the payment feature (Epic #45)? â”‚
â”‚ â”‚
â”‚ ðŸ¤– Amplifier 11:00 AM â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ **Epic #45: Payment System Improvements** â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ ðŸ“Š Progress: 67% complete (8/12 items done) â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ **Completed:** â”‚â”‚
â”‚ â”‚ âœ… #101 - Retry logic implementation â”‚â”‚
â”‚ â”‚ âœ… #102 - Error handling improvements â”‚â”‚
â”‚ â”‚ âœ… #103 - Stripe v3 upgrade â”‚â”‚
â”‚ â”‚ ... 5 more â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ **In Progress:** â”‚â”‚
â”‚ â”‚ ðŸ”„ #108 - Circuit breaker (@alice) â”‚â”‚
â”‚ â”‚ ðŸ”„ #109 - Metrics dashboard (@bob) â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ **Blocked:** â”‚â”‚
â”‚ â”‚ âš ï¸ #110 - PayPal integration (waiting on API access) â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ **Code Status:** â”‚â”‚
â”‚ â”‚ â€¢ 3 PRs open, 2 ready for review â”‚â”‚
â”‚ â”‚ â€¢ Pipeline: All passing âœ… â”‚â”‚
â”‚ â”‚ â”‚â”‚
â”‚ â”‚ [View in Azure DevOps] [PRs] [Pipeline] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Teams Bot Service â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Bot Framework SDK â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ Channel â”‚ â”‚ DM â”‚ â”‚ Meeting â”‚ â”‚ Adaptive â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ Handler â”‚ â”‚ Handler â”‚ â”‚ Handler â”‚ â”‚ Cards â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Amplifier Client â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â–¼ â–¼ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Amplifier â”‚ â”‚ Azure â”‚ â”‚ Graph â”‚ â”‚
â”‚ â”‚ API Server â”‚ â”‚ DevOps API â”‚ â”‚ API â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Bot Commands

 | 
 
 | Command | Description | Example

 | `@Amplifier [question]` | Ask about codebase | `@Amplifier how does auth work?`
 
 | `@Amplifier /explain [code]` | Explain code snippet | `@Amplifier /explain \`\`\`code\`\`\``
 
 | `@Amplifier /incident analyze` | Analyze incident | In incident channel
 
 | `@Amplifier /pr [number]` | PR summary | `@Amplifier /pr 234`
 
 | `@Amplifier /work-item [id]` | Work item status | `@Amplifier /work-item 45`
 
 | `@Amplifier /pipeline [name]` | Pipeline status | `@Amplifier /pipeline main`
 
 | `@Amplifier /help` | Show commands

---

### Implementation

#### Bot Service (Node.js)

 typescript
 Copy

`// src/bot.ts
import {
 ActivityHandler,
 TurnContext,
 TeamsActivityHandler,
 CardFactory
} from 'botbuilder';
import { AmplifierClient } from './amplifier-client';
import { AdaptiveCardBuilder } from './cards';
import { CommandParser } from './commands';

export class AmplifierBot extends TeamsActivityHandler {
 private amplifier: AmplifierClient;
 private cardBuilder: AdaptiveCardBuilder;
 private commandParser: CommandParser;

 constructor() {
 super();

 this.amplifier = new AmplifierClient({
 apiUrl: process.env.AMPLIFIER_API_URL,
 apiKey: process.env.AMPLIFIER_API_KEY
 });

 this.cardBuilder = new AdaptiveCardBuilder();
 this.commandParser = new CommandParser();

 // Handle messages
 this.onMessage(async (context, next) => {
 await this.handleMessage(context);
 await next();
 });

 // Handle reactions
 this.onReactionsAdded(async (context, next) => {
 await this.handleReaction(context);
 await next();
 });
 }

 async handleMessage(context: TurnContext) {
 const text = context.activity.text?.trim() || '';

 // Remove bot mention
 const cleanText = this.removeMention(text);

 // Parse command
 const { command, args } = this.commandParser.parse(cleanText);

 switch (command) {
 case 'explain':
 await this.handleExplain(context, args);
 break;

 case 'incident':
 await this.handleIncident(context, args);
 break;

 case 'pr':
 await this.handlePR(context, args);
 break;

 case 'work-item':
 await this.handleWorkItem(context, args);
 break;

 case 'help':
 await this.handleHelp(context);
 break;

 default:
 // General question
 await this.handleQuestion(context, cleanText);
 }
 }

 async handleQuestion(context: TurnContext, question: string) {
 // Send typing indicator
 await context.sendActivity({ type: 'typing' });

 // Get team/channel context
 const teamContext = this.getTeamContext(context);

 // Execute query
 const result = await this.amplifier.execute({
 prompt: question,
 context: {
 type: 'teams_query',
 team: teamContext.teamName,
 channel: teamContext.channelName,
 user: context.activity.from.name
 }
 });

 // Build response card
 const card = this.cardBuilder.queryResponse({
 question,
 response: result.response,
 sources: result.sources
 });

 await context.sendActivity({
 attachments: [CardFactory.adaptiveCard(card)]
 });
 }

 async handleIncident(context: TurnContext, args: string[]) {
 const subCommand = args[0];

 if (subCommand === 'analyze') {
 // Get channel messages for context
 const messages = await this.getChannelMessages(context);

 const result = await this.amplifier.execute({
 prompt: `Analyze this incident based on the channel discussion:\n\n${messages}`,
 profile: 'enterprise-dev:incident',
 context: {
 type: 'incident_analysis',
 channel: context.activity.channelId
 }
 });

 const card = this.cardBuilder.incidentAnalysis(result.response);

 await context.sendActivity({
 attachments: [CardFactory.adaptiveCard(card)]
 });
 }
 }

 async handlePR(context: TurnContext, args: string[]) {
 const prNumber = args[0];

 const result = await this.amplifier.execute({
 prompt: `Summarize PR #${prNumber}`,
 context: {
 type: 'pr_summary',
 pr_number: prNumber
 }
 });

 const card = this.cardBuilder.prSummary({
 number: prNumber,
 summary: result.response
 });

 await context.sendActivity({
 attachments: [CardFactory.adaptiveCard(card)]
 });
 }

 async handleWorkItem(context: TurnContext, args: string[]) {
 const workItemId = args[0];

 // Get work item from Azure DevOps
 const workItem = await this.getAzureDevOpsWorkItem(workItemId);

 // Get AI analysis
 const result = await this.amplifier.execute({
 prompt: `Analyze the status of this work item:\n\n${JSON.stringify(workItem)}`,
 context: {
 type: 'work_item_analysis'
 }
 });

 const card = this.cardBuilder.workItemStatus({
 workItem,
 analysis: result.response
 });

 await context.sendActivity({
 attachments: [CardFactory.adaptiveCard(card)]
 });
 }
}`
```

#### Adaptive Card Builder

 typescript
 Copy

`// src/cards.ts
export class AdaptiveCardBuilder {
 queryResponse(data: QueryResponseData) {
 return {
 type: 'AdaptiveCard',
 $schema: 'http://adaptivecards.io/schemas/adaptive-card.json',
 version: '1.4',
 body: [
 {
 type: 'TextBlock',
 text: data.response,
 wrap: true
 },
 {
 type: 'FactSet',
 facts: data.sources?.map(s => ({
 title: 'ðŸ“„ Source',
 value: s.path
 })) || []
 }
 ],
 actions: [
 {
 type: 'Action.Submit',
 title: 'Ask Follow-up',
 data: { action: 'followup', context: data }
 },
 {
 type: 'Action.OpenUrl',
 title: 'View Code',
 url: data.sources?.[0]?.url
 }
 ]
 };
 }

 incidentAnalysis(analysis: string) {
 // Parse analysis into structured sections
 const sections = this.parseAnalysis(analysis);

 return {
 type: 'AdaptiveCard',
 $schema: 'http://adaptivecards.io/schemas/adaptive-card.json',
 version: '1.4',
 body: [
 {
 type: 'TextBlock',
 text: 'ðŸ” **Incident Analysis**',
 size: 'large',
 weight: 'bolder'
 },
 {
 type: 'Container',
 items: [
 {
 type: 'TextBlock',
 text: '**Timeline**',
 weight: 'bolder'
 },
 {
 type: 'TextBlock',
 text: sections.timeline,
 wrap: true
 }
 ]
 },
 {
 type: 'Container',
 items: [
 {
 type: 'TextBlock',
 text: '**Probable Cause**',
 weight: 'bolder'
 },
 {
 type: 'TextBlock',
 text: sections.cause,
 wrap: true
 }
 ]
 },
 {
 type: 'Container',
 items: [
 {
 type: 'TextBlock',
 text: '**Recommended Actions**',
 weight: 'bolder'
 },
 {
 type: 'TextBlock',
 text: sections.actions,
 wrap: true
 }
 ]
 }
 ],
 actions: [
 {
 type: 'Action.OpenUrl',
 title: 'View Metrics',
 url: sections.metricsUrl
 },
 {
 type: 'Action.Submit',
 title: 'Rollback',
 data: { action: 'rollback', pr: sections.recentPR }
 }
 ]
 };
 }

 prSummary(data: PRSummaryData) {
 return {
 type: 'AdaptiveCard',
 $schema: 'http://adaptivecards.io/schemas/adaptive-card.json',
 version: '1.4',
 body: [
 {
 type: 'TextBlock',
 text: `**PR #${data.number}**`,
 size: 'large'
 },
 {
 type: 'TextBlock',
 text: data.summary,
 wrap: true
 }
 ],
 actions: [
 {
 type: 'Action.OpenUrl',
 title: 'View PR',
 url: `https://github.com/org/repo/pull/${data.number}`
 },
 {
 type: 'Action.Submit',
 title: 'Approve',
 data: { action: 'approve_pr', pr: data.number }
 }
 ]
 };
 }
}`
```

---

### Deployment

#### Azure Bot Service

 yaml
 Copy

`# azure-pipelines.yml
trigger:
 - main

pool:
 vmImage: 'ubuntu-latest'

stages:
 - stage: Build
 jobs:
 - job: BuildBot
 steps:
 - task: NodeTool@0
 inputs:
 versionSpec: '18.x'

 - script: |
 npm ci
 npm run build
 displayName: 'Build'

 - task: ArchiveFiles@2
 inputs:
 rootFolderOrFile: '$(System.DefaultWorkingDirectory)'
 includeRootFolder: false
 archiveFile: '$(Build.ArtifactStagingDirectory)/bot.zip'

 - publish: $(Build.ArtifactStagingDirectory)/bot.zip
 artifact: bot

 - stage: Deploy
 jobs:
 - deployment: DeployBot
 environment: 'production'
 strategy:
 runOnce:
 deploy:
 steps:
 - task: AzureWebApp@1
 inputs:
 azureSubscription: 'Azure-Sub'
 appName: 'amplifier-teams-bot'
 package: '$(Pipeline.Workspace)/bot/bot.zip'`
```

#### App Manifest

 json
 Copy

`// manifest.json
{
 "$schema": "https://developer.microsoft.com/json-schemas/teams/v1.14/MicrosoftTeams.schema.json",
 "manifestVersion": "1.14",
 "version": "1.0.0",
 "id": "{{BOT_ID}}",
 "packageName": "com.amplifier.teams",
 "developer": {
 "name": "Microsoft",
 "websiteUrl": "https://amplifier.dev",
 "privacyUrl": "https://amplifier.dev/privacy",
 "termsOfUseUrl": "https://amplifier.dev/terms"
 },
 "name": {
 "short": "Amplifier",
 "full": "Amplifier AI Assistant"
 },
 "description": {
 "short": "AI-powered code assistant for Teams",
 "full": "Query your codebase, get AI assistance, and collaborate with your team using Amplifier."
 },
 "icons": {
 "outline": "outline.png",
 "color": "color.png"
 },
 "accentColor": "#6366f1",
 "bots": [
 {
 "botId": "{{BOT_ID}}",
 "scopes": ["personal", "team", "groupchat"],
 "supportsFiles": false,
 "isNotificationOnly": false,
 "commandLists": [
 {
 "scopes": ["personal", "team", "groupchat"],
 "commands": [
 {
 "title": "help",
 "description": "Show available commands"
 },
 {
 "title": "explain",
 "description": "Explain code snippet"
 },
 {
 "title": "pr",
 "description": "Get PR summary"
 },
 {
 "title": "incident",
 "description": "Analyze incident"
 }
 ]
 }
 ]
 }
 ],
 "permissions": ["identity", "messageTeamMembers"],
 "validDomains": ["amplifier.dev", "*.amplifier.dev"]
}`
```

---

### Configuration

 yaml
 Copy

`# Bot configuration
bot:
 app_id: ${AZURE_BOT_APP_ID}
 app_password: ${AZURE_BOT_APP_PASSWORD}

amplifier:
 api_url: https://api.amplifier.example.com
 api_key: ${AMPLIFIER_API_KEY}
 default_profile: enterprise-dev:teams

azure_devops:
 organization: myorg
 project: myproject
 pat: ${AZURE_DEVOPS_PAT}

features:
 channel_queries: true
 dm_assistant: true
 meeting_assistant: true
 incident_response: true
 azure_devops: true

permissions:
 # Who can use the bot
 allowed_teams: ["*"] # or specific team IDs
 admin_users: ["user1@company.com"]`
```

---

### Events

 | 
 
 | Event | Description | Data

 | `teams:query_received` | Query in channel/DM | team, channel, user
 
 | `teams:response_sent` | Response delivered | type, tokens
 
 | `teams:command_executed` | Slash command used | command, args
 
 | `teams:incident_analyzed` | Incident analysis done | channel, findings
 
 | `teams:pr_action` | PR action taken | action, pr_number

---

### Security

 yaml
 Copy

`security:
 # Azure AD authentication
 auth:
 tenant_id: ${AZURE_AD_TENANT_ID}
 validate_issuer: true

 # Bot-specific
 bot:
 validate_activity: true
 allowed_callers: ["*.botframework.com"]

 # Data handling
 data:
 log_queries: true
 redact_sensitive: true
 retention_days: 30`
```

---

### Open Questions

- Multi-tenant: Support for multiple Azure AD tenants?
 
- Meeting transcripts: Integrate with Teams meeting transcripts?
 
- Proactive messages: Notify teams about CI/CD events?
 
- Message threading: Reply in threads vs new messages?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Integration Vscode
 integrations

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-integration-vscode`

### Overview

VS Code extension providing native Amplifier integration within the IDE. Enables context-aware AI assistance, inline code actions, project-aware suggestions, and seamless access to all Amplifier capabilities.

#### Value Proposition

 | 
 
 | Without | With

 | Context switching to terminal | Inline AI assistance
 
 | Manual context sharing | Auto-detect project context
 
 | Generic AI suggestions | Codebase-aware responses
 
 | Separate tool windows | Integrated experience

---

### Features

#### 1. Inline Chat

AI chat panel integrated in VS Code sidebar.

 typescript
 Copy

`// Chat with full project context
User: "How does the payment processing work?"

// Amplifier searches codebase, finds relevant files
Assistant: "Based on the codebase analysis:

The payment processing flow works as follows:

1. **Entry Point** (`src/api/payments.ts:45`)
 - Receives payment request via POST /api/payments

2. **Validation** (`src/services/PaymentValidator.ts`)
 - Validates card details
 - Checks fraud signals

3. **Processing** (`src/services/PaymentProcessor.ts`)
 - Integrates with Stripe API
 - Implements retry logic with exponential backoff

4. **Completion** (`src/services/PaymentNotifier.ts`)
 - Sends confirmation email
 - Updates order status

Would you like me to explain any specific part in detail?"`
```

#### 2. Inline Code Actions

Context menu and lightbulb actions for selected code.

 typescript
 Copy

`// Right-click on code or use lightbulb
Code Actions:
 ðŸ”§ Amplifier: Explain this code
 ðŸ”§ Amplifier: Suggest improvements
 ðŸ”§ Amplifier: Find bugs
 ðŸ”§ Amplifier: Generate tests
 ðŸ”§ Amplifier: Add documentation
 ðŸ”§ Amplifier: Refactor`
```

#### 3. Smart Completions

AI-powered code completions with codebase awareness.

 typescript
 Copy

`// While typing in payment.ts
async function processRefund(orderId: string) {
 // Amplifier suggests based on existing patterns
 const order = await this.orderService.getOrder(orderId);
 const payment = await this.paymentService.getPaymentByOrder(orderId);

 // Suggestion shows: "Based on pattern in processPayment..."
 if (!payment.refundable) {
 throw new PaymentError('Payment is not refundable', 'REFUND_NOT_ALLOWED');
 }
 //...
}`
```

#### 4. Project Commands

Command palette commands for project-wide operations.

 text
 Copy

`Cmd/Ctrl + Shift + P:

> Amplifier: Explain Repository Architecture
> Amplifier: Find Dead Code
> Amplifier: Analyze Dependencies
> Amplifier: Generate Documentation
> Amplifier: Review Uncommitted Changes
> Amplifier: Find Similar Code
> Amplifier: Create Feature Plan`
```

#### 5. Problems Integration

AI-detected issues in VS Code Problems panel.

 text
 Copy

`PROBLEMS (3)
 src/payments/gateway.ts
 âš ï¸ [Amplifier] Potential SQL injection at line 45
 âš ï¸ [Amplifier] Missing error handling for network timeout
 src/auth/login.ts
 âš ï¸ [Amplifier] Weak password validation pattern`
```

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VS Code Extension â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Chat View â”‚ â”‚ Code Actions â”‚ â”‚ Completions â”‚ â”‚
â”‚ â”‚ Provider â”‚ â”‚ Provider â”‚ â”‚ Provider â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Amplifier Clientâ”‚ â”‚
â”‚ â”‚ (TypeScript) â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Amplifier CLI â”‚â—€â”€â”€ Local or Remote â”‚
â”‚ â”‚ Process â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Extension Configuration

 json
 Copy

`// .vscode/settings.json
{
 "amplifier.enabled": true,

 // Connection
 "amplifier.connection": {
 "type": "local", // local | remote | cloud
 "path": "amplifier" // CLI path for local
 },

 // Profile
 "amplifier.profile": "enterprise-dev:development",
 "amplifier.collection": "enterprise-dev",

 // Features
 "amplifier.features": {
 "inlineChat": true,
 "codeActions": true,
 "completions": true,
 "problemsIntegration": true,
 "hoverInfo": true
 },

 // Completions
 "amplifier.completions": {
 "enabled": true,
 "triggerCharacters": [".", "(", " "],
 "maxSuggestions": 3,
 "codebaseAware": true
 },

 // Security
 "amplifier.security": {
 "redactSecrets": true,
 "excludePatterns": [
 "*.env",
 "*.pem",
 "**/secrets/**"
 ]
 },

 // Keybindings
 "amplifier.keybindings": {
 "openChat": "cmd+shift+a",
 "explainSelection": "cmd+shift+e",
 "generateTests": "cmd+shift+t"
 }
}`
```

---

### Implementation

#### Extension Entry Point

 typescript
 Copy

`// extension.ts
import * as vscode from 'vscode';
import { AmplifierClient } from './client';
import { ChatViewProvider } from './providers/chat';
import { CodeActionProvider } from './providers/codeActions';
import { CompletionProvider } from './providers/completions';
import { ProblemsProvider } from './providers/problems';

export async function activate(context: vscode.ExtensionContext) {
 const config = vscode.workspace.getConfiguration('amplifier');

 // Initialize Amplifier client
 const client = new AmplifierClient({
 connection: config.get('connection'),
 profile: config.get('profile')
 });

 await client.connect();

 // Register Chat View
 const chatProvider = new ChatViewProvider(client, context);
 context.subscriptions.push(
 vscode.window.registerWebviewViewProvider(
 'amplifier.chatView',
 chatProvider
 )
 );

 // Register Code Actions
 const codeActionProvider = new CodeActionProvider(client);
 context.subscriptions.push(
 vscode.languages.registerCodeActionsProvider(
 { scheme: 'file' },
 codeActionProvider,
 { providedCodeActionKinds: [vscode.CodeActionKind.QuickFix] }
 )
 );

 // Register Completions
 if (config.get('features.completions')) {
 const completionProvider = new CompletionProvider(client);
 context.subscriptions.push(
 vscode.languages.registerCompletionItemProvider(
 { scheme: 'file' },
 completionProvider,
 ...config.get('completions.triggerCharacters')
 )
 );
 }

 // Register Problems Integration
 if (config.get('features.problemsIntegration')) {
 const problemsProvider = new ProblemsProvider(client, context);
 context.subscriptions.push(problemsProvider);
 }

 // Register Commands
 registerCommands(context, client);
}

function registerCommands(
 context: vscode.ExtensionContext,
 client: AmplifierClient
) {
 // Explain selection
 context.subscriptions.push(
 vscode.commands.registerCommand('amplifier.explainSelection', async () => {
 const editor = vscode.window.activeTextEditor;
 if (!editor) return;

 const selection = editor.selection;
 const text = editor.document.getText(selection);

 const result = await client.execute({
 prompt: `Explain this code:\n\n${text}`,
 context: {
 file: editor.document.fileName,
 language: editor.document.languageId
 }
 });

 // Show in chat panel
 vscode.commands.executeCommand('amplifier.chatView.focus');
 chatProvider.addMessage('assistant', result.response);
 })
 );

 // More commands...
}`
```

#### Chat View Provider

 typescript
 Copy

`// providers/chat.ts
export class ChatViewProvider implements vscode.WebviewViewProvider {
 private view?: vscode.WebviewView;
 private messages: Message[] = [];

 constructor(
 private client: AmplifierClient,
 private context: vscode.ExtensionContext
 ) {}

 resolveWebviewView(webviewView: vscode.WebviewView) {
 this.view = webviewView;

 webviewView.webview.options = {
 enableScripts: true,
 localResourceRoots: [this.context.extensionUri]
 };

 webviewView.webview.html = this.getHtml();

 // Handle messages from webview
 webviewView.webview.onDidReceiveMessage(async (message) => {
 if (message.type === 'userMessage') {
 await this.handleUserMessage(message.text);
 }
 });
 }

 async handleUserMessage(text: string) {
 // Add user message
 this.addMessage('user', text);

 // Get project context
 const context = await this.gatherContext();

 // Execute with Amplifier
 const result = await this.client.execute({
 prompt: text,
 context: context
 });

 // Add assistant response
 this.addMessage('assistant', result.response);
 }

 async gatherContext(): Promise<ProjectContext> {
 const editor = vscode.window.activeTextEditor;
 const workspaceFolder = vscode.workspace.workspaceFolders?.[0];

 return {
 // Current file context
 currentFile: editor?.document.fileName,
 currentSelection: editor?.selection
 ? editor.document.getText(editor.selection)
 : undefined,
 currentLanguage: editor?.document.languageId,

 // Project context
 workspaceRoot: workspaceFolder?.uri.fsPath,
 openFiles: vscode.window.visibleTextEditors.map(e => e.document.fileName),

 // Git context
 gitBranch: await this.getGitBranch(),
 gitStatus: await this.getGitStatus()
 };
 }

 addMessage(role: 'user' | 'assistant', content: string) {
 this.messages.push({ role, content, timestamp: new Date() });
 this.updateView();
 }

 private updateView() {
 this.view?.webview.postMessage({
 type: 'updateMessages',
 messages: this.messages
 });
 }
}`
```

#### Code Action Provider

 typescript
 Copy

`// providers/codeActions.ts
export class CodeActionProvider implements vscode.CodeActionProvider {
 constructor(private client: AmplifierClient) {}

 async provideCodeActions(
 document: vscode.TextDocument,
 range: vscode.Range
 ): Promise<vscode.CodeAction[]> {
 const actions: vscode.CodeAction[] = [];

 // Only show when there's a selection
 if (range.isEmpty) return actions;

 const selectedText = document.getText(range);

 // Explain code
 const explainAction = new vscode.CodeAction(
 'ðŸ”§ Amplifier: Explain this code',
 vscode.CodeActionKind.QuickFix
 );
 explainAction.command = {
 command: 'amplifier.explainSelection',
 title: 'Explain Code'
 };
 actions.push(explainAction);

 // Suggest improvements
 const improveAction = new vscode.CodeAction(
 'ðŸ”§ Amplifier: Suggest improvements',
 vscode.CodeActionKind.QuickFix
 );
 improveAction.command = {
 command: 'amplifier.suggestImprovements',
 title: 'Suggest Improvements'
 };
 actions.push(improveAction);

 // Generate tests
 const testAction = new vscode.CodeAction(
 'ðŸ”§ Amplifier: Generate tests',
 vscode.CodeActionKind.QuickFix
 );
 testAction.command = {
 command: 'amplifier.generateTests',
 title: 'Generate Tests'
 };
 actions.push(testAction);

 // Add documentation
 const docAction = new vscode.CodeAction(
 'ðŸ”§ Amplifier: Add documentation',
 vscode.CodeActionKind.QuickFix
 );
 docAction.command = {
 command: 'amplifier.addDocumentation',
 title: 'Add Documentation'
 };
 actions.push(docAction);

 return actions;
 }
}`
```

#### Problems Integration

 typescript
 Copy

`// providers/problems.ts
export class ProblemsProvider implements vscode.Disposable {
 private diagnosticCollection: vscode.DiagnosticCollection;
 private debounceTimer?: NodeJS.Timeout;

 constructor(
 private client: AmplifierClient,
 context: vscode.ExtensionContext
 ) {
 this.diagnosticCollection = vscode.languages.createDiagnosticCollection('amplifier');

 // Analyze on save
 context.subscriptions.push(
 vscode.workspace.onDidSaveTextDocument((doc) => {
 this.analyzeDocument(doc);
 })
 );

 // Analyze open documents
 vscode.workspace.textDocuments.forEach((doc) => {
 this.analyzeDocument(doc);
 });
 }

 async analyzeDocument(document: vscode.TextDocument) {
 // Debounce
 if (this.debounceTimer) {
 clearTimeout(this.debounceTimer);
 }

 this.debounceTimer = setTimeout(async () => {
 const result = await this.client.execute({
 prompt: 'Analyze this code for potential issues',
 context: {
 file: document.fileName,
 content: document.getText(),
 language: document.languageId
 },
 scenario: 'quick-analysis'
 });

 const diagnostics = this.parseIssues(result, document);
 this.diagnosticCollection.set(document.uri, diagnostics);
 }, 1000);
 }

 private parseIssues(
 result: ExecutionResult,
 document: vscode.TextDocument
 ): vscode.Diagnostic[] {
 const diagnostics: vscode.Diagnostic[] = [];

 for (const issue of result.issues || []) {
 const range = new vscode.Range(
 issue.line - 1, 0,
 issue.line - 1, document.lineAt(issue.line - 1).text.length
 );

 const severity = {
 critical: vscode.DiagnosticSeverity.Error,
 high: vscode.DiagnosticSeverity.Error,
 medium: vscode.DiagnosticSeverity.Warning,
 low: vscode.DiagnosticSeverity.Information
 }[issue.severity] || vscode.DiagnosticSeverity.Information;

 const diagnostic = new vscode.Diagnostic(
 range,
 `[Amplifier] ${issue.message}`,
 severity
 );
 diagnostic.source = 'amplifier';
 diagnostic.code = issue.code;

 diagnostics.push(diagnostic);
 }

 return diagnostics;
 }

 dispose() {
 this.diagnosticCollection.dispose();
 }
}`
```

---

### User Interface

#### Chat Panel

 html
 Copy

`<!-- Chat webview HTML -->
<div class="amplifier-chat">
 <div class="chat-messages" id="messages">
 <!-- Messages rendered here -->
 </div>

 <div class="chat-input">
 <textarea
 id="input"
 placeholder="Ask about your code..."
 rows="3"
 ></textarea>
 <button onclick="sendMessage()">Send</button>
 </div>

 <div class="chat-actions">
 <button onclick="clearChat()">Clear</button>
 <button onclick="exportChat()">Export</button>
 </div>
</div>`
```

#### Status Bar

 typescript
 Copy

`// Status bar integration
const statusBarItem = vscode.window.createStatusBarItem(
 vscode.StatusBarAlignment.Right,
 100
);

statusBarItem.text = "$(hubot) Amplifier";
statusBarItem.tooltip = "Amplifier AI Assistant - Click to open chat";
statusBarItem.command = "amplifier.chatView.focus";
statusBarItem.show();

// Update status based on connection
client.on('connected', () => {
 statusBarItem.text = "$(hubot) Amplifier";
 statusBarItem.backgroundColor = undefined;
});

client.on('disconnected', () => {
 statusBarItem.text = "$(hubot) Amplifier (Offline)";
 statusBarItem.backgroundColor = new vscode.ThemeColor(
 'statusBarItem.warningBackground'
 );
});`
```

---

### Commands Reference

 | 
 
 | Command | Keybinding | Description

 | `amplifier.openChat` | `Cmd+Shift+A` | Open chat panel
 
 | `amplifier.explainSelection` | `Cmd+Shift+E` | Explain selected code
 
 | `amplifier.generateTests` | `Cmd+Shift+T` | Generate tests
 
 | `amplifier.suggestImprovements` | - | Suggest improvements
 
 | `amplifier.addDocumentation` | - | Add documentation
 
 | `amplifier.findSimilarCode` | - | Find similar code
 
 | `amplifier.reviewChanges` | - | Review uncommitted changes
 
 | `amplifier.explainArchitecture` | - | Explain repository architecture

---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Integration Web Dashboard
 integrations

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-web-dashboard`

### Overview

Web-based dashboard for managing Amplifier: collections, profiles, sessions, analytics, and interactive chat. Provides visual management without requiring CLI knowledge. Built on top of the API Server.

#### Value Proposition

 | 
 
 | Without | With

 | CLI-only management | Visual point-and-click interface
 
 | Manual profile editing | Profile builder with live preview
 
 | Log file inspection | Real-time analytics dashboard
 
 | Single-session terminal | Multi-session workspace

---

### Features

#### 1. Interactive Chat Workspace

Multi-panel chat interface with session management.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Amplifier Dashboard [user@email.com] [âš™ï¸] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚ â”‚
â”‚ Sessions â”‚ Session: Code Review #42 [Profile]â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚ â”‚
â”‚ â— Active â”‚ User: Explain the payment processing flow â”‚
â”‚ #42 â”‚ â”‚
â”‚ #38 â”‚ Assistant: Based on my analysis of the codebase: â”‚
â”‚ â”‚ â”‚
â”‚ â—‹ Recent â”‚ 1. **Entry Point** (src/api/payments.ts:45) â”‚
â”‚ #35 â”‚ - Receives POST /api/payments â”‚
â”‚ #31 â”‚ â”‚
â”‚ â”‚ 2. **Validation** (src/services/PaymentValidator.ts)â”‚
â”‚ + New â”‚ - Card validation â”‚
â”‚ â”‚ - Fraud detection â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ [Referenced Files] â”‚
â”‚ â”‚ â€¢ payments.ts â€¢ PaymentValidator.ts â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚ [Type your message...] [Send] [ðŸ“Ž]â”‚
â”‚ â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 2. Collection Manager

Visual interface for browsing, installing, and managing collections.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Collections [+ Install] [ðŸ”„] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ Installed (4) â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ðŸ“¦ enterprise-dev v1.2.0 â”‚ â”‚
â”‚ â”‚ Enterprise development tools and profiles â”‚ â”‚
â”‚ â”‚ Profiles: 3 Agents: 5 Tools: 8 â”‚ â”‚
â”‚ â”‚ [View] [Update Available] [Remove] â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ðŸ“¦ foundation v2.0.0 â”‚ â”‚
â”‚ â”‚ Core profiles and base configurations â”‚ â”‚
â”‚ â”‚ Profiles: 2 Agents: 3 Tools: 0 â”‚ â”‚
â”‚ â”‚ [View] [Up to date] â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â”‚ Available (12) [Browse â†’] â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 3. Profile Builder

Visual profile editor with inheritance visualization.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Profile Builder: my-custom-profile [Save] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ Extends: [foundation:base â–¼] â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ Inheritance Chain â”‚â”‚
â”‚ â”‚ foundation:base â†’ enterprise-dev:development â†’ my-custom â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ Providers â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ðŸ¤– provider-anthropic â”‚ â”‚ + Add Provider â”‚ â”‚
â”‚ â”‚ Model: claude-sonnet â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ Temperature: 0.7 â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ [Configure] [Remove] â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â”‚ Tools â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ [x] filesystem [x] bash [x] web [ ] task [+ Add Tool] â”‚
â”‚ â”‚
â”‚ Hooks â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ [x] logging [x] security-scan [ ] audit-trail [+ Add Hook] â”‚
â”‚ â”‚
â”‚ Preview YAML [Copy] â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ extends: foundation:base â”‚â”‚
â”‚ â”‚ providers: â”‚â”‚
â”‚ â”‚ - module: provider-anthropic â”‚â”‚
â”‚ â”‚ config: â”‚â”‚
â”‚ â”‚ model: claude-sonnet-4-5 â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 4. Analytics Dashboard

Real-time usage analytics and insights.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analytics [Last 7 days â–¼] [ðŸ”„] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ 1,247 â”‚ â”‚ 45.2K â”‚ â”‚ $127.50 â”‚ â”‚ 2.3s â”‚ â”‚
â”‚ â”‚ Sessions â”‚ â”‚ Tokens â”‚ â”‚ Cost â”‚ â”‚ Avg Time â”‚ â”‚
â”‚ â”‚ â†‘ 12% â”‚ â”‚ â†‘ 8% â”‚ â”‚ â†“ 5% â”‚ â”‚ â†“ 15% â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â”‚ Usage Over Time â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ â•­â”€â”€â•® â•­â”€â”€â”€â”€â•® â”‚
â”‚ â”‚ â•­â”€â”€â•¯ â•°â”€â”€â•® â•­â”€â”€â”€â”€â•¯ â•°â”€â”€â•® â”‚
â”‚ â”‚â”€â”€â•¯ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â•°â”€â”€â”€â”€ â”‚
â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Mon Tue Wed Thu Fri Sat Sun â”‚
â”‚ â”‚
â”‚ Top Profiles â”‚ Top Tools â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ 1. enterprise-dev:dev 42% â”‚ 1. codebase-search 35% â”‚
â”‚ 2. foundation:base 28% â”‚ 2. filesystem 28% â”‚
â”‚ 3. custom:review 15% â”‚ 3. bash 22% â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### 5. Session History & Search

Browse and search past sessions.

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Session History [Search...] [Filter] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ Today â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ #47 â€¢ 10:30 AM â€¢ enterprise-dev:development â”‚â”‚
â”‚ â”‚ "How does the payment processing work?" â”‚â”‚
â”‚ â”‚ 12 messages â€¢ 4.5K tokens â€¢ [Resume] [Export] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ #46 â€¢ 9:15 AM â€¢ foundation:base â”‚â”‚
â”‚ â”‚ "Generate unit tests for UserService" â”‚â”‚
â”‚ â”‚ 8 messages â€¢ 2.1K tokens â€¢ [Resume] [Export] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ Yesterday â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚ â”‚ #45 â€¢ 4:45 PM â€¢ enterprise-dev:review â”‚â”‚
â”‚ â”‚ "Review PR #234 for security issues" â”‚â”‚
â”‚ â”‚ 15 messages â€¢ 8.2K tokens â€¢ [Resume] [Export] â”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚ â”‚
â”‚ [Load More] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Web Dashboard â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ React/Next.js Frontend â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ Chat â”‚ â”‚Collectionâ”‚ â”‚ Profile â”‚ â”‚Analytics â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ Workspaceâ”‚ â”‚ Manager â”‚ â”‚ Builder â”‚ â”‚Dashboard â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ API Client â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ (SDK) â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Amplifier API â”‚ â”‚
â”‚ â”‚ Server â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Tech Stack

 yaml
 Copy

`frontend:
 framework: Next.js 14
 language: TypeScript
 styling: Tailwind CSS
 state: Zustand or React Query
 components: shadcn/ui
 charts: Recharts

api_client:
 type: Generated from OpenAPI
 websocket: Native WebSocket

deployment:
 options:
 - Vercel (recommended)
 - Docker + nginx
 - Static export + CDN`
```

---

### Implementation

#### Pages Structure

 text
 Copy

`app/
â”œâ”€â”€ page.tsx # Landing / redirect to dashboard
â”œâ”€â”€ login/
â”‚ â””â”€â”€ page.tsx # Authentication
â”œâ”€â”€ dashboard/
â”‚ â”œâ”€â”€ page.tsx # Main dashboard (analytics)
â”‚ â”œâ”€â”€ chat/
â”‚ â”‚ â”œâ”€â”€ page.tsx # Chat workspace
â”‚ â”‚ â””â”€â”€ [sessionId]/
â”‚ â”‚ â””â”€â”€ page.tsx # Specific session
â”‚ â”œâ”€â”€ collections/
â”‚ â”‚ â”œâ”€â”€ page.tsx # Collection manager
â”‚ â”‚ â””â”€â”€ [name]/
â”‚ â”‚ â””â”€â”€ page.tsx # Collection details
â”‚ â”œâ”€â”€ profiles/
â”‚ â”‚ â”œâ”€â”€ page.tsx # Profile list
â”‚ â”‚ â”œâ”€â”€ new/
â”‚ â”‚ â”‚ â””â”€â”€ page.tsx # Profile builder
â”‚ â”‚ â””â”€â”€ [name]/
â”‚ â”‚ â””â”€â”€ page.tsx # Edit profile
â”‚ â”œâ”€â”€ history/
â”‚ â”‚ â””â”€â”€ page.tsx # Session history
â”‚ â””â”€â”€ settings/
â”‚ â””â”€â”€ page.tsx # User settings
â””â”€â”€ api/
 â””â”€â”€ [...proxy]/
 â””â”€â”€ route.ts # API proxy (optional)`
```

#### Chat Component

 tsx
 Copy

`// components/chat/ChatWorkspace.tsx
"use client";

import { useState, useEffect, useRef } from "react";
import { useSession } from "@/hooks/useSession";
import { MessageList } from "./MessageList";
import { ChatInput } from "./ChatInput";
import { SessionSidebar } from "./SessionSidebar";
import { ProfileSelector } from "./ProfileSelector";

export function ChatWorkspace() {
 const [sessionId, setSessionId] = useState<string | null>(null);
 const [messages, setMessages] = useState<Message[]>([]);
 const [isStreaming, setIsStreaming] = useState(false);
 const messagesEndRef = useRef<HTMLDivElement>(null);

 const { createSession, executePrompt, sessions } = useSession();

 const handleNewSession = async (profile: string) => {
 const session = await createSession(profile);
 setSessionId(session.id);
 setMessages([]);
 };

 const handleSendMessage = async (content: string) => {
 if (!sessionId) return;

 // Add user message
 setMessages((prev) => [...prev, { role: "user", content }]);
 setIsStreaming(true);

 // Stream response
 let assistantMessage = "";
 for await (const event of executePrompt(sessionId, content)) {
 if (event.type === "token") {
 assistantMessage += event.content;
 setMessages((prev) => {
 const updated = [...prev];
 const lastIdx = updated.length - 1;
 if (updated[lastIdx]?.role === "assistant") {
 updated[lastIdx].content = assistantMessage;
 } else {
 updated.push({ role: "assistant", content: assistantMessage });
 }
 return updated;
 });
 }
 }

 setIsStreaming(false);
 };

 return (
 <div className="flex h-screen">
 {/* Sidebar */}
 <SessionSidebar
 sessions={sessions}
 activeSessionId={sessionId}
 onSelectSession={setSessionId}
 onNewSession={() => setSessionId(null)}
 />

 {/* Main chat area */}
 <div className="flex-1 flex flex-col">
 {/* Header */}
 <div className="border-b p-4 flex justify-between items-center">
 <h2>
 {sessionId ? `Session #${sessionId.slice(0, 8)}` : "New Session"}
 </h2>
 <ProfileSelector
 onSelect={handleNewSession}
 disabled={!!sessionId}
 />
 </div>

 {/* Messages */}
 <div className="flex-1 overflow-y-auto p-4">
 <MessageList messages={messages} isStreaming={isStreaming} />
 <div ref={messagesEndRef} />
 </div>

 {/* Input */}
 <ChatInput
 onSend={handleSendMessage}
 disabled={!sessionId || isStreaming}
 placeholder={sessionId ? "Type your message..." : "Select a profile to start"}
 />
 </div>
 </div>
 );
}`
```

#### Collection Manager Component

 tsx
 Copy

`// components/collections/CollectionManager.tsx
"use client";

import { useCollections } from "@/hooks/useCollections";
import { CollectionCard } from "./CollectionCard";
import { InstallModal } from "./InstallModal";
import { useState } from "react";

export function CollectionManager() {
 const { collections, install, remove, checkUpdates } = useCollections();
 const [showInstall, setShowInstall] = useState(false);

 const handleInstall = async (source: string) => {
 await install(source);
 setShowInstall(false);
 };

 return (
 <div className="p-6">
 <div className="flex justify-between items-center mb-6">
 <h1 className="text-2xl font-bold">Collections</h1>
 <div className="flex gap-2">
 <button
 onClick={() => checkUpdates()}
 className="btn btn-secondary"
 >
 Check Updates
 </button>
 <button
 onClick={() => setShowInstall(true)}
 className="btn btn-primary"
 >
 + Install Collection
 </button>
 </div>
 </div>

 <section className="mb-8">
 <h2 className="text-lg font-semibold mb-4">
 Installed ({collections.length})
 </h2>
 <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
 {collections.map((collection) => (
 <CollectionCard
 key={collection.name}
 collection={collection}
 onRemove={() => remove(collection.name)}
 />
 ))}
 </div>
 </section>

 {showInstall && (
 <InstallModal
 onInstall={handleInstall}
 onClose={() => setShowInstall(false)}
 />
 )}
 </div>
 );
}`
```

---

### Authentication

Integrates with API server authentication:

 tsx
 Copy

`// lib/auth.ts
import { signIn, signOut, useSession } from "next-auth/react";

export const authConfig = {
 providers: [
 // GitHub OAuth
 GitHubProvider({
 clientId: process.env.GITHUB_ID,
 clientSecret: process.env.GITHUB_SECRET,
 }),
 // API Key auth
 CredentialsProvider({
 name: "API Key",
 credentials: {
 apiKey: { label: "API Key", type: "password" }
 },
 async authorize(credentials) {
 // Validate API key against Amplifier API
 const res = await fetch(`${API_URL}/v1/auth/validate`, {
 headers: { "X-API-Key": credentials.apiKey }
 });
 if (res.ok) {
 return await res.json();
 }
 return null;
 }
 })
 ]
};`
```

---

### Configuration

 yaml
 Copy

`# Dashboard configuration
dashboard:
 title: "Amplifier Dashboard"
 logo: "/logo.svg"

 api:
 url: "https://api.amplifier.example.com"
 # Or local
 # url: "http://localhost:8000"

 features:
 chat: true
 collections: true
 profiles: true
 analytics: true
 history: true

 theme:
 primary: "#6366f1"
 mode: "system" # light | dark | system

 auth:
 providers: ["github", "api_key"]
 required: true`
```

---

### Deployment

#### Vercel (Recommended)

 bash
 Copy

`# Deploy to Vercel
vercel deploy

# Environment variables
NEXT_PUBLIC_API_URL=https://api.amplifier.example.com
NEXTAUTH_SECRET=xxx
GITHUB_ID=xxx
GITHUB_SECRET=xxx`
```

#### Docker

 dockerfile
 Copy

`FROM node:20-alpine AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM node:20-alpine AS runner
WORKDIR /app
COPY --from=builder /app/.next/standalone ./
COPY --from=builder /app/.next/static ./.next/static
COPY --from=builder /app/public ./public

EXPOSE 3000
CMD ["node", "server.js"]`
```

---

### Open Questions

- Self-hosted vs Cloud: Should we offer a hosted version?
 
- Offline mode: Support for local-only without API server?
 
- Team features: Shared sessions, team profiles?
 
- Plugin system: Allow dashboard extensions?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Context Codebase Knowledge Graph
 contexts

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-context-codebase-knowledge-graph`

### Overview

A context manager that maintains a living knowledge graph of the codebase structure (files, functions, classes, dependencies, data flow) and injects relevant subgraphs into conversation context. Enables graph-based queries like "What depends on X?", "How does data flow from A to B?", and "What's the impact radius of changing Y?"

#### Value Proposition

 | 
 
 | Without | With

 | Flat file view of codebase | Relationship-aware graph view
 
 | "What depends on this?" requires manual tracing | Graph traversal shows all dependencies instantly
 
 | Impact analysis is guesswork | Precise impact radius calculation
 
 | Dead code unknown | Graph reachability detects unused code

#### Use Cases

- Refactoring impact analysis: "What breaks if I change this module?"
 
- Dependency tracing: "What does this function call? What calls it?"
 
- Data flow analysis: "How does user data get to the database?"
 
- Dead code detection: "What code is unreachable from entry points?"
 
- Architecture understanding: "Show me the call graph for authentication"
 
---

### Contract

#### ContextManager Interface

 python
 Copy

`class CodebaseKnowledgeGraphContext:
 """
 Context manager with codebase graph integration.
 
 Extends standard context with:
 - Codebase graph construction and maintenance
 - Graph-based queries
 - Relevant subgraph injection into context
 - Impact analysis
 """
 
 async def add_message(
 self, 
 message: dict[str, Any],
 ) -> None:
 """
 Add message to context.
 
 If message mentions code entities:
 1. Query graph for related entities
 2. Inject relevant subgraph into context
 """
 
 async def get_messages(
 self,
 include_graph_context: bool = True
 ) -> list[dict[str, Any]]:
 """
 Get messages with optional graph context.
 
 Args:
 include_graph_context: Include relevant graph data
 """
 
 # Graph query methods
 
 async def find_dependencies(
 self,
 entity: str
 ) -> list[Dependency]:
 """Find all dependencies of an entity."""
 
 async def find_dependents(
 self,
 entity: str
 ) -> list[Dependent]:
 """Find all entities that depend on this entity."""
 
 async def trace_call_chain(
 self,
 from_func: str,
 to_func: str
 ) -> list[CallPath]:
 """Find call paths between functions."""
 
 async def calculate_impact_radius(
 self,
 changed_files: list[str]
 ) -> ImpactAnalysis:
 """Calculate impact of changing files."""
 
 async def detect_circular_dependencies(self) -> list[Cycle]:
 """Find circular dependency chains."""
 
 async def find_unused_code(
 self,
 entry_points: list[str]
 ) -> list[str]:
 """Find code unreachable from entry points."""`
```

#### Configuration Schema

 toml
 Copy

`[[contexts]]
module = "context-codebase-knowledge-graph"
config = {
 # Graph construction
 codebase_paths = ["src/", "lib/"]
 exclude_paths = ["node_modules/", "dist/", ".git/"]
 languages = ["typescript", "python", "rust"]
 
 # Graph storage
 graph_database = "neo4j://localhost:7687" # or "sqlite", "memory"
 persistence = true
 incremental_updates = true
 
 # Indexing strategy
 index_on_startup = false # Build graph on first use
 watch_for_changes = true # Update graph on file changes
 debounce_ms = 1000 # Debounce rapid changes
 
 # Node types to track
 track_files = true
 track_functions = true
 track_classes = true
 track_variables = true
 track_imports = true
 track_tables = true # Database tables
 
 # Relationship types to track
 track_imports_relations = true # File imports file
 track_calls_relations = true # Function calls function
 track_inherits_relations = true # Class inherits class
 track_modifies_relations = true # Function modifies table
 track_reads_relations = true # Function reads table
 
 # Context injection
 auto_inject_graph = true # Auto-inject relevant subgraph
 max_depth = 3 # Max traversal depth
 max_nodes = 50 # Max nodes in subgraph
 
 # Query optimization
 cache_queries = true
 cache_ttl_seconds = 300
}`
```

#### Data Schema

 python
 Copy

`# Graph node types
@dataclass
class FileNode:
 path: str
 language: str
 lines_of_code: int
 last_modified: datetime

@dataclass
class FunctionNode:
 name: str
 file: str
 signature: str
 line_start: int
 line_end: int

@dataclass
class ClassNode:
 name: str
 file: str
 methods: list[str]
 line_start: int

@dataclass
class TableNode:
 name: str
 database: str
 columns: list[str]

# Graph relationship types
@dataclass
class ImportsRelation:
 from_file: str
 to_file: str

@dataclass
class CallsRelation:
 from_func: str
 to_func: str
 call_count: int

@dataclass
class InheritsRelation:
 child_class: str
 parent_class: str

@dataclass
class ModifiesRelation:
 function: str
 table: str
 operation: str # INSERT, UPDATE, DELETE

# Query results
@dataclass
class Dependency:
 entity: str
 type: str
 relationship: str

@dataclass
class ImpactAnalysis:
 directly_affected: list[str] # Files directly importing changed files
 indirectly_affected: list[str] # Files transitively affected
 estimated_risk: str # "low" | "medium" | "high"
 affected_count: int
 depth_levels: dict[int, list[str]] # {depth: [files at that depth]}`
```

#### Events Emitted

 | 
 
 | Event | When | Data

 | `context:graph:building` | Graph construction starts | codebase_path, file_count
 
 | `context:graph:built` | Graph construction complete | node_count, edge_count, duration_ms
 
 | `context:graph:updated` | Incremental update | changed_files, updated_nodes
 
 | `context:graph:queried` | Graph query executed | query_type, result_count
 
 | `context:graph:injected` | Subgraph injected into context | entity, subgraph_size

---

### Architecture

#### Component Diagram

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ context-codebase-knowledge-graph â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Codebase â”‚â”€â”€â”€â–¶â”‚ Graph â”‚â”€â”€â”€â–¶â”‚ Query â”‚ â”‚
â”‚ â”‚ Parser â”‚ â”‚ Builder â”‚ â”‚ Engine â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Change â”‚ â”‚ Subgraph â”‚ â”‚ Graph â”‚ â”‚
â”‚ â”‚ Watcher â”‚ â”‚ Extractor â”‚ â”‚ Store â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Graph Schema:

 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ File â”‚â”€IMPORTSâ†’â”‚ File â”‚â”€DEFINESâ†’â”‚Function â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
 â”‚CALLS
 â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Table â”‚â—€MODIFIESâ”€â”‚ Function â”‚â”€CALLSâ”€â†’â”‚Function â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Internal Components

#### 1. Codebase Parser

Parses code to extract entities and relationships:

 python
 Copy

`class CodebaseParser:
 """Parses codebase to extract graph nodes and edges."""
 
 def __init__(self, languages: list[str]):
 self.parsers = {
 lang: self._init_parser(lang)
 for lang in languages
 }
 
 def _init_parser(self, language: str):
 """Initialize TreeSitter parser for language."""
 import tree_sitter
 
 language_lib = tree_sitter.Language(
 f'build/{language}.so',
 language
 )
 
 parser = tree_sitter.Parser()
 parser.set_language(language_lib)
 
 return parser
 
 async def parse_file(self, file_path: Path) -> FileParseResult:
 """
 Parse file and extract entities and relationships.
 
 Returns:
 - Nodes: functions, classes, variables
 - Edges: calls, imports, inherits
 """
 
 language = self._detect_language(file_path)
 parser = self.parsers.get(language)
 
 if not parser:
 return FileParseResult.empty()
 
 # Read and parse file
 content = file_path.read_text()
 tree = parser.parse(bytes(content, "utf8"))
 
 # Extract entities
 nodes = []
 edges = []
 
 # Extract functions
 functions = self._extract_functions(tree, file_path)
 nodes.extend(functions)
 
 # Extract classes
 classes = self._extract_classes(tree, file_path)
 nodes.extend(classes)
 
 # Extract imports
 imports = self._extract_imports(tree, file_path)
 edges.extend(imports)
 
 # Extract function calls
 calls = self._extract_calls(tree, file_path)
 edges.extend(calls)
 
 return FileParseResult(nodes=nodes, edges=edges)
 
 def _extract_functions(
 self,
 tree: tree_sitter.Tree,
 file_path: Path
 ) -> list[FunctionNode]:
 """Extract function definitions."""
 
 functions = []
 
 # Query for function definitions
 query = """
 (function_declaration
 name: (identifier) @func_name
 parameters: (formal_parameters) @params
 ) @function
 """
 
 matches = self._query_tree(tree, query)
 
 for match in matches:
 func_node = match["function"]
 name = match["func_name"].text.decode()
 
 functions.append(FunctionNode(
 name=name,
 file=str(file_path),
 signature=self._extract_signature(match),
 line_start=func_node.start_point[0],
 line_end=func_node.end_point[0]
 ))
 
 return functions
 
 def _extract_calls(
 self,
 tree: tree_sitter.Tree,
 file_path: Path
 ) -> list[CallsRelation]:
 """Extract function calls."""
 
 calls = []
 
 # Query for call expressions
 query = """
 (call_expression
 function: (identifier) @callee
 ) @call
 """
 
 matches = self._query_tree(tree, query)
 
 # Track which function contains this call
 current_function = None # Determined by context
 
 for match in matches:
 callee = match["callee"].text.decode()
 
 if current_function:
 calls.append(CallsRelation(
 from_func=current_function,
 to_func=callee,
 call_count=1
 ))
 
 return calls`
```

#### 2. Graph Builder

Constructs and maintains graph:

 python
 Copy

`class GraphBuilder:
 """Builds and maintains codebase knowledge graph."""
 
 def __init__(self, graph_store: GraphStore):
 self.graph_store = graph_store
 self.parser = CodebaseParser(["typescript", "python", "rust"])
 
 async def build_graph(self, codebase_paths: list[Path]) -> GraphStats:
 """Build complete graph from codebase."""
 
 stats = GraphStats()
 
 # Find all source files
 files = []
 for path in codebase_paths:
 files.extend(self._find_source_files(path))
 
 stats.files_found = len(files)
 
 # Parse all files in parallel
 parse_tasks = [
 self.parser.parse_file(file)
 for file in files
 ]
 
 results = await asyncio.gather(*parse_tasks)
 
 # Build graph
 for file, result in zip(files, results):
 # Add file node
 await self.graph_store.add_node(FileNode(
 path=str(file),
 language=self._detect_language(file),
 lines_of_code=self._count_lines(file),
 last_modified=file.stat().st_mtime
 ))
 
 # Add entity nodes
 for node in result.nodes:
 await self.graph_store.add_node(node)
 stats.nodes_added += 1
 
 # Add relationships
 for edge in result.edges:
 await self.graph_store.add_edge(edge)
 stats.edges_added += 1
 
 return stats
 
 async def update_file(self, file_path: Path):
 """Incrementally update graph for changed file."""
 
 # Remove existing nodes/edges for this file
 await self.graph_store.remove_nodes_by_file(str(file_path))
 
 # Re-parse file
 result = await self.parser.parse_file(file_path)
 
 # Add updated nodes/edges
 for node in result.nodes:
 await self.graph_store.add_node(node)
 
 for edge in result.edges:
 await self.graph_store.add_edge(edge)`
```

#### 3. Graph Store

Persists and queries graph:

 python
 Copy

`class GraphStore:
 """Graph database abstraction."""
 
 def __init__(self, backend: str = "neo4j"):
 self.backend = backend
 self.conn = self._connect(backend)
 
 async def add_node(self, node: Node):
 """Add node to graph."""
 
 if self.backend == "neo4j":
 await self._neo4j_add_node(node)
 elif self.backend == "sqlite":
 await self._sqlite_add_node(node)
 
 async def add_edge(self, edge: Relation):
 """Add edge to graph."""
 # Implementation depends on backend
 ...
 
 async def query(
 self,
 cypher_query: str,
 params: dict | None = None
 ) -> list[dict]:
 """Execute Cypher query (or SQL equivalent)."""
 
 if self.backend == "neo4j":
 result = await self.conn.execute_read(
 lambda tx: tx.run(cypher_query, params or {})
 )
 return [record.data() for record in result]
 
 # Translate to SQL for sqlite backend
 ...
 
 # Common query patterns
 
 async def find_dependencies(self, entity: str) -> list[str]:
 """Find all dependencies of entity."""
 
 query = """
 MATCH (e {name: $entity})-[r:IMPORTS|CALLS|INHERITS]->(dep)
 RETURN dep.name as dependency
 """
 
 results = await self.query(query, {"entity": entity})
 return [r["dependency"] for r in results]
 
 async def find_dependents(self, entity: str) -> list[str]:
 """Find all entities that depend on this entity."""
 
 query = """
 MATCH (dependent)-[r:IMPORTS|CALLS|INHERITS]->(e {name: $entity})
 RETURN dependent.name as dependent
 """
 
 results = await self.query(query, {"entity": entity})
 return [r["dependent"] for r in results]
 
 async def find_call_paths(
 self,
 from_func: str,
 to_func: str,
 max_depth: int = 5
 ) -> list[list[str]]:
 """Find call paths between functions."""
 
 query = """
 MATCH path = (start:Function {name: $from})-[:CALLS*1..${max_depth}]->(end:Function {name: $to})
 RETURN [node in nodes(path) | node.name] as path
 LIMIT 10
 """
 
 results = await self.query(query, {
 "from": from_func,
 "to": to_func,
 "max_depth": max_depth
 })
 
 return [r["path"] for r in results]
 
 async def calculate_impact(
 self,
 changed_files: list[str],
 max_depth: int = 5
 ) -> dict[int, list[str]]:
 """Calculate impact radius (BFS from changed files)."""
 
 query = """
 MATCH (changed:File)
 WHERE changed.path IN $changed_files
 CALL {
 WITH changed
 MATCH path = (changed)<-[:IMPORTS*1..${max_depth}]-(dependent:File)
 RETURN dependent.path as file, length(path) as depth
 }
 RETURN depth, collect(DISTINCT file) as files
 ORDER BY depth
 """
 
 results = await self.query(query, {
 "changed_files": changed_files,
 "max_depth": max_depth
 })
 
 return {r["depth"]: r["files"] for r in results}`
```

#### 4. Subgraph Extractor

Extracts relevant subgraph for context:

 python
 Copy

`class SubgraphExtractor:
 """Extracts relevant subgraph for conversation context."""
 
 def __init__(self, graph_store: GraphStore):
 self.graph_store = graph_store
 
 async def extract_relevant_subgraph(
 self,
 entities: list[str],
 max_depth: int = 2,
 max_nodes: int = 50
 ) -> Subgraph:
 """
 Extract subgraph relevant to entities.
 
 Strategy:
 1. Start from mentioned entities
 2. Expand outward (BFS) up to max_depth
 3. Stop at max_nodes
 4. Format for context injection
 """
 
 subgraph = Subgraph(nodes=[], edges=[])
 visited = set()
 queue = [(entity, 0) for entity in entities]
 
 while queue and len(subgraph.nodes) < max_nodes:
 entity, depth = queue.pop(0)
 
 if entity in visited or depth > max_depth:
 continue
 
 visited.add(entity)
 
 # Get node
 node = await self.graph_store.get_node(entity)
 if node:
 subgraph.nodes.append(node)
 
 # Get edges
 edges = await self.graph_store.get_edges(entity)
 subgraph.edges.extend(edges)
 
 # Expand to neighbors (if within depth)
 if depth < max_depth:
 neighbors = await self.graph_store.get_neighbors(entity)
 queue.extend((n, depth + 1) for n in neighbors)
 
 return subgraph
 
 def format_for_context(self, subgraph: Subgraph) -> str:
 """Format subgraph for injection into context."""
 
 sections = []
 
 # Files
 files = [n for n in subgraph.nodes if isinstance(n, FileNode)]
 if files:
 sections.append("# Files")
 for file in files:
 sections.append(f"- {file.path} ({file.lines_of_code} LOC)")
 
 # Functions
 functions = [n for n in subgraph.nodes if isinstance(n, FunctionNode)]
 if functions:
 sections.append("\n# Functions")
 for func in functions:
 sections.append(f"- {func.name} in {func.file}:{func.line_start}")
 
 # Relationships
 sections.append("\n# Relationships")
 for edge in subgraph.edges[:20]: # Limit to 20 edges
 sections.append(f"- {edge.from_entity} {edge.relation_type} {edge.to_entity}")
 
 return "\n".join(sections)`
```

#### Data Flow

 text
 Copy

`File Change Detected
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Re-parse File â”‚
â”‚ - Extract entities â”‚
â”‚ - Extract relationsâ”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Update Graph â”‚
â”‚ - Remove old nodes â”‚
â”‚ - Add new nodes â”‚
â”‚ - Update edges â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
 Graph Updated

Conversation Message:
"Refactor auth module"
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Detect Entity â”‚
â”‚ "auth module" â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Query Graph â”‚
â”‚ - Find dependenciesâ”‚
â”‚ - Calculate impact â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Extract Subgraph â”‚
â”‚ - auth + deps â”‚
â”‚ - Max 50 nodes â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Inject into Contextâ”‚
â”‚ (as system message)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Examples

#### Example 1: Dependency Analysis

 yaml
 Copy

`# User asks
"What depends on the User model?"

# Graph query
find_dependents("User")

# Results
Dependencies on User model:
- src/api/users.py: Imports User model
 - createUser() reads User
 - updateUser() modifies User
- src/api/auth.py: Imports User model
 - authenticate() reads User
- src/services/email.py: Imports User
 - sendWelcomeEmail() reads User.email
- tests/test_users.py: Imports User (test code)

Direct dependents: 4 files
Indirect dependents: 12 files (via imports)
Impact: Medium

# Injected into context
---
Codebase Context: User Model Dependencies

## Direct Dependencies (4)
- src/api/users.py (IMPORTS User, MODIFIES users table)
- src/api/auth.py (IMPORTS User, READS users table)
- src/services/email.py (IMPORTS User)
- tests/test_users.py (IMPORTS User)

## Call Chains
- User.save() â† createUser() â† POST /api/users
- User.authenticate() â† authenticate() â† POST /api/auth/login

## Impact Estimate
Changing User model will affect:
- 4 files directly
- 12 files indirectly
- Risk: MEDIUM (auth flow impacted)
---`
```

#### Example 2: Impact Analysis for Refactoring

 yaml
 Copy

`# User asks
"I want to refactor the authentication module. What will break?"

# Graph queries
changed_files = ["src/auth/middleware.py", "src/auth/tokens.py"]
impact = calculate_impact_radius(changed_files)

# Results
Impact Analysis: Authentication Module Refactor

## Direct Impact (Depth 1) - 4 files
Files that directly import auth modules:
- src/api/routes/users.py (imports auth/middleware)
- src/api/routes/admin.py (imports auth/middleware)
- src/services/email.py (imports auth/tokens)
- src/background/jobs/cleanup.py (imports auth/sessions)

## Indirect Impact (Depth 2) - 14 files
Files that depend on direct dependents:
- src/api/routes/posts.py â†’ users.py â†’ auth
- src/api/routes/comments.py â†’ users.py â†’ auth
- [12 more files...]

## Database Impact
Tables modified by auth modules:
- users table (auth/sessions.py MODIFIES)
- refresh_tokens table (auth/tokens.py MODIFIES)
- Migration 003_add_auth.sql needs review

## Call Chains
Critical paths through auth:
1. POST /api/users â†’ users.create() â†’ auth.hashPassword() â†’ bcrypt.hash()
2. POST /api/login â†’ auth.authenticate() â†’ auth.verifyPassword()
3. Middleware: ALL protected routes â†’ auth.middleware.verify()

## Risk Assessment
- Files affected: 18 total
- Critical paths: 3 (all authentication flows)
- Database changes: 2 tables
- **Estimated Risk: HIGH** (auth is central, widely used)

## Recommendations
1. Update 4 direct imports (check API contracts)
2. Run test suite: pytest tests/auth/**
3. Check for breaking changes in middleware signature
4. Review migration 003_add_auth for schema dependencies
5. Consider feature flag for gradual rollout

# Injected subgraph into context
---
Codebase Context: Authentication Module Structure

[Full graph with 50 most relevant nodes showing structure]
---`
```

#### Example 3: Call Path Tracing

 yaml
 Copy

`# User asks
"How does a user login request get to the database?"

# Graph query
trace_call_chain("POST /api/login", "database.execute")

# Results
Call Path: Login Request â†’ Database

Path 1 (most common):
POST /api/login â†’ routes/auth.login()
 â†’ auth.authenticate()
 â†’ User.findByEmail()
 â†’ database.query()
 â†’ database.execute()

Path 2 (with caching):
POST /api/login â†’ routes/auth.login()
 â†’ auth.authenticate()
 â†’ cache.get() [cache miss]
 â†’ User.findByEmail()
 â†’ database.query()
 â†’ database.execute()

## Data Flow
1. Request: { email, password }
2. Validation: auth.validateCredentials()
3. Query: SELECT * FROM users WHERE email = ?
4. Password Check: bcrypt.compare()
5. Token Generation: auth.generateToken()
6. Response: { token, user }

## Tables Accessed
- users (READ: email, password_hash)
- refresh_tokens (WRITE: new token)`
```

---

### Configuration

 yaml
 Copy

`# Full configuration example
contexts:
 - module: context-codebase-knowledge-graph
 config:
 # Source paths
 codebase_paths:
 - src/
 - lib/
 exclude_paths:
 - node_modules/
 - dist/
 - .git/
 - "**/*.test.ts"
 languages:
 - typescript
 - python
 - rust
 
 # Graph storage
 graph_database: neo4j://localhost:7687 # or sqlite, memory
 persistence: true
 incremental_updates: true
 
 # Indexing
 index_on_startup: false
 watch_for_changes: true
 debounce_ms: 1000
 
 # Node types
 track_files: true
 track_functions: true
 track_classes: true
 track_variables: true
 track_tables: true
 
 # Relationships
 track_imports_relations: true
 track_calls_relations: true
 track_inherits_relations: true
 track_modifies_relations: true
 track_reads_relations: true
 
 # Context injection
 auto_inject_graph: true
 max_depth: 3
 max_nodes: 50
 injection_format: markdown
 
 # Performance
 cache_queries: true
 cache_ttl_seconds: 300
 parallel_parsing: true
 max_parse_workers: 4`
```

---

### Security Considerations

#### Data Access

- Codebase access: Reads all source files
 
- Graph data: Complete codebase structure exposed
 
- Sensitive paths: May reveal internal architecture
 
#### Resource Usage

- Graph construction: CPU/memory intensive
 
- Graph storage: Disk space for persistence
 
- Query performance: Complex graph queries may be slow

 python
 Copy

`REQUIRED_CAPABILITIES = [
 "context:read",
 "context:write",
 "filesystem:read", # Read codebase
 "filesystem:watch", # Watch for changes
]`
```

---

### Testing Strategy

#### Unit Tests

 python
 Copy

`def test_parser_extracts_functions():
 parser = CodebaseParser(["python"])
 result = parser.parse_file(Path("test.py"))
 assert len(result.nodes) > 0
 assert any(isinstance(n, FunctionNode) for n in result.nodes)

def test_graph_store_finds_dependencies():
 store = GraphStore("memory")
 # Add nodes and edges
 deps = store.find_dependencies("User")
 assert "auth.py" in deps`
```

#### Integration Tests

 python
 Copy

`async def test_full_graph_construction():
 context = CodebaseKnowledgeGraphContext(config)
 
 # Build graph
 await context.build_graph()
 
 # Query
 deps = await context.find_dependencies("User")
 assert len(deps) > 0
 
 # Calculate impact
 impact = await context.calculate_impact_radius(["src/user.py"])
 assert impact.directly_affected > 0`
```

---

### Dependencies

#### Required

- `tree-sitter` + language grammars - Code parsing
 
- `neo4j` or `sqlite3` - Graph storage
 
#### Optional

- `watchdog` - File watching
 
- `networkx` - Graph algorithms (if not using Neo4j)
 
---

### Open Questions

- Graph granularity: Track variable-level dependencies or just function-level?
 
- Cross-language support: How to handle calls between languages (Python â†’ TypeScript)?
 
- Database schema tracking: Extract schema from migrations vs runtime inspection?
 
- Performance at scale: How to handle codebases with 100K+ files?
 
- Semantic understanding: Should we use LLM to understand code semantics beyond syntax?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Context Decision Journal
 contexts

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-context-decision-journal`

### Overview

A context manager that automatically detects, extracts, and indexes architectural and product decisions from conversations. Maintains a queryable decision log with full context, rationale, alternatives considered, and temporal tracking of how decisions evolve or get revisited.

#### Value Proposition

 | 
 
 | Without | With

 | "Why did we choose X?" lost in history | Complete decision record with rationale
 
 | Re-litigating old decisions | Quick lookup: "We decided this because..."
 
 | New team members missing context | Decision journal as onboarding material
 
 | Inconsistent decision-making | Learn from past decisions

#### Use Cases

- Onboarding: New engineers/PMs quickly understand past architectural decisions
 
- Decision review: "Why did we choose Postgres over MongoDB?" - instant answer
 
- Architecture evolution: Track how decisions changed over time
 
- Pattern recognition: Identify decision patterns and principles
 
- Compliance/audit: Maintain decision trail for governance
 
---

### Contract

#### ContextManager Interface

 python
 Copy

`class DecisionJournalContext:
 """
 Context manager with decision detection and indexing.
 
 Extends standard context manager with:
 - Automatic decision detection in conversations
 - Structured decision extraction
 - Queryable decision index
 - Temporal decision tracking
 """
 
 async def add_message(
 self, 
 message: dict[str, Any],
 ) -> None:
 """
 Add message and detect decisions.
 
 If decision detected:
 1. Extract decision metadata
 2. Store in decision index
 3. Link to related code/features
 """
 
 async def get_messages(self) -> list[dict[str, Any]]:
 """Get conversation messages (standard behavior)."""
 
 async def search_decisions(
 self,
 query: str,
 filters: DecisionFilters | None = None
 ) -> list[Decision]:
 """
 Search decision journal.
 
 Args:
 query: Text search query
 filters: Optional filters (by tech, date, stakeholder)
 
 Returns:
 Matching decisions with full context
 """
 
 async def get_decision_chain(
 self,
 decision_id: str
 ) -> DecisionChain:
 """
 Get evolution of a decision.
 
 Returns:
 - Original decision
 - Revisions/updates
 - Superseded decisions
 """`
```

#### Configuration Schema

 toml
 Copy

`[[contexts]]
module = "context-decision-journal"
config = {
 # Decision detection
 auto_detect = true
 detection_keywords = [
 "decided", "decision:", "let's go with", "we should",
 "agreed", "consensus", "choosing", "selected"
 ]
 detection_threshold = 0.7 # Confidence threshold for LLM detection
 
 # Extraction
 structured_extraction = true # Extract metadata (what, why, alternatives)
 extract_rationale = true
 extract_alternatives = true
 extract_trade_offs = true
 
 # Linking
 link_to_code = true # Link decisions to code files
 link_to_features = true # Link to features/epics
 auto_link_strategy = "file_mention" # "file_mention" | "git_context" | "llm_inference"
 
 # Indexing
 search_index = "sqlite" # "memory" | "sqlite" | "elasticsearch"
 index_embeddings = true # Enable semantic search
 embedding_model = "text-embedding-3-small"
 
 # Storage
 persistence = true # Persist decisions across sessions
 storage_path = ".amplifier/decisions/"
 retention_days = 730 # 2 years default
 
 # Querying
 enable_temporal_queries = true # "decisions made in Q2 2024"
 enable_stakeholder_queries = true # "decisions by @alice"
 enable_technology_queries = true # "decisions about databases"
}`
```

#### Data Schema

 python
 Copy

`@dataclass
class Decision:
 """Structured decision record."""
 id: str # UUID
 timestamp: datetime
 session_id: str
 
 # Core decision
 decision: str # What was decided
 context: str # Why was it being discussed
 rationale: str # Why this choice
 
 # Alternatives
 alternatives: list[Alternative] # Other options considered
 trade_offs: TradeOffs | None # Pros/cons analysis
 
 # Stakeholders
 stakeholders: list[str] # Who was involved
 decision_maker: str | None # Final decision maker
 
 # Links
 related_code: list[str] # File paths affected
 related_features: list[str] # Features/epics
 related_docs: list[str] # Documentation
 
 # Status
 status: DecisionStatus # active | superseded | revisited
 superseded_by: str | None # Decision ID if replaced
 supersedes: str | None # Decision ID if this replaces another
 
 # Search
 tags: list[str] # ["database", "architecture"]
 keywords: list[str] # Extracted key terms

@dataclass
class Alternative:
 """Alternative option that was considered."""
 option: str
 pros: list[str]
 cons: list[str]
 why_not_chosen: str | None

@dataclass
class TradeOffs:
 """Structured pros/cons."""
 pros: list[str]
 cons: list[str]
 risks: list[str]
 assumptions: list[str]

@dataclass
class DecisionChain:
 """Evolution of a decision over time."""
 original: Decision
 revisions: list[Decision]
 current: Decision
 
enum DecisionStatus:
 ACTIVE = "active" # Current decision
 SUPERSEDED = "superseded" # Replaced by newer decision
 REVISITED = "revisited" # Reconsidered but kept`
```

#### Events Emitted

 | 
 
 | Event | When | Data

 | `context:decision:detected` | Decision detected | decision_id, confidence
 
 | `context:decision:extracted` | Metadata extracted | decision_id, decision_summary
 
 | `context:decision:indexed` | Added to index | decision_id
 
 | `context:decision:superseded` | Decision replaced | old_decision_id, new_decision_id
 
 | `context:decision:searched` | Search performed | query, result_count

---

### Architecture

#### Component Diagram

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ context-decision-journal â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Decision â”‚â”€â”€â”€â–¶â”‚ Metadata â”‚â”€â”€â”€â–¶â”‚ Decision â”‚ â”‚
â”‚ â”‚ Detector â”‚ â”‚ Extractor â”‚ â”‚ Index â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Code â”‚ â”‚ Temporal â”‚ â”‚ Search â”‚ â”‚
â”‚ â”‚ Linker â”‚ â”‚ Tracker â”‚ â”‚ Engine â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Internal Components

#### 1. Decision Detector

Identifies decision points in conversations:

 python
 Copy

`class DecisionDetector:
 """Detects when decisions are made in conversations."""
 
 DECISION_KEYWORDS = [
 "decided", "decision:", "let's go with", "we should",
 "agreed", "consensus", "choosing", "selected", "approved",
 "going with", "will use", "settled on"
 ]
 
 def __init__(self, threshold: float = 0.7):
 self.threshold = threshold
 
 async def detect(
 self,
 message: dict[str, Any],
 conversation_context: list[dict[str, Any]]
 ) -> DetectionResult:
 """
 Detect if message contains a decision.
 
 Detection strategy:
 1. Keyword matching (fast, high recall)
 2. LLM confirmation (slower, high precision)
 3. Context analysis (is this really a decision?)
 """
 content = message.get("content", "")
 
 # Fast keyword check
 has_keyword = any(
 keyword in content.lower()
 for keyword in self.DECISION_KEYWORDS
 )
 
 if not has_keyword:
 return DetectionResult(is_decision=False, confidence=0.0)
 
 # LLM confirmation
 confidence = await self._llm_confirm(message, conversation_context)
 
 return DetectionResult(
 is_decision=confidence >= self.threshold,
 confidence=confidence,
 decision_snippet=self._extract_snippet(content)
 )
 
 async def _llm_confirm(
 self,
 message: dict[str, Any],
 context: list[dict[str, Any]]
 ) -> float:
 """Use LLM to confirm this is a decision."""
 
 context_str = self._format_context(context[-5:]) # Last 5 messages
 
 prompt = f"""
Analyze if this message contains a finalized decision:

Recent context:
{context_str}

Current message:
{message['content']}

Is this a decision being made (not just a proposal or discussion)?

Answer with a confidence score (0.0-1.0) and brief explanation:
- 1.0: Definitely a decision
- 0.5: Possibly a decision
- 0.0: Not a decision

Format: score|explanation
"""
 
 # Parse LLM response
 response = await self._call_llm(prompt)
 score, explanation = self._parse_response(response)
 
 return score`
```

#### 2. Metadata Extractor

Extracts structured decision data:

 python
 Copy

`class MetadataExtractor:
 """Extracts structured metadata from decision conversations."""
 
 async def extract(
 self,
 decision_message: dict[str, Any],
 conversation_context: list[dict[str, Any]]
 ) -> Decision:
 """
 Extract structured decision data.
 
 Extracts:
 - What was decided
 - Why (rationale)
 - What alternatives were considered
 - Who decided
 - What it relates to
 """
 
 # Build extraction prompt with conversation context
 prompt = self._build_extraction_prompt(
 decision_message,
 conversation_context
 )
 
 # Get structured extraction from LLM
 raw_extraction = await self._call_llm(prompt)
 
 # Parse into Decision object
 decision = self._parse_extraction(raw_extraction)
 
 # Enrich with additional metadata
 decision = await self._enrich_decision(decision, conversation_context)
 
 return decision
 
 def _build_extraction_prompt(
 self,
 message: dict[str, Any],
 context: list[dict[str, Any]]
 ) -> str:
 """Build prompt for structured extraction."""
 
 context_str = self._format_context(context[-10:])
 
 return f"""
Extract structured decision information:

Conversation context:
{context_str}

Decision message:
{message['content']}

Extract the following in JSON format:
{{
 "decision": "What was decided (one sentence)",
 "context": "Why was this being discussed",
 "rationale": "Why was this choice made",
 "alternatives": [
 {{
 "option": "Alternative that was considered",
 "pros": ["advantage 1", "advantage 2"],
 "cons": ["disadvantage 1"],
 "why_not_chosen": "Reason not selected"
 }}
 ],
 "trade_offs": {{
 "pros": ["advantage of chosen option"],
 "cons": ["disadvantage of chosen option"],
 "risks": ["potential risks"],
 "assumptions": ["assumptions made"]
 }},
 "stakeholders": ["@person1", "@person2"],
 "decision_maker": "@person or null",
 "tags": ["technology", "domain"]
}}

Be specific and extract actual information from the conversation.
"""
 
 async def _enrich_decision(
 self,
 decision: Decision,
 context: list[dict[str, Any]]
 ) -> Decision:
 """Enrich decision with additional context."""
 
 # Extract stakeholders from conversation
 decision.stakeholders = self._extract_stakeholders(context)
 
 # Extract related code/files mentioned
 decision.related_code = self._extract_file_mentions(context)
 
 # Generate keywords for search
 decision.keywords = await self._generate_keywords(decision)
 
 return decision
 
 def _extract_file_mentions(
 self,
 context: list[dict[str, Any]]
 ) -> list[str]:
 """Extract file paths mentioned in conversation."""
 import re
 
 file_pattern = r'([a-zA-Z0-9_/.-]+\.(py|js|ts|go|java|rb|rs|md))'
 
 files = set()
 for msg in context:
 content = msg.get("content", "")
 matches = re.findall(file_pattern, content)
 files.update(match[0] for match in matches)
 
 return list(files)`
```

#### 3. Decision Index

Searchable decision storage:

 python
 Copy

`class DecisionIndex:
 """Searchable index of decisions."""
 
 def __init__(
 self,
 storage_path: Path,
 enable_embeddings: bool = True
 ):
 self.storage_path = storage_path
 self.db = self._init_database()
 self.embeddings = EmbeddingIndex() if enable_embeddings else None
 
 def _init_database(self) -> sqlite3.Connection:
 """Initialize SQLite database for decisions."""
 
 conn = sqlite3.connect(self.storage_path / "decisions.db")
 
 conn.execute("""
 CREATE TABLE IF NOT EXISTS decisions (
 id TEXT PRIMARY KEY,
 timestamp DATETIME,
 session_id TEXT,
 decision TEXT,
 context TEXT,
 rationale TEXT,
 alternatives JSON,
 trade_offs JSON,
 stakeholders JSON,
 decision_maker TEXT,
 related_code JSON,
 related_features JSON,
 status TEXT,
 superseded_by TEXT,
 supersedes TEXT,
 tags JSON,
 keywords JSON
 )
 """)
 
 conn.execute("""
 CREATE VIRTUAL TABLE IF NOT EXISTS decisions_fts
 USING fts5(decision, context, rationale, content='decisions')
 """)
 
 return conn
 
 async def store(self, decision: Decision):
 """Store decision in index."""
 
 # Store in SQLite
 self.db.execute("""
 INSERT INTO decisions VALUES (
 :id, :timestamp, :session_id, :decision, :context,
 :rationale, :alternatives, :trade_offs, :stakeholders,
 :decision_maker, :related_code, :related_features,
 :status, :superseded_by, :supersedes, :tags, :keywords
 )
 """, self._decision_to_dict(decision))
 
 # Store in FTS
 self.db.execute("""
 INSERT INTO decisions_fts (rowid, decision, context, rationale)
 SELECT rowid, decision, context, rationale FROM decisions
 WHERE id = ?
 """, (decision.id,))
 
 self.db.commit()
 
 # Store embedding for semantic search
 if self.embeddings:
 text = f"{decision.decision} {decision.context} {decision.rationale}"
 await self.embeddings.add(decision.id, text)
 
 async def search(
 self,
 query: str,
 filters: DecisionFilters | None = None,
 limit: int = 10
 ) -> list[Decision]:
 """
 Search decisions.
 
 Search strategies:
 1. Semantic search (if embeddings enabled)
 2. Full-text search (SQLite FTS)
 3. Filtered search (by tags, dates, stakeholders)
 """
 
 results = []
 
 # Semantic search
 if self.embeddings:
 semantic_results = await self.embeddings.search(query, k=limit)
 results.extend(semantic_results)
 
 # Full-text search
 fts_results = self.db.execute("""
 SELECT id FROM decisions_fts
 WHERE decisions_fts MATCH ?
 LIMIT ?
 """, (query, limit)).fetchall()
 
 # Deduplicate and load full decisions
 decision_ids = list(set(
 r[0] for r in fts_results
 ) | set(r.id for r in results))
 
 decisions = [
 self._load_decision(did)
 for did in decision_ids[:limit]
 ]
 
 # Apply filters
 if filters:
 decisions = self._apply_filters(decisions, filters)
 
 return decisions
 
 async def get_chain(self, decision_id: str) -> DecisionChain:
 """Get decision evolution chain."""
 
 decision = self._load_decision(decision_id)
 
 # Find all related decisions
 revisions = []
 current = decision
 
 # Walk forward (superseded by)
 while current.superseded_by:
 next_decision = self._load_decision(current.superseded_by)
 revisions.append(next_decision)
 current = next_decision
 
 # Walk backward (supersedes)
 original = decision
 while original.supersedes:
 prev_decision = self._load_decision(original.supersedes)
 original = prev_decision
 
 return DecisionChain(
 original=original,
 revisions=revisions,
 current=current
 )`
```

#### 4. Temporal Tracker

Tracks decision evolution:

 python
 Copy

`class TemporalTracker:
 """Tracks how decisions evolve over time."""
 
 async def link_superseding_decision(
 self,
 old_decision_id: str,
 new_decision_id: str,
 reason: str
 ):
 """Link new decision as superseding old one."""
 
 # Update old decision
 await self.index.update(old_decision_id, {
 "status": DecisionStatus.SUPERSEDED,
 "superseded_by": new_decision_id
 })
 
 # Update new decision
 await self.index.update(new_decision_id, {
 "supersedes": old_decision_id
 })
 
 async def detect_revisited_decisions(
 self,
 current_discussion: str,
 existing_decisions: list[Decision]
 ) -> list[Decision]:
 """
 Detect if current discussion revisits past decisions.
 
 Uses semantic similarity to find related decisions.
 """
 
 if not self.embeddings:
 return []
 
 # Semantic search for similar decisions
 similar = await self.embeddings.search(
 current_discussion,
 k=5
 )
 
 # Filter by similarity threshold
 revisited = [
 d for d in similar
 if d.similarity_score > 0.7
 ]
 
 return revisited`
```

#### Data Flow

 text
 Copy

`Conversation Message
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Decision Detector â”‚
â”‚ - Keywords match? â”‚
â”‚ - LLM confirms? â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚ (Decision detected)
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metadata Extractor â”‚
â”‚ - What decided? â”‚
â”‚ - Why? â”‚
â”‚ - Alternatives? â”‚
â”‚ - Stakeholders? â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Code Linker â”‚
â”‚ - Extract files â”‚
â”‚ - Link features â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Decision Index â”‚
â”‚ - SQLite storage â”‚
â”‚ - FTS index â”‚
â”‚ - Embedding index â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Later Query:
"Why did we choose X?"
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Search Engine â”‚
â”‚ - Semantic search â”‚
â”‚ - FTS search â”‚
â”‚ - Filter results â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
 Decision(s)
 with full context`
```

---

### Examples

#### Example 1: Decision Detection and Extraction

 yaml
 Copy

`# Conversation
User: "Should we use REST or GraphQL for the new API?"
Agent: "Let's evaluate both options..."
[10 messages discussing trade-offs]
User: "Based on this, I think we should go with REST for now."
Agent: "Agreed. REST gives us simplicity and we can add GraphQL later if needed."

# Decision Detection
Message: "Agreed. REST gives us simplicity..."
Keywords matched: ["Agreed"]
LLM confirmation: 0.92 (high confidence)
â†’ Decision detected!

# Metadata Extraction
Decision extracted:
{
 "id": "dec-789",
 "timestamp": "2024-03-15T14:30:00Z",
 "decision": "Use REST API instead of GraphQL for new API",
 "context": "Choosing API architecture for new service",
 "rationale": "Team has REST expertise, simpler to implement, client needs are straightforward. Can add GraphQL later if requirements change.",
 "alternatives": [
 {
 "option": "GraphQL",
 "pros": ["Flexible queries", "Single endpoint", "Type safety"],
 "cons": ["Learning curve", "Overhead for simple queries", "Caching complexity"],
 "why_not_chosen": "Team lacks GraphQL experience, current requirements don't justify complexity"
 },
 {
 "option": "gRPC",
 "pros": ["Performance", "Type safety", "Streaming"],
 "cons": ["Browser support limited", "Tooling not familiar"],
 "why_not_chosen": "Primarily HTTP clients, no need for streaming yet"
 }
 ],
 "trade_offs": {
 "pros": ["Simpler implementation", "Team expertise", "Easier caching"],
 "cons": ["Over-fetching", "Multiple round-trips for complex queries"],
 "risks": ["May need to migrate to GraphQL later if requirements change"],
 "assumptions": ["Client needs remain simple", "Performance acceptable with caching"]
 },
 "stakeholders": ["@alice (architect)", "@bob (tech lead)", "@carol (PM)"],
 "decision_maker": "@alice",
 "related_code": ["src/api/routes/", "docs/api-design.md"],
 "tags": ["architecture", "api", "rest", "graphql"],
 "status": "active"
}

# Indexed and searchable`
```

#### Example 2: Decision Search

 yaml
 Copy

`# Query (6 months later)
New engineer: "Why aren't we using GraphQL?"

# Search
search_decisions("GraphQL")

# Results
[
 {
 "id": "dec-789",
 "decision": "Use REST API instead of GraphQL",
 "context": "Choosing API architecture for new service",
 "rationale": "Team has REST expertise, simpler to implement...",
 "timestamp": "2024-03-15",
 "stakeholders": ["@alice", "@bob", "@carol"],
 "status": "active"
 }
]

# Agent Response
"We decided on REST in March 2024. Here's the full context:

**Decision**: Use REST API instead of GraphQL

**Made by**: @alice (architect), with @bob and @carol

**Rationale**: 
- Team had REST expertise (faster to ship)
- Client needs were simple (no complex queries needed)
- Could revisit later if requirements change

**Alternatives Considered**:
- GraphQL: Flexible but steeper learning curve
- gRPC: High performance but limited browser support

**Current Status**: Active (6 months old)

**Related Code**: src/api/routes/, docs/api-design.md

**Should we revisit?** 
Current context suggests:
- We now have 15 endpoints (growing complexity)
- Mobile team requesting flexible queries
- GraphQL expertise improved (new hires)

Consider scheduling a review meeting to reassess."`
```

#### Example 3: Decision Chain

 yaml
 Copy

`# Original decision (March 2024)
Decision: "Use PostgreSQL for primary database"
Rationale: "ACID guarantees, team expertise"

# Revisited (September 2024)
Discussion: "Should we migrate to DynamoDB for better scale?"
[Discussion happens]
Decision: "Keep PostgreSQL, add Redis for caching"
Supersedes: dec-123 (partial revision)

# Query decision chain
get_decision_chain("dec-123")

# Returns
{
 "original": {
 "decision": "Use PostgreSQL",
 "timestamp": "2024-03-15",
 "status": "revisited"
 },
 "revisions": [
 {
 "decision": "Keep PostgreSQL, add Redis for caching",
 "timestamp": "2024-09-20",
 "rationale": "Scaling issues addressed with caching, migration cost not justified",
 "supersedes": "dec-123"
 }
 ],
 "current": { /* latest decision */ }
}`
```

---

### Configuration

 yaml
 Copy

`# Full configuration example
contexts:
 - module: context-decision-journal
 config:
 # Detection
 auto_detect: true
 detection_keywords:
 - decided
 - decision:
 - "let's go with"
 - we should
 - agreed
 - consensus
 detection_threshold: 0.7
 llm_confirmation: true # Use LLM to confirm
 
 # Extraction
 structured_extraction: true
 extract_rationale: true
 extract_alternatives: true
 extract_trade_offs: true
 extract_stakeholders: true
 
 # Linking
 link_to_code: true
 link_to_features: true
 auto_link_strategy: file_mention # Look for file mentions
 
 # Indexing
 search_index: sqlite
 index_embeddings: true
 embedding_model: text-embedding-3-small
 enable_fts: true # Full-text search
 
 # Storage
 persistence: true
 storage_path: .amplifier/decisions/
 retention_days: 730 # 2 years
 
 # Querying
 enable_temporal_queries: true
 enable_stakeholder_queries: true
 enable_technology_queries: true
 
 # Evolution tracking
 track_superseded_decisions: true
 detect_revisited_decisions: true`
```

---

### Security Considerations

#### Data Storage

- Persistence: Decisions stored on disk (configurable retention)
 
- Sensitive decisions: May contain confidential information
 
- Access control: Decisions inherit session permissions
 
#### Privacy

- Stakeholder attribution: Names extracted from conversations
 
- Code links: File paths exposed in decisions

 python
 Copy

`REQUIRED_CAPABILITIES = [
 "context:read",
 "context:write",
 "filesystem:read", # For storage
]`
```

---

### Testing Strategy

#### Unit Tests

 python
 Copy

`def test_decision_detector_detects_keywords():
 detector = DecisionDetector()
 message = {"content": "We've decided to use PostgreSQL"}
 result = detector.detect(message, [])
 assert result.is_decision

def test_metadata_extractor_extracts_alternatives():
 extractor = MetadataExtractor()
 # Test extraction from sample conversation
 ...

def test_decision_index_search():
 index = DecisionIndex(storage_path=Path("/tmp/test"))
 # Store decisions
 # Search and verify results
 ...`
```

#### Integration Tests

 python
 Copy

`async def test_full_decision_lifecycle():
 context = DecisionJournalContext(config)
 
 # Add conversation leading to decision
 await context.add_message({"content": "Should we use X or Y?"})
 await context.add_message({"content": "Let's go with X"})
 
 # Search for decision
 results = await context.search_decisions("use X")
 assert len(results) == 1
 assert "X" in results[0].decision`
```

---

### Dependencies

#### Required

- `amplifier-core`
 
- `sqlite3` (stdlib)
 
#### Optional

- `openai` - For embeddings
 
- `tiktoken` - Token counting
 
---

### Open Questions

- Decision confidence: Should we track confidence/certainty of decisions?
 
- Decision categories: Should we categorize decisions (technical, product, design)?
 
- Automatic linking: How aggressive should automatic code linking be?
 
- Notification: Should stakeholders be notified when their decisions are superseded?
 
- Export: Should decisions be exportable to Markdown/Confluence/etc.?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Context Stakeholder Lenses
 contexts

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-context-stakeholder-lenses`

### Overview

A context manager that filters and shapes conversation context based on stakeholder roles (PM, engineering, design, security, etc.). Each role sees a tailored view of the conversation with relevant information emphasized and irrelevant details filtered out, while maintaining the ability to reference cross-lens information when needed.

#### Value Proposition

 | 
 
 | Without | With

 | Everyone sees all technical details | PM sees business context, engineers see code, designers see UX
 
 | Wading through irrelevant information | Role-specific context filtering
 
 | One-size-fits-all responses | Responses tailored to stakeholder needs
 
 | Context window filled with noise | Efficient token usage per role

#### Use Cases

- Cross-functional reviews: PM, eng, and design review same feature with different context
 
- Team collaboration: Each team member gets relevant context for their role
 
- Onboarding: New PMs see business context, new engineers see architecture
 
- Documentation: Generate role-specific documentation from conversations
 
- Meeting summaries: Different summaries for technical and non-technical stakeholders
 
---

### Contract

#### ContextManager Interface

 python
 Copy

`class StakeholderLensesContext:
 """
 Context manager with role-based filtering.
 
 Each stakeholder lens:
 - Filters messages by relevance to role
 - Emphasizes role-specific information
 - Hides low-relevance details
 - Maintains references to other lenses
 """
 
 async def add_message(
 self, 
 message: dict[str, Any],
 metadata: MessageMetadata | None = None
 ) -> None:
 """
 Add message to context.
 
 Args:
 message: Standard Anthropic message format
 metadata: Optional metadata (tags, relevance scores per role)
 """
 
 async def get_messages(
 self,
 role: str | None = None,
 max_tokens: int | None = None
 ) -> list[dict[str, Any]]:
 """
 Get messages for specific role lens.
 
 Args:
 role: Role to filter for (None = base context)
 max_tokens: Optional token limit
 
 Returns:
 Filtered message list for role
 """
 
 async def set_active_role(self, role: str):
 """Set the active stakeholder role for filtering."""
 
 async def get_cross_lens_reference(
 self,
 message_id: str,
 source_role: str
 ) -> dict[str, Any]:
 """Retrieve message from another role's lens."""`
```

#### Configuration Schema

 toml
 Copy

`[[contexts]]
module = "context-stakeholder-lenses"
config = {
 # Role definitions
 lenses = [
 {
 role = "product",
 includes = ["business", "user_feedback", "roadmap", "metrics", "decisions"],
 excludes = ["implementation_details", "code_snippets", "technical_architecture"],
 weight = 1.0,
 emoji = "ðŸ“Š"
 },
 {
 role = "engineering",
 includes = ["architecture", "tech_debt", "performance", "code", "dependencies"],
 excludes = ["marketing_copy", "design_tokens", "brand_guidelines"],
 weight = 1.0,
 emoji = "âš™ï¸"
 },
 {
 role = "design",
 includes = ["ux", "accessibility", "design_system", "brand", "user_research"],
 excludes = ["database_schemas", "api_contracts", "infrastructure"],
 weight = 1.0,
 emoji = "ðŸŽ¨"
 },
 {
 role = "security",
 includes = ["security", "compliance", "authentication", "data_protection"],
 excludes = ["ui_details", "design_tokens"],
 weight = 1.2,
 emoji = "ðŸ”’"
 }
 ]
 
 # Filtering strategy
 filtering_strategy = "relevance_score" # "relevance_score" | "tag_based" | "hybrid"
 min_relevance_threshold = 0.3 # Messages below this are filtered
 
 # Cross-lens references
 allow_cross_lens_references = true
 cross_lens_reference_format = "summary" # "summary" | "full" | "link"
 
 # Compaction
 compaction_strategy = "per_lens" # Compact each lens independently
 preserve_shared_decisions = true # Important decisions visible to all lenses
 
 # Auto-tagging
 auto_tag_messages = true # Use LLM to tag messages with topics
 auto_score_relevance = true # Calculate relevance scores per role
}`
```

#### Data Schema

 python
 Copy

`@dataclass
class MessageMetadata:
 """Metadata for context messages."""
 tags: list[str] # ["business", "technical", "design"]
 relevance_scores: dict[str, float] # {role: score} - 0.0 to 1.0
 importance: str # "critical" | "high" | "medium" | "low"
 is_decision: bool # Shared decisions visible to all lenses
 
@dataclass
class LensDefinition:
 role: str # Role identifier
 includes: list[str] # Topics to include
 excludes: list[str] # Topics to exclude
 weight: float # Importance weight
 emoji: str # Visual identifier
 
@dataclass
class FilteredMessage:
 message: dict[str, Any] # Original message
 relevance_score: float # Relevance to current lens
 filtered_content: str | None # Optional filtered version
 summary: str | None # Optional summary for low-relevance`
```

#### Events Emitted

 | 
 
 | Event | When | Data

 | `context:lens:activated` | Lens switched | role, previous_role
 
 | `context:message:tagged` | Message auto-tagged | message_id, tags
 
 | `context:message:filtered` | Message filtered | message_id, role, reason
 
 | `context:cross_lens:accessed` | Cross-lens reference | target_role, message_id

---

### Architecture

#### Component Diagram

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ context-stakeholder-lenses â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Message â”‚â”€â”€â”€â–¶â”‚ Relevance â”‚â”€â”€â”€â–¶â”‚ Lens â”‚ â”‚
â”‚ â”‚ Storage â”‚ â”‚ Scorer â”‚ â”‚ Filter â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Auto â”‚ â”‚ Cross-Lens â”‚ â”‚ Compaction â”‚ â”‚
â”‚ â”‚ Tagger â”‚ â”‚ References â”‚ â”‚ Engine â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Storage Structure:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Base Storage â”‚
â”‚ - All messages â”‚
â”‚ - Metadata per message â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â–¼ â–¼ â–¼ â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Product â”‚ â”‚ Eng â”‚ â”‚Design â”‚ â”‚Securityâ”‚
â”‚Lens â”‚ â”‚Lens â”‚ â”‚Lens â”‚ â”‚Lens â”‚
â”‚View â”‚ â”‚View â”‚ â”‚View â”‚ â”‚View â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Filtered Filtered Filtered Filtered`
```

#### Internal Components

#### 1. Message Storage

Central storage with metadata:

 python
 Copy

`class MessageStorage:
 """Stores all messages with metadata."""
 
 def __init__(self):
 self.messages: list[StoredMessage] = []
 self.message_index: dict[str, StoredMessage] = {}
 
 async def store(self, message: dict[str, Any], metadata: MessageMetadata) -> str:
 """Store message with metadata."""
 message_id = str(uuid.uuid4())
 
 stored = StoredMessage(
 id=message_id,
 message=message,
 metadata=metadata,
 timestamp=datetime.now()
 )
 
 self.messages.append(stored)
 self.message_index[message_id] = stored
 
 return message_id
 
 async def get_all(self) -> list[StoredMessage]:
 """Get all messages (base view)."""
 return self.messages.copy()
 
 async def get_by_id(self, message_id: str) -> StoredMessage | None:
 """Get specific message by ID."""
 return self.message_index.get(message_id)`
```

#### 2. Relevance Scorer

Calculates relevance per role:

 python
 Copy

`class RelevanceScorer:
 """Calculates message relevance per role."""
 
 def __init__(self, lenses: list[LensDefinition]):
 self.lenses = {lens.role: lens for lens in lenses}
 
 async def score_message(
 self,
 message: dict[str, Any],
 tags: list[str]
 ) -> dict[str, float]:
 """
 Calculate relevance score per role.
 
 Scoring:
 1. Check includes: +1.0 per matching tag
 2. Check excludes: -1.0 per matching tag
 3. Normalize to 0.0-1.0 range
 """
 scores = {}
 
 for role, lens in self.lenses.items():
 score = 0.0
 
 # Positive signal from includes
 included_tags = set(tags) & set(lens.includes)
 score += len(included_tags)
 
 # Negative signal from excludes
 excluded_tags = set(tags) & set(lens.excludes)
 score -= len(excluded_tags)
 
 # Normalize (assume max 10 tags)
 normalized = max(0.0, min(1.0, (score + 5) / 10))
 
 scores[role] = normalized
 
 return scores
 
 async def score_message_with_llm(
 self,
 message: dict[str, Any],
 roles: list[str]
 ) -> dict[str, float]:
 """
 Use LLM to score relevance (more accurate but slower).
 
 Asks LLM: "On a scale of 0-10, how relevant is this message
 to a [role] stakeholder?"
 """
 prompt = f"""
Score this message's relevance to each role (0-10):

Message: {message['content'][:500]}

Roles: {', '.join(roles)}

Output as JSON: {{"role": score, ...}}
"""
 # Call LLM and parse scores
 ...`
```

#### 3. Lens Filter

Filters messages for specific role:

 python
 Copy

`class LensFilter:
 """Filters messages for specific stakeholder lens."""
 
 def __init__(
 self, 
 lens: LensDefinition,
 min_relevance: float = 0.3
 ):
 self.lens = lens
 self.min_relevance = min_relevance
 
 async def filter_messages(
 self,
 messages: list[StoredMessage]
 ) -> list[FilteredMessage]:
 """
 Filter messages for this lens.
 
 Rules:
 1. Always include messages with is_decision=True
 2. Include messages with relevance >= threshold
 3. Summarize borderline messages (0.2-0.3 relevance)
 4. Exclude low-relevance messages (< 0.2)
 """
 filtered = []
 
 for stored in messages:
 relevance = stored.metadata.relevance_scores.get(self.lens.role, 0.0)
 
 # Always include decisions
 if stored.metadata.is_decision:
 filtered.append(FilteredMessage(
 message=stored.message,
 relevance_score=1.0,
 filtered_content=None,
 summary=None
 ))
 continue
 
 # High relevance - include fully
 if relevance >= self.min_relevance:
 filtered.append(FilteredMessage(
 message=stored.message,
 relevance_score=relevance,
 filtered_content=None,
 summary=None
 ))
 
 # Borderline - include as summary
 elif relevance >= (self.min_relevance - 0.1):
 summary = await self._summarize_for_lens(stored.message)
 filtered.append(FilteredMessage(
 message=stored.message,
 relevance_score=relevance,
 filtered_content=None,
 summary=summary
 ))
 
 # Low relevance - exclude
 # (but keep reference for cross-lens lookups)
 
 return filtered
 
 async def _summarize_for_lens(self, message: dict[str, Any]) -> str:
 """Create brief summary for borderline messages."""
 content = message.get("content", "")
 
 # Simple truncation or LLM-based summarization
 if len(content) < 100:
 return content
 
 # LLM summarization
 prompt = f"""
Summarize this message in one sentence for a {self.lens.role} stakeholder:

{content}

One-sentence summary:
"""
 # Returns brief summary
 ...`
```

#### 4. Auto-Tagger

Automatically tags messages:

 python
 Copy

`class AutoTagger:
 """Automatically tags messages with topic categories."""
 
 KEYWORD_MAP = {
 "business": ["revenue", "market", "user", "customer", "roadmap"],
 "technical": ["code", "architecture", "database", "api", "performance"],
 "design": ["ux", "ui", "component", "design system", "accessibility"],
 "security": ["auth", "security", "encryption", "vulnerability", "compliance"],
 # ... more mappings
 }
 
 async def tag_message(self, message: dict[str, Any]) -> list[str]:
 """
 Auto-tag message with topic categories.
 
 Strategy:
 1. Keyword matching (fast, simple)
 2. LLM tagging (accurate, slower) - optional
 """
 content = message.get("content", "").lower()
 tags = set()
 
 # Keyword matching
 for category, keywords in self.KEYWORD_MAP.items():
 if any(keyword in content for keyword in keywords):
 tags.add(category)
 
 # Optional: LLM enhancement
 if self.use_llm_tagging and len(tags) < 2:
 llm_tags = await self._llm_tag(message)
 tags.update(llm_tags)
 
 return list(tags)
 
 async def _llm_tag(self, message: dict[str, Any]) -> list[str]:
 """Use LLM to tag message."""
 prompt = f"""
Categorize this message with relevant tags:

{message['content'][:500]}

Available categories: business, technical, design, security, product, 
infrastructure, compliance, user_research, marketing

Tags (comma-separated):
"""
 # Returns tags
 ...`
```

#### 5. Cross-Lens References

Enable viewing other lenses:

 python
 Copy

`class CrossLensReference:
 """Handle cross-lens references."""
 
 def __init__(self, storage: MessageStorage):
 self.storage = storage
 
 async def get_reference(
 self,
 message_id: str,
 target_lens: str,
 format: str = "summary"
 ) -> dict[str, Any]:
 """
 Get message from another lens's perspective.
 
 Formats:
 - "summary": Brief summary
 - "full": Complete message
 - "link": Reference pointer
 """
 stored = await self.storage.get_by_id(message_id)
 if not stored:
 return None
 
 if format == "summary":
 return {
 "type": "cross_lens_reference",
 "source_lens": target_lens,
 "message_id": message_id,
 "summary": f"[From {target_lens}] {stored.message['content'][:100]}..."
 }
 elif format == "full":
 return {
 "type": "cross_lens_reference",
 "source_lens": target_lens,
 "message": stored.message
 }
 else: # link
 return {
 "type": "cross_lens_reference",
 "source_lens": target_lens,
 "message_id": message_id,
 "reference": f"See {target_lens} lens for details"
 }`
```

#### Data Flow

 text
 Copy

`Message Added
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Auto-Tag Message â”‚
â”‚ tags: ["technical", â”‚
â”‚ "architecture"]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Score Relevance â”‚
â”‚ product: 0.2 â”‚
â”‚ engineering: 0.9 â”‚
â”‚ design: 0.3 â”‚
â”‚ security: 0.4 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Store with Metadata â”‚
â”‚ (central storage) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â–¼ â–¼ â–¼ â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Product â”‚ â”‚Engineer â”‚ â”‚Design â”‚ â”‚Securityâ”‚
â”‚Lens â”‚ â”‚Lens â”‚ â”‚Lens â”‚ â”‚Lens â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚Score:0.2â”‚ â”‚Score:0.9â”‚ â”‚Score: â”‚ â”‚Score: â”‚
â”‚â†’Exclude â”‚ â”‚â†’Include â”‚ â”‚0.3 â”‚ â”‚0.4 â”‚
â”‚ â”‚ â”‚ (full) â”‚ â”‚â†’Summaryâ”‚ â”‚â†’Includeâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Examples

#### Example 1: Feature Discussion

 yaml
 Copy

`# Message 1: Feature request
User (PM): "We need PDF export. Users requested it 247 times."

Auto-tags: ["business", "user_feedback", "product"]
Relevance scores:
 product: 0.95 (user feedback, feature request)
 engineering: 0.60 (feature to build)
 design: 0.40 (UI needed)
 security: 0.20 (low relevance)

Product Lens: âœ“ Include (high relevance)
Engineering Lens: âœ“ Include (moderate relevance)
Design Lens: âœ“ Include as summary
Security Lens: âœ— Exclude (below threshold)

# Message 2: Technical implementation
Developer: "We'll use Puppeteer for rendering. Need 200MB Docker image..."

Auto-tags: ["technical", "implementation", "infrastructure"]
Relevance scores:
 product: 0.20 (implementation detail)
 engineering: 1.00 (technical detail)
 design: 0.30 (affects design delivery)
 security: 0.50 (Docker image security)

Product Lens: âœ— Exclude (technical detail)
Engineering Lens: âœ“ Include (highly relevant)
Design Lens: âœ“ Include as summary ("Implementation uses Puppeteer")
Security Lens: âœ“ Include (Docker security relevant)

# Message 3: Design concern
Designer: "Export modal needs format picker (PDF, PNG, SVG)"

Auto-tags: ["design", "ux", "component"]
Relevance scores:
 product: 0.60 (feature scope)
 engineering: 0.50 (interface to implement)
 design: 1.00 (design specification)
 security: 0.10 (low relevance)

Product Lens: âœ“ Include (affects feature scope)
Engineering Lens: âœ“ Include (needs implementation)
Design Lens: âœ“ Include (full detail)
Security Lens: âœ— Exclude

# Message 4: DECISION
Team: "DECISION: Build PDF export in Q2 with security review"

Metadata: is_decision=True
Relevance scores: N/A (always included)

All Lenses: âœ“ Include (decisions visible to all)

# Context retrieval examples

## Product Manager perspective
get_messages(role="product") returns:
1. "We need PDF export. Users requested it 247 times."
2. (Summary) "Export modal needs format picker"
3. "DECISION: Build PDF export in Q2 with security review"

## Engineering perspective
get_messages(role="engineering") returns:
1. "We need PDF export. Users requested it 247 times."
2. "We'll use Puppeteer for rendering. Need 200MB Docker image..."
3. "Export modal needs format picker (PDF, PNG, SVG)"
4. "DECISION: Build PDF export in Q2 with security review"

## Design perspective
get_messages(role="design") returns:
1. (Summary) "PDF export requested by users"
2. (Summary) "Implementation uses Puppeteer"
3. "Export modal needs format picker (PDF, PNG, SVG)"
4. "DECISION: Build PDF export in Q2 with security review"`
```

#### Example 2: Cross-Lens Reference

 python
 Copy

`# Designer asks: "What did engineering say about the timeline?"
# System detects query about engineering lens

# Retrieve from engineering lens
engineering_message = await context.get_cross_lens_reference(
 message_id="msg-123",
 source_role="engineering"
)

# Returns summary format
{
 "type": "cross_lens_reference",
 "source_lens": "engineering",
 "summary": "[From engineering] Implementation needs 12 weeks: 6 for infrastructure, 6 for feature development"
}`
```

---

### Configuration

 yaml
 Copy

`# Full configuration example
contexts:
 - module: context-stakeholder-lenses
 config:
 # Lens definitions
 lenses:
 - role: product
 includes: [business, user_feedback, roadmap, metrics, decisions]
 excludes: [implementation_details, code_snippets, technical_architecture]
 weight: 1.0
 emoji: "ðŸ“Š"
 
 - role: engineering
 includes: [architecture, tech_debt, performance, code, dependencies]
 excludes: [marketing_copy, design_tokens, brand_guidelines]
 weight: 1.0
 emoji: "âš™ï¸"
 
 - role: design
 includes: [ux, accessibility, design_system, brand, user_research]
 excludes: [database_schemas, api_contracts, infrastructure]
 weight: 1.0
 emoji: "ðŸŽ¨"
 
 - role: security
 includes: [security, compliance, authentication, data_protection]
 excludes: [ui_details, design_tokens]
 weight: 1.2
 emoji: "ðŸ”’"
 
 # Filtering
 filtering_strategy: hybrid # relevance_score | tag_based | hybrid
 min_relevance_threshold: 0.3
 summary_threshold: 0.2 # Summarize messages between 0.2-0.3
 
 # Auto-processing
 auto_tag_messages: true
 auto_score_relevance: true
 use_llm_scoring: false # Keyword-based by default (faster)
 
 # Cross-lens
 allow_cross_lens_references: true
 cross_lens_reference_format: summary
 
 # Compaction
 compaction_strategy: per_lens
 preserve_shared_decisions: true
 max_tokens_per_lens: 150000
 
 # Base context (no lens)
 include_base_context: true # Allow viewing unfiltered context`
```

---

### Security Considerations

#### Data Isolation

- Lens isolation: Each lens sees filtered view only
 
- Cross-lens access: Controlled via configuration
 
- Shared decisions: Flagged messages visible to all roles
 
#### Privacy

- Role-based filtering: Prevents accidental exposure of sensitive info
 
- Metadata privacy: Relevance scores not exposed to users

 python
 Copy

`REQUIRED_CAPABILITIES = [
 "context:read",
 "context:write",
]`
```

---

### Testing Strategy

#### Unit Tests

 python
 Copy

`def test_relevance_scorer_calculates_scores():
 scorer = RelevanceScorer(lenses=[...])
 scores = scorer.score_message(
 message={"content": "Deploy to production"},
 tags=["technical", "infrastructure"]
 )
 assert scores["engineering"] > 0.5
 assert scores["product"] < 0.5

def test_lens_filter_excludes_low_relevance():
 filter = LensFilter(lens=product_lens, min_relevance=0.3)
 messages = [
 StoredMessage(metadata=MessageMetadata(relevance_scores={"product": 0.9})),
 StoredMessage(metadata=MessageMetadata(relevance_scores={"product": 0.1}))
 ]
 filtered = filter.filter_messages(messages)
 assert len(filtered) == 1 # Only high-relevance included`
```

#### Integration Tests

 python
 Copy

`async def test_full_lens_filtering():
 context = StakeholderLensesContext(config)
 
 # Add messages
 await context.add_message({"role": "user", "content": "User wants feature X"})
 await context.add_message({"role": "assistant", "content": "Technical: Use database Y"})
 
 # Product lens should see first, not second
 product_messages = await context.get_messages(role="product")
 assert len(product_messages) == 1
 assert "feature X" in product_messages[0]["content"]
 
 # Engineering lens should see both
 eng_messages = await context.get_messages(role="engineering")
 assert len(eng_messages) == 2`
```

---

### Dependencies

#### Required

- `amplifier-core`
 
#### Optional

- `tiktoken` - Token counting per lens
 
---

### Open Questions

- Dynamic lens creation: Should users be able to define custom lenses?
 
- LLM scoring frequency: Always use LLM or only for ambiguous messages?
 
- Lens switching UX: How should users switch between lenses in CLI/UI?
 
- Historical lens views: Should past conversations be re-filtered when lenses change?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Orchestrator Loop Iterative Refinement
 orchestrators

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-loop-iterative-refinement`

### Overview

An orchestrator that manages iterative refinement workflows with structured feedback loops, version tracking, and convergence detection. Enables design sprint-style iteration where each cycle produces a versioned artifact, captures feedback, and tracks what changed and why.

#### Value Proposition

 | 
 
 | Without | With

 | Manual iteration tracking, lost context between versions | Automatic version tracking with delta visualization
 
 | "What changed since last time?" requires memory | Side-by-side diffs with rationale for each change
 
 | Feedback scattered across messages | Structured feedback correlation to specific changes
 
 | No convergence signal | Automatic detection when iterations stabilize

#### Use Cases

- Design system component iteration: Designer reviews and refines component specs through multiple rounds
 
- API design refinement: Architecture evolves based on stakeholder feedback
 
- Feature specification: PM iterates on PRD with eng/design input
 
- Code refactoring: Large refactors broken into reviewable iterations
 
- Documentation writing: Technical docs refined with SME feedback
 
---

### Contract

#### Orchestrator Interface

 python
 Copy

`class IterativeRefinementOrchestrator:
 """
 Orchestrator that manages iterative refinement with feedback tracking.
 
 Each iteration:
 1. Generate or refine artifact
 2. Checkpoint version
 3. Present for review (optional pause)
 4. Capture feedback
 5. Assess convergence
 6. Continue or conclude
 """
 
 async def execute(
 self,
 prompt: str,
 context: ContextManager,
 providers: dict[str, Any],
 tools: dict[str, Any],
 hooks: HookRegistry,
 coordinator: ModuleCoordinator | None = None,
 ) -> str:
 """
 Execute iterative refinement loop.
 
 Args:
 prompt: Initial user request
 context: Conversation context
 providers: Available LLM providers
 tools: Available tools
 hooks: Hook registry for events
 coordinator: Module coordinator for capabilities
 
 Returns:
 Final refined artifact with evolution history
 """`
```

#### Configuration Schema

 toml
 Copy

`[[orchestrators]]
module = "loop-iterative-refinement"
config = {
 # Iteration control
 max_iterations = 10 # Maximum refinement cycles
 min_iterations = 1 # Minimum cycles before allowing convergence
 
 # Convergence detection
 convergence_threshold = 0.9 # 0.0-1.0: fraction of feedback addressed
 auto_converge = true # Stop when threshold reached
 
 # Review flow
 pause_for_review = true # Pause between iterations for human review
 review_prompt = "Review iteration {n}. Provide feedback or approve:"
 
 # Version tracking
 track_deltas = true # Calculate and show diffs between versions
 delta_format = "semantic" # "semantic" | "line-by-line" | "summary"
 track_rationale = true # Capture "why" for each change
 
 # Feedback correlation
 correlate_changes_to_feedback = true # Map changes back to feedback items
 feedback_scoring = true # Score how well each feedback was addressed
 
 # Output control
 show_evolution_history = true # Include complete history in final output
 checkpoint_storage = "memory" # "memory" | "file" | "database"
}`
```

#### Events Emitted

 | 
 
 | Event | When | Data

 | `orchestrator:iteration:start` | Iteration begins | iteration_number, total_iterations
 
 | `orchestrator:iteration:complete` | Iteration done | iteration_number, artifact_id, changes_count
 
 | `orchestrator:review:pause` | Paused for review | iteration_number, artifact_preview
 
 | `orchestrator:review:resume` | Review complete | iteration_number, feedback_items
 
 | `orchestrator:convergence:detected` | Convergence reached | convergence_score, iterations_completed
 
 | `orchestrator:refinement:complete` | All iterations done | final_artifact_id, total_iterations, evolution_summary

---

### Architecture

#### Component Diagram

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ orchestrator-loop-iterative-refinement â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Iteration â”‚â”€â”€â”€â–¶â”‚ Version â”‚â”€â”€â”€â–¶â”‚ Convergence â”‚ â”‚
â”‚ â”‚ Controller â”‚ â”‚ Tracker â”‚ â”‚ Detector â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Feedback â”‚ â”‚ Delta â”‚ â”‚ Evolution â”‚ â”‚
â”‚ â”‚ Correlator â”‚ â”‚ Calculator â”‚ â”‚ Historian â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Internal Components

#### 1. Iteration Controller

Manages the refinement loop lifecycle:

 python
 Copy

`@dataclass
class Iteration:
 number: int
 artifact: str # Current version of work
 artifact_id: str # UUID for this version
 feedback: list[FeedbackItem] # Feedback to address
 changes: list[Change] # Changes made this iteration
 timestamp: datetime
 convergence_score: float # 0.0-1.0

@dataclass
class FeedbackItem:
 id: str
 source: str # "user" | "agent" | "automated"
 content: str
 priority: str # "must" | "should" | "could"
 addressed: bool
 iteration_addressed: int | None

@dataclass
class Change:
 description: str
 rationale: str
 addresses_feedback: list[str] # Feedback IDs
 diff: str | None

class IterationController:
 """Manages iteration lifecycle and flow control."""
 
 def __init__(self, config: IterativeRefinementConfig):
 self.config = config
 self.iterations: list[Iteration] = []
 self.current_iteration = 0
 
 async def should_continue(self) -> bool:
 """Determine if another iteration is needed."""
 if self.current_iteration >= self.config.max_iterations:
 return False
 
 if self.current_iteration < self.config.min_iterations:
 return True
 
 if self.config.auto_converge:
 score = await self.convergence_detector.check()
 if score >= self.config.convergence_threshold:
 return False
 
 return True
 
 async def execute_iteration(self, prompt: str, context: ContextManager) -> Iteration:
 """Execute one refinement iteration."""
 self.current_iteration += 1
 
 # Get pending feedback
 pending_feedback = self._get_pending_feedback()
 
 # Build iteration prompt
 iteration_prompt = self._build_iteration_prompt(
 iteration_num=self.current_iteration,
 base_prompt=prompt,
 feedback=pending_feedback,
 previous_artifact=self._get_latest_artifact()
 )
 
 # Execute with standard loop (delegate to loop-basic)
 result = await self._execute_standard_loop(iteration_prompt, context)
 
 # Create iteration record
 iteration = Iteration(
 number=self.current_iteration,
 artifact=result,
 artifact_id=str(uuid.uuid4()),
 feedback=pending_feedback,
 changes=[], # Extracted in post-processing
 timestamp=datetime.now(),
 convergence_score=0.0
 )
 
 # Post-process: extract changes, calculate deltas
 iteration = await self._post_process_iteration(iteration)
 
 self.iterations.append(iteration)
 return iteration
 
 def _build_iteration_prompt(
 self, 
 iteration_num: int, 
 base_prompt: str,
 feedback: list[FeedbackItem],
 previous_artifact: str | None
 ) -> str:
 """Build prompt for this iteration."""
 if iteration_num == 1:
 return base_prompt
 
 prompt_parts = [
 f"# Iteration {iteration_num}",
 "",
 "## Previous Version",
 previous_artifact,
 "",
 "## Feedback to Address",
 ]
 
 for item in feedback:
 priority_marker = {
 "must": "ðŸ”´ MUST FIX",
 "should": "ðŸŸ¡ SHOULD FIX",
 "could": "ðŸŸ¢ NICE TO HAVE"
 }[item.priority]
 
 prompt_parts.append(f"{priority_marker}: {item.content}")
 
 prompt_parts.extend([
 "",
 "## Task",
 "Refine the previous version based on the feedback above.",
 "For each change, explain WHY you made it and which feedback it addresses.",
 "",
 base_prompt
 ])
 
 return "\n".join(prompt_parts)`
```

#### 2. Version Tracker

Tracks artifact versions and changes:

 python
 Copy

`class VersionTracker:
 """Tracks versions and computes deltas between iterations."""
 
 def __init__(self):
 self.versions: dict[str, str] = {} # artifact_id -> content
 
 def store_version(self, artifact_id: str, content: str):
 """Store a version."""
 self.versions[artifact_id] = content
 
 async def compute_delta(
 self, 
 from_artifact_id: str, 
 to_artifact_id: str,
 format: str = "semantic"
 ) -> Delta:
 """Compute changes between versions."""
 from_content = self.versions[from_artifact_id]
 to_content = self.versions[to_artifact_id]
 
 if format == "semantic":
 return await self._semantic_diff(from_content, to_content)
 elif format == "line-by-line":
 return self._line_diff(from_content, to_content)
 else: # summary
 return self._summary_diff(from_content, to_content)
 
 async def _semantic_diff(self, old: str, new: str) -> SemanticDelta:
 """Use LLM to identify semantic changes."""
 # Ask LLM to identify what changed conceptually
 prompt = f"""
 Compare these two versions and identify semantic changes:
 
 VERSION A:
 {old}
 
 VERSION B:
 {new}
 
 List changes as: [Added|Modified|Removed] - <description>
 """
 # Returns structured list of semantic changes
 ...
 
 def _line_diff(self, old: str, new: str) -> LineDelta:
 """Traditional unified diff."""
 import difflib
 diff = difflib.unified_diff(
 old.splitlines(keepends=True),
 new.splitlines(keepends=True),
 lineterm=''
 )
 return LineDelta(lines=list(diff))`
```

#### 3. Feedback Correlator

Links changes back to feedback items:

 python
 Copy

`class FeedbackCorrelator:
 """Correlates changes to feedback items and scores addressing."""
 
 async def correlate_changes(
 self,
 changes: list[Change],
 feedback: list[FeedbackItem]
 ) -> CorrelationResult:
 """
 Determine which changes address which feedback.
 Uses LLM to understand if a change addresses feedback.
 """
 correlations = []
 
 for feedback_item in feedback:
 addressing_changes = []
 
 for change in changes:
 # Check if change explicitly mentions feedback
 if feedback_item.id in change.addresses_feedback:
 addressing_changes.append(change)
 continue
 
 # Use LLM to infer if change addresses feedback
 is_addressing = await self._infer_correlation(
 feedback_item, 
 change
 )
 if is_addressing:
 addressing_changes.append(change)
 
 correlation = FeedbackCorrelation(
 feedback_item=feedback_item,
 changes=addressing_changes,
 fully_addressed=len(addressing_changes) > 0,
 quality_score=self._score_addressing_quality(
 feedback_item, 
 addressing_changes
 )
 )
 correlations.append(correlation)
 
 return CorrelationResult(correlations=correlations)
 
 async def _infer_correlation(
 self,
 feedback: FeedbackItem,
 change: Change
 ) -> bool:
 """Use LLM to determine if change addresses feedback."""
 prompt = f"""
 Feedback: {feedback.content}
 Change: {change.description} - {change.rationale}
 
 Does this change address the feedback? (yes/no)
 """
 # Returns boolean
 ...
 
 def _score_addressing_quality(
 self,
 feedback: FeedbackItem,
 changes: list[Change]
 ) -> float:
 """Score 0.0-1.0: how well was feedback addressed."""
 if not changes:
 return 0.0
 
 # Simple heuristic: more changes = better (could be LLM-based)
 return min(1.0, len(changes) * 0.5)`
```

#### 4. Convergence Detector

Determines when iteration can stop:

 python
 Copy

`class ConvergenceDetector:
 """Detects when iterations have converged."""
 
 def __init__(self, threshold: float = 0.9):
 self.threshold = threshold
 
 async def check_convergence(
 self,
 iterations: list[Iteration],
 all_feedback: list[FeedbackItem]
 ) -> ConvergenceScore:
 """
 Check if iteration has converged.
 
 Convergence signals:
 1. High percentage of feedback addressed
 2. Small deltas between recent iterations
 3. No critical feedback outstanding
 """
 if len(iterations) < 2:
 return ConvergenceScore(score=0.0, reason="Too few iterations")
 
 # Signal 1: Feedback addressed
 feedback_score = self._feedback_addressed_score(all_feedback)
 
 # Signal 2: Delta shrinking
 delta_score = await self._delta_shrinking_score(iterations[-3:])
 
 # Signal 3: No blockers
 blocker_score = self._no_blockers_score(all_feedback)
 
 # Weighted average
 overall_score = (
 feedback_score * 0.5 +
 delta_score * 0.3 +
 blocker_score * 0.2
 )
 
 converged = overall_score >= self.threshold
 
 return ConvergenceScore(
 score=overall_score,
 converged=converged,
 reason=self._explain_score(feedback_score, delta_score, blocker_score)
 )
 
 def _feedback_addressed_score(self, feedback: list[FeedbackItem]) -> float:
 """What fraction of feedback has been addressed."""
 if not feedback:
 return 1.0
 
 addressed = sum(1 for f in feedback if f.addressed)
 return addressed / len(feedback)
 
 async def _delta_shrinking_score(self, recent_iterations: list[Iteration]) -> float:
 """Are changes getting smaller (convergence signal)?"""
 if len(recent_iterations) < 2:
 return 0.0
 
 # Compare delta sizes (smaller = converging)
 deltas = [len(it.changes) for it in recent_iterations]
 
 # If deltas are decreasing, score high
 if all(deltas[i] >= deltas[i+1] for i in range(len(deltas)-1)):
 return 1.0
 
 # Otherwise score by how small the latest delta is
 latest_delta = deltas[-1]
 return max(0.0, 1.0 - (latest_delta / 10)) # Assume 10+ changes = big delta`
```

#### Data Flow

 text
 Copy

`User Prompt
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Iteration 1: Create â”‚
â”‚ - Generate initial â”‚
â”‚ - Store version v1 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Pause for â”‚â”€â”€â”€ Optional: Wait for human review
 â”‚ Review â”‚
 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼ (Feedback captured)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Iteration 2: Refine â”‚
â”‚ - Apply feedback â”‚
â”‚ - Compute delta â”‚
â”‚ - Store version v2 â”‚
â”‚ - Correlate changes â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Check â”‚
 â”‚ Convergence â”‚
 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
 â”‚ â”‚
 No â”‚ â”‚ Yes
 â”‚ â”‚
 â–¼ â–¼
 [Continue] [Done]
 â”‚
 â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Generate â”‚
 â”‚ Evolution â”‚
 â”‚ Report â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Configuration

 yaml
 Copy

`# Full configuration example
orchestrators:
 - module: loop-iterative-refinement
 config:
 # Iteration control
 max_iterations: 10
 min_iterations: 1
 
 # Convergence
 convergence_threshold: 0.9
 auto_converge: true
 convergence_signals:
 - feedback_addressed
 - delta_shrinking
 - no_critical_issues
 
 # Review workflow
 pause_for_review: true
 review_prompt: |
 ## Iteration {iteration_number} Review
 
 {artifact_preview}
 
 Please provide feedback:
 - What's working well?
 - What needs improvement?
 - Any blockers or must-fix issues?
 
 Type 'approve' when satisfied.
 
 # Version tracking
 track_deltas: true
 delta_format: semantic # semantic | line-by-line | summary
 track_rationale: true
 store_intermediate_versions: true
 
 # Feedback management
 correlate_changes_to_feedback: true
 feedback_scoring: true
 feedback_priorities:
 must: 1.0 # Weight for "must fix" feedback
 should: 0.7 # Weight for "should fix"
 could: 0.3 # Weight for "nice to have"
 
 # Output formatting
 show_evolution_history: true
 evolution_format: detailed # detailed | summary | minimal
 include_all_versions: false # Include full text of all versions
 
 # Storage
 checkpoint_storage: memory # memory | file | database
 checkpoint_path: .amplifier/iterations/`
```

---

### Examples

#### Example 1: Design Component Iteration

 yaml
 Copy

`# Initial prompt
"Design a data table component for our design system"

# Iteration 1: Initial design
Agent generates:
"""
# DataTable Component

## Props
- data: array of objects
- columns: column definitions
- onRowClick: callback

## Variants
- default: standard table
- compact: dense spacing
"""

# Pause for review
User feedback:
"Needs sorting, filtering, and column resize"

# Iteration 2: Add features
Agent refines:
"""
# DataTable Component (v2)

## Props
- data: array of objects
- columns: column definitions 
- onRowClick: callback
+ sortable: boolean
+ filterable: boolean
+ resizable: boolean

## Features
+ Sorting: Click column header to sort
+ Filtering: Filter panel above table
+ Resize: Drag column borders
"""

Changes:
- Added: sortable, filterable, resizable props [Addresses: "needs sorting, filtering, column resize"]
- Added: Sorting feature with header click [Addresses: "needs sorting"]
- Added: Filtering feature with filter panel [Addresses: "needs filtering"]
- Added: Resize feature with drag borders [Addresses: "needs column resize"]

# Pause for review
User feedback:
"Sorting looks good, but filter UX unclear"

# Iteration 3: Refine filtering
Agent refines:
"""
[Previous content]

## Filtering Details
- Filter button in header opens panel
- Panel shows filter inputs per column
- Presets: "Clear All", "Save Filter"
- Visual: Shows active filter count badge
"""

Changes:
- Modified: Filter feature with detailed UX [Addresses: "filter UX unclear"]
- Added: Filter presets for common actions
- Added: Active filter indicator

# Convergence check
Feedback addressed: 100% (3/3 items)
Delta size: Small (1 feature refined)
Critical issues: None
Convergence score: 0.95

â†’ Iteration complete!

# Final output
"""
# DataTable Component - Evolution Report

## Final Specification
[Full spec]

## Iteration History
Iteration 1: Initial design (baseline)
Iteration 2: Added sorting, filtering, resize (+3 features)
Iteration 3: Refined filter UX (+1 detail)

## Feedback Tracking
âœ“ Needs sorting â†’ Addressed in iteration 2
âœ“ Needs filtering â†’ Addressed in iteration 2, refined in 3
âœ“ Needs column resize â†’ Addressed in iteration 2
âœ“ Filter UX unclear â†’ Addressed in iteration 3

## Design Decisions
- Sorting: Chose click-to-sort (standard pattern)
- Filtering: Chose panel over inline (more space for complex filters)
- Resize: Chose drag borders (familiar to users)
"""`
```

#### Example 2: API Design Refinement

 python
 Copy

`# Initial prompt
"Design a REST API for user permissions"

# Iteration 1
{
 "artifact": """
 POST /api/v1/users/{id}/permissions
 GET /api/v1/users/{id}/permissions
 DELETE /api/v1/users/{id}/permissions/{permissionId}
 """,
 "iteration": 1
}

# Feedback
[
 {"content": "Need bulk operations", "priority": "should"},
 {"content": "Missing permission inheritance", "priority": "must"}
]

# Iteration 2
{
 "artifact": """
 POST /api/v1/users/{id}/permissions (bulk support via array)
 GET /api/v1/users/{id}/permissions?include=inherited
 DELETE /api/v1/users/{id}/permissions (bulk support)
 POST /api/v1/permissions/inherit
 """,
 "iteration": 2,
 "changes": [
 {
 "description": "Added bulk support to POST/DELETE",
 "addresses_feedback": ["Need bulk operations"]
 },
 {
 "description": "Added ?include=inherited query param",
 "addresses_feedback": ["Missing permission inheritance"]
 },
 {
 "description": "Added /inherit endpoint for inheritance rules",
 "addresses_feedback": ["Missing permission inheritance"]
 }
 ]
}

# Convergence: Score 1.0 (all feedback addressed)`
```

---

### Security Considerations

#### Data Storage

- Iteration checkpoints: May contain sensitive work-in-progress
 
- Feedback: User feedback may contain sensitive context
 
- Versioning: All versions stored until session end
 
#### Access Control

 python
 Copy

`REQUIRED_CAPABILITIES = [
 "orchestrator:execute", # Execute orchestration loops
 "context:read", # Read conversation context
 "context:write", # Write iteration checkpoints
]`
```

#### Risk Mitigations

 | 
 
 | Risk | Mitigation

 | Large version history consuming memory | Configurable storage backend (memory/file/database)
 
 | Sensitive iterations persisted | Clear checkpoints on session end
 
 | Feedback leaking to other users | Feedback scoped to session

---

### Testing Strategy

#### Unit Tests

 python
 Copy

`def test_iteration_controller_respects_max_iterations():
 controller = IterationController(max_iterations=3)
 assert controller.should_continue() == True # iteration 1
 # ... execute 3 iterations
 assert controller.should_continue() == False # max reached

def test_convergence_detector_identifies_high_score():
 detector = ConvergenceDetector(threshold=0.9)
 feedback = [
 FeedbackItem(id="1", addressed=True),
 FeedbackItem(id="2", addressed=True),
 FeedbackItem(id="3", addressed=False)
 ]
 score = detector._feedback_addressed_score(feedback)
 assert score == 0.67 # 2/3

def test_feedback_correlator_links_changes():
 correlator = FeedbackCorrelator()
 feedback = FeedbackItem(id="1", content="Add sorting")
 change = Change(
 description="Added sort",
 addresses_feedback=["1"]
 )
 # Should link change to feedback
 ...`
```

#### Integration Tests

 python
 Copy

`async def test_full_iteration_flow():
 """Test complete iteration cycle."""
 orchestrator = IterativeRefinementOrchestrator(config)
 
 result = await orchestrator.execute(
 prompt="Design a button component",
 context=mock_context
 )
 
 # Should have multiple iterations
 assert len(orchestrator.iterations) > 1
 
 # Should track changes
 assert all(it.changes for it in orchestrator.iterations[1:])
 
 # Should converge
 assert orchestrator.iterations[-1].convergence_score > 0.9`
```

---

### Implementation Notes

#### Delegation to Standard Loop

The iterative refinement orchestrator delegates to the standard `loop-basic` for each iteration's execution. It provides:

- Pre-processing: Build iteration-specific prompt with feedback
 
- Post-processing: Extract changes, compute deltas, correlate feedback
 
This keeps the orchestrator focused on iteration management rather than reimplementing execution logic.

#### LLM Usage

The orchestrator uses the LLM for:

- Semantic diff: Understanding what changed conceptually
 
- Change extraction: Parsing change descriptions from agent responses
 
- Feedback correlation: Inferring if a change addresses feedback
 
#### Performance Considerations

- Checkpoint storage: Memory mode is fast but limited; file mode scales better
 
- Delta computation: Semantic diffs require LLM calls (slower but higher quality)
 
- Convergence detection: Runs after each iteration (overhead acceptable)
 
---

### Dependencies

#### Required

- `amplifier-core` - Core session and module infrastructure
 
- `amplifier-module-loop-basic` - Delegates iteration execution
 
#### Optional

- `difflib` - Line-by-line diffs (stdlib)
 
- `tiktoken` - Token counting for large artifacts
 
---

### Open Questions

- Feedback format: Should feedback be structured (schema) or free-form text?
 
 - Option A: Structured (easier to correlate, requires template)

 - Option B: Free-form (flexible, harder to correlate)

- Convergence tuning: Should convergence be project-configurable?
 
 - Some projects may want stricter convergence (critical systems)

 - Others may want looser (creative work)

- Parallel iterations: Should we support exploring multiple refinement paths simultaneously?
 
 - Would enable A/B comparison of different approaches

 - Increases complexity significantly

- Human-in-the-loop: How to best pause for review?
 
 - Option A: Block orchestrator, wait for user input

 - Option B: Emit event, allow async review submission

 - Option C: Interactive review UI (requires integration)

- Version persistence: Should intermediate versions be saved long-term?
 
 - Useful for audit trails but increases storage

 - Could offer configurable retention policy

---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Orchestrator Loop Parallel Exploration
 orchestrators

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-loop-parallel-exploration`

### Overview

An orchestrator that explores multiple solution approaches in parallel, evaluates each against defined criteria, and presents a comparative analysis with recommendations. Enables rapid exploration of solution space by generating multiple prototypes simultaneously rather than exploring sequentially.

#### Value Proposition

 | 
 
 | Without | With

 | Sequential exploration (try A, fail, try B, etc.) | Parallel exploration of 3-5 approaches simultaneously
 
 | Anchor on first solution | Fair evaluation of multiple alternatives
 
 | Miss better alternatives | Comprehensive solution space coverage
 
 | Subjective comparison | Structured evaluation matrix with criteria

#### Use Cases

- Architecture decisions: Evaluate multiple database choices (Postgres, MongoDB, DynamoDB) in parallel
 
- API design: Compare REST, GraphQL, gRPC with working examples
 
- Algorithm selection: Test multiple sorting/search algorithms with benchmarks
 
- Design patterns: Explore different implementation patterns (Strategy, Factory, etc.)
 
- Technology choices: Compare frameworks/libraries with proof-of-concepts
 
---

### Contract

#### Orchestrator Interface

 python
 Copy

`class ParallelExplorationOrchestrator:
 """
 Orchestrator that explores multiple solution approaches in parallel.
 
 Flow:
 1. Receive problem statement
 2. Generate N different approaches
 3. Spawn sub-agents to develop each approach in parallel
 4. Collect all approach results
 5. Evaluate against criteria
 6. Generate comparison matrix
 7. Recommend best approach(es)
 """
 
 async def execute(
 self,
 prompt: str,
 context: ContextManager,
 providers: dict[str, Any],
 tools: dict[str, Any],
 hooks: HookRegistry,
 coordinator: ModuleCoordinator | None = None,
 ) -> str:
 """
 Execute parallel exploration.
 
 Args:
 prompt: Problem to solve
 context: Conversation context
 providers: Available LLM providers
 tools: Available tools
 hooks: Hook registry for events
 coordinator: Module coordinator
 
 Returns:
 Comparison matrix with recommendations
 """`
```

#### Configuration Schema

 toml
 Copy

`[[orchestrators]]
module = "loop-parallel-exploration"
config = {
 # Exploration parameters
 num_approaches = 4 # How many alternatives to explore
 approach_generation = "automatic" # "automatic" | "user_specified"
 
 # Evaluation criteria
 evaluation_criteria = [
 "performance",
 "cost", 
 "complexity",
 "scalability",
 "maintainability"
 ]
 
 # Criteria weights (for scoring)
 weights = {
 performance = 1.0,
 cost = 0.8,
 complexity = 1.2,
 scalability = 0.9,
 maintainability = 1.0
 }
 
 # Prototype generation
 generate_prototypes = true # Generate working examples
 prototype_depth = "proof_of_concept" # "sketch" | "proof_of_concept" | "production_ready"
 
 # Execution
 parallel_execution = true # Run all explorations simultaneously
 timeout_per_approach = 180 # Seconds per approach
 
 # Output control
 comparison_format = "matrix" # "matrix" | "narrative" | "both"
 include_code_samples = true
 include_trade_off_analysis = true
}`
```

#### Events Emitted

 | 
 
 | Event | When | Data

 | `orchestrator:exploration:start` | Exploration begins | num_approaches, criteria
 
 | `orchestrator:approach:generated` | Approach identified | approach_id, description
 
 | `orchestrator:approach:start` | Approach exploration starts | approach_id
 
 | `orchestrator:approach:complete` | Approach done | approach_id, scores
 
 | `orchestrator:evaluation:complete` | All evaluated | top_approach, comparison_matrix

---

### Architecture

#### Component Diagram

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ orchestrator-loop-parallel-exploration â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Approach â”‚â”€â”€â”€â–¶â”‚ Parallel â”‚â”€â”€â”€â–¶â”‚ Evaluator â”‚ â”‚
â”‚ â”‚ Generator â”‚ â”‚ Executor â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Prototype â”‚ â”‚ Comparison â”‚ â”‚ Scoring â”‚ â”‚
â”‚ â”‚ Generator â”‚ â”‚ Matrix â”‚ â”‚ Engine â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Internal Components

#### 1. Approach Generator

Generates alternative solution approaches:

 python
 Copy

`@dataclass
class Approach:
 id: str # UUID
 name: str # "Approach A: PostgreSQL"
 description: str # High-level description
 rationale: str # Why this approach?
 key_characteristics: list[str] # Defining features
 prototype: str | None # Code/config example
 evaluation_scores: dict[str, float] | None # Criteria scores

class ApproachGenerator:
 """Generates diverse solution approaches for exploration."""
 
 def __init__(self, num_approaches: int = 4):
 self.num_approaches = num_approaches
 
 async def generate_approaches(
 self,
 problem: str,
 context: ContextManager
 ) -> list[Approach]:
 """
 Generate diverse approaches to solve the problem.
 
 Uses LLM to brainstorm alternatives, aiming for:
 - Different paradigms (SQL vs NoSQL, REST vs GraphQL)
 - Different trade-offs (performance vs simplicity)
 - Different implementation strategies
 """
 prompt = f"""
You are exploring solutions to this problem:

{problem}

Generate {self.num_approaches} different approaches. Each approach should:
1. Take a fundamentally different strategy
2. Have clear pros and cons
3. Be viable (not strawman alternatives)

For each approach, provide:
- Name: Brief identifier
- Description: What is this approach?
- Rationale: Why would someone choose this?
- Key characteristics: What defines this approach?

Output as JSON array.
"""
 
 # Get LLM to generate approaches
 result = await self._call_llm(prompt, context)
 approaches = self._parse_approaches(result)
 
 # Assign UUIDs
 for approach in approaches:
 approach.id = str(uuid.uuid4())
 
 return approaches
 
 def _parse_approaches(self, llm_output: str) -> list[Approach]:
 """Parse LLM output into Approach objects."""
 # Extract JSON, create Approach objects
 ...`
```

#### 2. Parallel Executor

Executes exploration of all approaches simultaneously:

 python
 Copy

`class ParallelExecutor:
 """Executes exploration of approaches in parallel."""
 
 async def explore_all(
 self,
 approaches: list[Approach],
 problem: str,
 context: ContextManager,
 coordinator: ModuleCoordinator,
 config: ExplorationConfig
 ) -> list[Approach]:
 """Explore all approaches in parallel."""
 
 # Create exploration tasks
 tasks = [
 self._explore_approach(approach, problem, context, coordinator, config)
 for approach in approaches
 ]
 
 # Execute in parallel
 results = await asyncio.gather(*tasks, return_exceptions=True)
 
 # Filter errors
 explored_approaches = []
 for i, result in enumerate(results):
 if isinstance(result, Exception):
 logger.error(f"Approach {approaches[i].name} failed: {result}")
 else:
 explored_approaches.append(result)
 
 return explored_approaches
 
 async def _explore_approach(
 self,
 approach: Approach,
 problem: str,
 context: ContextManager,
 coordinator: ModuleCoordinator,
 config: ExplorationConfig
 ) -> Approach:
 """Explore a single approach in depth."""
 
 # Build exploration prompt
 exploration_prompt = f"""
# Approach: {approach.name}

## Description
{approach.description}

## Original Problem
{problem}

## Task
Develop this approach in detail:

1. **Architecture**: How would this work?
2. **Implementation**: {"Generate working code example" if config.generate_prototypes else "Describe implementation"}
3. **Pros**: What are the advantages?
4. **Cons**: What are the disadvantages?
5. **Evaluation**: Score this approach on:
 {chr(10).join(f" - {criterion}: 0-10 scale" for criterion in config.evaluation_criteria)}

Be specific and realistic. This will be compared to other approaches.
"""
 
 # Use task tool to spawn exploration
 result = await coordinator.call_tool("task", {
 "agent": "developer-expertise:zen-architect", # Or configurable agent
 "instruction": exploration_prompt
 })
 
 # Parse result and update approach
 return self._parse_exploration_result(result, approach, config)
 
 def _parse_exploration_result(
 self,
 result: str,
 approach: Approach,
 config: ExplorationConfig
 ) -> Approach:
 """Parse exploration result and extract scores."""
 
 # Extract prototype code (if generated)
 if config.generate_prototypes:
 approach.prototype = self._extract_code(result)
 
 # Extract evaluation scores
 scores = {}
 for criterion in config.evaluation_criteria:
 score = self._extract_score(result, criterion)
 scores[criterion] = score
 
 approach.evaluation_scores = scores
 
 return approach`
```

#### 3. Evaluator & Scoring Engine

Evaluates approaches against criteria:

 python
 Copy

`class ScoringEngine:
 """Scores and ranks approaches based on evaluation criteria."""
 
 def __init__(self, weights: dict[str, float]):
 self.weights = weights
 
 def score_approaches(
 self,
 approaches: list[Approach],
 criteria: list[str]
 ) -> list[ScoredApproach]:
 """
 Score and rank approaches.
 
 Scoring:
 1. Normalize scores to 0-1 range
 2. Apply weights per criterion
 3. Calculate weighted average
 4. Rank by total score
 """
 scored = []
 
 for approach in approaches:
 # Calculate weighted score
 total_score = 0.0
 max_possible = 0.0
 
 for criterion in criteria:
 score = approach.evaluation_scores.get(criterion, 0.0)
 weight = self.weights.get(criterion, 1.0)
 
 # Normalize to 0-1 (assuming scores are 0-10)
 normalized_score = score / 10.0
 
 total_score += normalized_score * weight
 max_possible += weight
 
 # Final score (0-1 range)
 final_score = total_score / max_possible if max_possible > 0 else 0.0
 
 scored.append(ScoredApproach(
 approach=approach,
 total_score=final_score,
 criterion_scores=approach.evaluation_scores,
 rank=0 # Assigned after sorting
 ))
 
 # Sort by score (descending)
 scored.sort(key=lambda x: x.total_score, reverse=True)
 
 # Assign ranks
 for i, scored_approach in enumerate(scored):
 scored_approach.rank = i + 1
 
 return scored
 
 def identify_best_approach(
 self,
 scored_approaches: list[ScoredApproach],
 threshold: float = 0.1
 ) -> tuple[ScoredApproach, list[ScoredApproach]]:
 """
 Identify best approach and close alternatives.
 
 Returns:
 - Best approach (highest score)
 - Close alternatives (within threshold of best)
 """
 if not scored_approaches:
 raise ValueError("No approaches to evaluate")
 
 best = scored_approaches[0]
 
 # Find alternatives within threshold
 alternatives = [
 a for a in scored_approaches[1:]
 if (best.total_score - a.total_score) <= threshold
 ]
 
 return best, alternatives`
```

#### 4. Comparison Matrix Generator

Generates structured comparison:

 python
 Copy

`class ComparisonMatrix:
 """Generates comparison matrix for approaches."""
 
 def generate_matrix(
 self,
 scored_approaches: list[ScoredApproach],
 criteria: list[str]
 ) -> str:
 """
 Generate comparison matrix table.
 
 Format:
 | Approach | Performance | Cost | Complexity | ... | Total Score | Rank |
 |----------|-------------|------|------------|-----|-------------|------|
 | A: Redis | 9/10 | 6/10 | 7/10 | ... | 0.85 | 1 |
 | B: CDN | 8/10 | 8/10 | 6/10 | ... | 0.82 | 2 |
 """
 
 # Build header
 header = ["Approach"] + criteria + ["Total Score", "Rank"]
 
 # Build rows
 rows = []
 for scored in scored_approaches:
 row = [scored.approach.name]
 
 # Add criterion scores
 for criterion in criteria:
 score = scored.criterion_scores.get(criterion, 0.0)
 row.append(f"{score:.1f}/10")
 
 # Add total score and rank
 row.append(f"{scored.total_score:.2f}")
 row.append(str(scored.rank))
 
 rows.append(row)
 
 # Format as markdown table
 return self._format_table(header, rows)
 
 def generate_trade_off_analysis(
 self,
 scored_approaches: list[ScoredApproach],
 criteria: list[str]
 ) -> str:
 """
 Generate prose explanation of trade-offs.
 
 Example:
 "Approach A excels in performance (9/10) but is more expensive (6/10).
 Approach B offers better cost efficiency (8/10) at the expense of 
 slightly lower performance (8/10)."
 """
 analysis = []
 
 # Find best/worst per criterion
 for criterion in criteria:
 scores = [
 (a.approach.name, a.criterion_scores.get(criterion, 0.0))
 for a in scored_approaches
 ]
 scores.sort(key=lambda x: x[1], reverse=True)
 
 best_name, best_score = scores[0]
 worst_name, worst_score = scores[-1]
 
 analysis.append(
 f"**{criterion.title()}**: {best_name} leads ({best_score:.1f}/10), "
 f"{worst_name} trails ({worst_score:.1f}/10)"
 )
 
 return "\n".join(analysis)`
```

#### Data Flow

 text
 Copy

`User Problem: "Design a caching strategy"
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate Approaches â”‚
â”‚ â†’ A: Redis in-memory cache â”‚
â”‚ â†’ B: CDN edge caching â”‚
â”‚ â†’ C: Application-level cache â”‚
â”‚ â†’ D: Database query cache â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Explore All Approaches (Parallel) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Approach A: Redis â”‚
â”‚ - Architecture: Centralized cache â”‚
â”‚ - Prototype: Redis config + code â”‚
â”‚ - Scores: perf=9, cost=6, complex=7 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Approach B: CDN â”‚
â”‚ - Architecture: Edge distribution â”‚
â”‚ - Prototype: CDN rules + headers â”‚
â”‚ - Scores: perf=8, cost=8, complex=6 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [... C and D ...] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚ (All complete)
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Score & Rank â”‚
â”‚ Weights: perf=1.0, cost=0.8, complex=1.2â”‚
â”‚ â”‚
â”‚ A: Redis â†’ 0.85 (rank 1) â”‚
â”‚ B: CDN â†’ 0.82 (rank 2) â”‚
â”‚ C: App â†’ 0.75 (rank 3) â”‚
â”‚ D: DB â†’ 0.60 (rank 4) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate Comparison Matrix â”‚
â”‚ + Trade-off Analysis â”‚
â”‚ + Recommendation â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Examples

#### Example 1: Caching Strategy

 yaml
 Copy

`# Input
"Design a caching strategy for our API"

# Generated Approaches (4)

Approach A: Redis In-Memory Cache
Description: Centralized Redis cache with TTL
Rationale: Fast, mature, horizontal scale
Characteristics: [Centralized, Network-based, Configurable TTL]

Approach B: CDN Edge Caching
Description: Cache at CDN edge locations
Rationale: Geographic distribution, offload origin
Characteristics: [Distributed, HTTP-level, Edge computing]

Approach C: Application-Level Cache
Description: In-process cache (in-memory map)
Rationale: Zero network latency, simple
Characteristics: [Local, Fast, No shared state]

Approach D: Database Query Cache
Description: PostgreSQL query result cache
Rationale: Transparent, built-in, no new infra
Characteristics: [Database-level, Automatic, Limited control]

# Exploration Results (parallel)

## Approach A: Redis
Architecture:
- Redis cluster with read replicas
- Cache-aside pattern (lazy loading)
- TTL-based expiration

Prototype:`
```

import redis

client = redis.Redis(host='localhost', decode_responses=True)

def get_user(user_id):

 # Check cache

 cached = client.get(f"user:{user_id}")

 if cached:

 return json.loads(cached)

 # Cache miss - fetch from DB

 user = db.query_user(user_id)

 client.setex(f"user:{user_id}", 3600, json.dumps(user))

 return user

 text
 Copy

`Scores:
- Performance: 9/10 (sub-ms reads)
- Cost: 6/10 ($200/month for cluster)
- Complexity: 7/10 (need cluster ops)
- Scalability: 9/10 (horizontal scale)
- Maintainability: 7/10 (new dependency)

## Approach B: CDN Edge Caching
Architecture:
- CloudFlare/Fastly edge caching
- Cache-Control headers
- Purge API for invalidation

Prototype:`
```

@app.route('/api/users/')

def get_user(id):

 user = db.query_user(id)

 response = jsonify(user)

 response.headers['Cache-Control'] = 'public, max-age=3600'

 response.headers['Vary'] = 'Authorization'

 return response

 text
 Copy

`Scores:
- Performance: 8/10 (CDN latency)
- Cost: 8/10 ($50/month)
- Complexity: 6/10 (simpler than Redis)
- Scalability: 10/10 (global edge network)
- Maintainability: 8/10 (managed service)

[... Approaches C and D ...]

# Evaluation Matrix

| Approach | Performance | Cost | Complexity | Scalability | Maintainability | Total | Rank |
|----------|-------------|------|------------|-------------|-----------------|-------|------|
| A: Redis | 9/10 | 6/10 | 7/10 | 9/10 | 7/10 | 0.85 | 1 |
| B: CDN | 8/10 | 8/10 | 6/10 | 10/10 | 8/10 | 0.82 | 2 |
| C: App | 10/10 | 10/10 | 9/10 | 4/10 | 9/10 | 0.75 | 3 |
| D: DB | 6/10 | 9/10 | 8/10 | 5/10 | 8/10 | 0.60 | 4 |

Weights applied: performance=1.0, cost=0.8, complexity=1.2, scalability=0.9, maintainability=1.0

# Trade-off Analysis

**Performance**: Application-level cache leads (10/10, zero latency), Database cache trails (6/10)
**Cost**: Application and Database caches are cheapest (no infra), Redis most expensive (cluster required)
**Complexity**: Application cache is simplest (9/10), Redis cluster is most complex (7/10)
**Scalability**: CDN excels (10/10, global), Application cache limited (4/10, single-instance)
**Maintainability**: Application and Database caches easiest (no ops), Redis requires cluster management

# Recommendation

**Primary Choice: Approach A (Redis)**
- Score: 0.85/1.0
- Best for: High-traffic APIs needing shared cache across instances
- Trade-off: Higher cost and complexity, but superior scalability

**Close Alternative: Approach B (CDN)**
- Score: 0.82/1.0 (within 0.03 of best)
- Consider if: API is mostly public, read-heavy, geographically distributed users
- Trade-off: Less control over cache invalidation

**Use Case Guidance:**
- Start with **Application-level cache** (C) if: Small app, single instance, simplicity critical
- Use **Redis** (A) if: Multi-instance, shared state, high traffic
- Use **CDN** (B) if: Public API, read-heavy, global users
- Avoid **Database cache** (D): Lowest scores, limited control`
```

---

### Configuration

 yaml
 Copy

`# Full configuration example
orchestrators:
 - module: loop-parallel-exploration
 config:
 # Exploration
 num_approaches: 4
 approach_generation: automatic
 approach_diversity: high # Encourage different paradigms
 
 # Evaluation criteria
 evaluation_criteria:
 - performance
 - cost
 - complexity
 - scalability
 - maintainability
 - security # Optional: add domain-specific criteria
 
 # Weights (customize per project)
 weights:
 performance: 1.0
 cost: 0.8
 complexity: 1.2 # Emphasize simplicity
 scalability: 0.9
 maintainability: 1.0
 security: 1.5 # High priority for security
 
 # Prototype generation
 generate_prototypes: true
 prototype_depth: proof_of_concept
 prototype_format: code # code | pseudocode | diagram
 
 # Execution
 parallel_execution: true
 timeout_per_approach: 180
 agent_per_approach: developer-expertise:zen-architect
 
 # Output
 comparison_format: both # matrix and narrative
 include_code_samples: true
 include_trade_off_analysis: true
 include_recommendation: true
 recommendation_style: decisive # decisive | options | conditional`
```

---

### Security Considerations

#### Resource Limits

- Timeout per approach: Prevents runaway explorations
 
- Max approaches: Configurable limit (default 4, max 10)
 
#### Code Generation

- Prototype code: May execute code if depth = production_ready
 
- Validation: Generated code should be reviewed before use

 python
 Copy

`REQUIRED_CAPABILITIES = [
 "orchestrator:execute",
 "tool:task:spawn",
 "context:read",
]`
```

---

### Testing Strategy

#### Unit Tests

 python
 Copy

`def test_approach_generator_creates_diverse_approaches():
 generator = ApproachGenerator(num_approaches=3)
 approaches = generator.generate_approaches("Design a cache")
 assert len(approaches) == 3
 # Should have different strategies
 assert len(set(a.name for a in approaches)) == 3

def test_scoring_engine_applies_weights():
 engine = ScoringEngine(weights={"perf": 2.0, "cost": 1.0})
 approach = Approach(
 evaluation_scores={"perf": 5, "cost": 5}
 )
 score = engine.score_approaches([approach], ["perf", "cost"])
 # Performance weighted 2x should dominate
 assert score[0].total_score > 0.5`
```

#### Integration Tests

 python
 Copy

`async def test_full_parallel_exploration():
 orchestrator = ParallelExplorationOrchestrator(config)
 result = await orchestrator.execute(
 prompt="Design an API authentication system",
 context=mock_context
 )
 # Should explore multiple approaches
 assert "Approach A" in result
 assert "Approach B" in result
 # Should have comparison matrix
 assert "| Approach |" in result
 # Should have recommendation
 assert "Recommendation" in result`
```

---

### Dependencies

#### Required

- `amplifier-core`
 
- `amplifier-module-tool-task`
 
#### Optional

- `tabulate` - For pretty tables
 
---

### Open Questions

- Approach diversity: How to ensure approaches are sufficiently different?
 
- Domain-specific criteria: Should criteria be customizable per domain (web, ML, infra)?
 
- Interactive exploration: Allow user to add approaches mid-exploration?
 
- Cost estimation: Should we estimate actual costs ($$) vs relative scoring?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Orchestrator Loop Perspective Synthesis
 orchestrators

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-module-loop-perspective-synthesis`

### Overview

An orchestrator that analyzes problems from multiple stakeholder perspectives in parallel, then synthesizes insights into a cohesive recommendation. Enables cross-functional decision-making by spawning specialized sub-agents for each role (PM, engineering, design, security, etc.) and combining their analyses.

#### Value Proposition

 | 
 
 | Without | With

 | One-size-fits-all analysis | Role-specific perspectives (PM, eng, design, security)
 
 | Sequential stakeholder consultation | Parallel analysis, faster results
 
 | Missing blind spots | Each role highlights different concerns
 
 | Vague recommendations | Clear trade-offs per stakeholder

#### Use Cases

- Feature decisions: "Should we build feature X?" analyzed by PM (market), eng (feasibility), design (UX)
 
- Architecture reviews: System design evaluated by multiple technical specialists
 
- Incident post-mortems: Root cause from ops, eng, product, security angles
 
- Compliance assessment: Legal, security, privacy perspectives on new feature
 
- Technical design: Database choice evaluated by performance, cost, ops perspectives
 
---

### Contract

#### Orchestrator Interface

 python
 Copy

`class PerspectiveSynthesisOrchestrator:
 """
 Orchestrator that analyzes from multiple perspectives in parallel.
 
 Flow:
 1. Receive user query/problem
 2. Spawn sub-agents for each configured perspective
 3. Execute all perspectives in parallel
 4. Detect conflicts between perspectives
 5. Synthesize unified recommendation
 6. Generate role-specific reports
 """
 
 async def execute(
 self,
 prompt: str,
 context: ContextManager,
 providers: dict[str, Any],
 tools: dict[str, Any],
 hooks: HookRegistry,
 coordinator: ModuleCoordinator | None = None,
 ) -> str:
 """
 Execute multi-perspective analysis.
 
 Args:
 prompt: User's question or problem
 context: Conversation context
 providers: Available LLM providers
 tools: Available tools
 hooks: Hook registry for events
 coordinator: Module coordinator
 
 Returns:
 Synthesized recommendation with all perspectives
 """`
```

#### Configuration Schema

 toml
 Copy

`[[orchestrators]]
module = "loop-perspective-synthesis"
config = {
 # Perspectives to analyze
 perspectives = [
 { 
 role = "product",
 agent = "agent-product-analyst",
 weight = 1.0,
 focus_areas = ["market", "user_feedback", "roadmap", "metrics"]
 },
 { 
 role = "engineering",
 agent = "agent-architect",
 weight = 1.0,
 focus_areas = ["architecture", "tech_debt", "performance", "scale"]
 },
 { 
 role = "design",
 agent = "agent-design-system",
 weight = 0.8,
 focus_areas = ["ux", "accessibility", "design_system", "brand"]
 },
 { 
 role = "security",
 agent = "agent-security-guardian",
 weight = 1.2,
 focus_areas = ["threat_model", "compliance", "data_protection"]
 }
 ]
 
 # Synthesis strategy
 synthesis_strategy = "weighted_voting" # "weighted_voting" | "consensus" | "veto"
 conflict_resolution = "surface" # "surface" | "mediate" | "escalate"
 
 # Execution
 parallel_execution = true # Run all perspectives simultaneously
 timeout_per_perspective = 120 # Seconds per perspective
 
 # Output control
 include_individual_reports = true # Show each perspective's full analysis
 include_conflict_analysis = true # Highlight disagreements
 generate_role_specific_summaries = true # Summary per stakeholder type
}`
```

#### Events Emitted

 | 
 
 | Event | When | Data

 | `orchestrator:perspectives:start` | Analysis begins | perspectives_count, roles
 
 | `orchestrator:perspective:start` | Perspective analysis starts | role, agent
 
 | `orchestrator:perspective:complete` | Perspective done | role, recommendation, confidence
 
 | `orchestrator:conflict:detected` | Disagreement found | conflicting_roles, topic
 
 | `orchestrator:synthesis:complete` | Synthesis done | final_recommendation, consensus_score

---

### Architecture

#### Component Diagram

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ orchestrator-loop-perspective-synthesis â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Perspective â”‚â”€â”€â”€â–¶â”‚ Parallel â”‚â”€â”€â”€â–¶â”‚ Conflict â”‚ â”‚
â”‚ â”‚ Spawner â”‚ â”‚ Executor â”‚ â”‚ Detector â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Synthesis â”‚â—€â”€â”€â”€â”‚ Weighting â”‚â—€â”€â”€â”€â”‚ Report â”‚ â”‚
â”‚ â”‚ Engine â”‚ â”‚ Engine â”‚ â”‚ Generator â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

#### Internal Components

#### 1. Perspective Spawner

Spawns specialized sub-agents for each role:

 python
 Copy

`@dataclass
class PerspectiveDefinition:
 role: str # "product", "engineering", etc.
 agent: str # Agent/profile to use
 weight: float # Importance weight (0.0-2.0)
 focus_areas: list[str] # Areas this perspective focuses on
 prompt_template: str | None # Custom prompt per perspective

@dataclass
class PerspectiveResult:
 role: str
 recommendation: str # Main recommendation
 rationale: str # Reasoning
 confidence: float # 0.0-1.0
 concerns: list[str] # Risks/concerns raised
 questions: list[str] # Questions for other perspectives
 metadata: dict[str, Any] # Role-specific data

class PerspectiveSpawner:
 """Spawns and manages sub-agents for each perspective."""
 
 def __init__(self, perspectives: list[PerspectiveDefinition]):
 self.perspectives = perspectives
 
 async def spawn_all(
 self, 
 query: str,
 context: ContextManager,
 coordinator: ModuleCoordinator
 ) -> list[PerspectiveResult]:
 """Spawn all perspectives in parallel."""
 tasks = [
 self._spawn_perspective(p, query, context, coordinator)
 for p in self.perspectives
 ]
 
 results = await asyncio.gather(*tasks, return_exceptions=True)
 
 # Filter out errors, log them
 valid_results = []
 for i, result in enumerate(results):
 if isinstance(result, Exception):
 logger.error(f"Perspective {self.perspectives[i].role} failed: {result}")
 else:
 valid_results.append(result)
 
 return valid_results
 
 async def _spawn_perspective(
 self,
 perspective: PerspectiveDefinition,
 query: str,
 context: ContextManager,
 coordinator: ModuleCoordinator
 ) -> PerspectiveResult:
 """Spawn a single perspective analysis."""
 # Build role-specific prompt
 perspective_prompt = self._build_perspective_prompt(
 perspective, 
 query
 )
 
 # Use task tool to spawn sub-agent with specific perspective
 result = await coordinator.call_tool("task", {
 "agent": perspective.agent,
 "instruction": perspective_prompt
 })
 
 # Parse result into structured format
 return self._parse_result(result, perspective.role)
 
 def _build_perspective_prompt(
 self,
 perspective: PerspectiveDefinition,
 query: str
 ) -> str:
 """Build a role-specific prompt."""
 template = perspective.prompt_template or self._default_template(perspective.role)
 
 prompt = f"""
# Your Role: {perspective.role.upper()} Perspective

You are analyzing this question from the {perspective.role} perspective.

## Focus Areas
{chr(10).join(f"- {area}" for area in perspective.focus_areas)}

## Query
{query}

## Task
Analyze this question from your role's perspective. Provide:

1. **Recommendation**: What should we do?
2. **Rationale**: Why do you recommend this?
3. **Concerns**: What risks or issues do you see?
4. **Questions**: What do you need to know from other perspectives?
5. **Confidence**: How confident are you? (0-100%)

Be specific and focus on your domain. Other perspectives will cover other areas.
"""
 return prompt.strip()`
```

#### 2. Conflict Detector

Identifies disagreements between perspectives:

 python
 Copy

`@dataclass
class Conflict:
 topic: str
 conflicting_roles: list[str]
 positions: dict[str, str] # role -> position
 severity: str # "minor" | "moderate" | "critical"

class ConflictDetector:
 """Detects conflicts between perspective recommendations."""
 
 async def detect_conflicts(
 self,
 results: list[PerspectiveResult]
 ) -> list[Conflict]:
 """
 Identify conflicts between perspectives.
 
 Conflicts occur when:
 1. Direct contradictions (build vs don't build)
 2. Different priorities (cost vs quality)
 3. Unresolved concerns between roles
 """
 conflicts = []
 
 # Check for direct contradictions
 recommendations = [r.recommendation for r in results]
 if self._has_contradictions(recommendations):
 conflicts.append(
 self._create_contradiction_conflict(results)
 )
 
 # Check for concern overlaps
 concern_conflicts = await self._analyze_concern_conflicts(results)
 conflicts.extend(concern_conflicts)
 
 # Check for priority misalignment
 priority_conflicts = self._detect_priority_conflicts(results)
 conflicts.extend(priority_conflicts)
 
 return conflicts
 
 def _has_contradictions(self, recommendations: list[str]) -> bool:
 """Detect if recommendations contradict each other."""
 # Simple heuristic: look for opposing keywords
 has_build = any("build" in r.lower() or "implement" in r.lower() 
 for r in recommendations)
 has_dont_build = any("don't" in r.lower() or "defer" in r.lower() 
 for r in recommendations)
 
 return has_build and has_dont_build
 
 async def _analyze_concern_conflicts(
 self,
 results: list[PerspectiveResult]
 ) -> list[Conflict]:
 """Use LLM to identify concern conflicts."""
 # Ask LLM to identify where concerns conflict
 prompt = f"""
 Analyze these perspectives for conflicting concerns:
 
 {self._format_results(results)}
 
 List conflicts where one role's concern conflicts with another's recommendation.
 """
 # Returns structured conflicts
 ...`
```

#### 3. Synthesis Engine

Combines perspectives into unified recommendation:

 python
 Copy

`class SynthesisEngine:
 """Synthesizes multiple perspectives into cohesive recommendation."""
 
 def __init__(self, strategy: str = "weighted_voting"):
 self.strategy = strategy
 
 async def synthesize(
 self,
 results: list[PerspectiveResult],
 conflicts: list[Conflict],
 weights: dict[str, float]
 ) -> SynthesisResult:
 """
 Synthesize perspectives based on configured strategy.
 """
 if self.strategy == "weighted_voting":
 return await self._weighted_synthesis(results, weights)
 elif self.strategy == "consensus":
 return await self._consensus_synthesis(results)
 elif self.strategy == "veto":
 return await self._veto_synthesis(results)
 else:
 raise ValueError(f"Unknown strategy: {self.strategy}")
 
 async def _weighted_synthesis(
 self,
 results: list[PerspectiveResult],
 weights: dict[str, float]
 ) -> SynthesisResult:
 """
 Weighted voting: higher weight = more influence.
 
 Example:
 - Security (weight 1.2): Don't build
 - Product (weight 1.0): Build
 - Design (weight 0.8): Build
 
 Weighted scores:
 - Don't build: 1.2
 - Build: 1.8
 
 â†’ Recommendation: Build (but highlight security concerns)
 """
 # Calculate weighted scores per recommendation
 recommendation_scores = {}
 
 for result in results:
 weight = weights.get(result.role, 1.0)
 score = result.confidence * weight
 
 rec = self._normalize_recommendation(result.recommendation)
 recommendation_scores[rec] = recommendation_scores.get(rec, 0) + score
 
 # Top recommendation
 top_rec = max(recommendation_scores, key=recommendation_scores.get)
 consensus_score = recommendation_scores[top_rec] / sum(recommendation_scores.values())
 
 # Collect dissenting perspectives
 dissenters = [
 r for r in results 
 if self._normalize_recommendation(r.recommendation) != top_rec
 ]
 
 return SynthesisResult(
 recommendation=top_rec,
 consensus_score=consensus_score,
 supporting_roles=[r.role for r in results if self._normalize_recommendation(r.recommendation) == top_rec],
 dissenting_roles=[r.role for r in dissenters],
 synthesis_rationale=await self._generate_rationale(results, top_rec),
 role_breakdowns=results
 )
 
 async def _consensus_synthesis(
 self,
 results: list[PerspectiveResult]
 ) -> SynthesisResult:
 """
 Consensus: Only recommend if all (or majority) agree.
 """
 recommendations = [
 self._normalize_recommendation(r.recommendation) 
 for r in results
 ]
 
 # Check for unanimous agreement
 if len(set(recommendations)) == 1:
 return SynthesisResult(
 recommendation=recommendations[0],
 consensus_score=1.0,
 supporting_roles=[r.role for r in results],
 dissenting_roles=[],
 synthesis_rationale="Unanimous agreement across all perspectives"
 )
 
 # No consensus - highlight disagreement
 return SynthesisResult(
 recommendation="No consensus reached",
 consensus_score=0.0,
 supporting_roles=[],
 dissenting_roles=[r.role for r in results],
 synthesis_rationale="Perspectives disagree. See individual analyses.",
 needs_escalation=True
 )
 
 async def _veto_synthesis(
 self,
 results: list[PerspectiveResult]
 ) -> SynthesisResult:
 """
 Veto: Any critical concern blocks recommendation.
 """
 # Check for critical concerns (typically from security, legal, compliance)
 blocking_concerns = [
 r for r in results
 if any(c.lower().startswith("critical") or c.lower().startswith("blocker") 
 for c in r.concerns)
 ]
 
 if blocking_concerns:
 return SynthesisResult(
 recommendation="Blocked by critical concerns",
 consensus_score=0.0,
 supporting_roles=[],
 dissenting_roles=[r.role for r in blocking_concerns],
 synthesis_rationale=f"Blocked by {', '.join(r.role for r in blocking_concerns)}",
 blocking_concerns=[c for r in blocking_concerns for c in r.concerns]
 )
 
 # No blocks - synthesize normally
 return await self._weighted_synthesis(results, {r.role: 1.0 for r in results})`
```

#### 4. Report Generator

Generates role-specific summaries:

 python
 Copy

`class ReportGenerator:
 """Generates reports tailored to different stakeholders."""
 
 def generate_full_report(
 self,
 synthesis: SynthesisResult,
 conflicts: list[Conflict]
 ) -> str:
 """Generate comprehensive report with all perspectives."""
 sections = [
 self._executive_summary(synthesis),
 self._recommendation_section(synthesis),
 self._perspective_breakdowns(synthesis.role_breakdowns),
 self._conflict_analysis(conflicts),
 self._next_steps(synthesis)
 ]
 
 return "\n\n".join(sections)
 
 def generate_role_specific_summary(
 self,
 role: str,
 synthesis: SynthesisResult
 ) -> str:
 """Generate summary for specific role (PM, eng, design)."""
 # Emphasize information relevant to this role
 
 if role == "product":
 return self._product_summary(synthesis)
 elif role == "engineering":
 return self._engineering_summary(synthesis)
 elif role == "design":
 return self._design_summary(synthesis)
 else:
 return self._generic_summary(synthesis)
 
 def _executive_summary(self, synthesis: SynthesisResult) -> str:
 """High-level summary for decision-makers."""
 return f"""
# Executive Summary

**Recommendation**: {synthesis.recommendation}
**Consensus Level**: {synthesis.consensus_score:.0%}
**Supporting**: {', '.join(synthesis.supporting_roles)}
**Concerns**: {', '.join(synthesis.dissenting_roles) if synthesis.dissenting_roles else 'None'}

{synthesis.synthesis_rationale}
"""`
```

#### Data Flow

 text
 Copy

`User Query: "Should we build feature X?"
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Spawn Perspectives (Parallel) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â†’ Product Agent: Market analysis â”‚
â”‚ â†’ Engineering Agent: Feasibility â”‚
â”‚ â†’ Design Agent: UX impact â”‚
â”‚ â†’ Security Agent: Threat model â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚ (All complete)
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Collect Results â”‚
â”‚ - Product: Build (conf: 0.9) â”‚
â”‚ - Engineering: Build, needs SRE (0.7) â”‚
â”‚ - Design: Build, 8 weeks (0.8) â”‚
â”‚ - Security: Build, review req'd (0.6) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Detect Conflicts â”‚
â”‚ - Moderate: Timeline (eng vs product) â”‚
â”‚ - Minor: Security review process â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Synthesize (Weighted Voting) â”‚
â”‚ Weights: Product=1.0, Eng=1.0, â”‚
â”‚ Design=0.8, Security=1.2 â”‚
â”‚ â”‚
â”‚ Result: BUILD (consensus: 0.75) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate Reports â”‚
â”‚ - Full report (all perspectives) â”‚
â”‚ - PM summary (business focus) â”‚
â”‚ - Eng summary (technical focus) â”‚
â”‚ - Design summary (UX focus) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Examples

#### Example 1: Feature Decision

 yaml
 Copy

`# Query
"Should we add real-time collaboration to our editor?"

# Spawned Perspectives (parallel)

## Product Perspective
Role: product
Agent: agent-product-analyst
Result:
 Recommendation: Build in Q2
 Rationale: |
 - Market: Top 3 feature request (247 users)
 - Competition: Figma, Google Docs have it
 - Revenue: Unblocks 3 enterprise deals ($450K ARR)
 - Risk: Delays Q1 roadmap
 Concerns:
 - Delays other priorities
 - Complex, may take longer than estimated
 Confidence: 0.85

## Engineering Perspective
Role: engineering
Agent: agent-architect
Result:
 Recommendation: Build, but hire SRE first
 Rationale: |
 - Architecture: Need WebSocket infra (6 weeks)
 - Tech debt: State management refactor needed (2 weeks)
 - Scale: 10K concurrent = $5K/month infra
 - Ops: No on-call experience with WebSockets
 Concerns:
 - Operational complexity
 - Hiring timeline unknown
 Confidence: 0.70

## Design Perspective
Role: design
Agent: agent-design-system
Result:
 Recommendation: Build, budget 8 weeks for design
 Rationale: |
 - UX: Need conflict resolution UI
 - Components: Cursors, avatars, presence (4 new)
 - Accessibility: Real-time updates for screen readers
 - Risk: Can't half-ship, UX must be polished
 Concerns:
 - 8 weeks design is optimistic
 - Need design system expansion
 Confidence: 0.80

## Security Perspective
Role: security
Agent: agent-security-guardian
Result:
 Recommendation: Build with security review
 Rationale: |
 - Threat: User impersonation, data leakage
 - Compliance: GDPR for shared sessions
 - Audit: Need activity logs for enterprise
 Concerns:
 - Critical: Security review before launch
 - Moderate: Pen test required
 Confidence: 0.60

# Conflict Detection
Conflicts:
 - Topic: Timeline
 Roles: [product, engineering]
 Severity: moderate
 Details: Product wants Q1, engineering needs Q2
 
 - Topic: Prerequisites
 Roles: [engineering]
 Severity: moderate
 Details: Engineering blocks on SRE hire

# Synthesis (Weighted Voting)
Weights:
 product: 1.0
 engineering: 1.0
 design: 0.8
 security: 1.2

Scores:
 "Build": 1.0 + 1.0 + 0.8 = 2.8
 "Build with conditions": 1.2 = 1.2
 Total: 4.0
 
Final Recommendation: Build (consensus: 70%)

# Generated Report

## Executive Summary
**Recommendation**: Build real-time collaboration feature
**Consensus**: 70% (weighted agreement)
**Timeline**: Q2 target (not Q1)
**Prerequisites**: Hire SRE, complete security review

All perspectives agree the feature should be built, but disagree on timing
and prerequisites.

## Recommendation Details

**Build the feature with these conditions:**
1. Target Q2 (not Q1) - allows time for infrastructure
2. Hire SRE before starting - mitigates operational risk
3. Security review required - addresses compliance concerns
4. Budget 8 weeks for design - ensures quality UX

**Estimated Investment:**
- Engineering: 12 weeks (6 infra + 6 feature)
- Design: 8 weeks
- Infrastructure: $60K/year
- Prerequisites: 1 SRE hire

**Expected Return:**
- Unlocks $450K ARR in enterprise deals
- Top user-requested feature (247 requests)
- Competitive parity with Figma, Google Docs

## Perspective Breakdowns
[Full details from each perspective]

## Conflicts & Trade-offs
1. **Timeline** (Product vs Engineering)
 - Product wants Q1 for enterprise deals
 - Engineering needs Q2 for proper infrastructure
 - Resolution: Q2 target, communicate delay to prospects

2. **Prerequisites** (Engineering)
 - SRE hire needed before starting
 - Hiring timeline: 1-2 months
 - Mitigation: Start recruiting now

## Next Steps
1. [ ] Approve Q2 timeline
2. [ ] Start SRE recruitment
3. [ ] Schedule security review meeting
4. [ ] Allocate design team capacity`
```

---

### Security Considerations

#### Sub-agent Spawning

- Isolation: Each perspective gets isolated context
 
- Resource limits: Timeout per perspective prevents runaway agents
 
- Error handling: Failed perspectives don't block synthesis
 
#### Data Access

 python
 Copy

`REQUIRED_CAPABILITIES = [
 "orchestrator:execute",
 "tool:task:spawn", # Spawn sub-agents
 "context:read",
 "context:write",
]`
```

---

### Testing Strategy

#### Unit Tests

 python
 Copy

`def test_conflict_detector_identifies_contradictions():
 results = [
 PerspectiveResult(role="pm", recommendation="Build now"),
 PerspectiveResult(role="security", recommendation="Don't build")
 ]
 detector = ConflictDetector()
 conflicts = detector.detect_conflicts(results)
 assert len(conflicts) > 0
 assert "Build" in conflicts[0].topic

def test_weighted_synthesis_respects_weights():
 results = [
 PerspectiveResult(role="pm", recommendation="Build", confidence=1.0),
 PerspectiveResult(role="security", recommendation="Don't", confidence=1.0)
 ]
 weights = {"pm": 1.0, "security": 2.0}
 engine = SynthesisEngine("weighted_voting")
 result = engine.synthesize(results, [], weights)
 assert "Don't" in result.recommendation # Security weight wins`
```

#### Integration Tests

 python
 Copy

`async def test_full_perspective_synthesis():
 orchestrator = PerspectiveSynthesisOrchestrator(config)
 result = await orchestrator.execute(
 prompt="Should we migrate to microservices?",
 context=mock_context
 )
 # Should have multiple perspectives
 assert len(orchestrator.perspectives_results) >= 3
 # Should have synthesis
 assert "recommendation" in result.lower()`
```

---

### Dependencies

#### Required

- `amplifier-core`
 
- `amplifier-module-tool-task` - For spawning sub-agents
 
#### Optional

- `amplifier-collection-recipes` - For agent profiles
 
---

### Open Questions

- Dynamic perspective selection: Should perspectives be auto-selected based on query?
 
- Async review: How to handle long-running perspective analyses?
 
- Perspective plugins: Should perspectives be pluggable/configurable?
 
- Cross-perspective dialogue: Should perspectives be able to ask each other questions?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Codebase Onboarder
 scenario-tools

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-scenario-codebase-onboarder`

### Overview

Interactive codebase exploration and learning tool for new team members. Generates personalized learning paths, explains architecture, answers questions with full context, and tracks onboarding progress.

#### Value Proposition

 | 
 
 | Without | With

 | Weeks to understand codebase | Days with guided exploration
 
 | Scattered documentation | Unified, contextual explanations
 
 | Constant interruptions to seniors | Self-service learning
 
 | No visibility into onboarding progress | Tracked milestones

---

### Workflow Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Codebase Onboarding Pipeline â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Profile â”‚â”€â”€â”€â–¶â”‚ Generate â”‚â”€â”€â”€â–¶â”‚ Explore â”‚â”€â”€â”€â–¶â”‚ Assess â”‚ â”‚
â”‚ â”‚ Setup â”‚ â”‚ Path â”‚ â”‚ & Learn â”‚ â”‚ Progress â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â–¼ â–¼ â–¼ â–¼ â”‚
â”‚ â€¢ Role â€¢ Learning â€¢ Interactive â€¢ Quiz â”‚
â”‚ â€¢ Experience modules Q&A â€¢ Practical â”‚
â”‚ â€¢ Focus areas â€¢ Milestones â€¢ Code walks challenges â”‚
â”‚ â€¢ Time budget â€¢ Resources â€¢ Architecture â€¢ Knowledge â”‚
â”‚ explanations check â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Progress â”‚â—€â”€â”€ Throughout â”‚
â”‚ â”‚ Tracking â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Configuration

 yaml
 Copy

`scenario:
 name: codebase-onboarder
 version: "1.0.0"

 # User profile
 profile:
 collect:
 - role # frontend, backend, fullstack, etc.
 - experience_level # junior, mid, senior
 - prior_technologies # Familiar languages/frameworks
 - focus_areas # What they'll work on
 - time_budget # Hours per day for learning

 # Content generation
 content:
 # Documentation sources
 sources:
 readme_files: true
 inline_docs: true
 architecture_docs: true
 adr_files: true
 wiki: false
 confluence: false

 # Learning modules to generate
 modules:
 architecture_overview:
 priority: 1
 estimated_time: 2h
 core_concepts:
 priority: 2
 estimated_time: 3h
 development_workflow:
 priority: 3
 estimated_time: 1h
 key_components:
 priority: 4
 estimated_time: 4h
 common_patterns:
 priority: 5
 estimated_time: 2h
 testing_practices:
 priority: 6
 estimated_time: 1h

 # Interactive features
 interactive:
 code_walkthrough: true
 architecture_diagrams: true
 live_questions: true
 practical_exercises: true

 # Assessment
 assessment:
 knowledge_checks: true
 practical_challenges: true
 mentor_review_points: true

 # Progress tracking
 progress:
 storage: file # file | database
 path: ".amplifier/onboarding/"
 milestones: true
 time_tracking: true

 # Output
 output:
 format: interactive # interactive | static | both
 export_pdf: false`
```

---

### Pipeline Implementation

 python
 Copy

`class CodebaseOnboarderScenario:
 """Interactive codebase onboarding experience."""

 def __init__(self, config: OnboarderConfig):
 self.config = config
 self.tools = ToolRegistry()
 self.progress = OnboardingProgress()

 async def start_onboarding(self, user_id: str) -> OnboardingSession:
 """Initialize onboarding for a new user."""

 # Stage 1: Collect Profile
 profile = await self._collect_profile(user_id)

 # Stage 2: Analyze Codebase
 codebase_info = await self._analyze_codebase()

 # Stage 3: Generate Learning Path
 learning_path = await self._generate_learning_path(profile, codebase_info)

 # Stage 4: Start Interactive Session
 session = OnboardingSession(
 user_id=user_id,
 profile=profile,
 learning_path=learning_path,
 codebase_info=codebase_info,
 progress=self.progress.load(user_id)
 )

 return session

 async def _collect_profile(self, user_id: str) -> UserProfile:
 """Stage 1: Collect user profile through interactive questions."""

 questions = [
 ProfileQuestion(
 id="role",
 text="What's your primary role?",
 options=["Frontend", "Backend", "Full-stack", "DevOps", "Data/ML", "Other"]
 ),
 ProfileQuestion(
 id="experience",
 text="What's your experience level?",
 options=["Junior (0-2 years)", "Mid (2-5 years)", "Senior (5+ years)"]
 ),
 ProfileQuestion(
 id="languages",
 text="Which languages/frameworks are you already familiar with?",
 multi_select=True,
 options=["Python", "JavaScript/TypeScript", "Go", "Java", "React", "Node.js", "Other"]
 ),
 ProfileQuestion(
 id="focus",
 text="What area will you primarily work on?",
 options=await self._get_codebase_areas()
 ),
 ProfileQuestion(
 id="time",
 text="How much time can you dedicate to onboarding daily?",
 options=["1 hour", "2 hours", "4 hours", "Full day"]
 )
 ]

 # Collect answers (interactive or from config)
 answers = await self._collect_answers(questions)

 return UserProfile(
 user_id=user_id,
 role=answers["role"],
 experience=answers["experience"],
 familiar_with=answers["languages"],
 focus_area=answers["focus"],
 daily_time_budget=self._parse_time(answers["time"])
 )

 async def _analyze_codebase(self) -> CodebaseInfo:
 """Stage 2: Analyze codebase structure and content."""

 info = CodebaseInfo()

 # Get architecture
 arch_tool = self.tools.get("tool-architecture-map")
 info.architecture = await arch_tool.execute({
 "action": "generate",
 "include_descriptions": True
 })

 # Get key components
 search_tool = self.tools.get("tool-codebase-search")

 # Find main entry points
 info.entry_points = await search_tool.execute({
 "query": "main entry point",
 "file_patterns": ["main.*", "index.*", "app.*"]
 })

 # Find core modules
 info.core_modules = await self._identify_core_modules()

 # Collect documentation
 info.documentation = await self._collect_documentation()

 # Identify patterns
 info.patterns = await self._identify_patterns()

 # Get tech stack
 info.tech_stack = await self._identify_tech_stack()

 return info

 async def _generate_learning_path(
 self,
 profile: UserProfile,
 codebase: CodebaseInfo
 ) -> LearningPath:
 """Stage 3: Generate personalized learning path."""

 modules = []

 # Module 1: Architecture Overview (always first)
 modules.append(await self._generate_architecture_module(codebase))

 # Module 2: Core Concepts (tailored to tech stack)
 modules.append(await self._generate_concepts_module(
 codebase, profile.familiar_with
 ))

 # Module 3: Development Workflow
 modules.append(await self._generate_workflow_module(codebase))

 # Module 4: Focus Area Deep Dive
 if profile.focus_area:
 modules.append(await self._generate_focus_module(
 codebase, profile.focus_area
 ))

 # Module 5: Key Components
 modules.append(await self._generate_components_module(
 codebase, profile.focus_area
 ))

 # Module 6: Common Patterns
 modules.append(await self._generate_patterns_module(
 codebase, profile.experience
 ))

 # Module 7: Testing Practices
 modules.append(await self._generate_testing_module(codebase))

 # Adjust based on time budget
 learning_path = LearningPath(
 modules=modules,
 estimated_total_time=sum(m.estimated_time for m in modules),
 daily_schedule=self._create_schedule(modules, profile.daily_time_budget)
 )

 return learning_path

 async def _generate_architecture_module(
 self,
 codebase: CodebaseInfo
 ) -> LearningModule:
 """Generate architecture overview module."""

 sections = []

 # High-level overview
 sections.append(Section(
 title="System Overview",
 content=await self._generate_overview(codebase),
 type="reading",
 estimated_time=timedelta(minutes=15)
 ))

 # Architecture diagram
 sections.append(Section(
 title="Architecture Diagram",
 content=self._render_architecture_diagram(codebase.architecture),
 type="visual",
 estimated_time=timedelta(minutes=10)
 ))

 # Key services/components
 for component in codebase.architecture.main_components[:5]:
 sections.append(Section(
 title=f"Component: {component.name}",
 content=await self._explain_component(component),
 type="reading",
 code_references=component.key_files,
 estimated_time=timedelta(minutes=10)
 ))

 # Interactive exploration
 sections.append(Section(
 title="Explore the Architecture",
 content="Let's walk through the codebase interactively.",
 type="interactive",
 exercise=ArchitectureExploration(codebase),
 estimated_time=timedelta(minutes=30)
 ))

 # Knowledge check
 sections.append(Section(
 title="Architecture Quiz",
 type="quiz",
 questions=await self._generate_arch_quiz(codebase),
 estimated_time=timedelta(minutes=10)
 ))

 return LearningModule(
 id="architecture",
 title="Architecture Overview",
 description="Understand the high-level structure of the codebase",
 sections=sections,
 estimated_time=sum(s.estimated_time for s in sections, timedelta())
 )

 async def answer_question(
 self,
 session: OnboardingSession,
 question: str
 ) -> Answer:
 """Answer a question about the codebase with full context."""

 # Search for relevant code
 search_tool = self.tools.get("tool-codebase-search")
 relevant_code = await search_tool.execute({
 "query": question,
 "search_type": "semantic",
 "max_results": 10
 })

 # Get architecture context
 arch_context = self._get_relevant_architecture(
 question, session.codebase_info.architecture
 )

 # Check documentation
 doc_context = self._search_documentation(
 question, session.codebase_info.documentation
 )

 # Generate answer with full context
 answer = await self._generate_answer(
 question=question,
 code_context=relevant_code,
 architecture_context=arch_context,
 documentation_context=doc_context,
 user_profile=session.profile,
 learning_progress=session.progress
 )

 # Track question for learning insights
 session.questions_asked.append(QuestionRecord(
 question=question,
 topic=answer.topic,
 timestamp=datetime.utcnow()
 ))

 return answer

 async def run_code_walkthrough(
 self,
 session: OnboardingSession,
 starting_point: str
 ) -> CodeWalkthrough:
 """Interactive code walkthrough from a starting point."""

 walkthrough = CodeWalkthrough(starting_point=starting_point)

 # Load starting file
 current_file = await self._load_file(starting_point)

 # Explain the file
 explanation = await self._explain_file(
 current_file, session.profile, session.codebase_info
 )

 walkthrough.add_step(WalkthroughStep(
 file=starting_point,
 explanation=explanation,
 highlights=explanation.key_lines
 ))

 # Follow imports/dependencies
 dependencies = await self._get_file_dependencies(current_file)

 walkthrough.suggested_next = [
 SuggestedExploration(
 file=dep.path,
 reason=dep.relationship,
 relevance=dep.relevance_score
 )
 for dep in dependencies[:5]
 ]

 return walkthrough

class InteractiveExplorer:
 """Interactive code exploration features."""

 async def explain_function(
 self,
 file_path: str,
 function_name: str,
 profile: UserProfile
 ) -> FunctionExplanation:
 """Explain a specific function in detail."""

 # Load function code
 code = await self._extract_function(file_path, function_name)

 # Generate explanation based on experience level
 explanation = await self._generate_explanation(
 code=code,
 experience_level=profile.experience,
 familiar_technologies=profile.familiar_with
 )

 return FunctionExplanation(
 name=function_name,
 purpose=explanation.purpose,
 parameters=explanation.parameters,
 return_value=explanation.return_value,
 algorithm=explanation.algorithm,
 complexity=explanation.complexity,
 related_functions=explanation.related,
 example_usage=explanation.examples
 )

 async def trace_data_flow(
 self,
 starting_point: str,
 data_name: str
 ) -> DataFlowTrace:
 """Trace how data flows through the system."""

 trace = DataFlowTrace(data=data_name)

 # Use dependency graph to trace
 dep_tool = self.tools.get("tool-dependency-graph")

 # Find where data originates
 sources = await dep_tool.execute({
 "action": "find_sources",
 "symbol": data_name,
 "start_file": starting_point
 })

 trace.sources = sources

 # Find transformations
 transforms = await dep_tool.execute({
 "action": "find_transforms",
 "symbol": data_name
 })

 trace.transformations = transforms

 # Find consumers
 consumers = await dep_tool.execute({
 "action": "find_consumers",
 "symbol": data_name
 })

 trace.consumers = consumers

 # Generate visual
 trace.diagram = self._generate_flow_diagram(sources, transforms, consumers)

 return trace

class ProgressTracker:
 """Track onboarding progress and milestones."""

 async def update_progress(
 self,
 user_id: str,
 module_id: str,
 section_id: str,
 completion: float
 ) -> ProgressUpdate:
 """Update learning progress."""

 progress = self.load(user_id)

 # Update section progress
 if module_id not in progress.modules:
 progress.modules[module_id] = ModuleProgress(module_id=module_id)

 progress.modules[module_id].sections[section_id] = completion

 # Calculate module completion
 module_completion = self._calculate_module_completion(
 progress.modules[module_id]
 )
 progress.modules[module_id].completion = module_completion

 # Check milestones
 new_milestones = self._check_milestones(progress)
 for milestone in new_milestones:
 progress.milestones_achieved.append(milestone)

 # Update total progress
 progress.total_completion = self._calculate_total_completion(progress)
 progress.time_spent += self._session_time()

 self.save(user_id, progress)

 return ProgressUpdate(
 module_completion=module_completion,
 total_completion=progress.total_completion,
 new_milestones=new_milestones,
 next_recommended=self._recommend_next(progress)
 )

 def generate_report(self, user_id: str) -> OnboardingReport:
 """Generate progress report."""

 progress = self.load(user_id)

 return OnboardingReport(
 user_id=user_id,
 started=progress.started_at,
 total_completion=progress.total_completion,
 time_spent=progress.time_spent,
 modules=[
 ModuleReport(
 module_id=m.module_id,
 completion=m.completion,
 quiz_scores=m.quiz_scores,
 challenges_completed=m.challenges_completed
 )
 for m in progress.modules.values()
 ],
 milestones=progress.milestones_achieved,
 topics_explored=progress.topics_explored,
 questions_asked=len(progress.questions),
 strengths=self._identify_strengths(progress),
 areas_for_focus=self._identify_focus_areas(progress)
 )`
```

---

### Learning Module Examples

#### Architecture Overview

 markdown
 Copy

`# Architecture Overview

## System Structure

This codebase follows a **microservices architecture** with the following
key components:

### API Gateway (`/services/gateway/`)
The entry point for all client requests. Handles:
- Authentication/authorization
- Rate limiting
- Request routing

### User Service (`/services/users/`)
Manages user accounts, profiles, and authentication.

### Payment Service (`/services/payments/`)
Handles all payment processing with Stripe integration.

[View Architecture Diagram]

---

## Interactive Exploration

Let's explore the architecture together. I'll guide you through the
main entry points and how requests flow through the system.

**Starting point**: `services/gateway/src/index.ts`

> "This is the API gateway entry point. When a request comes in,
> it first goes through the authentication middleware (line 45),
> then gets routed to the appropriate service (line 67)."

Would you like to:
1. Dive deeper into the authentication flow
2. See how a payment request is processed
3. Explore the user service
4. Ask a question

---

## Knowledge Check

1. What is the primary role of the API Gateway?
 - [ ] Database management
 - [x] Request routing and authentication
 - [ ] Payment processing

2. Where would you find the code that handles user registration?
 - [ ] services/gateway/
 - [x] services/users/
 - [ ] services/payments/`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `profile.collect` | list | [all] | Profile info to collect
 
 | `content.sources.*` | bool | varies | Documentation sources
 
 | `interactive.code_walkthrough` | bool | true | Enable walkthroughs
 
 | `assessment.knowledge_checks` | bool | true | Enable quizzes
 
 | `progress.storage` | string | "file" | Progress storage

---

### Dependencies

#### Required Tools

- `tool-codebase-search` - Code search and analysis
 
- `tool-architecture-map` - Architecture visualization
 
- `tool-dependency-graph` - Code flow analysis
 
#### Optional

- Documentation platforms (Confluence, Notion)
 
- LMS integrations
 
---

### Open Questions

- Team integration: Assign mentors based on onboarding progress?
 
- Gamification: Add achievements/badges for motivation?
 
- Adaptive learning: Adjust difficulty based on performance?
 
- Content updates: Auto-update when codebase changes?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Feature Planner
 scenario-tools

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-scenario-feature-planner`

### Overview

Collaborative feature planning workflow that transforms requirements into actionable technical specifications. Analyzes codebase architecture, identifies integration points, estimates complexity, and generates implementation plans with tasks.

#### Value Proposition

 | 
 
 | Without | With

 | Requirements lost in translation | Structured technical specs
 
 | Unclear integration points | Automated architecture analysis
 
 | Inaccurate estimates | Data-driven complexity scoring
 
 | Scattered planning docs | Integrated planning workflow

---

### Workflow Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature Planning Pipeline â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Require- â”‚â”€â”€â”€â–¶â”‚ Analysis â”‚â”€â”€â”€â–¶â”‚ Design â”‚â”€â”€â”€â–¶â”‚ Plan â”‚ â”‚
â”‚ â”‚ ments â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ Output â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â–¼ â–¼ â–¼ â–¼ â”‚
â”‚ â€¢ PRD/spec â€¢ Codebase â€¢ Components â€¢ Tech spec â”‚
â”‚ â€¢ User stories analysis â€¢ APIs â€¢ Tasks â”‚
â”‚ â€¢ Constraints â€¢ Integration â€¢ Data models â€¢ Estimates â”‚
â”‚ â€¢ Acceptance points â€¢ Sequences â€¢ Risks â”‚
â”‚ criteria â€¢ Dependencies â€¢ Trade-offs â€¢ JIRA tickets â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Human Review â”‚â—€â”€â”€ At each stage â”‚
â”‚ â”‚ & Iteration â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Configuration

 yaml
 Copy

`scenario:
 name: feature-planner
 version: "1.0.0"

 # Input
 input:
 requirements:
 source: markdown # markdown | jira | notion | confluence
 path: "${REQUIREMENTS_PATH}"

 # Analysis stage
 analysis:
 codebase:
 enabled: true
 tools:
 - tool-codebase-search
 - tool-architecture-map
 - tool-dependency-graph
 scope:
 include:
 - "src/**"
 - "api/**"
 exclude:
 - "**/*.test.*"
 - "node_modules/**"

 patterns:
 enabled: true
 detect:
 - existing_implementations
 - coding_patterns
 - api_conventions
 - data_models

 # Design stage
 design:
 outputs:
 component_diagram: true
 sequence_diagrams: true
 api_spec: true
 data_model: true

 constraints:
 max_components: 10
 prefer_existing_patterns: true
 backwards_compatible: true

 # Planning stage
 planning:
 task_breakdown:
 granularity: medium # fine | medium | coarse
 include_tests: true
 include_docs: true

 estimation:
 method: complexity_points # complexity_points | hours | story_points
 confidence_threshold: 0.7

 risk_analysis:
 enabled: true
 categories:
 - technical_risk
 - integration_risk
 - scope_risk
 - dependency_risk

 # Output
 output:
 formats:
 - tech_spec_markdown
 - jira_tickets
 - architecture_diagram

 jira:
 project: "${JIRA_PROJECT}"
 epic_type: Epic
 story_type: Story
 task_type: Task
 create_tickets: false # false = dry run`
```

---

### Pipeline Implementation

 python
 Copy

`class FeaturePlannerScenario:
 """Transform requirements into implementation plans."""

 def __init__(self, config: FeaturePlannerConfig):
 self.config = config
 self.tools = ToolRegistry()

 async def plan(self, requirements_path: str) -> FeaturePlan:
 """Execute feature planning pipeline."""

 # Stage 1: Parse Requirements
 requirements = await self._parse_requirements(requirements_path)

 # Stage 2: Analyze Codebase
 analysis = await self._analyze_codebase(requirements)

 # Stage 3: Design Solution
 design = await self._design_solution(requirements, analysis)

 # Stage 4: Generate Plan
 plan = await self._generate_plan(requirements, analysis, design)

 # Stage 5: Output
 return await self._generate_outputs(plan)

 async def _parse_requirements(self, path: str) -> Requirements:
 """Stage 1: Parse and structure requirements."""

 content = Path(path).read_text()

 # Extract structured requirements using LLM
 parsed = await self._extract_requirements(content)

 return Requirements(
 title=parsed["title"],
 summary=parsed["summary"],
 user_stories=parsed["user_stories"],
 acceptance_criteria=parsed["acceptance_criteria"],
 constraints=parsed["constraints"],
 non_functional=parsed["non_functional_requirements"],
 out_of_scope=parsed["out_of_scope"]
 )

 async def _analyze_codebase(self, requirements: Requirements) -> CodebaseAnalysis:
 """Stage 2: Analyze codebase for implementation context."""

 analysis = CodebaseAnalysis()

 # Search for related code
 search_tool = self.tools.get("tool-codebase-search")

 # Extract key concepts from requirements
 concepts = await self._extract_concepts(requirements)

 for concept in concepts:
 results = await search_tool.execute({
 "query": concept,
 "search_type": "semantic",
 "max_results": 10
 })
 analysis.related_code[concept] = results

 # Get architecture map
 arch_tool = self.tools.get("tool-architecture-map")
 analysis.architecture = await arch_tool.execute({
 "action": "generate",
 "format": "json"
 })

 # Identify integration points
 analysis.integration_points = await self._find_integration_points(
 requirements, analysis.related_code, analysis.architecture
 )

 # Get dependency information
 dep_tool = self.tools.get("tool-dependency-graph")
 analysis.dependencies = await dep_tool.execute({
 "paths": [ip.file_path for ip in analysis.integration_points]
 })

 # Detect patterns
 analysis.patterns = await self._detect_patterns(analysis.related_code)

 return analysis

 async def _find_integration_points(
 self,
 requirements: Requirements,
 related_code: dict,
 architecture: Architecture
 ) -> list[IntegrationPoint]:
 """Identify where new feature integrates with existing code."""

 integration_points = []

 # Analyze with LLM
 prompt = f"""
 Given these requirements:
 {requirements.summary}

 And this existing architecture:
 {json.dumps(architecture.components)}

 Identify integration points where the new feature should connect.
 For each point, specify:
 - Component name
 - File path
 - Type (API, Event, Database, Service)
 - Why this integration is needed
 """

 result = await self._llm_analyze(prompt)

 for point in result["integration_points"]:
 integration_points.append(IntegrationPoint(
 component=point["component"],
 file_path=point["file_path"],
 integration_type=point["type"],
 rationale=point["rationale"],
 existing_code=related_code.get(point["component"], [])
 ))

 return integration_points

 async def _design_solution(
 self,
 requirements: Requirements,
 analysis: CodebaseAnalysis
 ) -> Design:
 """Stage 3: Design the solution."""

 design = Design()

 # Generate component design
 design.components = await self._design_components(requirements, analysis)

 # Generate API design (if needed)
 if self._needs_api(requirements):
 design.api = await self._design_api(requirements, analysis)

 # Generate data model (if needed)
 if self._needs_data_model(requirements):
 design.data_model = await self._design_data_model(requirements, analysis)

 # Generate sequence diagrams
 design.sequences = await self._design_sequences(
 requirements, design.components, analysis
 )

 # Identify trade-offs
 design.trade_offs = await self._identify_trade_offs(design, requirements)

 return design

 async def _design_components(
 self,
 requirements: Requirements,
 analysis: CodebaseAnalysis
 ) -> list[ComponentDesign]:
 """Design new/modified components."""

 # Use existing patterns
 patterns = analysis.patterns

 prompt = f"""
 Design components for this feature:
 {requirements.summary}

 Integration points:
 {json.dumps([ip.to_dict() for ip in analysis.integration_points])}

 Existing patterns to follow:
 {json.dumps(patterns)}

 For each component, specify:
 - Name and purpose
 - Responsibilities
 - Interfaces (methods/APIs)
 - Dependencies
 - New vs modification of existing
 """

 result = await self._llm_design(prompt)

 components = []
 for comp in result["components"]:
 components.append(ComponentDesign(
 name=comp["name"],
 purpose=comp["purpose"],
 responsibilities=comp["responsibilities"],
 interfaces=comp["interfaces"],
 dependencies=comp["dependencies"],
 is_new=comp["is_new"],
 modifies=comp.get("modifies"),
 file_path=comp.get("file_path")
 ))

 return components

 async def _generate_plan(
 self,
 requirements: Requirements,
 analysis: CodebaseAnalysis,
 design: Design
 ) -> ImplementationPlan:
 """Stage 4: Generate implementation plan."""

 plan = ImplementationPlan(
 feature=requirements.title,
 summary=requirements.summary
 )

 # Generate tasks
 plan.tasks = await self._generate_tasks(design, analysis)

 # Estimate complexity
 plan.estimates = await self._estimate_complexity(plan.tasks, analysis)

 # Analyze risks
 plan.risks = await self._analyze_risks(requirements, design, analysis)

 # Determine milestones
 plan.milestones = await self._define_milestones(plan.tasks)

 # Calculate dependencies between tasks
 plan.task_dependencies = await self._calculate_task_dependencies(plan.tasks)

 return plan

 async def _generate_tasks(
 self,
 design: Design,
 analysis: CodebaseAnalysis
 ) -> list[Task]:
 """Break down design into tasks."""

 tasks = []

 # Tasks for each component
 for component in design.components:
 component_tasks = await self._tasks_for_component(component, analysis)
 tasks.extend(component_tasks)

 # API tasks
 if design.api:
 api_tasks = await self._tasks_for_api(design.api)
 tasks.extend(api_tasks)

 # Data model tasks
 if design.data_model:
 data_tasks = await self._tasks_for_data_model(design.data_model)
 tasks.extend(data_tasks)

 # Testing tasks
 if self.config.planning.task_breakdown.include_tests:
 test_tasks = await self._generate_test_tasks(tasks)
 tasks.extend(test_tasks)

 # Documentation tasks
 if self.config.planning.task_breakdown.include_docs:
 doc_tasks = await self._generate_doc_tasks(design)
 tasks.extend(doc_tasks)

 return tasks

 async def _estimate_complexity(
 self,
 tasks: list[Task],
 analysis: CodebaseAnalysis
 ) -> Estimates:
 """Estimate task complexity."""

 estimates = Estimates()

 for task in tasks:
 # Factors affecting complexity
 factors = {
 "code_familiarity": self._calculate_familiarity(
 task, analysis.patterns
 ),
 "integration_complexity": self._calculate_integration_complexity(
 task, analysis.integration_points
 ),
 "technical_uncertainty": task.uncertainty,
 "dependency_count": len(task.dependencies)
 }

 # Calculate complexity score
 complexity = self._calculate_complexity_score(factors)

 estimates.task_estimates[task.id] = TaskEstimate(
 complexity_points=complexity,
 confidence=self._estimate_confidence(factors),
 factors=factors
 )

 # Total estimate
 estimates.total = sum(e.complexity_points for e in estimates.task_estimates.values())
 estimates.confidence = min(e.confidence for e in estimates.task_estimates.values())

 return estimates

 async def _analyze_risks(
 self,
 requirements: Requirements,
 design: Design,
 analysis: CodebaseAnalysis
 ) -> list[Risk]:
 """Analyze implementation risks."""

 risks = []

 # Technical risks
 if any(c.is_new for c in design.components):
 risks.append(Risk(
 category="technical_risk",
 title="New component complexity",
 description="New components may have unforeseen complexity",
 likelihood="medium",
 impact="medium",
 mitigation="Prototype new components early, get architecture review"
 ))

 # Integration risks
 if len(analysis.integration_points) > 3:
 risks.append(Risk(
 category="integration_risk",
 title="Multiple integration points",
 description=f"Feature touches {len(analysis.integration_points)} integration points",
 likelihood="medium",
 impact="high",
 mitigation="Create integration tests early, coordinate with component owners"
 ))

 # Scope risks
 if len(requirements.user_stories) > 5:
 risks.append(Risk(
 category="scope_risk",
 title="Large scope",
 description="Feature has many user stories that may expand",
 likelihood="high",
 impact="medium",
 mitigation="Prioritize MVP stories, defer nice-to-haves"
 ))

 # Dependency risks
 external_deps = [d for d in analysis.dependencies if d.is_external]
 if external_deps:
 risks.append(Risk(
 category="dependency_risk",
 title="External dependencies",
 description=f"Feature depends on {len(external_deps)} external services",
 likelihood="medium",
 impact="high",
 mitigation="Create mocks/stubs, have fallback behavior"
 ))

 return risks

class TaskGenerator:
 """Generate implementation tasks from design."""

 async def tasks_for_component(
 self,
 component: ComponentDesign,
 analysis: CodebaseAnalysis,
 granularity: str
 ) -> list[Task]:
 """Generate tasks for a component."""

 tasks = []

 if component.is_new:
 # New component tasks
 tasks.append(Task(
 title=f"Create {component.name} component",
 description=f"Implement {component.purpose}",
 type="implementation",
 component=component.name,
 acceptance_criteria=[
 f"Implements: {', '.join(component.responsibilities)}",
 "Follows existing code patterns",
 "Has unit tests"
 ]
 ))

 if granularity in ("fine", "medium"):
 # Add interface tasks
 for interface in component.interfaces:
 tasks.append(Task(
 title=f"Implement {component.name}.{interface.name}",
 description=interface.description,
 type="implementation",
 component=component.name,
 parent=tasks[0].id
 ))

 else:
 # Modification tasks
 tasks.append(Task(
 title=f"Modify {component.modifies} for {component.name}",
 description=f"Add {component.purpose} to existing component",
 type="modification",
 component=component.modifies,
 file_path=component.file_path
 ))

 return tasks`
```

---

### Output Formats

#### Technical Specification (Markdown)

 markdown
 Copy

`# Technical Specification: User Notification Preferences

## Overview

Allow users to customize their notification preferences across email,
push, and in-app channels.

## Requirements Summary

### User Stories
1. As a user, I want to enable/disable notification channels
2. As a user, I want to set quiet hours
3. As a user, I want per-notification-type preferences

### Constraints
- Must be backwards compatible with existing notifications
- Must support GDPR data export

---

## Architecture

### Components

#### 1. NotificationPreferenceService (New)
**Purpose**: Manage user notification preferences
**Location**: `src/services/notification-preferences/`

**Interfaces**:
- `getPreferences(userId): Preferences`
- `updatePreferences(userId, updates): Preferences`
- `checkShouldNotify(userId, type, channel): boolean`

**Dependencies**:
- UserService
- NotificationService (existing, to be modified)

#### 2. NotificationService (Modification)
**Changes**: Add preference checking before sending
**Location**: `src/services/notifications/notification-service.ts`

### Data Model`
```

CREATE TABLE notification_preferences (

 id UUID PRIMARY KEY,

 user_id UUID REFERENCES users(id),

 channel VARCHAR(50), -- email, push, in_app

 notification_type VARCHAR(100),

 enabled BOOLEAN DEFAULT true,

 quiet_hours_start TIME,

 quiet_hours_end TIME,

 created_at TIMESTAMP,

 updated_at TIMESTAMP

);

 text
 Copy

`### API`
```

/api/v1/users/{userId}/notification-preferences:

 GET:

 summary: Get user notification preferences

 responses:

 200:

 schema: NotificationPreferences

 PATCH:

 summary: Update notification preferences

 body:

 schema: NotificationPreferenceUpdate

 text
 Copy

`---

## Implementation Plan

### Milestone 1: Core Preference Management (Week 1)
- [ ] Create NotificationPreferenceService
- [ ] Create database migration
- [ ] Implement CRUD API endpoints
- [ ] Add unit tests

### Milestone 2: Integration (Week 2)
- [ ] Modify NotificationService to check preferences
- [ ] Add quiet hours logic
- [ ] Integration tests

### Milestone 3: UI & Polish (Week 3)
- [ ] Settings UI component
- [ ] Notification preview
- [ ] Documentation

---

## Estimates

| Task | Complexity | Confidence |
|------|------------|------------|
| NotificationPreferenceService | 5 points | 85% |
| Database migration | 2 points | 95% |
| API endpoints | 3 points | 90% |
| NotificationService modification | 3 points | 80% |
| UI components | 5 points | 75% |
| **Total** | **18 points** | **80%** |

---

## Risks

### Medium Risk: NotificationService Modification
**Impact**: Could affect existing notification delivery
**Mitigation**: Feature flag, comprehensive integration tests

### Low Risk: Performance
**Impact**: Additional DB query per notification
**Mitigation**: Cache preferences, batch queries`
```

#### JIRA Export

 python
 Copy

`# Generated JIRA tickets
{
 "epic": {
 "project": "PROJ",
 "type": "Epic",
 "summary": "User Notification Preferences",
 "description": "Allow users to customize notification preferences..."
 },
 "stories": [
 {
 "type": "Story",
 "summary": "User can enable/disable notification channels",
 "description": "As a user, I want to...",
 "acceptance_criteria": "...",
 "story_points": 5
 },
 # ...
 ],
 "tasks": [
 {
 "type": "Task",
 "summary": "Create NotificationPreferenceService",
 "parent": "PROJ-123", # Story key
 "description": "Implement service with CRUD operations",
 "complexity_points": 5
 },
 # ...
 ]
}`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `analysis.scope.include` | list | ["src/**"] | Paths to analyze
 
 | `design.constraints.backwards_compatible` | bool | true | Require backwards compat
 
 | `planning.task_breakdown.granularity` | string | "medium" | Task detail level
 
 | `planning.estimation.method` | string | "complexity_points" | Estimation method
 
 | `output.jira.create_tickets` | bool | false | Create actual tickets

---

### Dependencies

#### Required Tools

- `tool-codebase-search` - Code analysis
 
- `tool-architecture-map` - Architecture visualization
 
- `tool-dependency-graph` - Dependency analysis
 
#### Optional Integrations

- JIRA API
 
- Confluence API
 
- Notion API
 
---

### Open Questions

- Template library: Provide templates for common feature types?
 
- Historical data: Use past estimates to improve accuracy?
 
- Collaboration: Support multi-user planning sessions?
 
- Integration: Deeper IDE integration for viewing plans?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Incident Responder
 scenario-tools

Priority: P0 (Critical Path)

Status: Draft

Module: `amplifier-scenario-incident-responder`

### Overview

Automated incident response workflow that gathers context, analyzes symptoms, suggests root causes, and coordinates remediation. Reduces MTTR by automating the information gathering and initial diagnosis phases.

#### Value Proposition

 | 
 
 | Without | With

 | Manual log diving | Automated log aggregation
 
 | Knowledge scattered | Relevant context surfaced
 
 | Slow initial diagnosis | Rapid symptom analysis
 
 | War room chaos | Structured response workflow

---

### Workflow Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Incident Response Pipeline â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Alert â”‚â”€â”€â”€â–¶â”‚ Context â”‚â”€â”€â”€â–¶â”‚ Diagnose â”‚â”€â”€â”€â–¶â”‚ Remediateâ”‚ â”‚
â”‚ â”‚ Ingest â”‚ â”‚ Gather â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â–¼ â–¼ â–¼ â–¼ â”‚
â”‚ â€¢ PagerDuty â€¢ Recent deploys â€¢ Log analysis â€¢ Rollback? â”‚
â”‚ â€¢ Datadog â€¢ Code changes â€¢ Error patternsâ€¢ Config fix? â”‚
â”‚ â€¢ Slack â€¢ Related alerts â€¢ Correlation â€¢ Scale? â”‚
â”‚ â€¢ Custom â€¢ System metrics â€¢ Root cause â€¢ Communicate â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Document â”‚â—€â”€â”€ Throughout â”‚
â”‚ â”‚ & Learn â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ â€¢ Timeline â”‚
â”‚ â€¢ Postmortem â”‚
â”‚ â€¢ Runbook update â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Configuration

 yaml
 Copy

`scenario:
 name: incident-responder
 version: "1.0.0"

 # Alert sources
 alerts:
 sources:
 pagerduty:
 enabled: true
 api_key: "${PAGERDUTY_API_KEY}"
 datadog:
 enabled: true
 api_key: "${DD_API_KEY}"
 app_key: "${DD_APP_KEY}"
 slack:
 enabled: true
 channel: "#incidents"

 # Context gathering
 context:
 # Recent deployments
 deployments:
 sources:
 - github-actions
 - argocd
 - jenkins
 lookback: 24h

 # Code changes
 code:
 lookback: 48h
 focus_areas: # Priority areas to check
 - config
 - database
 - api
 - dependencies

 # Observability
 metrics:
 provider: datadog # datadog | prometheus | cloudwatch
 queries:
 error_rate: "sum:http.requests{status:5xx}.as_rate()"
 latency_p99: "avg:http.request.latency.p99{*}"
 cpu: "avg:system.cpu.user{*}"
 memory: "avg:system.mem.used{*}"
 lookback: 4h

 # Logs
 logs:
 provider: datadog # datadog | elasticsearch | cloudwatch
 lookback: 2h
 max_entries: 1000
 focus_patterns:
 - "error"
 - "exception"
 - "timeout"
 - "connection refused"

 # Related incidents
 history:
 similar_lookback: 90d
 correlation_threshold: 0.7

 # Diagnosis
 diagnosis:
 # Analysis approaches
 approaches:
 log_pattern_analysis: true
 metric_correlation: true
 change_correlation: true
 similar_incident_match: true

 # Root cause categories
 categories:
 - deployment_issue
 - configuration_error
 - capacity_problem
 - dependency_failure
 - code_bug
 - external_factor

 # Remediation
 remediation:
 # Automated actions (require approval)
 actions:
 rollback:
 enabled: true
 require_approval: true
 scale:
 enabled: true
 require_approval: true
 config_revert:
 enabled: true
 require_approval: true

 # Communication
 communication:
 slack_channel: "#incidents"
 status_page: true
 stakeholder_notify: true

 # Documentation
 documentation:
 timeline: true
 auto_postmortem: true
 runbook_suggestions: true`
```

---

### Pipeline Implementation

 python
 Copy

`class IncidentResponderScenario:
 """Automated incident response workflow."""

 def __init__(self, config: IncidentConfig):
 self.config = config
 self.tools = ToolRegistry()
 self.timeline = Timeline()

 async def respond(self, alert: Alert) -> IncidentReport:
 """Execute incident response pipeline."""

 # Initialize incident
 incident = await self._initialize_incident(alert)
 self.timeline.add("Incident started", alert.summary)

 # Stage 1: Gather Context
 context = await self._gather_context(incident)
 self.timeline.add("Context gathered", f"{len(context.items)} items")

 # Stage 2: Diagnose
 diagnosis = await self._diagnose(incident, context)
 self.timeline.add("Diagnosis complete", diagnosis.summary)

 # Stage 3: Suggest Remediation
 remediation = await self._suggest_remediation(diagnosis)
 self.timeline.add("Remediation suggested", remediation.summary)

 # Stage 4: Coordinate Response
 if self.config.remediation.communication.slack_channel:
 await self._post_status(incident, diagnosis, remediation)

 # Generate report
 return await self._generate_report(
 incident, context, diagnosis, remediation
 )

 async def _gather_context(self, incident: Incident) -> IncidentContext:
 """Stage 1: Gather all relevant context."""

 context = IncidentContext()

 # Parallel context gathering
 tasks = [
 self._get_recent_deploys(incident),
 self._get_recent_changes(incident),
 self._get_metrics(incident),
 self._get_logs(incident),
 self._get_similar_incidents(incident),
 self._get_related_alerts(incident),
 ]

 results = await asyncio.gather(*tasks, return_exceptions=True)

 context.deployments = results[0] if not isinstance(results[0], Exception) else []
 context.code_changes = results[1] if not isinstance(results[1], Exception) else []
 context.metrics = results[2] if not isinstance(results[2], Exception) else {}
 context.logs = results[3] if not isinstance(results[3], Exception) else []
 context.similar_incidents = results[4] if not isinstance(results[4], Exception) else []
 context.related_alerts = results[5] if not isinstance(results[5], Exception) else []

 return context

 async def _get_recent_deploys(self, incident: Incident) -> list[Deployment]:
 """Get recent deployments."""
 deployments = []

 for source in self.config.context.deployments.sources:
 if source == "github-actions":
 runs = await self._query_github_actions(incident)
 deployments.extend(runs)
 elif source == "argocd":
 syncs = await self._query_argocd(incident)
 deployments.extend(syncs)

 # Sort by time, most recent first
 deployments.sort(key=lambda d: d.timestamp, reverse=True)

 return deployments

 async def _get_logs(self, incident: Incident) -> list[LogEntry]:
 """Fetch relevant logs."""
 metrics_tool = self.tools.get("tool-metrics-query")

 # Build log query based on incident
 query = self._build_log_query(incident)

 logs = await metrics_tool.execute({
 "action": "query_logs",
 "provider": self.config.context.logs.provider,
 "query": query,
 "start_time": incident.started_at - timedelta(
 hours=int(self.config.context.logs.lookback.rstrip('h'))
 ),
 "end_time": datetime.utcnow(),
 "limit": self.config.context.logs.max_entries
 })

 # Filter for relevant entries
 filtered = self._filter_relevant_logs(logs, incident)

 return filtered

 async def _diagnose(
 self,
 incident: Incident,
 context: IncidentContext
 ) -> Diagnosis:
 """Stage 2: Analyze and diagnose."""

 hypotheses = []

 # Approach 1: Log pattern analysis
 if self.config.diagnosis.approaches.log_pattern_analysis:
 log_hypothesis = await self._analyze_log_patterns(context.logs)
 if log_hypothesis:
 hypotheses.append(log_hypothesis)

 # Approach 2: Metric correlation
 if self.config.diagnosis.approaches.metric_correlation:
 metric_hypothesis = await self._analyze_metric_correlation(
 context.metrics, incident
 )
 if metric_hypothesis:
 hypotheses.append(metric_hypothesis)

 # Approach 3: Change correlation
 if self.config.diagnosis.approaches.change_correlation:
 change_hypothesis = await self._correlate_changes(
 context.deployments, context.code_changes, incident
 )
 if change_hypothesis:
 hypotheses.append(change_hypothesis)

 # Approach 4: Similar incident matching
 if self.config.diagnosis.approaches.similar_incident_match:
 similar_hypothesis = await self._match_similar_incidents(
 context.similar_incidents, incident
 )
 if similar_hypothesis:
 hypotheses.append(similar_hypothesis)

 # Synthesize diagnosis
 diagnosis = await self._synthesize_diagnosis(hypotheses, context)

 return diagnosis

 async def _analyze_log_patterns(self, logs: list[LogEntry]) -> Hypothesis | None:
 """Analyze logs for error patterns."""

 # Extract error patterns
 error_patterns = defaultdict(int)
 error_examples = defaultdict(list)

 for log in logs:
 if log.level in ("error", "fatal"):
 pattern = self._extract_pattern(log.message)
 error_patterns[pattern] += 1
 if len(error_examples[pattern]) < 3:
 error_examples[pattern].append(log)

 if not error_patterns:
 return None

 # Find dominant pattern
 dominant = max(error_patterns, key=error_patterns.get)
 count = error_patterns[dominant]

 # Analyze pattern
 analysis = await self._analyze_error_pattern(
 dominant, error_examples[dominant]
 )

 return Hypothesis(
 category=analysis.category,
 description=analysis.description,
 confidence=min(0.9, count / 100), # More occurrences = higher confidence
 evidence=[
 f"Error pattern occurred {count} times",
 f"First occurrence: {error_examples[dominant][0].timestamp}",
 f"Example: {error_examples[dominant][0].message[:200]}"
 ],
 suggested_actions=analysis.suggested_actions
 )

 async def _correlate_changes(
 self,
 deployments: list[Deployment],
 code_changes: list[CodeChange],
 incident: Incident
 ) -> Hypothesis | None:
 """Correlate incident with recent changes."""

 # Find changes in time window before incident
 window_start = incident.started_at - timedelta(hours=4)

 suspect_deploys = [
 d for d in deployments
 if window_start <= d.timestamp <= incident.started_at
 ]

 if not suspect_deploys:
 return None

 # Most recent deployment is prime suspect
 prime_suspect = suspect_deploys[0]

 # Analyze what changed
 changes = await self._analyze_deployment_changes(prime_suspect)

 return Hypothesis(
 category="deployment_issue",
 description=f"Incident correlates with deployment {prime_suspect.id}",
 confidence=0.7,
 evidence=[
 f"Deployment at {prime_suspect.timestamp}",
 f"Incident started at {incident.started_at}",
 f"Time between: {incident.started_at - prime_suspect.timestamp}",
 f"Changes: {', '.join(changes.summary)}"
 ],
 suggested_actions=[
 f"Consider rollback to {prime_suspect.previous_version}",
 "Review deployment changes for issues",
 "Check deployment health metrics"
 ],
 metadata={
 "deployment_id": prime_suspect.id,
 "previous_version": prime_suspect.previous_version,
 "changes": changes
 }
 )

 async def _suggest_remediation(self, diagnosis: Diagnosis) -> Remediation:
 """Stage 3: Suggest remediation actions."""

 actions = []

 for hypothesis in diagnosis.hypotheses:
 if hypothesis.category == "deployment_issue":
 if hypothesis.confidence >= 0.6:
 actions.append(RemediationAction(
 type="rollback",
 description="Roll back to previous version",
 command=f"kubectl rollout undo deployment/{hypothesis.metadata['deployment']}",
 risk="low",
 require_approval=True
 ))

 elif hypothesis.category == "capacity_problem":
 actions.append(RemediationAction(
 type="scale",
 description="Scale up affected service",
 command=f"kubectl scale deployment/{hypothesis.metadata['service']} --replicas=+2",
 risk="low",
 require_approval=True
 ))

 elif hypothesis.category == "configuration_error":
 actions.append(RemediationAction(
 type="config_revert",
 description="Revert configuration change",
 risk="medium",
 require_approval=True
 ))

 # Add communication actions
 actions.append(RemediationAction(
 type="communicate",
 description="Update status page",
 risk="none",
 require_approval=False
 ))

 return Remediation(
 primary_action=actions[0] if actions else None,
 alternative_actions=actions[1:],
 communication_plan=await self._generate_comms_plan(diagnosis)
 )

 async def _post_status(
 self,
 incident: Incident,
 diagnosis: Diagnosis,
 remediation: Remediation
 ) -> None:
 """Post status update to Slack."""

 slack_tool = self.tools.get("tool-slack-search")

 message = self._format_status_message(incident, diagnosis, remediation)

 await slack_tool.execute({
 "action": "post",
 "channel": self.config.remediation.communication.slack_channel,
 "message": message,
 "thread_ts": incident.slack_thread_ts # Continue in thread if exists
 })`
```

---

### Status Message Format

 markdown
 Copy

`ðŸš¨ **Incident Update: Payment Processing Errors**

**Status**: Investigating
**Severity**: P1
**Duration**: 23 minutes

---

### Summary
Payment API returning 500 errors for ~15% of requests since 14:32 UTC.

### Initial Diagnosis
**Most Likely Cause**: Recent deployment (deploy-abc123 at 14:28 UTC)
**Confidence**: 75%

**Evidence**:
- Error spike began 4 minutes after deployment
- Errors concentrated in new payment validation code
- No infrastructure anomalies detected

### Suggested Actions
1. âš¡ **Recommended**: Rollback to previous version (v2.3.4)
2. ðŸ”§ Alternative: Hot-fix validation logic
3. ðŸ“ž Notify payment team

### Timeline
- 14:28 - Deployment deploy-abc123 completed
- 14:32 - First errors detected
- 14:35 - Alert triggered (PagerDuty)
- 14:37 - Incident responder activated
- 14:45 - Initial diagnosis complete

---
ðŸ¤– *Generated by Incident Responder*`
```

---

### Postmortem Generation

 python
 Copy

`class PostmortemGenerator:
 """Generate postmortem from incident data."""

 async def generate(
 self,
 incident: Incident,
 timeline: Timeline,
 diagnosis: Diagnosis,
 remediation_taken: RemediationAction
 ) -> Postmortem:
 """Generate structured postmortem."""

 return Postmortem(
 title=f"Postmortem: {incident.title}",
 date=incident.started_at.date(),
 duration=incident.resolved_at - incident.started_at,
 severity=incident.severity,

 summary=await self._generate_summary(incident, diagnosis),

 impact=Impact(
 users_affected=incident.metrics.users_affected,
 requests_failed=incident.metrics.requests_failed,
 revenue_impact=incident.metrics.revenue_impact,
 sla_breach=incident.metrics.sla_breach
 ),

 timeline=timeline.entries,

 root_cause=RootCause(
 category=diagnosis.primary_hypothesis.category,
 description=diagnosis.primary_hypothesis.description,
 evidence=diagnosis.primary_hypothesis.evidence
 ),

 resolution=Resolution(
 action_taken=remediation_taken.description,
 time_to_resolve=incident.resolved_at - incident.started_at,
 verified_by=remediation_taken.verified_by
 ),

 lessons_learned=await self._extract_lessons(incident, diagnosis),

 action_items=await self._generate_action_items(incident, diagnosis),

 appendix=Appendix(
 logs=incident.key_logs,
 metrics=incident.key_metrics,
 related_links=incident.related_links
 )
 )

 async def _generate_action_items(
 self,
 incident: Incident,
 diagnosis: Diagnosis
 ) -> list[ActionItem]:
 """Generate follow-up action items."""

 items = []

 # Prevention items
 if diagnosis.primary_hypothesis.category == "deployment_issue":
 items.append(ActionItem(
 type="prevention",
 title="Improve deployment canary analysis",
 description="Add automated canary metrics checking",
 priority="high",
 owner=None # To be assigned
 ))

 # Detection items
 if incident.time_to_detect > timedelta(minutes=5):
 items.append(ActionItem(
 type="detection",
 title="Improve alerting thresholds",
 description=f"Current TTD was {incident.time_to_detect}, target is <5min",
 priority="medium"
 ))

 # Documentation items
 items.append(ActionItem(
 type="documentation",
 title="Update runbook for this failure mode",
 description=f"Add steps for {diagnosis.primary_hypothesis.category}",
 priority="low"
 ))

 return items`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `context.deployments.lookback` | string | "24h" | Deploy history window
 
 | `context.logs.lookback` | string | "2h" | Log query window
 
 | `context.metrics.lookback` | string | "4h" | Metrics window
 
 | `diagnosis.approaches.*` | bool | true | Enable diagnosis approaches
 
 | `remediation.actions.*.require_approval` | bool | true | Require human approval

---

### Dependencies

#### Required Tools

- `tool-metrics-query` - Observability data
 
- `tool-git-advanced` - Change correlation
 
- `tool-slack-search` - Communication
 
#### External Integrations

- PagerDuty / OpsGenie API
 
- Datadog / Prometheus
 
- GitHub / GitLab
 
- Slack
 
---

### Open Questions

- Automated remediation: How much automation without human approval?
 
- ML diagnosis: Train on past incidents for better pattern matching?
 
- Runbook integration: Link to and execute runbooks?
 
- Multi-service correlation: Handle distributed system incidents?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Pr Reviewer
 scenario-tools

Priority: P0 (Critical Path)

Status: Draft

Module: `amplifier-scenario-pr-reviewer`

### Overview

Comprehensive pull request review automation that analyzes code changes, checks for issues, runs tests, and provides structured feedback. Combines multiple tools and hooks into a coherent review workflow that augments human reviewers.

#### Value Proposition

 | 
 
 | Without | With

 | Manual code inspection | Automated issue detection
 
 | Missed edge cases | Systematic coverage analysis
 
 | Inconsistent review quality | Standardized review checklist
 
 | Hours per complex PR | Minutes with human verification

---

### Workflow Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PR Review Pipeline â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Context â”‚â”€â”€â”€â–¶â”‚ Analysis â”‚â”€â”€â”€â–¶â”‚ Testing â”‚â”€â”€â”€â–¶â”‚ Report â”‚ â”‚
â”‚ â”‚ Gather â”‚ â”‚ Phase â”‚ â”‚ Phase â”‚ â”‚ Generate â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â–¼ â–¼ â–¼ â–¼ â”‚
â”‚ â€¢ PR metadata â€¢ Security â€¢ Run tests â€¢ Summary â”‚
â”‚ â€¢ File diffs â€¢ Code quality â€¢ Coverage â€¢ Issues list â”‚
â”‚ â€¢ Related PRs â€¢ Breaking â€¢ Performance â€¢ Suggestions â”‚
â”‚ â€¢ Linked issues changes â€¢ Linting â€¢ Approval rec â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Configuration

 yaml
 Copy

`scenario:
 name: pr-reviewer
 version: "1.0.0"

 # Input
 input:
 pr_url: "${PR_URL}" # Required: GitHub/GitLab PR URL
 depth: standard # quick | standard | thorough

 # Pipeline stages
 stages:
 context:
 enabled: true
 tools:
 - tool-pr-context
 - tool-jira-ops
 config:
 fetch_linked_issues: true
 fetch_related_prs: true
 max_related: 5

 analysis:
 enabled: true
 parallel: true # Run analyses in parallel
 analyses:
 security:
 enabled: true
 hook: hooks-security-scan
 severity_threshold: medium

 code_quality:
 enabled: true
 tool: tool-codebase-search
 checks:
 - complexity
 - duplication
 - naming
 - documentation

 breaking_changes:
 enabled: true
 hook: hooks-breaking-change
 check_api: true
 check_schema: true

 license:
 enabled: true
 hook: hooks-license-checker

 architecture:
 enabled: true
 tool: tool-dependency-graph
 check_cycles: true
 check_boundaries: true

 testing:
 enabled: true
 tool: tool-test-runner
 config:
 run_affected: true # Only tests affected by changes
 coverage_threshold: 80
 require_new_tests: true # New code needs tests

 style:
 enabled: true
 hook: hooks-style-enforcer
 auto_fix: false # Don't auto-fix in review

 # Output
 output:
 format: markdown # markdown | json | github-review
 post_comment: true # Post as PR comment
 request_changes: auto # auto | manual | never
 approve_threshold: 0 # 0 issues = auto approve suggestion

 # Customization
 rules:
 # File-specific rules
 paths:
 - pattern: "src/api/**"
 require_openapi_update: true
 - pattern: "migrations/**"
 require_dba_approval: true
 - pattern: "*.test.*"
 skip_coverage_check: true

 # Reviewer-specific
 expertise_match: true # Match reviewers to changed areas`
```

---

### Pipeline Implementation

 python
 Copy

`class PRReviewerScenario:
 """Comprehensive PR review automation."""

 def __init__(self, config: PRReviewerConfig):
 self.config = config
 self.tools = ToolRegistry()
 self.hooks = HookRegistry()

 async def run(self, pr_url: str) -> ReviewReport:
 """Execute full review pipeline."""

 # Stage 1: Gather Context
 context = await self._gather_context(pr_url)

 # Stage 2: Run Analyses (parallel)
 analyses = await self._run_analyses(context)

 # Stage 3: Run Tests
 test_results = await self._run_tests(context)

 # Stage 4: Style Check
 style_results = await self._check_style(context)

 # Stage 5: Generate Report
 report = await self._generate_report(
 context, analyses, test_results, style_results
 )

 # Stage 6: Post Results
 if self.config.output.post_comment:
 await self._post_comment(pr_url, report)

 return report

 async def _gather_context(self, pr_url: str) -> PRContext:
 """Stage 1: Gather all relevant context."""

 # Get PR details
 pr_context_tool = self.tools.get("tool-pr-context")
 pr_data = await pr_context_tool.execute({
 "pr_url": pr_url,
 "include_diff": True,
 "include_comments": True,
 "include_reviews": True
 })

 # Get linked issues
 jira_tool = self.tools.get("tool-jira-ops")
 linked_issues = []

 for issue_ref in pr_data.get("linked_issues", []):
 issue = await jira_tool.execute({
 "action": "get",
 "issue_key": issue_ref
 })
 linked_issues.append(issue)

 # Get related PRs
 related_prs = await pr_context_tool.execute({
 "action": "find_related",
 "pr_url": pr_url,
 "max_results": self.config.stages.context.config.max_related
 })

 return PRContext(
 pr=pr_data,
 linked_issues=linked_issues,
 related_prs=related_prs,
 changed_files=pr_data["changed_files"],
 diff=pr_data["diff"]
 )

 async def _run_analyses(self, context: PRContext) -> AnalysisResults:
 """Stage 2: Run all configured analyses in parallel."""

 tasks = []
 results = AnalysisResults()

 if self.config.stages.analysis.analyses.security.enabled:
 tasks.append(self._analyze_security(context))

 if self.config.stages.analysis.analyses.code_quality.enabled:
 tasks.append(self._analyze_quality(context))

 if self.config.stages.analysis.analyses.breaking_changes.enabled:
 tasks.append(self._analyze_breaking(context))

 if self.config.stages.analysis.analyses.license.enabled:
 tasks.append(self._analyze_licenses(context))

 if self.config.stages.analysis.analyses.architecture.enabled:
 tasks.append(self._analyze_architecture(context))

 # Run in parallel
 completed = await asyncio.gather(*tasks, return_exceptions=True)

 # Collect results
 for result in completed:
 if isinstance(result, Exception):
 results.errors.append(str(result))
 else:
 results.merge(result)

 return results

 async def _analyze_security(self, context: PRContext) -> SecurityAnalysis:
 """Run security analysis on changed files."""

 security_hook = self.hooks.get("hooks-security-scan")
 issues = []

 for file in context.changed_files:
 result = await security_hook({
 "file_path": file.path,
 "content": file.new_content,
 "diff": file.diff
 })

 if result.findings:
 issues.extend(result.findings)

 # Filter by severity threshold
 threshold = self.config.stages.analysis.analyses.security.severity_threshold
 filtered = [i for i in issues if i.severity >= threshold]

 return SecurityAnalysis(
 issues=filtered,
 passed=len([i for i in filtered if i.severity == "high"]) == 0
 )

 async def _analyze_breaking(self, context: PRContext) -> BreakingAnalysis:
 """Check for breaking changes."""

 breaking_hook = self.hooks.get("hooks-breaking-change")
 changes = []

 for file in context.changed_files:
 if file.old_content: # Existing file modified
 result = await breaking_hook.analyze(
 file.path,
 file.old_content,
 file.new_content
 )
 changes.extend(result.breaking_changes)

 return BreakingAnalysis(
 changes=changes,
 requires_version_bump=len(changes) > 0
 )

 async def _run_tests(self, context: PRContext) -> TestResults:
 """Stage 3: Run relevant tests."""

 test_tool = self.tools.get("tool-test-runner")

 # Determine affected tests
 affected = await test_tool.execute({
 "action": "find_affected",
 "changed_files": [f.path for f in context.changed_files]
 })

 # Run tests
 results = await test_tool.execute({
 "action": "run",
 "test_files": affected,
 "coverage": True
 })

 # Check coverage for new code
 if self.config.stages.testing.config.require_new_tests:
 new_code_coverage = self._calculate_new_code_coverage(
 context, results.coverage
 )
 results.new_code_coverage = new_code_coverage

 return results

 async def _generate_report(
 self,
 context: PRContext,
 analyses: AnalysisResults,
 tests: TestResults,
 style: StyleResults
 ) -> ReviewReport:
 """Stage 5: Generate comprehensive review report."""

 # Collect all issues
 all_issues = []
 all_issues.extend(analyses.security.issues)
 all_issues.extend(analyses.breaking.changes)
 all_issues.extend(analyses.quality.issues)
 all_issues.extend(style.issues)

 # Determine recommendation
 blocking_issues = [i for i in all_issues if i.blocking]
 recommendation = self._determine_recommendation(
 blocking_issues, tests, analyses
 )

 # Generate summary using LLM
 summary = await self._generate_summary(context, all_issues, tests)

 return ReviewReport(
 pr_url=context.pr["url"],
 summary=summary,
 recommendation=recommendation,
 issues=all_issues,
 test_results=tests,
 analyses=analyses,
 suggested_reviewers=await self._suggest_reviewers(context)
 )

 def _determine_recommendation(
 self,
 blocking_issues: list,
 tests: TestResults,
 analyses: AnalysisResults
 ) -> ReviewRecommendation:
 """Determine review recommendation."""

 if blocking_issues:
 return ReviewRecommendation(
 action="request_changes",
 reason=f"{len(blocking_issues)} blocking issues found",
 confidence=0.9
 )

 if not tests.passed:
 return ReviewRecommendation(
 action="request_changes",
 reason="Tests failing",
 confidence=0.95
 )

 if analyses.security.issues:
 return ReviewRecommendation(
 action="comment",
 reason="Security findings require review",
 confidence=0.7
 )

 # All checks passed
 return ReviewRecommendation(
 action="approve",
 reason="All automated checks passed",
 confidence=0.8
 )`
```

---

### Report Format

#### Markdown Output

 markdown
 Copy

`# PR Review: Add payment retry logic (#1234)

## Summary

This PR adds exponential backoff retry logic to the payment gateway.
Changes look good overall with a few minor suggestions.

**Recommendation: âœ… Approve** (with comments)

---

## Analysis Results

### Security (âœ… Passed)
No security issues detected.

### Breaking Changes (âš ï¸ Warning)
- API endpoint `POST /payments` has new required field `idempotency_key`
 - **Suggestion**: Make field optional for backward compatibility

### Code Quality (âœ… Passed)
- Complexity: Within limits
- Duplication: None detected
- Test coverage: 87% (threshold: 80%)

### License Check (âœ… Passed)
No new dependencies with restricted licenses.

---

## Test Results

| Suite | Passed | Failed | Skipped |
|-------|--------|--------|---------|
| Unit | 45 | 0 | 2 |
| Integration | 12 | 0 | 0 |

**Coverage**: 87% overall, 92% for new code

---

## Issues (3)

### ðŸ”´ High Priority

1. **Missing error handling** (src/payments/gateway.py:142)
 ```python
 # Current
 response = await client.post(url, data)

 # Suggested
 try:
 response = await client.post(url, data)
 except TimeoutError:
 raise PaymentTimeoutError(...)
 ```

### ðŸŸ¡ Medium Priority

2. **Consider adding type hints** (src/payments/retry.py:28)
 Function `calculate_backoff` lacks return type annotation.

### ðŸŸ¢ Low Priority

3. **Documentation update needed** (README.md)
 New retry behavior should be documented.

---

## Suggested Reviewers

Based on code ownership and expertise:
- **@alice** - Primary owner of payments module
- **@bob** - Recent contributor to gateway code

---

*Generated by PR Reviewer v1.0.0*`
```

---

### Integration with CI/CD

#### GitHub Actions

 yaml
 Copy

`name: PR Review
on:
 pull_request:
 types: [opened, synchronize]

jobs:
 review:
 runs-on: ubuntu-latest
 steps:
 - uses: actions/checkout@v4
 with:
 fetch-depth: 0

 - name: Run PR Review
 uses: amplifier/pr-reviewer-action@v1
 with:
 pr-url: ${{ github.event.pull_request.html_url }}
 github-token: ${{ secrets.GITHUB_TOKEN }}
 depth: standard
 post-comment: true`
```

#### GitLab CI

 yaml
 Copy

`pr-review:
 stage: review
 script:
 - amplifier run pr-reviewer --pr-url $CI_MERGE_REQUEST_IID
 rules:
 - if: $CI_PIPELINE_SOURCE == "merge_request_event"`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `input.depth` | string | "standard" | Review depth
 
 | `stages.*.enabled` | bool | true | Enable/disable stages
 
 | `output.format` | string | "markdown" | Output format
 
 | `output.post_comment` | bool | true | Post as PR comment
 
 | `output.request_changes` | string | "auto" | When to request changes
 
 | `rules.expertise_match` | bool | true | Match reviewers to areas

---

### Dependencies

#### Required Tools

- `tool-pr-context` - PR data fetching
 
- `tool-test-runner` - Test execution
 
- `tool-codebase-search` - Code analysis
 
#### Required Hooks

- `hooks-security-scan` - Security analysis
 
- `hooks-breaking-change` - Breaking change detection
 
- `hooks-license-checker` - License compliance
 
- `hooks-style-enforcer` - Style checking
 
#### External

- GitHub/GitLab API access
 
- CI/CD integration (optional)
 
---

### Open Questions

- ML enhancement: Train on past reviews to improve suggestions?
 
- Custom rules: Support organization-specific review rules?
 
- Review history: Track review patterns and outcomes?
 
- Batch review: Review multiple related PRs together?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

 Tech Debt Prioritizer
 scenario-tools

Priority: P1 (High Value)

Status: Draft

Module: `amplifier-scenario-tech-debt-prioritizer`

### Overview

Systematic technical debt identification and prioritization workflow. Scans codebase for debt indicators, calculates business impact, estimates remediation effort, and generates prioritized action plans aligned with product goals.

#### Value Proposition

 | 
 
 | Without | With

 | Invisible accumulating debt | Visible, tracked inventory
 
 | Arbitrary prioritization | Data-driven decisions
 
 | Debt addressed reactively | Strategic planning
 
 | No ROI visibility | Clear cost/benefit analysis

---

### Workflow Architecture

 text
 Copy

`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tech Debt Prioritization Pipeline â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Scan â”‚â”€â”€â”€â–¶â”‚ Analyze â”‚â”€â”€â”€â–¶â”‚ Priorit- â”‚â”€â”€â”€â–¶â”‚ Plan â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ Impact â”‚ â”‚ ize â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â–¼ â–¼ â–¼ â–¼ â”‚
â”‚ â€¢ Code smell â€¢ Velocity â€¢ Business â€¢ Sprints â”‚
â”‚ detection impact alignment â€¢ Resources â”‚
â”‚ â€¢ Complexity â€¢ Bug â€¢ Cost/ â€¢ Dependencies â”‚
â”‚ â€¢ Duplication correlation benefit â€¢ Risks â”‚
â”‚ â€¢ Dependencies â€¢ Change risk â€¢ Quick wins â€¢ Tracking â”‚
â”‚ â€¢ Test coverage â€¢ Team pain â€¢ Critical â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Dashboard â”‚â—€â”€â”€ Continuous â”‚
â”‚ â”‚ & Reporting â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
```

---

### Configuration

 yaml
 Copy

`scenario:
 name: tech-debt-prioritizer
 version: "1.0.0"

 # Scanning
 scan:
 # Code analysis
 code:
 complexity:
 enabled: true
 threshold:
 cyclomatic: 10
 cognitive: 15
 duplication:
 enabled: true
 min_tokens: 50
 min_occurrences: 2
 code_smells:
 enabled: true
 rules:
 - long_method
 - large_class
 - feature_envy
 - shotgun_surgery
 - god_object
 naming:
 enabled: true
 conventions: auto-detect

 # Architecture
 architecture:
 dependency_cycles: true
 layer_violations: true
 unstable_dependencies: true
 dead_code: true

 # Testing
 testing:
 coverage_threshold: 80
 test_quality: true
 flaky_tests: true

 # Dependencies
 dependencies:
 outdated: true
 security_vulnerabilities: true
 deprecated_usage: true
 unmaintained: 365d # Not updated in X days

 # Documentation
 documentation:
 missing_docs: true
 stale_docs: true
 incomplete_api_docs: true

 # Impact analysis
 impact:
 # Correlations
 correlations:
 bugs_by_file: true
 change_frequency: true
 review_time: true
 deployment_failures: true

 # Sources
 sources:
 jira:
 enabled: true
 bug_labels: ["bug", "defect"]
 lookback: 180d
 github:
 enabled: true
 lookback: 365d

 # Prioritization
 prioritization:
 # Scoring weights
 weights:
 business_impact: 0.30
 remediation_effort: 0.20 # Inverse - prefer easier
 bug_correlation: 0.20
 change_risk: 0.15
 team_pain: 0.15

 # Business alignment
 alignment:
 roadmap_areas: # Priority multiplier for roadmap areas
 - path: "src/payments/"
 multiplier: 1.5
 - path: "src/onboarding/"
 multiplier: 1.3

 # Categories
 categories:
 critical: # Address immediately
 threshold: 0.9
 high: # Next quarter
 threshold: 0.7
 medium: # Future planning
 threshold: 0.4
 low: # Track but defer
 threshold: 0.0

 # Output
 output:
 report_format: markdown
 jira_export: true
 dashboard_data: true
 tracking:
 create_epics: false
 update_existing: true`
```

---

### Pipeline Implementation

 python
 Copy

`class TechDebtPrioritizerScenario:
 """Systematic tech debt identification and prioritization."""

 def __init__(self, config: TechDebtConfig):
 self.config = config
 self.tools = ToolRegistry()

 async def run(self) -> TechDebtReport:
 """Execute full tech debt analysis pipeline."""

 # Stage 1: Scan Codebase
 debt_items = await self._scan_codebase()

 # Stage 2: Analyze Impact
 for item in debt_items:
 item.impact = await self._analyze_impact(item)

 # Stage 3: Prioritize
 prioritized = await self._prioritize(debt_items)

 # Stage 4: Generate Plan
 plan = await self._generate_plan(prioritized)

 # Stage 5: Output
 return await self._generate_report(prioritized, plan)

 async def _scan_codebase(self) -> list[DebtItem]:
 """Stage 1: Scan for all tech debt indicators."""

 debt_items = []

 # Code analysis
 if self.config.scan.code.complexity.enabled:
 complexity_issues = await self._scan_complexity()
 debt_items.extend(complexity_issues)

 if self.config.scan.code.duplication.enabled:
 duplication_issues = await self._scan_duplication()
 debt_items.extend(duplication_issues)

 if self.config.scan.code.code_smells.enabled:
 smell_issues = await self._scan_code_smells()
 debt_items.extend(smell_issues)

 # Architecture analysis
 if self.config.scan.architecture.dependency_cycles:
 cycle_issues = await self._scan_dependency_cycles()
 debt_items.extend(cycle_issues)

 if self.config.scan.architecture.dead_code:
 dead_code_issues = await self._scan_dead_code()
 debt_items.extend(dead_code_issues)

 # Testing analysis
 coverage_issues = await self._scan_test_coverage()
 debt_items.extend(coverage_issues)

 # Dependency analysis
 dep_issues = await self._scan_dependencies()
 debt_items.extend(dep_issues)

 # Deduplicate and merge related issues
 debt_items = self._consolidate_issues(debt_items)

 return debt_items

 async def _scan_complexity(self) -> list[DebtItem]:
 """Scan for code complexity issues."""

 debt_tool = self.tools.get("tool-tech-debt-scanner")

 results = await debt_tool.execute({
 "scan_type": "complexity",
 "thresholds": {
 "cyclomatic": self.config.scan.code.complexity.threshold.cyclomatic,
 "cognitive": self.config.scan.code.complexity.threshold.cognitive
 }
 })

 items = []
 for result in results:
 items.append(DebtItem(
 id=f"complexity-{hash(result['file'] + str(result['line']))}",
 type="complexity",
 title=f"High complexity in {result['function']}",
 description=f"Cyclomatic: {result['cyclomatic']}, Cognitive: {result['cognitive']}",
 location=Location(
 file=result["file"],
 line_start=result["line"],
 line_end=result["line_end"]
 ),
 severity=self._complexity_severity(result),
 raw_data=result
 ))

 return items

 async def _scan_duplication(self) -> list[DebtItem]:
 """Scan for code duplication."""

 debt_tool = self.tools.get("tool-tech-debt-scanner")

 results = await debt_tool.execute({
 "scan_type": "duplication",
 "min_tokens": self.config.scan.code.duplication.min_tokens,
 "min_occurrences": self.config.scan.code.duplication.min_occurrences
 })

 items = []
 for dup in results:
 items.append(DebtItem(
 id=f"dup-{hash(str(dup['locations']))}",
 type="duplication",
 title=f"Duplicated code ({dup['occurrences']} occurrences)",
 description=f"{dup['tokens']} tokens duplicated across {dup['occurrences']} locations",
 locations=[Location(**loc) for loc in dup["locations"]],
 severity=self._duplication_severity(dup),
 raw_data=dup
 ))

 return items

 async def _scan_dependencies(self) -> list[DebtItem]:
 """Scan for dependency issues."""

 dep_tool = self.tools.get("tool-dependency-graph")
 items = []

 # Outdated dependencies
 if self.config.scan.dependencies.outdated:
 outdated = await dep_tool.execute({
 "action": "check_outdated"
 })

 for dep in outdated:
 severity = "high" if dep["major_versions_behind"] > 1 else "medium"
 items.append(DebtItem(
 id=f"outdated-{dep['name']}",
 type="outdated_dependency",
 title=f"Outdated: {dep['name']}",
 description=f"Current: {dep['current']}, Latest: {dep['latest']}",
 severity=severity,
 metadata={
 "package": dep["name"],
 "current": dep["current"],
 "latest": dep["latest"],
 "breaking_changes": dep.get("breaking_changes", [])
 }
 ))

 # Security vulnerabilities
 if self.config.scan.dependencies.security_vulnerabilities:
 vulns = await dep_tool.execute({
 "action": "security_audit"
 })

 for vuln in vulns:
 items.append(DebtItem(
 id=f"vuln-{vuln['id']}",
 type="security_vulnerability",
 title=f"Security: {vuln['package']} ({vuln['severity']})",
 description=vuln["description"],
 severity="critical" if vuln["severity"] == "high" else vuln["severity"],
 metadata=vuln
 ))

 return items

 async def _analyze_impact(self, item: DebtItem) -> ImpactAnalysis:
 """Stage 2: Analyze impact of a debt item."""

 impact = ImpactAnalysis()

 # Bug correlation
 if self.config.impact.correlations.bugs_by_file and item.location:
 jira_tool = self.tools.get("tool-jira-ops")
 bugs = await jira_tool.execute({
 "action": "search",
 "jql": f'labels in ({",".join(self.config.impact.sources.jira.bug_labels)}) '
 f'AND text ~ "{item.location.file}"'
 })
 impact.bug_count = len(bugs)
 impact.bug_correlation = min(len(bugs) / 10, 1.0) # Normalize

 # Change frequency
 if self.config.impact.correlations.change_frequency and item.location:
 git_tool = self.tools.get("tool-git-advanced")
 history = await git_tool.execute({
 "action": "file_history",
 "file": item.location.file,
 "days": 365
 })
 impact.change_frequency = len(history)
 impact.change_risk = self._calculate_change_risk(history)

 # Team pain (from PR review times)
 if self.config.impact.correlations.review_time and item.location:
 pr_tool = self.tools.get("tool-pr-context")
 prs = await pr_tool.execute({
 "action": "search",
 "file": item.location.file
 })
 if prs:
 avg_review_time = sum(pr["review_hours"] for pr in prs) / len(prs)
 impact.team_pain = min(avg_review_time / 24, 1.0) # Normalize

 # Business impact (based on area)
 impact.business_impact = self._calculate_business_impact(item)

 return impact

 def _calculate_business_impact(self, item: DebtItem) -> float:
 """Calculate business impact score."""

 base_impact = {
 "security_vulnerability": 1.0,
 "complexity": 0.5,
 "duplication": 0.3,
 "outdated_dependency": 0.4,
 "test_coverage": 0.5,
 "dead_code": 0.2
 }.get(item.type, 0.3)

 # Apply roadmap multiplier
 if item.location:
 for area in self.config.prioritization.alignment.roadmap_areas:
 if item.location.file.startswith(area["path"]):
 base_impact *= area["multiplier"]
 break

 return min(base_impact, 1.0)

 async def _prioritize(self, items: list[DebtItem]) -> list[PrioritizedDebt]:
 """Stage 3: Score and prioritize debt items."""

 weights = self.config.prioritization.weights
 prioritized = []

 for item in items:
 # Calculate composite score
 score = (
 weights.business_impact * item.impact.business_impact +
 weights.remediation_effort * (1 - item.estimated_effort / 40) + # Inverse
 weights.bug_correlation * item.impact.bug_correlation +
 weights.change_risk * item.impact.change_risk +
 weights.team_pain * item.impact.team_pain
 )

 # Determine category
 category = self._categorize_score(score)

 prioritized.append(PrioritizedDebt(
 item=item,
 score=score,
 category=category,
 score_breakdown={
 "business_impact": item.impact.business_impact,
 "effort_score": 1 - item.estimated_effort / 40,
 "bug_correlation": item.impact.bug_correlation,
 "change_risk": item.impact.change_risk,
 "team_pain": item.impact.team_pain
 }
 ))

 # Sort by score descending
 prioritized.sort(key=lambda x: x.score, reverse=True)

 return prioritized

 async def _generate_plan(
 self,
 prioritized: list[PrioritizedDebt]
 ) -> RemediationPlan:
 """Stage 4: Generate actionable remediation plan."""

 plan = RemediationPlan()

 # Quick wins (high score, low effort)
 plan.quick_wins = [
 p for p in prioritized
 if p.score >= 0.6 and p.item.estimated_effort <= 4
 ][:5]

 # Critical items (must address)
 plan.critical = [
 p for p in prioritized
 if p.category == "critical"
 ]

 # Sprint candidates (next 2 weeks)
 sprint_capacity = 40 # Story points
 plan.next_sprint = self._fit_to_capacity(
 [p for p in prioritized if p.category in ("critical", "high")],
 sprint_capacity
 )

 # Quarterly roadmap
 plan.quarterly = self._plan_quarterly(prioritized)

 # Track improvements
 plan.expected_improvements = self._calculate_improvements(plan)

 return plan

 def _fit_to_capacity(
 self,
 items: list[PrioritizedDebt],
 capacity: int
 ) -> list[PrioritizedDebt]:
 """Fit items into sprint capacity."""

 selected = []
 remaining_capacity = capacity

 for item in items:
 if item.item.estimated_effort <= remaining_capacity:
 selected.append(item)
 remaining_capacity -= item.item.estimated_effort

 return selected

class TechDebtScanner:
 """Scanner for various tech debt indicators."""

 async def scan_code_smells(
 self,
 rules: list[str]
 ) -> list[dict]:
 """Detect code smells."""

 findings = []

 for rule in rules:
 if rule == "long_method":
 findings.extend(await self._find_long_methods())
 elif rule == "large_class":
 findings.extend(await self._find_large_classes())
 elif rule == "god_object":
 findings.extend(await self._find_god_objects())
 elif rule == "shotgun_surgery":
 findings.extend(await self._find_shotgun_surgery())

 return findings

 async def _find_god_objects(self) -> list[dict]:
 """Find god objects (classes that do too much)."""

 # Use AST analysis
 findings = []

 for file in self._get_source_files():
 classes = await self._parse_classes(file)

 for cls in classes:
 # God object indicators
 indicators = {
 "method_count": len(cls.methods),
 "dependency_count": len(cls.dependencies),
 "loc": cls.lines_of_code,
 "responsibility_count": self._estimate_responsibilities(cls)
 }

 if (indicators["method_count"] > 20 or
 indicators["dependency_count"] > 10 or
 indicators["responsibility_count"] > 3):
 findings.append({
 "type": "god_object",
 "file": file,
 "class": cls.name,
 "indicators": indicators,
 "suggestion": f"Consider splitting {cls.name} into smaller, focused classes"
 })

 return findings`
```

---

### Report Format

 markdown
 Copy

`# Technical Debt Report

**Generated**: 2024-01-15
**Scan Coverage**: 1,234 files analyzed
**Total Debt Items**: 156

## Executive Summary

| Category | Count | Estimated Effort |
|----------|-------|------------------|
| Critical | 8 | 45 hours |
| High | 23 | 120 hours |
| Medium | 67 | 280 hours |
| Low | 58 | 200 hours |

**Total Estimated Effort**: 645 hours (~16 weeks)

### Key Findings

1. **Security vulnerabilities** in 3 dependencies require immediate attention
2. **Payment module** has highest complexity debt (affects roadmap priority)
3. **Test coverage** below threshold in 12 modules

---

## Quick Wins (High Impact, Low Effort)

### 1. Update vulnerable dependency: lodash
**Effort**: 1 hour | **Impact Score**: 0.95

Current: 4.17.15 â†’ Latest: 4.17.21
- Fixes prototype pollution vulnerability (CVE-2021-23337)
- No breaking changes`
```

npm update lodash

 text
 Copy

`### 2. Extract duplicated validation logic
**Effort**: 2 hours | **Impact Score**: 0.82

Found in:
- `src/api/users.ts:45`
- `src/api/payments.ts:67`
- `src/api/orders.ts:89`

Suggested: Create `src/utils/validation.ts`

---

## Critical Items

### CRIT-1: SQL Injection Vulnerability
**Location**: `src/db/queries.ts:123`
**Severity**: Critical
**Bug Correlation**: 0 (not yet exploited)

Raw SQL string concatenation detected. Must use parameterized queries.

**Current Code**:`
```

const query = `SELECT * FROM users WHERE id = '${userId}'`;

 text
 Copy

`**Remediation**:`
```

const query = 'SELECT * FROM users WHERE id = $1';

await db.query(query, [userId]);

 text
 Copy

`---

## Sprint Recommendations

### Next Sprint (40 points capacity)

| Item | Points | Score | Category |
|------|--------|-------|----------|
| CRIT-1: SQL Injection | 2 | 0.98 | Critical |
| CRIT-2: Auth bypass | 4 | 0.95 | Critical |
| HIGH-1: Payment complexity | 8 | 0.85 | High |
| HIGH-2: Duplicate handlers | 4 | 0.78 | High |

**Total**: 18 points (45% capacity)

**Remaining capacity** for feature work or additional debt.

---

## Quarterly Roadmap

### Q1 Focus: Security & Stability
- All critical security items
- Payment module refactoring
- Test coverage improvement

### Q2 Focus: Architecture
- Dependency cycle resolution
- Dead code removal
- Documentation updates

---

## Trends

### Debt Accumulation (6 months)`
```

Jan: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 89 items

Feb: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 102 items

Mar: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 118 items

Apr: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 134 items

May: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 145 items

Jun: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 156 items

 text
 Copy

`**Trend**: +12% monthly accumulation
**Recommendation**: Allocate 20% sprint capacity to debt reduction

---

## Appendix

### Methodology
- Complexity: Cyclomatic + Cognitive complexity analysis
- Duplication: Token-based detection (min 50 tokens)
- Impact: Weighted score based on bugs, changes, team pain

### Configuration Used
- Complexity threshold: Cyclomatic > 10, Cognitive > 15
- Coverage threshold: 80%
- Lookback period: 180 days for correlation analysis`
```

---

### Configuration Options

 | 
 
 | Option | Type | Default | Description

 | `scan.code.complexity.threshold.*` | int | varies | Complexity thresholds
 
 | `scan.code.duplication.min_tokens` | int | 50 | Min duplication size
 
 | `impact.sources.jira.lookback` | string | "180d" | Bug correlation period
 
 | `prioritization.weights.*` | float | varies | Scoring weights

---

### Dependencies

#### Required Tools

- `tool-tech-debt-scanner` - Code analysis
 
- `tool-dependency-graph` - Dependency analysis
 
- `tool-git-advanced` - Change history
 
#### Optional

- `tool-jira-ops` - Bug correlation
 
- `tool-pr-context` - Review time analysis
 
---

### Open Questions

- Baseline tracking: Track debt trends over time?
 
- Team allocation: Suggest who should work on what?
 
- Automated fixing: Auto-remediate simple issues?
 
- CI integration: Block PRs that increase debt?
 
---

### Changelog

 | 
 
 | Version | Date | Changes

 | 0.1.0 | Draft | Initial specification

âš ï¸ Guidelines, Not Commitments: This roadmap is subject to change based on new information, priorities, and discoveries.

### Project Status

Amplifier is an experimental platform focused on discovering what's possible when AI partnership amplifies human capability. We're building a system that makes AI assistants dramatically more effective.

### Current Focus Areas

 ðŸ”§ Building Amplifier with Amplifier
 
Using Amplifier to improve and extend Amplifier. Building new capabilities, improving existing features, and climbing the ladder of metacognitive recipes.

 ðŸŒŸ Discovering Emergent Value
 
Recognizing and amplifying use-cases that emerge from the system. Surfacing emergent uses, especially those extending beyond code development.

### Exploration Directions

 | 
 
 | Area | Description

 | Orchestration Strategies
 | Specialized orchestrators tailored to specific workflows, optimization goals, or interaction patterns.

 | Collections & Workflows
 | Collections for new domains, workflows, or ways of organizing reusable knowledge and patterns.

 | Metacognitive Recipes
 | Structured workflows mixing tasks with higher-level philosophy, decision-making rationale, and problem-solving.

 | Context & Memory
 | Richer approaches to memory, knowledge synthesis, session learning, and team context sharing.

 | Learning from Sessions
 | Tools to parse session data, reconstruct logs, and analyze patterns for system improvement.

### Naming Conventions

When creating your own repositories:

- Applications: `amplifier-app-{name}`
 
- Modules: `amplifier-module-{type}-{name}`
 
- Collections: `amplifier-collection-{name}`

### Security Warning

âš ï¸ Critical: Modules and applications execute arbitrary code with full system access. Users must review code before installation. Build with security in mind.

============================================================
END OF DOCUMENTATION
Generated: 2025-12-11T14:41:12.234Z
Source: https://michaeljabbour.github.io/amplifier-dx/
